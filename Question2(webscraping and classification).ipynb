{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de3d7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "text = get_text()\n",
    "# the function will process the text present on the given URL.\n",
    "def get_text():\n",
    "    url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "    # gets the html data from by requesting the url\n",
    "    source_code = requests.get(url)\n",
    "    plain_text = source_code.text\n",
    "    # it will parse the html document to get tag or required data.\n",
    "    soup = BeautifulSoup(plain_text, \"html.parser\")\n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags and links\n",
    "        data.decompose()\n",
    "    return ' '.join(soup.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca4a5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing - Wikipedia Natural language processing From Wikipedia, the free encyclopedia Jump to navigation Jump to search This article is about natural language processing done by computers. For the natural language processing done by the human brain, see Language processing in the brain . Field of computer science and linguistics An automated online assistant providing customer service on a web page, an example of an application where natural language processing is a major component. [1] Natural language processing ( NLP ) is a subfield of linguistics , computer science , and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.  The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition , natural language understanding , and natural language generation . Contents 1 History 1.1 Symbolic NLP (1950s – early 1990s) 1.2 Statistical NLP (1990s–2010s) 1.3 Neural NLP (present) 2 Methods: Rules, statistics, neural networks 2.1 Statistical methods 2.2 Neural networks 3 Common NLP tasks 3.1 Text and speech processing 3.2 Morphological analysis 3.3 Syntactic analysis 3.4 Lexical semantics (of individual words in context) 3.5 Relational semantics (semantics of individual sentences) 3.6 Discourse (semantics beyond individual sentences) 3.7 Higher-level NLP applications 4 General tendencies and (possible) future directions 4.1 Cognition and NLP 5 See also 6 References 7 Further reading 8 External link History [ edit ] Further information: History of natural language processing Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \" Computing Machinery and Intelligence \" which proposed what is now called the Turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence. Symbolic NLP (1950s – early 1990s) [ edit ] The premise of symbolic NLP is well-summarized by John Searle 's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it is confronted with. 1950s : The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. [2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.  Little further research in machine translation was conducted until the late 1980s when the first statistical machine translation systems were developed. 1960s : Some notably successful natural language processing systems developed in the 1960s were SHRDLU , a natural language system working in restricted \" blocks worlds \" with restricted vocabularies, and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 and 1966.  Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". 1970s : During the 1970s, many programmers began to write \"conceptual ontologies \", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, the first many chatterbots were written (e.g., PARRY ). 1980s : The 1980s and early 1990s mark the hey-day of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar ), morphology (e.g., two-level morphology [3] ), semantics (e.g., Lesk algorithm ), reference (e.g., within Centering Theory [4] ) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory ). Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky . An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period. [5] Statistical NLP (1990s–2010s) [ edit ] Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law ) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar ), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. [6] 1990s : Many of the notable early successes on statistical methods in NLP occurred in the field of machine translation , due especially to work at IBM Research.  These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data. 2000s : With the growth of the web, increasing amounts of raw (unannotated) language data has become available since the mid-1990s. Research has thus increasingly focused on unsupervised and semi-supervised learning algorithms.  Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data.  Generally, this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data.  However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web ), which can often make up for the inferior results if the algorithm used has a low enough time complexity to be practical. Neural NLP (present) [ edit ] In the 2010s, representation learning and deep neural network -style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques [7] [8] can achieve state-of-the-art results in many natural language tasks, for example in language modeling, [9] parsing, [10] [11] and many others. This is increasingly important in medicine and healthcare, where NLP is being used to analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care. [12] Methods: Rules, statistics, neural networks [ edit ] In the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup: [13] [14] such as by writing grammars or devising heuristic rules for stemming . More recent systems based on machine-learning algorithms have many advantages over hand-produced rules: The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not at all obvious where the effort should be directed. Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted). Generally, handling such input gracefully with handwritten rules, or, more generally, creating systems of handwritten rules that make soft decisions, is extremely difficult, error-prone and time-consuming. Systems based on automatically learning the rules can be made more accurate simply by supplying more input data. However, systems based on handwritten rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task. In particular, there is a limit to the complexity of systems based on handwritten rules, beyond which the systems become more and more unmanageable. However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process. Despite the popularity of machine learning in NLP research, symbolic methods are still (2020) commonly used: when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system, for preprocessing in NLP pipelines, e.g., tokenization , or for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses. Statistical methods [ edit ] Since the so-called \"statistical revolution\" [15] [16] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus , is a set of documents, possibly with human or computer annotations) of typical real-world examples. Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Increasingly, however, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to each input feature (complex-valued embeddings , [17] and neural networks in general have also been proposed, for e.g. speech [18] ). Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system. Some of the earliest-used machine learning algorithms, such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules.  However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks. Since the neural turn, statistical methods in NLP research have been largely replaced by neural networks. However, they continue to be relevant for contexts in which statistical interpretability and transparency is required. Neural networks [ edit ] Further information: Artificial neural network A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015, [19] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT). Latest works tend to use non-technical structure of a given task to build proper neural network. [20] Common NLP tasks [ edit ] The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks. Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below. Text and speech processing [ edit ] Optical character recognition (OCR) Given an image representing printed text, determine the corresponding text. Speech recognition Given a sound clip of a person or people speaking, determine the textual representation of the speech.  This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \" AI-complete \" (see above).  In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation , so the conversion of the analog signal to discrete characters can be a very difficult process. Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent. Speech segmentation Given a sound clip of a person or people speaking, separate it into words.  A subtask of speech recognition and typically grouped with it. Text-to-speech Given a text, transform those units and produce a spoken representation. Text-to-speech can be used to aid the visually impaired. [21] Word segmentation ( Tokenization ) Separate a chunk of continuous text into separate words. For a language like English , this is fairly trivial, since words are usually separated by spaces. However, some written languages like Chinese , Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language. Sometimes this process is also used in cases like bag of words (BOW) creation in data mining. Morphological analysis [ edit ] Lemmatization The task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form. [22] Morphological segmentation Separate words into individual morphemes and identify the class of the morphemes. The difficulty of this task depends greatly on the complexity of the morphology ( i.e. , the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology , and thus it is often possible to ignore this task entirely and simply model all possible forms of a word ( e.g. , \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei , [23] a highly agglutinated Indian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms. Part-of-speech tagging Given a sentence, determine the part of speech (POS) for each word. Many words, especially common ones, can serve as multiple parts of speech . For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun , verb or adjective ; and \"out\" can be any of at least five different parts of speech. Stemming The process of reducing inflected (or sometimes derived) words to a base form ( e.g. , \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary. Syntactic analysis [ edit ] Grammar induction [24] Generate a formal grammar that describes a language's syntax. Sentence breaking (also known as \" sentence boundary disambiguation \") Given a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by periods or other punctuation marks , but these same characters can serve other purposes ( e.g. , marking abbreviations ). Parsing Determine the parse tree (grammatical analysis) of a given sentence. The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing: dependency parsing and constituency parsing . Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar ). Lexical semantics (of individual words in context) [ edit ] Lexical semantics What is the computational meaning of individual words in context? Distributional semantics How can we learn semantic representations from data? Named entity recognition (NER) Given a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity , and in any case, is often inaccurate or insufficient.  For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.  Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic ) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns , regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives . Sentiment analysis (see also Multimodal sentiment analysis ) Extract subjective information usually from a set of documents, often using online reviews to determine \"polarity\" about specific objects. It is especially useful for identifying trends of public opinion in social media, for marketing. Terminology extraction The goal of terminology extraction is to automatically extract relevant terms from a given corpus. Word sense disambiguation (WSD) Many words have more than one meaning ; we have to select the meaning which makes the most sense in context.  For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or an online resource such as WordNet . Entity linking Many words - typically proper names - refer to named entities ; here we have to select the entity (a famous individual, a location, a company, etc.) which is referred to in context. Relational semantics (semantics of individual sentences) [ edit ] Relationship extraction Given a chunk of text, identify the relationships among named entities (e.g. who is married to whom). Semantic parsing Given a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing ) or in accordance with a logical formalism (e.g., in DRT parsing ). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below). Semantic role labelling (see also implicit semantic role labelling below) Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames ), then identify and classify the frame elements ( semantic roles ). Discourse (semantics beyond individual sentences) [ edit ] Coreference resolution Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\"). Anaphora resolution is a specific example of this task, and is specifically concerned with matching up pronouns with the nouns or names to which they refer. The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions . For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to). Discourse analysis This rubric includes several related tasks.  One task is discourse parsing, i.e., identifying the discourse structure of a connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast).  Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g. yes-no question, content question, statement, assertion, etc.). Implicit semantic role labelling Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames ) and their explicit semantic roles in the current sentence (see Semantic role labelling above). Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text. A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to pro-drop languages . Recognizing textual entailment Given two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false. [25] Topic segmentation and recognition Given a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment. Argument mining The goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs. [26] Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse. [27] [28] Higher-level NLP applications [ edit ] Automatic summarization (text summarization) Produce a readable summary of a chunk of text.  Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper. Book generation Not an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed ). [29] The first published work by a neural network was published in 2018, 1 the Road , marketed as a novel, contains sixty million words. Both these systems are basically elaborate but non-sensical (semantics-free) language models . The first machine-generated science book was published in 2019 (Beta Writer, Lithium-Ion Batteries , Springer, Cham). [30] Unlike Racter and 1 the Road , this is grounded on factual knowledge and based on text summarization. Dialogue management Computer systems intended to converse with a human. Document AI A Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types. NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants. [31] Grammatical error correction Grammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology/orthography, morphology, syntax, semantics, pragmatics). Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language. It has thus been subject to a number of shared tasks since 2011. [32] [33] [34] As far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2 , this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications. Machine translation Automatically translate text from one human language to another.  This is one of the most difficult problems, and is a member of a class of problems colloquially termed \" AI-complete \", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly. Natural language generation (NLG): Convert information from computer databases or semantic intents into readable human language. Natural language understanding (NLU) Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption , or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization. [35] Question answering Given a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\"). General tendencies and (possible) future directions [ edit ] Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed: [36] Interest on increasingly abstract, \"cognitive\" aspects of natural language (1999-2001: shallow parsing, 2002-03: named entity recognition, 2006-09/2017-18: dependency syntax, 2004-05/2008-09 semantic role labelling, 2011-12 coreference, 2015-16: discourse parsing, 2019: semantic parsing). Increasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+/100+ languages) Elimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems) Cognition and NLP [ edit ] Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above). Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\" [37] Cognitive science is the interdisciplinary, scientific study of the mind and its processes. [38] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics. [39] Especially during the age of symbolic NLP , the area of computational linguistics maintained strong ties with cognitive studies. As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science , along with the findings of cognitive linguistics , [40] with two defining aspects: Apply the theory of conceptual metaphor , explained by Lakoff as “the understanding of one idea, in terms of another” which provides an idea of the intent of the author. [41] For example, consider the English word “big” . When used in a comparison ( “That is a big tree” ), the author's intent is to imply that the tree is ”physically large” relative to other trees or the authors experience.  When used metaphorically ( ”Tomorrow is a big day” ), the author’s intent to imply ”importance” .  The intent behind other usages, like in ”She is a big person” will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information. Assign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a probabilistic context-free grammar (PCFG). The mathematical equation for such algorithms is presented in US patent 9269353 : R M M ( t o k e n N ) = P M M ( t o k e n N ) × 1 2 d ( ∑ i = − d d ( ( P M M ( t o k e n N − 1 ) × P F ( t o k e n N , t o k e n N − 1 ) ) i ) {\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N-1})}\\times {PF(token_{N},token_{N-1}))_{i}}\\right)} Where, RMM , is the Relative Measure of Meaning token , is any block of text, sentence, phrase or word N , is the number of tokens being analyzed PMM , is the Probable Measure of Meaning based on a corpora d , is the location of the token along the sequence of N-1 tokens PF , is the Probability Function specific to a language Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar, [42] functional grammar, [43] construction grammar, [44] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R ), however, with limited uptake in mainstream NLP (as measured by presence on major conferences [45] of the ACL ). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability , e.g., under the notion of \"cognitive AI\". [46] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit). [47] See also [ edit ] 1 the Road Automated essay scoring Biomedical text mining Compound term processing Computational linguistics Computer-assisted reviewing Controlled natural language Deep learning Deep linguistic processing Distributional semantics Foreign language reading aid Foreign language writing aid Information extraction Information retrieval Language and Communication Technologies Language technology Latent semantic indexing Native-language identification Natural language programming Natural language search Outline of natural language processing Query expansion Query understanding Reification (linguistics) Speech processing Spoken dialogue systems Text-proofing Text simplification Transformer (machine learning model) Truecasing Question answering Word2vec References [ edit ] ^ Kongthon, Alisa; Sangkeettrakarn, Chatchawal; Kongyoung, Sarawoot; Haruechaiyasak, Choochart (October 27–30, 2009). Implementing an online help desk system based on conversational agent . MEDES '09: The International Conference on Management of Emergent Digital EcoSystems. France: ACM. doi : 10.1145/1643823.1643908 . ^ Hutchins, J. (2005). \"The history of machine translation in a nutshell\" (PDF) . [ self-published source ] ^ Koskenniemi, Kimmo (1983), Two-level morphology: A general computational model of word-form recognition and production (PDF) , Department of General Linguistics, University of Helsinki ^ Joshi, A. K., & Weinstein, S. (1981, August). Control of Inference: Role of Some Aspects of Discourse Structure-Centering . In IJCAI (pp. 385-387). ^ Guida, G.; Mauri, G. (July 1986). \"Evaluation of natural language processing systems: Issues and approaches\". Proceedings of the IEEE . 74 (7): 1026–1035. doi : 10.1109/PROC.1986.13580 . ISSN 1558-2256 . S2CID 30688575 . ^ Chomskyan linguistics encourages the investigation of \" corner cases \" that stress the limits of its theoretical models (comparable to pathological phenomena in mathematics), typically created using thought experiments , rather than the systematic investigation of typical phenomena that occur in real-world data, as is the case in corpus linguistics .  The creation and use of such corpora of real-world data is a fundamental part of machine-learning algorithms for natural language processing.  In addition, theoretical underpinnings of Chomskyan linguistics such as the so-called \" poverty of the stimulus \" argument entail that general learning algorithms, as are typically used in machine learning, cannot be successful in language processing.  As a result, the Chomskyan paradigm discouraged the application of such models to language processing. ^ Goldberg, Yoav (2016). \"A Primer on Neural Network Models for Natural Language Processing\". Journal of Artificial Intelligence Research . 57 : 345–420. arXiv : 1807.10854 . doi : 10.1613/jair.4992 . S2CID 8273530 . ^ Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016). Deep Learning . MIT Press. ^ Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). Exploring the Limits of Language Modeling . arXiv : 1602.02410 . Bibcode : 2016arXiv160202410J . ^ Choe, Do Kook; Charniak, Eugene. \"Parsing as Language Modeling\" . Emnlp 2016 . ^ Vinyals, Oriol;  et al. (2014). \"Grammar as a Foreign Language\" (PDF) . Nips2015 . arXiv : 1412.7449 . Bibcode : 2014arXiv1412.7449V . ^ Turchin, Alexander; Florez Builes, Luisa F. (2021-03-19). \"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\" . Journal of Diabetes Science and Technology . 15 (3): 553–560. doi : 10.1177/19322968211000831 . ISSN 1932-2968 . PMC 8120048. PMID 33736486 . ^ Winograd, Terry (1971). Procedures as a Representation for Data in a Computer Program for Understanding Natural Language (Thesis). ^ Schank, Roger C.; Abelson, Robert P. (1977). Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures . Hillsdale: Erlbaum. ISBN 0-470-99033-3 . ^ Mark Johnson. How the statistical revolution changes (computational) linguistics. Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics. ^ Philip Resnik. Four revolutions. Language Log, February 5, 2011. ^ \"Investigating complex-valued representation in NLP\" (PDF) . ^ Trabelsi, Chiheb; Bilaniuk, Olexa; Zhang, Ying; Serdyuk, Dmitriy; Subramanian, Sandeep; Santos, João Felipe; Mehri, Soroush; Rostamzadeh, Negar; Bengio, Yoshua; Pal, Christopher J. (2018-02-25). \"Deep Complex Networks\". arXiv : 1705.09792 [ cs.NE ]. ^ Socher, Richard. \"Deep Learning For NLP-ACL 2012 Tutorial\" . www.socher.org . Retrieved 2020-08-17 . This was an early Deep Learning tutorial at the ACL 2012 and met with both interest and (at the time) skepticism by most participants. Until then, neural learning was basically rejected because of its lack of statistical interpretability. Until 2015, deep learning had evolved into the major framework of NLP. ^ Annamoradnejad, I. and Zoghi, G. (2020). Colbert: Using bert sentence embedding for humor detection . arXiv preprint arXiv:2004.12765. ^ Yi, Chucai; Tian, Yingli (2012), \"Assistive Text Reading from Complex Background for Blind Persons\", Camera-Based Document Analysis and Recognition , Springer Berlin Heidelberg, pp. 15–28, CiteSeerX 10.1.1.668.869 , doi : 10.1007/978-3-642-29364-1_2 , ISBN 9783642293634 ^ \"What is Natural Language Processing? Intro to NLP in Machine Learning\" . GyanSetu! . 2020-12-06 . Retrieved 2021-01-09 . ^ Kishorjit, N.; Vidya, Raj RK.; Nirmal, Y.; Sivaji, B. (2012). \"Manipuri Morpheme Identification\" (PDF) . Proceedings of the 3rd Workshop on South and Southeast Asian Natural Language Processing (SANLP) . COLING 2012, Mumbai, December 2012: 95–108. CS1 maint: location ( link ) ^ Klein, Dan; Manning, Christopher D. (2002). \"Natural language grammar induction using a constituent-context model\" (PDF) . Advances in Neural Information Processing Systems . ^ PASCAL Recognizing Textual Entailment Challenge (RTE-7) https://tac.nist.gov//2011/RTE/ ^ Lippi, Marco; Torroni, Paolo (2016-04-20). \"Argumentation Mining: State of the Art and Emerging Trends\" . ACM Transactions on Internet Technology . 16 (2): 1–25. doi : 10.1145/2850417 . ISSN 1533-5399 . S2CID 9561587 . ^ \"Argument Mining - IJCAI2016 Tutorial\" . www.i3s.unice.fr . Retrieved 2021-03-09 . ^ \"NLP Approaches to Computational Argumentation – ACL 2016, Berlin\" . Retrieved 2021-03-09 . ^ \"U B U W E B :: Racter\" . www.ubu.com . Retrieved 2020-08-17 . ^ Writer, Beta (2019). Lithium-Ion Batteries . doi : 10.1007/978-3-030-16800-1 . ISBN 978-3-030-16799-8 . ^ \"Document Understanding AI on Google Cloud (Cloud Next '19) - YouTube\" . www.youtube.com . Retrieved 2021-01-11 . ^ Administration. \"Centre for Language Technology (CLT)\" . Macquarie University . Retrieved 2021-01-11 . ^ \"Shared Task: Grammatical Error Correction\" . www.comp.nus.edu.sg . Retrieved 2021-01-11 . ^ \"Shared Task: Grammatical Error Correction\" . www.comp.nus.edu.sg . Retrieved 2021-01-11 . ^ Duan, Yucong; Cruz, Christophe (2011). \"Formalizing Semantic of Natural Language through Conceptualization from Existence\" . International Journal of Innovation, Management and Technology . 2 (1): 37–42. Archived from the original on 2011-10-09. ^ \"Previous shared tasks | CoNLL\" . www.conll.org . Retrieved 2021-01-11 . ^ \"Cognition\" . Lexico . Oxford University Press and Dictionary.com . Retrieved 6 May 2020 . ^ \"Ask the Cognitive Scientist\" . American Federation of Teachers . 8 August 2014. Cognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind. ^ Robinson, Peter (2008). Handbook of Cognitive Linguistics and Second Language Acquisition . Routledge. pp. 3–8. ISBN 978-0-805-85352-0 . ^ Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm . New York Basic Books. pp. 569–583. ISBN 978-0-465-05674-3 . ^ Strauss, Claudia (1999). A Cognitive Theory of Cultural Meaning . Cambridge University Press. pp. 156–164. ISBN 978-0-521-59541-4 . ^ \"Universal Conceptual Cognitive Annotation (UCCA)\" . Universal Conceptual Cognitive Annotation (UCCA) . Retrieved 2021-01-11 . ^ Rodríguez, F. C., & Mairal-Usón, R. (2016). Building an RRG computational grammar . Onomazein , (34), 86-117. ^ \"Fluid Construction Grammar – A fully operational processing system for construction grammars\" . Retrieved 2021-01-11 . ^ \"ACL Member Portal | The Association for Computational Linguistics Member Portal\" . www.aclweb.org . Retrieved 2021-01-11 . ^ \"Chunks and Rules\" . www.w3.org . Retrieved 2021-01-11 . ^ Socher, Richard; Karpathy, Andrej; Le, Quoc V.; Manning, Christopher D.; Ng, Andrew Y. (2014). \"Grounded Compositional Semantics for Finding and Describing Images with Sentences\" . Transactions of the Association for Computational Linguistics . 2 : 207–218. doi : 10.1162/tacl_a_00177 . S2CID 2317858 . Further reading [ edit ] Bates, M (1995). \"Models of natural language understanding\" . Proceedings of the National Academy of Sciences of the United States of America . 92 (22): 9977–9982. Bibcode : 1995PNAS...92.9977B . doi : 10.1073/pnas.92.22.9977 . PMC 40721 . PMID 7479812 . Steven Bird, Ewan Klein, and Edward Loper (2009). Natural Language Processing with Python . O'Reilly Media. ISBN 978-0-596-51649-9 . Daniel Jurafsky and James H. Martin (2008). Speech and Language Processing , 2nd edition. Pearson Prentice Hall. ISBN 978-0-13-187321-6 . Mohamed Zakaria Kurdi (2016). Natural Language Processing and Computational Linguistics: speech, morphology, and syntax , Volume 1. ISTE-Wiley. ISBN 978-1848218482 . Mohamed Zakaria Kurdi (2017). Natural Language Processing and Computational Linguistics: semantics, discourse, and applications , Volume 2. ISTE-Wiley. ISBN 978-1848219212 . Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008). Introduction to Information Retrieval . Cambridge University Press. ISBN 978-0-521-86571-5 . Official html and pdf versions available without charge. Christopher D. Manning and Hinrich Schütze (1999). Foundations of Statistical Natural Language Processing . The MIT Press. ISBN 978-0-262-13360-9 . David M. W. Powers and Christopher C. R. Turk (1989). Machine Learning of Natural Language . Springer-Verlag. ISBN 978-0-387-19557-5 . External link [ edit ] Media related to Natural language processing at Wikimedia Commons v t e Natural language processing General terms AI-complete Bag-of-words n-gram Bigram Trigram Computational linguistics Natural-language understanding Stopwords Text processing Text analysis Collocation extraction Concept mining Coreference resolution Deep linguistic processing Distant reading Information extraction Named-entity recognition Ontology learning Parsing Part-of-speech tagging Semantic role labeling Semantic similarity Sentiment analysis Terminology extraction Text mining Textual entailment Truecasing Word-sense disambiguation Word-sense induction Text segmentation Compound-term processing Lemmatisation Lexical analysis Text chunking Stemming Sentence segmentation Word segmentation Automatic summarization Multi-document summarization Sentence extraction Text simplification Machine translation Computer-assisted Example-based Rule-based Statistical Transfer-based Neural Distributional semantics models BERT Document-term matrix Explicit semantic analysis fastText GloVe Latent semantic analysis Word embedding Word2vec Language resources , datasets and corpora Types and standards Corpus linguistics Lexical resource Linguistic Linked Open Data Machine-readable dictionary Parallel text PropBank Semantic network Simple Knowledge Organization System Speech corpus Text corpus Thesaurus (information retrieval) Treebank Universal Dependencies Data BabelNet Bank of English DBpedia FrameNet Google Ngram Viewer ThoughtTreasure UBY WordNet Automatic identification and data capture Speech recognition Speech segmentation Speech synthesis Natural language generation Optical character recognition Topic model Document classification Latent Dirichlet allocation Pachinko allocation Computer-assisted reviewing Automated essay scoring Concordancer Grammar checker Predictive text Spell checker Syntax guessing Natural language user interface Chatbot Interactive fiction Question answering Virtual assistant Voice user interface Other software Natural Language Toolkit spaCy Authority control: National libraries United States Japan Language portal Retrieved from \" https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1048621730 \" Categories : Natural language processing Computational linguistics Speech recognition Computational fields of study Artificial intelligence Hidden categories: CS1 maint: location Articles with short description Short description matches Wikidata Commons category link from Wikidata Articles with LCCN identifiers Articles with NDL identifiers Navigation menu Personal tools Not logged in Talk Contributions Create account Log in Namespaces Article Talk Variants expanded collapsed Views Read Edit View history More expanded collapsed Search Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Upload file Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Languages Afrikaans العربية Azərbaycanca বাংলা Bân-lâm-gú Беларуская Беларуская (тарашкевіца) Български Català Čeština Dansk Deutsch Eesti Ελληνικά Español Euskara فارسی Français Galego 한국어 Հայերեն हिन्दी Hrvatski Bahasa Indonesia Íslenska Italiano עברית ಕನ್ನಡ ქართული Lietuvių Македонски मराठी مصرى Монгол မြန်မာဘာသာ 日本語 ଓଡ଼ିଆ Piemontèis Polski Português Română Русский Simple English کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi தமிழ் ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links This page was last edited on 7 October 2021, at 01:56 (UTC) . Text is available under the Creative Commons Attribution-ShareAlike License ;\n",
      "additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc. , a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Mobile view Developers Statistics Cookie statement\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc9268",
   "metadata": {},
   "source": [
    "# SENTENCE TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c081230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the funtion will break the complete text into sentences\n",
    "def get_sentence(text):\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    # used the sentence tokenization to divide it into the data\n",
    "    s_tokens = sent_tokenize(text)\n",
    "    ncount = 0\n",
    "    for i in s_tokens:\n",
    "        ncount += 1\n",
    "    print(ncount)\n",
    "    print(\"Sentences\")\n",
    "    # all the sentences are collected into a list and returning it.\n",
    "    return s_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b5dfd",
   "metadata": {},
   "source": [
    "# WORD TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06359be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function will divide the sentence into words and returns it.\n",
    "def get_words(text):\n",
    "    # imported the word tokennizer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    # breaks entire data into words.\n",
    "    w_tokens = word_tokenize(text)\n",
    "    ncount = 0;\n",
    "    for i in w_tokens:\n",
    "        ncount += 1\n",
    "    print(ncount)\n",
    "    print(\"words\")\n",
    "    # return the collection of words.\n",
    "    return w_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cf766",
   "metadata": {},
   "source": [
    "# Parts of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b75d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function will assign the parts of speech to the words collections and returns them\n",
    "def pos_tagging(words):\n",
    "    # used the pos_tag to break assign the parts of speech to each word\n",
    "    postag_words = nltk.pos_tag(words)\n",
    "    return postag_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b518d5",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9ac21ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function does the stemming for each word it converts \"organized\" to \"organize\"\n",
    "def perform_stemming(words):\n",
    "    from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "    # imported the porterstemmer from nltk and using it\n",
    "    pstemmer = PorterStemmer()\n",
    "    stemmed_list = [];\n",
    "    for i in words:\n",
    "        # iterating through the collection and applying the stemming to the each word.\n",
    "        stemmed_list.append(pstemmer.stem(i))\n",
    "        # print(i +\"-------->\" + pstemmer.stem(i))\n",
    "    return stemmed_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b691027",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69048025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function will perform the lemmatization based on the context\n",
    "def perform_lemmatization(words):\n",
    "    # imported the WordNetLemmatizer from nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_list = [];\n",
    "    for i in words:\n",
    "        # apply the lemmatizer for each word.\n",
    "        lemmatized_list.append(lemmatizer.lemmatize(i))\n",
    "        # print(i +\"-------->\" + lemmatizer.lemmatize(i))\n",
    "    # returning the lemmatized words collection.\n",
    "    return lemmatized_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83bd8f",
   "metadata": {},
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f5f3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below function will identify the names and location and categorize the data and return the result\n",
    "def perform_NER(text):\n",
    "    from nltk import wordpunct_tokenize, pos_tag, ne_chunk\n",
    "    nltk.download('maxent_ne_chunker')\n",
    "    nltk.download('words')\n",
    "    # applied nechunk for name entity recognition\n",
    "    result = ne_chunk(pos_tag(wordpunct_tokenize(text)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fac714",
   "metadata": {},
   "source": [
    "# Trigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3039c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigram(text):\n",
    "    from nltk.util import ngrams\n",
    "    # spliited entire data into words and created the trigram of size 3 using ngrams.\n",
    "    n_grams = ngrams(text.split(), 3)\n",
    "    return n_grams;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aaa60ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "Sentences\n",
      "Natural language processing - Wikipedia Natural language processing From Wikipedia, the free encyclopedia Jump to navigation Jump to search This article is about natural language processing done by computers.\n",
      "For the natural language processing done by the human brain, see Language processing in the brain .\n",
      "Field of computer science and linguistics An automated online assistant providing customer service on a web page, an example of an application where natural language processing is a major component.\n",
      "[1] Natural language processing ( NLP ) is a subfield of linguistics , computer science , and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.\n",
      "The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
      "Challenges in natural language processing frequently involve speech recognition , natural language understanding , and natural language generation .\n",
      "Contents 1 History 1.1 Symbolic NLP (1950s – early 1990s) 1.2 Statistical NLP (1990s–2010s) 1.3 Neural NLP (present) 2 Methods: Rules, statistics, neural networks 2.1 Statistical methods 2.2 Neural networks 3 Common NLP tasks 3.1 Text and speech processing 3.2 Morphological analysis 3.3 Syntactic analysis 3.4 Lexical semantics (of individual words in context) 3.5 Relational semantics (semantics of individual sentences) 3.6 Discourse (semantics beyond individual sentences) 3.7 Higher-level NLP applications 4 General tendencies and (possible) future directions 4.1 Cognition and NLP 5 See also 6 References 7 Further reading 8 External link History [ edit ] Further information: History of natural language processing Natural language processing has its roots in the 1950s.\n",
      "Already in 1950, Alan Turing published an article titled \" Computing Machinery and Intelligence \" which proposed what is now called the Turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.\n",
      "Symbolic NLP (1950s – early 1990s) [ edit ] The premise of symbolic NLP is well-summarized by John Searle 's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it is confronted with.\n",
      "1950s : The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English.\n",
      "The authors claimed that within three or five years, machine translation would be a solved problem.\n",
      "[2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.\n",
      "Little further research in machine translation was conducted until the late 1980s when the first statistical machine translation systems were developed.\n",
      "1960s : Some notably successful natural language processing systems developed in the 1960s were SHRDLU , a natural language system working in restricted \" blocks worlds \" with restricted vocabularies, and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 and 1966.\n",
      "Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction.\n",
      "When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\n",
      "1970s : During the 1970s, many programmers began to write \"conceptual ontologies \", which structured real-world information into computer-understandable data.\n",
      "Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).\n",
      "During this time, the first many chatterbots were written (e.g., PARRY ).\n",
      "1980s : The 1980s and early 1990s mark the hey-day of symbolic methods in NLP.\n",
      "Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar ), morphology (e.g., two-level morphology [3] ), semantics (e.g., Lesk algorithm ), reference (e.g., within Centering Theory [4] ) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory ).\n",
      "Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky .\n",
      "An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.\n",
      "[5] Statistical NLP (1990s–2010s) [ edit ] Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.\n",
      "Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.\n",
      "This was due to both the steady increase in computational power (see Moore's law ) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g.\n",
      "transformational grammar ), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.\n",
      "[6] 1990s : Many of the notable early successes on statistical methods in NLP occurred in the field of machine translation , due especially to work at IBM Research.\n",
      "These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.\n",
      "However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems.\n",
      "As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n",
      "2000s : With the growth of the web, increasing amounts of raw (unannotated) language data has become available since the mid-1990s.\n",
      "Research has thus increasingly focused on unsupervised and semi-supervised learning algorithms.\n",
      "Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data.\n",
      "Generally, this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data.\n",
      "However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web ), which can often make up for the inferior results if the algorithm used has a low enough time complexity to be practical.\n",
      "Neural NLP (present) [ edit ] In the 2010s, representation learning and deep neural network -style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques [7] [8] can achieve state-of-the-art results in many natural language tasks, for example in language modeling, [9] parsing, [10] [11] and many others.\n",
      "This is increasingly important in medicine and healthcare, where NLP is being used to analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care.\n",
      "[12] Methods: Rules, statistics, neural networks [ edit ] In the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup: [13] [14] such as by writing grammars or devising heuristic rules for stemming .\n",
      "More recent systems based on machine-learning algorithms have many advantages over hand-produced rules: The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not at all obvious where the effort should be directed.\n",
      "Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g.\n",
      "containing words or structures that have not been seen before) and to erroneous input (e.g.\n",
      "with misspelled words or words accidentally omitted).\n",
      "Generally, handling such input gracefully with handwritten rules, or, more generally, creating systems of handwritten rules that make soft decisions, is extremely difficult, error-prone and time-consuming.\n",
      "Systems based on automatically learning the rules can be made more accurate simply by supplying more input data.\n",
      "However, systems based on handwritten rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task.\n",
      "In particular, there is a limit to the complexity of systems based on handwritten rules, beyond which the systems become more and more unmanageable.\n",
      "However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process.\n",
      "Despite the popularity of machine learning in NLP research, symbolic methods are still (2020) commonly used: when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system, for preprocessing in NLP pipelines, e.g., tokenization , or for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.\n",
      "Statistical methods [ edit ] Since the so-called \"statistical revolution\" [15] [16] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning.\n",
      "The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus , is a set of documents, possibly with human or computer annotations) of typical real-world examples.\n",
      "Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks.\n",
      "These algorithms take as input a large set of \"features\" that are generated from the input data.\n",
      "Increasingly, however, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to each input feature (complex-valued embeddings , [17] and neural networks in general have also been proposed, for e.g.\n",
      "speech [18] ).\n",
      "Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\n",
      "Some of the earliest-used machine learning algorithms, such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules.\n",
      "However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.\n",
      "The cache language models upon which many speech recognition systems now rely are examples of such statistical models.\n",
      "Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\n",
      "Since the neural turn, statistical methods in NLP research have been largely replaced by neural networks.\n",
      "However, they continue to be relevant for contexts in which statistical interpretability and transparency is required.\n",
      "Neural networks [ edit ] Further information: Artificial neural network A major drawback of statistical methods is that they require elaborate feature engineering.\n",
      "Since 2015, [19] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning.\n",
      "Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing).\n",
      "In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing.\n",
      "For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT).\n",
      "Latest works tend to use non-technical structure of a given task to build proper neural network.\n",
      "[20] Common NLP tasks [ edit ] The following is a list of some of the most commonly researched tasks in natural language processing.\n",
      "Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n",
      "Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience.\n",
      "A coarse division is given below.\n",
      "Text and speech processing [ edit ] Optical character recognition (OCR) Given an image representing printed text, determine the corresponding text.\n",
      "Speech recognition Given a sound clip of a person or people speaking, determine the textual representation of the speech.\n",
      "This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \" AI-complete \" (see above).\n",
      "In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below).\n",
      "In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation , so the conversion of the analog signal to discrete characters can be a very difficult process.\n",
      "Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent.\n",
      "Speech segmentation Given a sound clip of a person or people speaking, separate it into words.\n",
      "A subtask of speech recognition and typically grouped with it.\n",
      "Text-to-speech Given a text, transform those units and produce a spoken representation.\n",
      "Text-to-speech can be used to aid the visually impaired.\n",
      "[21] Word segmentation ( Tokenization ) Separate a chunk of continuous text into separate words.\n",
      "For a language like English , this is fairly trivial, since words are usually separated by spaces.\n",
      "However, some written languages like Chinese , Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language.\n",
      "Sometimes this process is also used in cases like bag of words (BOW) creation in data mining.\n",
      "Morphological analysis [ edit ] Lemmatization The task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma.\n",
      "Lemmatization is another technique for reducing words to their normalized form.\n",
      "But in this case, the transformation actually uses a dictionary to map words to their actual form.\n",
      "[22] Morphological segmentation Separate words into individual morphemes and identify the class of the morphemes.\n",
      "The difficulty of this task depends greatly on the complexity of the morphology ( i.e.\n",
      ", the structure of words) of the language being considered.\n",
      "English has fairly simple morphology, especially inflectional morphology , and thus it is often possible to ignore this task entirely and simply model all possible forms of a word ( e.g.\n",
      ", \"open, opens, opened, opening\") as separate words.\n",
      "In languages such as Turkish or Meitei , [23] a highly agglutinated Indian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.\n",
      "Part-of-speech tagging Given a sentence, determine the part of speech (POS) for each word.\n",
      "Many words, especially common ones, can serve as multiple parts of speech .\n",
      "For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun , verb or adjective ; and \"out\" can be any of at least five different parts of speech.\n",
      "Stemming The process of reducing inflected (or sometimes derived) words to a base form ( e.g.\n",
      ", \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.).\n",
      "Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.\n",
      "Syntactic analysis [ edit ] Grammar induction [24] Generate a formal grammar that describes a language's syntax.\n",
      "Sentence breaking (also known as \" sentence boundary disambiguation \") Given a chunk of text, find the sentence boundaries.\n",
      "Sentence boundaries are often marked by periods or other punctuation marks , but these same characters can serve other purposes ( e.g.\n",
      ", marking abbreviations ).\n",
      "Parsing Determine the parse tree (grammatical analysis) of a given sentence.\n",
      "The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human).\n",
      "There are two primary types of parsing: dependency parsing and constituency parsing .\n",
      "Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar ).\n",
      "Lexical semantics (of individual words in context) [ edit ] Lexical semantics What is the computational meaning of individual words in context?\n",
      "Distributional semantics How can we learn semantic representations from data?\n",
      "Named entity recognition (NER) Given a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g.\n",
      "person, location, organization).\n",
      "Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity , and in any case, is often inaccurate or insufficient.\n",
      "For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.\n",
      "Furthermore, many other languages in non-Western scripts (e.g.\n",
      "Chinese or Arabic ) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names.\n",
      "For example, German capitalizes all nouns , regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives .\n",
      "Sentiment analysis (see also Multimodal sentiment analysis ) Extract subjective information usually from a set of documents, often using online reviews to determine \"polarity\" about specific objects.\n",
      "It is especially useful for identifying trends of public opinion in social media, for marketing.\n",
      "Terminology extraction The goal of terminology extraction is to automatically extract relevant terms from a given corpus.\n",
      "Word sense disambiguation (WSD) Many words have more than one meaning ; we have to select the meaning which makes the most sense in context.\n",
      "For this problem, we are typically given a list of words and associated word senses, e.g.\n",
      "from a dictionary or an online resource such as WordNet .\n",
      "Entity linking Many words - typically proper names - refer to named entities ; here we have to select the entity (a famous individual, a location, a company, etc.)\n",
      "which is referred to in context.\n",
      "Relational semantics (semantics of individual sentences) [ edit ] Relationship extraction Given a chunk of text, identify the relationships among named entities (e.g.\n",
      "who is married to whom).\n",
      "Semantic parsing Given a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing ) or in accordance with a logical formalism (e.g., in DRT parsing ).\n",
      "This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below).\n",
      "Semantic role labelling (see also implicit semantic role labelling below) Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames ), then identify and classify the frame elements ( semantic roles ).\n",
      "Discourse (semantics beyond individual sentences) [ edit ] Coreference resolution Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\").\n",
      "Anaphora resolution is a specific example of this task, and is specifically concerned with matching up pronouns with the nouns or names to which they refer.\n",
      "The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions .\n",
      "For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\n",
      "Discourse analysis This rubric includes several related tasks.\n",
      "One task is discourse parsing, i.e., identifying the discourse structure of a connected text, i.e.\n",
      "the nature of the discourse relationships between sentences (e.g.\n",
      "elaboration, explanation, contrast).\n",
      "Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g.\n",
      "yes-no question, content question, statement, assertion, etc.).\n",
      "Implicit semantic role labelling Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames ) and their explicit semantic roles in the current sentence (see Semantic role labelling above).\n",
      "Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text.\n",
      "A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to pro-drop languages .\n",
      "Recognizing textual entailment Given two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false.\n",
      "[25] Topic segmentation and recognition Given a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment.\n",
      "Argument mining The goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs.\n",
      "[26] Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse.\n",
      "[27] [28] Higher-level NLP applications [ edit ] Automatic summarization (text summarization) Produce a readable summary of a chunk of text.\n",
      "Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper.\n",
      "Book generation Not an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books.\n",
      "The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed ).\n",
      "[29] The first published work by a neural network was published in 2018, 1 the Road , marketed as a novel, contains sixty million words.\n",
      "Both these systems are basically elaborate but non-sensical (semantics-free) language models .\n",
      "The first machine-generated science book was published in 2019 (Beta Writer, Lithium-Ion Batteries , Springer, Cham).\n",
      "[30] Unlike Racter and 1 the Road , this is grounded on factual knowledge and based on text summarization.\n",
      "Dialogue management Computer systems intended to converse with a human.\n",
      "Document AI A Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types.\n",
      "NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants.\n",
      "[31] Grammatical error correction Grammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology/orthography, morphology, syntax, semantics, pragmatics).\n",
      "Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language.\n",
      "It has thus been subject to a number of shared tasks since 2011.\n",
      "[32] [33] [34] As far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2 , this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications.\n",
      "Machine translation Automatically translate text from one human language to another.\n",
      "This is one of the most difficult problems, and is a member of a class of problems colloquially termed \" AI-complete \", i.e.\n",
      "requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.)\n",
      "to solve properly.\n",
      "Natural language generation (NLG): Convert information from computer databases or semantic intents into readable human language.\n",
      "Natural language understanding (NLU) Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate.\n",
      "Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts.\n",
      "Introduction and creation of language metamodel and ontology are efficient however empirical solutions.\n",
      "An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption , or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization.\n",
      "[35] Question answering Given a human-language question, determine its answer.\n",
      "Typical questions have a specific right answer (such as \"What is the capital of Canada?\n",
      "\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\n",
      "General tendencies and (possible) future directions [ edit ] Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP.\n",
      "As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed: [36] Interest on increasingly abstract, \"cognitive\" aspects of natural language (1999-2001: shallow parsing, 2002-03: named entity recognition, 2006-09/2017-18: dependency syntax, 2004-05/2008-09 semantic role labelling, 2011-12 coreference, 2015-16: discourse parsing, 2019: semantic parsing).\n",
      "Increasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+/100+ languages) Elimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems) Cognition and NLP [ edit ] Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language.\n",
      "More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n",
      "Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"\n",
      "[37] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.\n",
      "[38] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.\n",
      "[39] Especially during the age of symbolic NLP , the area of computational linguistics maintained strong ties with cognitive studies.\n",
      "As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science , along with the findings of cognitive linguistics , [40] with two defining aspects: Apply the theory of conceptual metaphor , explained by Lakoff as “the understanding of one idea, in terms of another” which provides an idea of the intent of the author.\n",
      "[41] For example, consider the English word “big” .\n",
      "When used in a comparison ( “That is a big tree” ), the author's intent is to imply that the tree is ”physically large” relative to other trees or the authors experience.\n",
      "When used metaphorically ( ”Tomorrow is a big day” ), the author’s intent to imply ”importance” .\n",
      "The intent behind other usages, like in ”She is a big person” will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information.\n",
      "Assign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a probabilistic context-free grammar (PCFG).\n",
      "The mathematical equation for such algorithms is presented in US patent 9269353 : R M M ( t o k e n N ) = P M M ( t o k e n N ) × 1 2 d ( ∑ i = − d d ( ( P M M ( t o k e n N − 1 ) × P F ( t o k e n N , t o k e n N − 1 ) ) i ) {\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N-1})}\\times {PF(token_{N},token_{N-1}))_{i}}\\right)} Where, RMM , is the Relative Measure of Meaning token , is any block of text, sentence, phrase or word N , is the number of tokens being analyzed PMM , is the Probable Measure of Meaning based on a corpora d , is the location of the token along the sequence of N-1 tokens PF , is the Probability Function specific to a language Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s.\n",
      "Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar, [42] functional grammar, [43] construction grammar, [44] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R ), however, with limited uptake in mainstream NLP (as measured by presence on major conferences [45] of the ACL ).\n",
      "More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability , e.g., under the notion of \"cognitive AI\".\n",
      "[46] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit).\n",
      "[47] See also [ edit ] 1 the Road Automated essay scoring Biomedical text mining Compound term processing Computational linguistics Computer-assisted reviewing Controlled natural language Deep learning Deep linguistic processing Distributional semantics Foreign language reading aid Foreign language writing aid Information extraction Information retrieval Language and Communication Technologies Language technology Latent semantic indexing Native-language identification Natural language programming Natural language search Outline of natural language processing Query expansion Query understanding Reification (linguistics) Speech processing Spoken dialogue systems Text-proofing Text simplification Transformer (machine learning model) Truecasing Question answering Word2vec References [ edit ] ^ Kongthon, Alisa; Sangkeettrakarn, Chatchawal; Kongyoung, Sarawoot; Haruechaiyasak, Choochart (October 27–30, 2009).\n",
      "Implementing an online help desk system based on conversational agent .\n",
      "MEDES '09: The International Conference on Management of Emergent Digital EcoSystems.\n",
      "France: ACM.\n",
      "doi : 10.1145/1643823.1643908 .\n",
      "^ Hutchins, J.\n",
      "(2005).\n",
      "\"The history of machine translation in a nutshell\" (PDF) .\n",
      "[ self-published source ] ^ Koskenniemi, Kimmo (1983), Two-level morphology: A general computational model of word-form recognition and production (PDF) , Department of General Linguistics, University of Helsinki ^ Joshi, A. K., & Weinstein, S. (1981, August).\n",
      "Control of Inference: Role of Some Aspects of Discourse Structure-Centering .\n",
      "In IJCAI (pp.\n",
      "385-387).\n",
      "^ Guida, G.; Mauri, G. (July 1986).\n",
      "\"Evaluation of natural language processing systems: Issues and approaches\".\n",
      "Proceedings of the IEEE .\n",
      "74 (7): 1026–1035.\n",
      "doi : 10.1109/PROC.1986.13580 .\n",
      "ISSN 1558-2256 .\n",
      "S2CID 30688575 .\n",
      "^ Chomskyan linguistics encourages the investigation of \" corner cases \" that stress the limits of its theoretical models (comparable to pathological phenomena in mathematics), typically created using thought experiments , rather than the systematic investigation of typical phenomena that occur in real-world data, as is the case in corpus linguistics .\n",
      "The creation and use of such corpora of real-world data is a fundamental part of machine-learning algorithms for natural language processing.\n",
      "In addition, theoretical underpinnings of Chomskyan linguistics such as the so-called \" poverty of the stimulus \" argument entail that general learning algorithms, as are typically used in machine learning, cannot be successful in language processing.\n",
      "As a result, the Chomskyan paradigm discouraged the application of such models to language processing.\n",
      "^ Goldberg, Yoav (2016).\n",
      "\"A Primer on Neural Network Models for Natural Language Processing\".\n",
      "Journal of Artificial Intelligence Research .\n",
      "57 : 345–420.\n",
      "arXiv : 1807.10854 .\n",
      "doi : 10.1613/jair.4992 .\n",
      "S2CID 8273530 .\n",
      "^ Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016).\n",
      "Deep Learning .\n",
      "MIT Press.\n",
      "^ Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016).\n",
      "Exploring the Limits of Language Modeling .\n",
      "arXiv : 1602.02410 .\n",
      "Bibcode : 2016arXiv160202410J .\n",
      "^ Choe, Do Kook; Charniak, Eugene.\n",
      "\"Parsing as Language Modeling\" .\n",
      "Emnlp 2016 .\n",
      "^ Vinyals, Oriol;  et al.\n",
      "(2014).\n",
      "\"Grammar as a Foreign Language\" (PDF) .\n",
      "Nips2015 .\n",
      "arXiv : 1412.7449 .\n",
      "Bibcode : 2014arXiv1412.7449V .\n",
      "^ Turchin, Alexander; Florez Builes, Luisa F. (2021-03-19).\n",
      "\"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\" .\n",
      "Journal of Diabetes Science and Technology .\n",
      "15 (3): 553–560.\n",
      "doi : 10.1177/19322968211000831 .\n",
      "ISSN 1932-2968 .\n",
      "PMC 8120048.\n",
      "PMID 33736486 .\n",
      "^ Winograd, Terry (1971).\n",
      "Procedures as a Representation for Data in a Computer Program for Understanding Natural Language (Thesis).\n",
      "^ Schank, Roger C.; Abelson, Robert P. (1977).\n",
      "Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures .\n",
      "Hillsdale: Erlbaum.\n",
      "ISBN 0-470-99033-3 .\n",
      "^ Mark Johnson.\n",
      "How the statistical revolution changes (computational) linguistics.\n",
      "Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics.\n",
      "^ Philip Resnik.\n",
      "Four revolutions.\n",
      "Language Log, February 5, 2011.\n",
      "^ \"Investigating complex-valued representation in NLP\" (PDF) .\n",
      "^ Trabelsi, Chiheb; Bilaniuk, Olexa; Zhang, Ying; Serdyuk, Dmitriy; Subramanian, Sandeep; Santos, João Felipe; Mehri, Soroush; Rostamzadeh, Negar; Bengio, Yoshua; Pal, Christopher J.\n",
      "(2018-02-25).\n",
      "\"Deep Complex Networks\".\n",
      "arXiv : 1705.09792 [ cs.NE ].\n",
      "^ Socher, Richard.\n",
      "\"Deep Learning For NLP-ACL 2012 Tutorial\" .\n",
      "www.socher.org .\n",
      "Retrieved 2020-08-17 .\n",
      "This was an early Deep Learning tutorial at the ACL 2012 and met with both interest and (at the time) skepticism by most participants.\n",
      "Until then, neural learning was basically rejected because of its lack of statistical interpretability.\n",
      "Until 2015, deep learning had evolved into the major framework of NLP.\n",
      "^ Annamoradnejad, I. and Zoghi, G. (2020).\n",
      "Colbert: Using bert sentence embedding for humor detection .\n",
      "arXiv preprint arXiv:2004.12765.\n",
      "^ Yi, Chucai; Tian, Yingli (2012), \"Assistive Text Reading from Complex Background for Blind Persons\", Camera-Based Document Analysis and Recognition , Springer Berlin Heidelberg, pp.\n",
      "15–28, CiteSeerX 10.1.1.668.869 , doi : 10.1007/978-3-642-29364-1_2 , ISBN 9783642293634 ^ \"What is Natural Language Processing?\n",
      "Intro to NLP in Machine Learning\" .\n",
      "GyanSetu!\n",
      ".\n",
      "2020-12-06 .\n",
      "Retrieved 2021-01-09 .\n",
      "^ Kishorjit, N.; Vidya, Raj RK.\n",
      "; Nirmal, Y.; Sivaji, B.\n",
      "(2012).\n",
      "\"Manipuri Morpheme Identification\" (PDF) .\n",
      "Proceedings of the 3rd Workshop on South and Southeast Asian Natural Language Processing (SANLP) .\n",
      "COLING 2012, Mumbai, December 2012: 95–108.\n",
      "CS1 maint: location ( link ) ^ Klein, Dan; Manning, Christopher D. (2002).\n",
      "\"Natural language grammar induction using a constituent-context model\" (PDF) .\n",
      "Advances in Neural Information Processing Systems .\n",
      "^ PASCAL Recognizing Textual Entailment Challenge (RTE-7) https://tac.nist.gov//2011/RTE/ ^ Lippi, Marco; Torroni, Paolo (2016-04-20).\n",
      "\"Argumentation Mining: State of the Art and Emerging Trends\" .\n",
      "ACM Transactions on Internet Technology .\n",
      "16 (2): 1–25.\n",
      "doi : 10.1145/2850417 .\n",
      "ISSN 1533-5399 .\n",
      "S2CID 9561587 .\n",
      "^ \"Argument Mining - IJCAI2016 Tutorial\" .\n",
      "www.i3s.unice.fr .\n",
      "Retrieved 2021-03-09 .\n",
      "^ \"NLP Approaches to Computational Argumentation – ACL 2016, Berlin\" .\n",
      "Retrieved 2021-03-09 .\n",
      "^ \"U B U W E B :: Racter\" .\n",
      "www.ubu.com .\n",
      "Retrieved 2020-08-17 .\n",
      "^ Writer, Beta (2019).\n",
      "Lithium-Ion Batteries .\n",
      "doi : 10.1007/978-3-030-16800-1 .\n",
      "ISBN 978-3-030-16799-8 .\n",
      "^ \"Document Understanding AI on Google Cloud (Cloud Next '19) - YouTube\" .\n",
      "www.youtube.com .\n",
      "Retrieved 2021-01-11 .\n",
      "^ Administration.\n",
      "\"Centre for Language Technology (CLT)\" .\n",
      "Macquarie University .\n",
      "Retrieved 2021-01-11 .\n",
      "^ \"Shared Task: Grammatical Error Correction\" .\n",
      "www.comp.nus.edu.sg .\n",
      "Retrieved 2021-01-11 .\n",
      "^ \"Shared Task: Grammatical Error Correction\" .\n",
      "www.comp.nus.edu.sg .\n",
      "Retrieved 2021-01-11 .\n",
      "^ Duan, Yucong; Cruz, Christophe (2011).\n",
      "\"Formalizing Semantic of Natural Language through Conceptualization from Existence\" .\n",
      "International Journal of Innovation, Management and Technology .\n",
      "2 (1): 37–42.\n",
      "Archived from the original on 2011-10-09.\n",
      "^ \"Previous shared tasks | CoNLL\" .\n",
      "www.conll.org .\n",
      "Retrieved 2021-01-11 .\n",
      "^ \"Cognition\" .\n",
      "Lexico .\n",
      "Oxford University Press and Dictionary.com .\n",
      "Retrieved 6 May 2020 .\n",
      "^ \"Ask the Cognitive Scientist\" .\n",
      "American Federation of Teachers .\n",
      "8 August 2014.\n",
      "Cognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind.\n",
      "^ Robinson, Peter (2008).\n",
      "Handbook of Cognitive Linguistics and Second Language Acquisition .\n",
      "Routledge.\n",
      "pp.\n",
      "3–8.\n",
      "ISBN 978-0-805-85352-0 .\n",
      "^ Lakoff, George (1999).\n",
      "Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm .\n",
      "New York Basic Books.\n",
      "pp.\n",
      "569–583.\n",
      "ISBN 978-0-465-05674-3 .\n",
      "^ Strauss, Claudia (1999).\n",
      "A Cognitive Theory of Cultural Meaning .\n",
      "Cambridge University Press.\n",
      "pp.\n",
      "156–164.\n",
      "ISBN 978-0-521-59541-4 .\n",
      "^ \"Universal Conceptual Cognitive Annotation (UCCA)\" .\n",
      "Universal Conceptual Cognitive Annotation (UCCA) .\n",
      "Retrieved 2021-01-11 .\n",
      "^ Rodríguez, F. C., & Mairal-Usón, R. (2016).\n",
      "Building an RRG computational grammar .\n",
      "Onomazein , (34), 86-117.\n",
      "^ \"Fluid Construction Grammar – A fully operational processing system for construction grammars\" .\n",
      "Retrieved 2021-01-11 .\n",
      "^ \"ACL Member Portal | The Association for Computational Linguistics Member Portal\" .\n",
      "www.aclweb.org .\n",
      "Retrieved 2021-01-11 .\n",
      "^ \"Chunks and Rules\" .\n",
      "www.w3.org .\n",
      "Retrieved 2021-01-11 .\n",
      "^ Socher, Richard; Karpathy, Andrej; Le, Quoc V.; Manning, Christopher D.; Ng, Andrew Y.\n",
      "(2014).\n",
      "\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\" .\n",
      "Transactions of the Association for Computational Linguistics .\n",
      "2 : 207–218.\n",
      "doi : 10.1162/tacl_a_00177 .\n",
      "S2CID 2317858 .\n",
      "Further reading [ edit ] Bates, M (1995).\n",
      "\"Models of natural language understanding\" .\n",
      "Proceedings of the National Academy of Sciences of the United States of America .\n",
      "92 (22): 9977–9982.\n",
      "Bibcode : 1995PNAS...92.9977B .\n",
      "doi : 10.1073/pnas.92.22.9977 .\n",
      "PMC 40721 .\n",
      "PMID 7479812 .\n",
      "Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "Natural Language Processing with Python .\n",
      "O'Reilly Media.\n",
      "ISBN 978-0-596-51649-9 .\n",
      "Daniel Jurafsky and James H. Martin (2008).\n",
      "Speech and Language Processing , 2nd edition.\n",
      "Pearson Prentice Hall.\n",
      "ISBN 978-0-13-187321-6 .\n",
      "Mohamed Zakaria Kurdi (2016).\n",
      "Natural Language Processing and Computational Linguistics: speech, morphology, and syntax , Volume 1.\n",
      "ISTE-Wiley.\n",
      "ISBN 978-1848218482 .\n",
      "Mohamed Zakaria Kurdi (2017).\n",
      "Natural Language Processing and Computational Linguistics: semantics, discourse, and applications , Volume 2.\n",
      "ISTE-Wiley.\n",
      "ISBN 978-1848219212 .\n",
      "Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008).\n",
      "Introduction to Information Retrieval .\n",
      "Cambridge University Press.\n",
      "ISBN 978-0-521-86571-5 .\n",
      "Official html and pdf versions available without charge.\n",
      "Christopher D. Manning and Hinrich Schütze (1999).\n",
      "Foundations of Statistical Natural Language Processing .\n",
      "The MIT Press.\n",
      "ISBN 978-0-262-13360-9 .\n",
      "David M. W. Powers and Christopher C. R. Turk (1989).\n",
      "Machine Learning of Natural Language .\n",
      "Springer-Verlag.\n",
      "ISBN 978-0-387-19557-5 .\n",
      "External link [ edit ] Media related to Natural language processing at Wikimedia Commons v t e Natural language processing General terms AI-complete Bag-of-words n-gram Bigram Trigram Computational linguistics Natural-language understanding Stopwords Text processing Text analysis Collocation extraction Concept mining Coreference resolution Deep linguistic processing Distant reading Information extraction Named-entity recognition Ontology learning Parsing Part-of-speech tagging Semantic role labeling Semantic similarity Sentiment analysis Terminology extraction Text mining Textual entailment Truecasing Word-sense disambiguation Word-sense induction Text segmentation Compound-term processing Lemmatisation Lexical analysis Text chunking Stemming Sentence segmentation Word segmentation Automatic summarization Multi-document summarization Sentence extraction Text simplification Machine translation Computer-assisted Example-based Rule-based Statistical Transfer-based Neural Distributional semantics models BERT Document-term matrix Explicit semantic analysis fastText GloVe Latent semantic analysis Word embedding Word2vec Language resources , datasets and corpora Types and standards Corpus linguistics Lexical resource Linguistic Linked Open Data Machine-readable dictionary Parallel text PropBank Semantic network Simple Knowledge Organization System Speech corpus Text corpus Thesaurus (information retrieval) Treebank Universal Dependencies Data BabelNet Bank of English DBpedia FrameNet Google Ngram Viewer ThoughtTreasure UBY WordNet Automatic identification and data capture Speech recognition Speech segmentation Speech synthesis Natural language generation Optical character recognition Topic model Document classification Latent Dirichlet allocation Pachinko allocation Computer-assisted reviewing Automated essay scoring Concordancer Grammar checker Predictive text Spell checker Syntax guessing Natural language user interface Chatbot Interactive fiction Question answering Virtual assistant Voice user interface Other software Natural Language Toolkit spaCy Authority control: National libraries United States Japan Language portal Retrieved from \" https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1048621730 \" Categories : Natural language processing Computational linguistics Speech recognition Computational fields of study Artificial intelligence Hidden categories: CS1 maint: location Articles with short description Short description matches Wikidata Commons category link from Wikidata Articles with LCCN identifiers Articles with NDL identifiers Navigation menu Personal tools Not logged in Talk Contributions Create account Log in Namespaces Article Talk Variants expanded collapsed Views Read Edit View history More expanded collapsed Search Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Upload file Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Languages Afrikaans العربية Azərbaycanca বাংলা Bân-lâm-gú Беларуская Беларуская (тарашкевіца) Български Català Čeština Dansk Deutsch Eesti Ελληνικά Español Euskara فارسی Français Galego 한국어 Հայերեն हिन्दी Hrvatski Bahasa Indonesia Íslenska Italiano עברית ಕನ್ನಡ ქართული Lietuvių Македонски मराठी مصرى Монгол မြန်မာဘာသာ 日本語 ଓଡ଼ିଆ Piemontèis Polski Português Română Русский Simple English کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi தமிழ் ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links This page was last edited on 7 October 2021, at 01:56 (UTC) .\n",
      "Text is available under the Creative Commons Attribution-ShareAlike License ;\n",
      "additional terms may apply.\n",
      "By using this site, you agree to the Terms of Use and Privacy Policy .\n",
      "Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc. , a non-profit organization.\n",
      "Privacy policy About Wikipedia Disclaimers Contact Wikipedia Mobile view Developers Statistics Cookie statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eduku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# called the function and created the sentences\n",
    "sentences = get_sentence(text)\n",
    "for i in sentences:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c3c09615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8381\n",
      "words\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "-\n",
      "Wikipedia\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Jump\n",
      "to\n",
      "navigation\n",
      "Jump\n",
      "to\n",
      "search\n",
      "This\n",
      "article\n",
      "is\n",
      "about\n",
      "natural\n",
      "language\n",
      "processing\n",
      "done\n",
      "by\n",
      "computers\n",
      ".\n",
      "For\n",
      "the\n",
      "natural\n",
      "language\n",
      "processing\n",
      "done\n",
      "by\n",
      "the\n",
      "human\n",
      "brain\n",
      ",\n",
      "see\n",
      "Language\n",
      "processing\n",
      "in\n",
      "the\n",
      "brain\n",
      ".\n",
      "Field\n",
      "of\n",
      "computer\n",
      "science\n",
      "and\n",
      "linguistics\n",
      "An\n",
      "automated\n",
      "online\n",
      "assistant\n",
      "providing\n",
      "customer\n",
      "service\n",
      "on\n",
      "a\n",
      "web\n",
      "page\n",
      ",\n",
      "an\n",
      "example\n",
      "of\n",
      "an\n",
      "application\n",
      "where\n",
      "natural\n",
      "language\n",
      "processing\n",
      "is\n",
      "a\n",
      "major\n",
      "component\n",
      ".\n",
      "[\n",
      "1\n",
      "]\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "linguistics\n",
      ",\n",
      "computer\n",
      "science\n",
      ",\n",
      "and\n",
      "artificial\n",
      "intelligence\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "language\n",
      ",\n",
      "in\n",
      "particular\n",
      "how\n",
      "to\n",
      "program\n",
      "computers\n",
      "to\n",
      "process\n",
      "and\n",
      "analyze\n",
      "large\n",
      "amounts\n",
      "of\n",
      "natural\n",
      "language\n",
      "data\n",
      ".\n",
      "The\n",
      "goal\n",
      "is\n",
      "a\n",
      "computer\n",
      "capable\n",
      "of\n",
      "``\n",
      "understanding\n",
      "''\n",
      "the\n",
      "contents\n",
      "of\n",
      "documents\n",
      ",\n",
      "including\n",
      "the\n",
      "contextual\n",
      "nuances\n",
      "of\n",
      "the\n",
      "language\n",
      "within\n",
      "them\n",
      ".\n",
      "The\n",
      "technology\n",
      "can\n",
      "then\n",
      "accurately\n",
      "extract\n",
      "information\n",
      "and\n",
      "insights\n",
      "contained\n",
      "in\n",
      "the\n",
      "documents\n",
      "as\n",
      "well\n",
      "as\n",
      "categorize\n",
      "and\n",
      "organize\n",
      "the\n",
      "documents\n",
      "themselves\n",
      ".\n",
      "Challenges\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "frequently\n",
      "involve\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "natural\n",
      "language\n",
      "understanding\n",
      ",\n",
      "and\n",
      "natural\n",
      "language\n",
      "generation\n",
      ".\n",
      "Contents\n",
      "1\n",
      "History\n",
      "1.1\n",
      "Symbolic\n",
      "NLP\n",
      "(\n",
      "1950s\n",
      "–\n",
      "early\n",
      "1990s\n",
      ")\n",
      "1.2\n",
      "Statistical\n",
      "NLP\n",
      "(\n",
      "1990s–2010s\n",
      ")\n",
      "1.3\n",
      "Neural\n",
      "NLP\n",
      "(\n",
      "present\n",
      ")\n",
      "2\n",
      "Methods\n",
      ":\n",
      "Rules\n",
      ",\n",
      "statistics\n",
      ",\n",
      "neural\n",
      "networks\n",
      "2.1\n",
      "Statistical\n",
      "methods\n",
      "2.2\n",
      "Neural\n",
      "networks\n",
      "3\n",
      "Common\n",
      "NLP\n",
      "tasks\n",
      "3.1\n",
      "Text\n",
      "and\n",
      "speech\n",
      "processing\n",
      "3.2\n",
      "Morphological\n",
      "analysis\n",
      "3.3\n",
      "Syntactic\n",
      "analysis\n",
      "3.4\n",
      "Lexical\n",
      "semantics\n",
      "(\n",
      "of\n",
      "individual\n",
      "words\n",
      "in\n",
      "context\n",
      ")\n",
      "3.5\n",
      "Relational\n",
      "semantics\n",
      "(\n",
      "semantics\n",
      "of\n",
      "individual\n",
      "sentences\n",
      ")\n",
      "3.6\n",
      "Discourse\n",
      "(\n",
      "semantics\n",
      "beyond\n",
      "individual\n",
      "sentences\n",
      ")\n",
      "3.7\n",
      "Higher-level\n",
      "NLP\n",
      "applications\n",
      "4\n",
      "General\n",
      "tendencies\n",
      "and\n",
      "(\n",
      "possible\n",
      ")\n",
      "future\n",
      "directions\n",
      "4.1\n",
      "Cognition\n",
      "and\n",
      "NLP\n",
      "5\n",
      "See\n",
      "also\n",
      "6\n",
      "References\n",
      "7\n",
      "Further\n",
      "reading\n",
      "8\n",
      "External\n",
      "link\n",
      "History\n",
      "[\n",
      "edit\n",
      "]\n",
      "Further\n",
      "information\n",
      ":\n",
      "History\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "has\n",
      "its\n",
      "roots\n",
      "in\n",
      "the\n",
      "1950s\n",
      ".\n",
      "Already\n",
      "in\n",
      "1950\n",
      ",\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "``\n",
      "Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\n",
      "``\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence\n",
      ",\n",
      "a\n",
      "task\n",
      "that\n",
      "involves\n",
      "the\n",
      "automated\n",
      "interpretation\n",
      "and\n",
      "generation\n",
      "of\n",
      "natural\n",
      "language\n",
      ",\n",
      "but\n",
      "at\n",
      "the\n",
      "time\n",
      "not\n",
      "articulated\n",
      "as\n",
      "a\n",
      "problem\n",
      "separate\n",
      "from\n",
      "artificial\n",
      "intelligence\n",
      ".\n",
      "Symbolic\n",
      "NLP\n",
      "(\n",
      "1950s\n",
      "–\n",
      "early\n",
      "1990s\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "The\n",
      "premise\n",
      "of\n",
      "symbolic\n",
      "NLP\n",
      "is\n",
      "well-summarized\n",
      "by\n",
      "John\n",
      "Searle\n",
      "'s\n",
      "Chinese\n",
      "room\n",
      "experiment\n",
      ":\n",
      "Given\n",
      "a\n",
      "collection\n",
      "of\n",
      "rules\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "a\n",
      "Chinese\n",
      "phrasebook\n",
      ",\n",
      "with\n",
      "questions\n",
      "and\n",
      "matching\n",
      "answers\n",
      ")\n",
      ",\n",
      "the\n",
      "computer\n",
      "emulates\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "or\n",
      "other\n",
      "NLP\n",
      "tasks\n",
      ")\n",
      "by\n",
      "applying\n",
      "those\n",
      "rules\n",
      "to\n",
      "the\n",
      "data\n",
      "it\n",
      "is\n",
      "confronted\n",
      "with\n",
      ".\n",
      "1950s\n",
      ":\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentences\n",
      "into\n",
      "English\n",
      ".\n",
      "The\n",
      "authors\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "years\n",
      ",\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem\n",
      ".\n",
      "[\n",
      "2\n",
      "]\n",
      "However\n",
      ",\n",
      "real\n",
      "progress\n",
      "was\n",
      "much\n",
      "slower\n",
      ",\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966\n",
      ",\n",
      "which\n",
      "found\n",
      "that\n",
      "ten-year-long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectations\n",
      ",\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "was\n",
      "dramatically\n",
      "reduced\n",
      ".\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "was\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "were\n",
      "developed\n",
      ".\n",
      "1960s\n",
      ":\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "natural\n",
      "language\n",
      "processing\n",
      "systems\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU\n",
      ",\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "``\n",
      "blocks\n",
      "worlds\n",
      "``\n",
      "with\n",
      "restricted\n",
      "vocabularies\n",
      ",\n",
      "and\n",
      "ELIZA\n",
      ",\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist\n",
      ",\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "and\n",
      "1966\n",
      ".\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion\n",
      ",\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction\n",
      ".\n",
      "When\n",
      "the\n",
      "``\n",
      "patient\n",
      "''\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base\n",
      ",\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "responding\n",
      "to\n",
      "``\n",
      "My\n",
      "head\n",
      "hurts\n",
      "''\n",
      "with\n",
      "``\n",
      "Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurts\n",
      "?\n",
      "''\n",
      ".\n",
      "1970s\n",
      ":\n",
      "During\n",
      "the\n",
      "1970s\n",
      ",\n",
      "many\n",
      "programmers\n",
      "began\n",
      "to\n",
      "write\n",
      "``\n",
      "conceptual\n",
      "ontologies\n",
      "``\n",
      ",\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data\n",
      ".\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "(\n",
      "Schank\n",
      ",\n",
      "1975\n",
      ")\n",
      ",\n",
      "SAM\n",
      "(\n",
      "Cullingford\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "PAM\n",
      "(\n",
      "Wilensky\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "TaleSpin\n",
      "(\n",
      "Meehan\n",
      ",\n",
      "1976\n",
      ")\n",
      ",\n",
      "QUALM\n",
      "(\n",
      "Lehnert\n",
      ",\n",
      "1977\n",
      ")\n",
      ",\n",
      "Politics\n",
      "(\n",
      "Carbonell\n",
      ",\n",
      "1979\n",
      ")\n",
      ",\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "(\n",
      "Lehnert\n",
      "1981\n",
      ")\n",
      ".\n",
      "During\n",
      "this\n",
      "time\n",
      ",\n",
      "the\n",
      "first\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "PARRY\n",
      ")\n",
      ".\n",
      "1980s\n",
      ":\n",
      "The\n",
      "1980s\n",
      "and\n",
      "early\n",
      "1990s\n",
      "mark\n",
      "the\n",
      "hey-day\n",
      "of\n",
      "symbolic\n",
      "methods\n",
      "in\n",
      "NLP\n",
      ".\n",
      "Focus\n",
      "areas\n",
      "of\n",
      "the\n",
      "time\n",
      "included\n",
      "research\n",
      "on\n",
      "rule-based\n",
      "parsing\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "development\n",
      "of\n",
      "HPSG\n",
      "as\n",
      "a\n",
      "computational\n",
      "operationalization\n",
      "of\n",
      "generative\n",
      "grammar\n",
      ")\n",
      ",\n",
      "morphology\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "two-level\n",
      "morphology\n",
      "[\n",
      "3\n",
      "]\n",
      ")\n",
      ",\n",
      "semantics\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "Lesk\n",
      "algorithm\n",
      ")\n",
      ",\n",
      "reference\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "within\n",
      "Centering\n",
      "Theory\n",
      "[\n",
      "4\n",
      "]\n",
      ")\n",
      "and\n",
      "other\n",
      "areas\n",
      "of\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "the\n",
      "Rhetorical\n",
      "Structure\n",
      "Theory\n",
      ")\n",
      ".\n",
      "Other\n",
      "lines\n",
      "of\n",
      "research\n",
      "were\n",
      "continued\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "development\n",
      "of\n",
      "chatterbots\n",
      "with\n",
      "Racter\n",
      "and\n",
      "Jabberwacky\n",
      ".\n",
      "An\n",
      "important\n",
      "development\n",
      "(\n",
      "that\n",
      "eventually\n",
      "led\n",
      "to\n",
      "the\n",
      "statistical\n",
      "turn\n",
      "in\n",
      "the\n",
      "1990s\n",
      ")\n",
      "was\n",
      "the\n",
      "rising\n",
      "importance\n",
      "of\n",
      "quantitative\n",
      "evaluation\n",
      "in\n",
      "this\n",
      "period\n",
      ".\n",
      "[\n",
      "5\n",
      "]\n",
      "Statistical\n",
      "NLP\n",
      "(\n",
      "1990s–2010s\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "natural\n",
      "language\n",
      "processing\n",
      "systems\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "sets\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "however\n",
      ",\n",
      "there\n",
      "was\n",
      "a\n",
      "revolution\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "This\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "(\n",
      "see\n",
      "Moore\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theories\n",
      "of\n",
      "linguistics\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transformational\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "[\n",
      "6\n",
      "]\n",
      "1990s\n",
      ":\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "successes\n",
      "on\n",
      "statistical\n",
      "methods\n",
      "in\n",
      "NLP\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation\n",
      ",\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research\n",
      ".\n",
      "These\n",
      "systems\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "laws\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceedings\n",
      "into\n",
      "all\n",
      "official\n",
      "languages\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "systems\n",
      "of\n",
      "government\n",
      ".\n",
      "However\n",
      ",\n",
      "most\n",
      "other\n",
      "systems\n",
      "depended\n",
      "on\n",
      "corpora\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "tasks\n",
      "implemented\n",
      "by\n",
      "these\n",
      "systems\n",
      ",\n",
      "which\n",
      "was\n",
      "(\n",
      "and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be\n",
      ")\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "systems\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "has\n",
      "gone\n",
      "into\n",
      "methods\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amounts\n",
      "of\n",
      "data\n",
      ".\n",
      "2000s\n",
      ":\n",
      "With\n",
      "the\n",
      "growth\n",
      "of\n",
      "the\n",
      "web\n",
      ",\n",
      "increasing\n",
      "amounts\n",
      "of\n",
      "raw\n",
      "(\n",
      "unannotated\n",
      ")\n",
      "language\n",
      "data\n",
      "has\n",
      "become\n",
      "available\n",
      "since\n",
      "the\n",
      "mid-1990s\n",
      ".\n",
      "Research\n",
      "has\n",
      "thus\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithms\n",
      ".\n",
      "Such\n",
      "algorithms\n",
      "can\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answers\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data\n",
      ".\n",
      "Generally\n",
      ",\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning\n",
      ",\n",
      "and\n",
      "typically\n",
      "produces\n",
      "less\n",
      "accurate\n",
      "results\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "(\n",
      "including\n",
      ",\n",
      "among\n",
      "other\n",
      "things\n",
      ",\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web\n",
      ")\n",
      ",\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "results\n",
      "if\n",
      "the\n",
      "algorithm\n",
      "used\n",
      "has\n",
      "a\n",
      "low\n",
      "enough\n",
      "time\n",
      "complexity\n",
      "to\n",
      "be\n",
      "practical\n",
      ".\n",
      "Neural\n",
      "NLP\n",
      "(\n",
      "present\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "In\n",
      "the\n",
      "2010s\n",
      ",\n",
      "representation\n",
      "learning\n",
      "and\n",
      "deep\n",
      "neural\n",
      "network\n",
      "-style\n",
      "machine\n",
      "learning\n",
      "methods\n",
      "became\n",
      "widespread\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      ",\n",
      "due\n",
      "in\n",
      "part\n",
      "to\n",
      "a\n",
      "flurry\n",
      "of\n",
      "results\n",
      "showing\n",
      "that\n",
      "such\n",
      "techniques\n",
      "[\n",
      "7\n",
      "]\n",
      "[\n",
      "8\n",
      "]\n",
      "can\n",
      "achieve\n",
      "state-of-the-art\n",
      "results\n",
      "in\n",
      "many\n",
      "natural\n",
      "language\n",
      "tasks\n",
      ",\n",
      "for\n",
      "example\n",
      "in\n",
      "language\n",
      "modeling\n",
      ",\n",
      "[\n",
      "9\n",
      "]\n",
      "parsing\n",
      ",\n",
      "[\n",
      "10\n",
      "]\n",
      "[\n",
      "11\n",
      "]\n",
      "and\n",
      "many\n",
      "others\n",
      ".\n",
      "This\n",
      "is\n",
      "increasingly\n",
      "important\n",
      "in\n",
      "medicine\n",
      "and\n",
      "healthcare\n",
      ",\n",
      "where\n",
      "NLP\n",
      "is\n",
      "being\n",
      "used\n",
      "to\n",
      "analyze\n",
      "notes\n",
      "and\n",
      "text\n",
      "in\n",
      "electronic\n",
      "health\n",
      "records\n",
      "that\n",
      "would\n",
      "otherwise\n",
      "be\n",
      "inaccessible\n",
      "for\n",
      "study\n",
      "when\n",
      "seeking\n",
      "to\n",
      "improve\n",
      "care\n",
      ".\n",
      "[\n",
      "12\n",
      "]\n",
      "Methods\n",
      ":\n",
      "Rules\n",
      ",\n",
      "statistics\n",
      ",\n",
      "neural\n",
      "networks\n",
      "[\n",
      "edit\n",
      "]\n",
      "In\n",
      "the\n",
      "early\n",
      "days\n",
      ",\n",
      "many\n",
      "language-processing\n",
      "systems\n",
      "were\n",
      "designed\n",
      "by\n",
      "symbolic\n",
      "methods\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "hand-coding\n",
      "of\n",
      "a\n",
      "set\n",
      "of\n",
      "rules\n",
      ",\n",
      "coupled\n",
      "with\n",
      "a\n",
      "dictionary\n",
      "lookup\n",
      ":\n",
      "[\n",
      "13\n",
      "]\n",
      "[\n",
      "14\n",
      "]\n",
      "such\n",
      "as\n",
      "by\n",
      "writing\n",
      "grammars\n",
      "or\n",
      "devising\n",
      "heuristic\n",
      "rules\n",
      "for\n",
      "stemming\n",
      ".\n",
      "More\n",
      "recent\n",
      "systems\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "many\n",
      "advantages\n",
      "over\n",
      "hand-produced\n",
      "rules\n",
      ":\n",
      "The\n",
      "learning\n",
      "procedures\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "cases\n",
      ",\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rules\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "at\n",
      "all\n",
      "obvious\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed\n",
      ".\n",
      "Automatic\n",
      "learning\n",
      "procedures\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithms\n",
      "to\n",
      "produce\n",
      "models\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "containing\n",
      "words\n",
      "or\n",
      "structures\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before\n",
      ")\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "with\n",
      "misspelled\n",
      "words\n",
      "or\n",
      "words\n",
      "accidentally\n",
      "omitted\n",
      ")\n",
      ".\n",
      "Generally\n",
      ",\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "handwritten\n",
      "rules\n",
      ",\n",
      "or\n",
      ",\n",
      "more\n",
      "generally\n",
      ",\n",
      "creating\n",
      "systems\n",
      "of\n",
      "handwritten\n",
      "rules\n",
      "that\n",
      "make\n",
      "soft\n",
      "decisions\n",
      ",\n",
      "is\n",
      "extremely\n",
      "difficult\n",
      ",\n",
      "error-prone\n",
      "and\n",
      "time-consuming\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rules\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "systems\n",
      "based\n",
      "on\n",
      "handwritten\n",
      "rules\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rules\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      ".\n",
      "In\n",
      "particular\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "systems\n",
      "based\n",
      "on\n",
      "handwritten\n",
      "rules\n",
      ",\n",
      "beyond\n",
      "which\n",
      "the\n",
      "systems\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable\n",
      ".\n",
      "However\n",
      ",\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "systems\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked\n",
      ",\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increases\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process\n",
      ".\n",
      "Despite\n",
      "the\n",
      "popularity\n",
      "of\n",
      "machine\n",
      "learning\n",
      "in\n",
      "NLP\n",
      "research\n",
      ",\n",
      "symbolic\n",
      "methods\n",
      "are\n",
      "still\n",
      "(\n",
      "2020\n",
      ")\n",
      "commonly\n",
      "used\n",
      ":\n",
      "when\n",
      "the\n",
      "amount\n",
      "of\n",
      "training\n",
      "data\n",
      "is\n",
      "insufficient\n",
      "to\n",
      "successfully\n",
      "apply\n",
      "machine\n",
      "learning\n",
      "methods\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "the\n",
      "machine\n",
      "translation\n",
      "of\n",
      "low-resource\n",
      "languages\n",
      "such\n",
      "as\n",
      "provided\n",
      "by\n",
      "the\n",
      "Apertium\n",
      "system\n",
      ",\n",
      "for\n",
      "preprocessing\n",
      "in\n",
      "NLP\n",
      "pipelines\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "tokenization\n",
      ",\n",
      "or\n",
      "for\n",
      "postprocessing\n",
      "and\n",
      "transforming\n",
      "the\n",
      "output\n",
      "of\n",
      "NLP\n",
      "pipelines\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "knowledge\n",
      "extraction\n",
      "from\n",
      "syntactic\n",
      "parses\n",
      ".\n",
      "Statistical\n",
      "methods\n",
      "[\n",
      "edit\n",
      "]\n",
      "Since\n",
      "the\n",
      "so-called\n",
      "``\n",
      "statistical\n",
      "revolution\n",
      "''\n",
      "[\n",
      "15\n",
      "]\n",
      "[\n",
      "16\n",
      "]\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      "and\n",
      "mid-1990s\n",
      ",\n",
      "much\n",
      "natural\n",
      "language\n",
      "processing\n",
      "research\n",
      "has\n",
      "relied\n",
      "heavily\n",
      "on\n",
      "machine\n",
      "learning\n",
      ".\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "calls\n",
      "instead\n",
      "for\n",
      "using\n",
      "statistical\n",
      "inference\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rules\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpora\n",
      "(\n",
      "the\n",
      "plural\n",
      "form\n",
      "of\n",
      "corpus\n",
      ",\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      ",\n",
      "possibly\n",
      "with\n",
      "human\n",
      "or\n",
      "computer\n",
      "annotations\n",
      ")\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "examples\n",
      ".\n",
      "Many\n",
      "different\n",
      "classes\n",
      "of\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "natural-language-processing\n",
      "tasks\n",
      ".\n",
      "These\n",
      "algorithms\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "``\n",
      "features\n",
      "''\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "Increasingly\n",
      ",\n",
      "however\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "each\n",
      "input\n",
      "feature\n",
      "(\n",
      "complex-valued\n",
      "embeddings\n",
      ",\n",
      "[\n",
      "17\n",
      "]\n",
      "and\n",
      "neural\n",
      "networks\n",
      "in\n",
      "general\n",
      "have\n",
      "also\n",
      "been\n",
      "proposed\n",
      ",\n",
      "for\n",
      "e.g\n",
      ".\n",
      "speech\n",
      "[\n",
      "18\n",
      "]\n",
      ")\n",
      ".\n",
      "Such\n",
      "models\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answers\n",
      "rather\n",
      "than\n",
      "only\n",
      "one\n",
      ",\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "as\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      ",\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      ",\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "However\n",
      ",\n",
      "part-of-speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "hidden\n",
      "Markov\n",
      "models\n",
      "to\n",
      "natural\n",
      "language\n",
      "processing\n",
      ",\n",
      "and\n",
      "increasingly\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "the\n",
      "features\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "The\n",
      "cache\n",
      "language\n",
      "models\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "now\n",
      "rely\n",
      "are\n",
      "examples\n",
      "of\n",
      "such\n",
      "statistical\n",
      "models\n",
      ".\n",
      "Such\n",
      "models\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      ",\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "errors\n",
      "(\n",
      "as\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      ")\n",
      ",\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks\n",
      ".\n",
      "Since\n",
      "the\n",
      "neural\n",
      "turn\n",
      ",\n",
      "statistical\n",
      "methods\n",
      "in\n",
      "NLP\n",
      "research\n",
      "have\n",
      "been\n",
      "largely\n",
      "replaced\n",
      "by\n",
      "neural\n",
      "networks\n",
      ".\n",
      "However\n",
      ",\n",
      "they\n",
      "continue\n",
      "to\n",
      "be\n",
      "relevant\n",
      "for\n",
      "contexts\n",
      "in\n",
      "which\n",
      "statistical\n",
      "interpretability\n",
      "and\n",
      "transparency\n",
      "is\n",
      "required\n",
      ".\n",
      "Neural\n",
      "networks\n",
      "[\n",
      "edit\n",
      "]\n",
      "Further\n",
      "information\n",
      ":\n",
      "Artificial\n",
      "neural\n",
      "network\n",
      "A\n",
      "major\n",
      "drawback\n",
      "of\n",
      "statistical\n",
      "methods\n",
      "is\n",
      "that\n",
      "they\n",
      "require\n",
      "elaborate\n",
      "feature\n",
      "engineering\n",
      ".\n",
      "Since\n",
      "2015\n",
      ",\n",
      "[\n",
      "19\n",
      "]\n",
      "the\n",
      "field\n",
      "has\n",
      "thus\n",
      "largely\n",
      "abandoned\n",
      "statistical\n",
      "methods\n",
      "and\n",
      "shifted\n",
      "to\n",
      "neural\n",
      "networks\n",
      "for\n",
      "machine\n",
      "learning\n",
      ".\n",
      "Popular\n",
      "techniques\n",
      "include\n",
      "the\n",
      "use\n",
      "of\n",
      "word\n",
      "embeddings\n",
      "to\n",
      "capture\n",
      "semantic\n",
      "properties\n",
      "of\n",
      "words\n",
      ",\n",
      "and\n",
      "an\n",
      "increase\n",
      "in\n",
      "end-to-end\n",
      "learning\n",
      "of\n",
      "a\n",
      "higher-level\n",
      "task\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "question\n",
      "answering\n",
      ")\n",
      "instead\n",
      "of\n",
      "relying\n",
      "on\n",
      "a\n",
      "pipeline\n",
      "of\n",
      "separate\n",
      "intermediate\n",
      "tasks\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "part-of-speech\n",
      "tagging\n",
      "and\n",
      "dependency\n",
      "parsing\n",
      ")\n",
      ".\n",
      "In\n",
      "some\n",
      "areas\n",
      ",\n",
      "this\n",
      "shift\n",
      "has\n",
      "entailed\n",
      "substantial\n",
      "changes\n",
      "in\n",
      "how\n",
      "NLP\n",
      "systems\n",
      "are\n",
      "designed\n",
      ",\n",
      "such\n",
      "that\n",
      "deep\n",
      "neural\n",
      "network-based\n",
      "approaches\n",
      "may\n",
      "be\n",
      "viewed\n",
      "as\n",
      "a\n",
      "new\n",
      "paradigm\n",
      "distinct\n",
      "from\n",
      "statistical\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "For\n",
      "instance\n",
      ",\n",
      "the\n",
      "term\n",
      "neural\n",
      "machine\n",
      "translation\n",
      "(\n",
      "NMT\n",
      ")\n",
      "emphasizes\n",
      "the\n",
      "fact\n",
      "that\n",
      "deep\n",
      "learning-based\n",
      "approaches\n",
      "to\n",
      "machine\n",
      "translation\n",
      "directly\n",
      "learn\n",
      "sequence-to-sequence\n",
      "transformations\n",
      ",\n",
      "obviating\n",
      "the\n",
      "need\n",
      "for\n",
      "intermediate\n",
      "steps\n",
      "such\n",
      "as\n",
      "word\n",
      "alignment\n",
      "and\n",
      "language\n",
      "modeling\n",
      "that\n",
      "was\n",
      "used\n",
      "in\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "(\n",
      "SMT\n",
      ")\n",
      ".\n",
      "Latest\n",
      "works\n",
      "tend\n",
      "to\n",
      "use\n",
      "non-technical\n",
      "structure\n",
      "of\n",
      "a\n",
      "given\n",
      "task\n",
      "to\n",
      "build\n",
      "proper\n",
      "neural\n",
      "network\n",
      ".\n",
      "[\n",
      "20\n",
      "]\n",
      "Common\n",
      "NLP\n",
      "tasks\n",
      "[\n",
      "edit\n",
      "]\n",
      "The\n",
      "following\n",
      "is\n",
      "a\n",
      "list\n",
      "of\n",
      "some\n",
      "of\n",
      "the\n",
      "most\n",
      "commonly\n",
      "researched\n",
      "tasks\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "Some\n",
      "of\n",
      "these\n",
      "tasks\n",
      "have\n",
      "direct\n",
      "real-world\n",
      "applications\n",
      ",\n",
      "while\n",
      "others\n",
      "more\n",
      "commonly\n",
      "serve\n",
      "as\n",
      "subtasks\n",
      "that\n",
      "are\n",
      "used\n",
      "to\n",
      "aid\n",
      "in\n",
      "solving\n",
      "larger\n",
      "tasks\n",
      ".\n",
      "Though\n",
      "natural\n",
      "language\n",
      "processing\n",
      "tasks\n",
      "are\n",
      "closely\n",
      "intertwined\n",
      ",\n",
      "they\n",
      "can\n",
      "be\n",
      "subdivided\n",
      "into\n",
      "categories\n",
      "for\n",
      "convenience\n",
      ".\n",
      "A\n",
      "coarse\n",
      "division\n",
      "is\n",
      "given\n",
      "below\n",
      ".\n",
      "Text\n",
      "and\n",
      "speech\n",
      "processing\n",
      "[\n",
      "edit\n",
      "]\n",
      "Optical\n",
      "character\n",
      "recognition\n",
      "(\n",
      "OCR\n",
      ")\n",
      "Given\n",
      "an\n",
      "image\n",
      "representing\n",
      "printed\n",
      "text\n",
      ",\n",
      "determine\n",
      "the\n",
      "corresponding\n",
      "text\n",
      ".\n",
      "Speech\n",
      "recognition\n",
      "Given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "people\n",
      "speaking\n",
      ",\n",
      "determine\n",
      "the\n",
      "textual\n",
      "representation\n",
      "of\n",
      "the\n",
      "speech\n",
      ".\n",
      "This\n",
      "is\n",
      "the\n",
      "opposite\n",
      "of\n",
      "text\n",
      "to\n",
      "speech\n",
      "and\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "extremely\n",
      "difficult\n",
      "problems\n",
      "colloquially\n",
      "termed\n",
      "``\n",
      "AI-complete\n",
      "``\n",
      "(\n",
      "see\n",
      "above\n",
      ")\n",
      ".\n",
      "In\n",
      "natural\n",
      "speech\n",
      "there\n",
      "are\n",
      "hardly\n",
      "any\n",
      "pauses\n",
      "between\n",
      "successive\n",
      "words\n",
      ",\n",
      "and\n",
      "thus\n",
      "speech\n",
      "segmentation\n",
      "is\n",
      "a\n",
      "necessary\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognition\n",
      "(\n",
      "see\n",
      "below\n",
      ")\n",
      ".\n",
      "In\n",
      "most\n",
      "spoken\n",
      "languages\n",
      ",\n",
      "the\n",
      "sounds\n",
      "representing\n",
      "successive\n",
      "letters\n",
      "blend\n",
      "into\n",
      "each\n",
      "other\n",
      "in\n",
      "a\n",
      "process\n",
      "termed\n",
      "coarticulation\n",
      ",\n",
      "so\n",
      "the\n",
      "conversion\n",
      "of\n",
      "the\n",
      "analog\n",
      "signal\n",
      "to\n",
      "discrete\n",
      "characters\n",
      "can\n",
      "be\n",
      "a\n",
      "very\n",
      "difficult\n",
      "process\n",
      ".\n",
      "Also\n",
      ",\n",
      "given\n",
      "that\n",
      "words\n",
      "in\n",
      "the\n",
      "same\n",
      "language\n",
      "are\n",
      "spoken\n",
      "by\n",
      "people\n",
      "with\n",
      "different\n",
      "accents\n",
      ",\n",
      "the\n",
      "speech\n",
      "recognition\n",
      "software\n",
      "must\n",
      "be\n",
      "able\n",
      "to\n",
      "recognize\n",
      "the\n",
      "wide\n",
      "variety\n",
      "of\n",
      "input\n",
      "as\n",
      "being\n",
      "identical\n",
      "to\n",
      "each\n",
      "other\n",
      "in\n",
      "terms\n",
      "of\n",
      "its\n",
      "textual\n",
      "equivalent\n",
      ".\n",
      "Speech\n",
      "segmentation\n",
      "Given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "people\n",
      "speaking\n",
      ",\n",
      "separate\n",
      "it\n",
      "into\n",
      "words\n",
      ".\n",
      "A\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognition\n",
      "and\n",
      "typically\n",
      "grouped\n",
      "with\n",
      "it\n",
      ".\n",
      "Text-to-speech\n",
      "Given\n",
      "a\n",
      "text\n",
      ",\n",
      "transform\n",
      "those\n",
      "units\n",
      "and\n",
      "produce\n",
      "a\n",
      "spoken\n",
      "representation\n",
      ".\n",
      "Text-to-speech\n",
      "can\n",
      "be\n",
      "used\n",
      "to\n",
      "aid\n",
      "the\n",
      "visually\n",
      "impaired\n",
      ".\n",
      "[\n",
      "21\n",
      "]\n",
      "Word\n",
      "segmentation\n",
      "(\n",
      "Tokenization\n",
      ")\n",
      "Separate\n",
      "a\n",
      "chunk\n",
      "of\n",
      "continuous\n",
      "text\n",
      "into\n",
      "separate\n",
      "words\n",
      ".\n",
      "For\n",
      "a\n",
      "language\n",
      "like\n",
      "English\n",
      ",\n",
      "this\n",
      "is\n",
      "fairly\n",
      "trivial\n",
      ",\n",
      "since\n",
      "words\n",
      "are\n",
      "usually\n",
      "separated\n",
      "by\n",
      "spaces\n",
      ".\n",
      "However\n",
      ",\n",
      "some\n",
      "written\n",
      "languages\n",
      "like\n",
      "Chinese\n",
      ",\n",
      "Japanese\n",
      "and\n",
      "Thai\n",
      "do\n",
      "not\n",
      "mark\n",
      "word\n",
      "boundaries\n",
      "in\n",
      "such\n",
      "a\n",
      "fashion\n",
      ",\n",
      "and\n",
      "in\n",
      "those\n",
      "languages\n",
      "text\n",
      "segmentation\n",
      "is\n",
      "a\n",
      "significant\n",
      "task\n",
      "requiring\n",
      "knowledge\n",
      "of\n",
      "the\n",
      "vocabulary\n",
      "and\n",
      "morphology\n",
      "of\n",
      "words\n",
      "in\n",
      "the\n",
      "language\n",
      ".\n",
      "Sometimes\n",
      "this\n",
      "process\n",
      "is\n",
      "also\n",
      "used\n",
      "in\n",
      "cases\n",
      "like\n",
      "bag\n",
      "of\n",
      "words\n",
      "(\n",
      "BOW\n",
      ")\n",
      "creation\n",
      "in\n",
      "data\n",
      "mining\n",
      ".\n",
      "Morphological\n",
      "analysis\n",
      "[\n",
      "edit\n",
      "]\n",
      "Lemmatization\n",
      "The\n",
      "task\n",
      "of\n",
      "removing\n",
      "inflectional\n",
      "endings\n",
      "only\n",
      "and\n",
      "to\n",
      "return\n",
      "the\n",
      "base\n",
      "dictionary\n",
      "form\n",
      "of\n",
      "a\n",
      "word\n",
      "which\n",
      "is\n",
      "also\n",
      "known\n",
      "as\n",
      "a\n",
      "lemma\n",
      ".\n",
      "Lemmatization\n",
      "is\n",
      "another\n",
      "technique\n",
      "for\n",
      "reducing\n",
      "words\n",
      "to\n",
      "their\n",
      "normalized\n",
      "form\n",
      ".\n",
      "But\n",
      "in\n",
      "this\n",
      "case\n",
      ",\n",
      "the\n",
      "transformation\n",
      "actually\n",
      "uses\n",
      "a\n",
      "dictionary\n",
      "to\n",
      "map\n",
      "words\n",
      "to\n",
      "their\n",
      "actual\n",
      "form\n",
      ".\n",
      "[\n",
      "22\n",
      "]\n",
      "Morphological\n",
      "segmentation\n",
      "Separate\n",
      "words\n",
      "into\n",
      "individual\n",
      "morphemes\n",
      "and\n",
      "identify\n",
      "the\n",
      "class\n",
      "of\n",
      "the\n",
      "morphemes\n",
      ".\n",
      "The\n",
      "difficulty\n",
      "of\n",
      "this\n",
      "task\n",
      "depends\n",
      "greatly\n",
      "on\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "morphology\n",
      "(\n",
      "i.e\n",
      ".\n",
      ",\n",
      "the\n",
      "structure\n",
      "of\n",
      "words\n",
      ")\n",
      "of\n",
      "the\n",
      "language\n",
      "being\n",
      "considered\n",
      ".\n",
      "English\n",
      "has\n",
      "fairly\n",
      "simple\n",
      "morphology\n",
      ",\n",
      "especially\n",
      "inflectional\n",
      "morphology\n",
      ",\n",
      "and\n",
      "thus\n",
      "it\n",
      "is\n",
      "often\n",
      "possible\n",
      "to\n",
      "ignore\n",
      "this\n",
      "task\n",
      "entirely\n",
      "and\n",
      "simply\n",
      "model\n",
      "all\n",
      "possible\n",
      "forms\n",
      "of\n",
      "a\n",
      "word\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "open\n",
      ",\n",
      "opens\n",
      ",\n",
      "opened\n",
      ",\n",
      "opening\n",
      "''\n",
      ")\n",
      "as\n",
      "separate\n",
      "words\n",
      ".\n",
      "In\n",
      "languages\n",
      "such\n",
      "as\n",
      "Turkish\n",
      "or\n",
      "Meitei\n",
      ",\n",
      "[\n",
      "23\n",
      "]\n",
      "a\n",
      "highly\n",
      "agglutinated\n",
      "Indian\n",
      "language\n",
      ",\n",
      "however\n",
      ",\n",
      "such\n",
      "an\n",
      "approach\n",
      "is\n",
      "not\n",
      "possible\n",
      ",\n",
      "as\n",
      "each\n",
      "dictionary\n",
      "entry\n",
      "has\n",
      "thousands\n",
      "of\n",
      "possible\n",
      "word\n",
      "forms\n",
      ".\n",
      "Part-of-speech\n",
      "tagging\n",
      "Given\n",
      "a\n",
      "sentence\n",
      ",\n",
      "determine\n",
      "the\n",
      "part\n",
      "of\n",
      "speech\n",
      "(\n",
      "POS\n",
      ")\n",
      "for\n",
      "each\n",
      "word\n",
      ".\n",
      "Many\n",
      "words\n",
      ",\n",
      "especially\n",
      "common\n",
      "ones\n",
      ",\n",
      "can\n",
      "serve\n",
      "as\n",
      "multiple\n",
      "parts\n",
      "of\n",
      "speech\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "``\n",
      "book\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      "(\n",
      "``\n",
      "the\n",
      "book\n",
      "on\n",
      "the\n",
      "table\n",
      "''\n",
      ")\n",
      "or\n",
      "verb\n",
      "(\n",
      "``\n",
      "to\n",
      "book\n",
      "a\n",
      "flight\n",
      "''\n",
      ")\n",
      ";\n",
      "``\n",
      "set\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      ",\n",
      "verb\n",
      "or\n",
      "adjective\n",
      ";\n",
      "and\n",
      "``\n",
      "out\n",
      "''\n",
      "can\n",
      "be\n",
      "any\n",
      "of\n",
      "at\n",
      "least\n",
      "five\n",
      "different\n",
      "parts\n",
      "of\n",
      "speech\n",
      ".\n",
      "Stemming\n",
      "The\n",
      "process\n",
      "of\n",
      "reducing\n",
      "inflected\n",
      "(\n",
      "or\n",
      "sometimes\n",
      "derived\n",
      ")\n",
      "words\n",
      "to\n",
      "a\n",
      "base\n",
      "form\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      "will\n",
      "be\n",
      "the\n",
      "root\n",
      "for\n",
      "``\n",
      "closed\n",
      "''\n",
      ",\n",
      "``\n",
      "closing\n",
      "''\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      ",\n",
      "``\n",
      "closer\n",
      "''\n",
      "etc.\n",
      ")\n",
      ".\n",
      "Stemming\n",
      "yields\n",
      "similar\n",
      "results\n",
      "as\n",
      "lemmatization\n",
      ",\n",
      "but\n",
      "does\n",
      "so\n",
      "on\n",
      "grounds\n",
      "of\n",
      "rules\n",
      ",\n",
      "not\n",
      "a\n",
      "dictionary\n",
      ".\n",
      "Syntactic\n",
      "analysis\n",
      "[\n",
      "edit\n",
      "]\n",
      "Grammar\n",
      "induction\n",
      "[\n",
      "24\n",
      "]\n",
      "Generate\n",
      "a\n",
      "formal\n",
      "grammar\n",
      "that\n",
      "describes\n",
      "a\n",
      "language\n",
      "'s\n",
      "syntax\n",
      ".\n",
      "Sentence\n",
      "breaking\n",
      "(\n",
      "also\n",
      "known\n",
      "as\n",
      "``\n",
      "sentence\n",
      "boundary\n",
      "disambiguation\n",
      "``\n",
      ")\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "find\n",
      "the\n",
      "sentence\n",
      "boundaries\n",
      ".\n",
      "Sentence\n",
      "boundaries\n",
      "are\n",
      "often\n",
      "marked\n",
      "by\n",
      "periods\n",
      "or\n",
      "other\n",
      "punctuation\n",
      "marks\n",
      ",\n",
      "but\n",
      "these\n",
      "same\n",
      "characters\n",
      "can\n",
      "serve\n",
      "other\n",
      "purposes\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "marking\n",
      "abbreviations\n",
      ")\n",
      ".\n",
      "Parsing\n",
      "Determine\n",
      "the\n",
      "parse\n",
      "tree\n",
      "(\n",
      "grammatical\n",
      "analysis\n",
      ")\n",
      "of\n",
      "a\n",
      "given\n",
      "sentence\n",
      ".\n",
      "The\n",
      "grammar\n",
      "for\n",
      "natural\n",
      "languages\n",
      "is\n",
      "ambiguous\n",
      "and\n",
      "typical\n",
      "sentences\n",
      "have\n",
      "multiple\n",
      "possible\n",
      "analyses\n",
      ":\n",
      "perhaps\n",
      "surprisingly\n",
      ",\n",
      "for\n",
      "a\n",
      "typical\n",
      "sentence\n",
      "there\n",
      "may\n",
      "be\n",
      "thousands\n",
      "of\n",
      "potential\n",
      "parses\n",
      "(\n",
      "most\n",
      "of\n",
      "which\n",
      "will\n",
      "seem\n",
      "completely\n",
      "nonsensical\n",
      "to\n",
      "a\n",
      "human\n",
      ")\n",
      ".\n",
      "There\n",
      "are\n",
      "two\n",
      "primary\n",
      "types\n",
      "of\n",
      "parsing\n",
      ":\n",
      "dependency\n",
      "parsing\n",
      "and\n",
      "constituency\n",
      "parsing\n",
      ".\n",
      "Dependency\n",
      "parsing\n",
      "focuses\n",
      "on\n",
      "the\n",
      "relationships\n",
      "between\n",
      "words\n",
      "in\n",
      "a\n",
      "sentence\n",
      "(\n",
      "marking\n",
      "things\n",
      "like\n",
      "primary\n",
      "objects\n",
      "and\n",
      "predicates\n",
      ")\n",
      ",\n",
      "whereas\n",
      "constituency\n",
      "parsing\n",
      "focuses\n",
      "on\n",
      "building\n",
      "out\n",
      "the\n",
      "parse\n",
      "tree\n",
      "using\n",
      "a\n",
      "probabilistic\n",
      "context-free\n",
      "grammar\n",
      "(\n",
      "PCFG\n",
      ")\n",
      "(\n",
      "see\n",
      "also\n",
      "stochastic\n",
      "grammar\n",
      ")\n",
      ".\n",
      "Lexical\n",
      "semantics\n",
      "(\n",
      "of\n",
      "individual\n",
      "words\n",
      "in\n",
      "context\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Lexical\n",
      "semantics\n",
      "What\n",
      "is\n",
      "the\n",
      "computational\n",
      "meaning\n",
      "of\n",
      "individual\n",
      "words\n",
      "in\n",
      "context\n",
      "?\n",
      "Distributional\n",
      "semantics\n",
      "How\n",
      "can\n",
      "we\n",
      "learn\n",
      "semantic\n",
      "representations\n",
      "from\n",
      "data\n",
      "?\n",
      "Named\n",
      "entity\n",
      "recognition\n",
      "(\n",
      "NER\n",
      ")\n",
      "Given\n",
      "a\n",
      "stream\n",
      "of\n",
      "text\n",
      ",\n",
      "determine\n",
      "which\n",
      "items\n",
      "in\n",
      "the\n",
      "text\n",
      "map\n",
      "to\n",
      "proper\n",
      "names\n",
      ",\n",
      "such\n",
      "as\n",
      "people\n",
      "or\n",
      "places\n",
      ",\n",
      "and\n",
      "what\n",
      "the\n",
      "type\n",
      "of\n",
      "each\n",
      "such\n",
      "name\n",
      "is\n",
      "(\n",
      "e.g\n",
      ".\n",
      "person\n",
      ",\n",
      "location\n",
      ",\n",
      "organization\n",
      ")\n",
      ".\n",
      "Although\n",
      "capitalization\n",
      "can\n",
      "aid\n",
      "in\n",
      "recognizing\n",
      "named\n",
      "entities\n",
      "in\n",
      "languages\n",
      "such\n",
      "as\n",
      "English\n",
      ",\n",
      "this\n",
      "information\n",
      "can\n",
      "not\n",
      "aid\n",
      "in\n",
      "determining\n",
      "the\n",
      "type\n",
      "of\n",
      "named\n",
      "entity\n",
      ",\n",
      "and\n",
      "in\n",
      "any\n",
      "case\n",
      ",\n",
      "is\n",
      "often\n",
      "inaccurate\n",
      "or\n",
      "insufficient\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "the\n",
      "first\n",
      "letter\n",
      "of\n",
      "a\n",
      "sentence\n",
      "is\n",
      "also\n",
      "capitalized\n",
      ",\n",
      "and\n",
      "named\n",
      "entities\n",
      "often\n",
      "span\n",
      "several\n",
      "words\n",
      ",\n",
      "only\n",
      "some\n",
      "of\n",
      "which\n",
      "are\n",
      "capitalized\n",
      ".\n",
      "Furthermore\n",
      ",\n",
      "many\n",
      "other\n",
      "languages\n",
      "in\n",
      "non-Western\n",
      "scripts\n",
      "(\n",
      "e.g\n",
      ".\n",
      "Chinese\n",
      "or\n",
      "Arabic\n",
      ")\n",
      "do\n",
      "not\n",
      "have\n",
      "any\n",
      "capitalization\n",
      "at\n",
      "all\n",
      ",\n",
      "and\n",
      "even\n",
      "languages\n",
      "with\n",
      "capitalization\n",
      "may\n",
      "not\n",
      "consistently\n",
      "use\n",
      "it\n",
      "to\n",
      "distinguish\n",
      "names\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "German\n",
      "capitalizes\n",
      "all\n",
      "nouns\n",
      ",\n",
      "regardless\n",
      "of\n",
      "whether\n",
      "they\n",
      "are\n",
      "names\n",
      ",\n",
      "and\n",
      "French\n",
      "and\n",
      "Spanish\n",
      "do\n",
      "not\n",
      "capitalize\n",
      "names\n",
      "that\n",
      "serve\n",
      "as\n",
      "adjectives\n",
      ".\n",
      "Sentiment\n",
      "analysis\n",
      "(\n",
      "see\n",
      "also\n",
      "Multimodal\n",
      "sentiment\n",
      "analysis\n",
      ")\n",
      "Extract\n",
      "subjective\n",
      "information\n",
      "usually\n",
      "from\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      ",\n",
      "often\n",
      "using\n",
      "online\n",
      "reviews\n",
      "to\n",
      "determine\n",
      "``\n",
      "polarity\n",
      "''\n",
      "about\n",
      "specific\n",
      "objects\n",
      ".\n",
      "It\n",
      "is\n",
      "especially\n",
      "useful\n",
      "for\n",
      "identifying\n",
      "trends\n",
      "of\n",
      "public\n",
      "opinion\n",
      "in\n",
      "social\n",
      "media\n",
      ",\n",
      "for\n",
      "marketing\n",
      ".\n",
      "Terminology\n",
      "extraction\n",
      "The\n",
      "goal\n",
      "of\n",
      "terminology\n",
      "extraction\n",
      "is\n",
      "to\n",
      "automatically\n",
      "extract\n",
      "relevant\n",
      "terms\n",
      "from\n",
      "a\n",
      "given\n",
      "corpus\n",
      ".\n",
      "Word\n",
      "sense\n",
      "disambiguation\n",
      "(\n",
      "WSD\n",
      ")\n",
      "Many\n",
      "words\n",
      "have\n",
      "more\n",
      "than\n",
      "one\n",
      "meaning\n",
      ";\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "meaning\n",
      "which\n",
      "makes\n",
      "the\n",
      "most\n",
      "sense\n",
      "in\n",
      "context\n",
      ".\n",
      "For\n",
      "this\n",
      "problem\n",
      ",\n",
      "we\n",
      "are\n",
      "typically\n",
      "given\n",
      "a\n",
      "list\n",
      "of\n",
      "words\n",
      "and\n",
      "associated\n",
      "word\n",
      "senses\n",
      ",\n",
      "e.g\n",
      ".\n",
      "from\n",
      "a\n",
      "dictionary\n",
      "or\n",
      "an\n",
      "online\n",
      "resource\n",
      "such\n",
      "as\n",
      "WordNet\n",
      ".\n",
      "Entity\n",
      "linking\n",
      "Many\n",
      "words\n",
      "-\n",
      "typically\n",
      "proper\n",
      "names\n",
      "-\n",
      "refer\n",
      "to\n",
      "named\n",
      "entities\n",
      ";\n",
      "here\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "entity\n",
      "(\n",
      "a\n",
      "famous\n",
      "individual\n",
      ",\n",
      "a\n",
      "location\n",
      ",\n",
      "a\n",
      "company\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "which\n",
      "is\n",
      "referred\n",
      "to\n",
      "in\n",
      "context\n",
      ".\n",
      "Relational\n",
      "semantics\n",
      "(\n",
      "semantics\n",
      "of\n",
      "individual\n",
      "sentences\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Relationship\n",
      "extraction\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "identify\n",
      "the\n",
      "relationships\n",
      "among\n",
      "named\n",
      "entities\n",
      "(\n",
      "e.g\n",
      ".\n",
      "who\n",
      "is\n",
      "married\n",
      "to\n",
      "whom\n",
      ")\n",
      ".\n",
      "Semantic\n",
      "parsing\n",
      "Given\n",
      "a\n",
      "piece\n",
      "of\n",
      "text\n",
      "(\n",
      "typically\n",
      "a\n",
      "sentence\n",
      ")\n",
      ",\n",
      "produce\n",
      "a\n",
      "formal\n",
      "representation\n",
      "of\n",
      "its\n",
      "semantics\n",
      ",\n",
      "either\n",
      "as\n",
      "a\n",
      "graph\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "AMR\n",
      "parsing\n",
      ")\n",
      "or\n",
      "in\n",
      "accordance\n",
      "with\n",
      "a\n",
      "logical\n",
      "formalism\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "DRT\n",
      "parsing\n",
      ")\n",
      ".\n",
      "This\n",
      "challenge\n",
      "typically\n",
      "includes\n",
      "aspects\n",
      "of\n",
      "several\n",
      "more\n",
      "elementary\n",
      "NLP\n",
      "tasks\n",
      "from\n",
      "semantics\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      ",\n",
      "word\n",
      "sense\n",
      "disambiguation\n",
      ")\n",
      "and\n",
      "can\n",
      "be\n",
      "extended\n",
      "to\n",
      "include\n",
      "full-fledged\n",
      "discourse\n",
      "analysis\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "discourse\n",
      "analysis\n",
      ",\n",
      "coreference\n",
      ";\n",
      "see\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "below\n",
      ")\n",
      ".\n",
      "Semantic\n",
      "role\n",
      "labelling\n",
      "(\n",
      "see\n",
      "also\n",
      "implicit\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      "below\n",
      ")\n",
      "Given\n",
      "a\n",
      "single\n",
      "sentence\n",
      ",\n",
      "identify\n",
      "and\n",
      "disambiguate\n",
      "semantic\n",
      "predicates\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frames\n",
      ")\n",
      ",\n",
      "then\n",
      "identify\n",
      "and\n",
      "classify\n",
      "the\n",
      "frame\n",
      "elements\n",
      "(\n",
      "semantic\n",
      "roles\n",
      ")\n",
      ".\n",
      "Discourse\n",
      "(\n",
      "semantics\n",
      "beyond\n",
      "individual\n",
      "sentences\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Coreference\n",
      "resolution\n",
      "Given\n",
      "a\n",
      "sentence\n",
      "or\n",
      "larger\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "determine\n",
      "which\n",
      "words\n",
      "(\n",
      "``\n",
      "mentions\n",
      "''\n",
      ")\n",
      "refer\n",
      "to\n",
      "the\n",
      "same\n",
      "objects\n",
      "(\n",
      "``\n",
      "entities\n",
      "''\n",
      ")\n",
      ".\n",
      "Anaphora\n",
      "resolution\n",
      "is\n",
      "a\n",
      "specific\n",
      "example\n",
      "of\n",
      "this\n",
      "task\n",
      ",\n",
      "and\n",
      "is\n",
      "specifically\n",
      "concerned\n",
      "with\n",
      "matching\n",
      "up\n",
      "pronouns\n",
      "with\n",
      "the\n",
      "nouns\n",
      "or\n",
      "names\n",
      "to\n",
      "which\n",
      "they\n",
      "refer\n",
      ".\n",
      "The\n",
      "more\n",
      "general\n",
      "task\n",
      "of\n",
      "coreference\n",
      "resolution\n",
      "also\n",
      "includes\n",
      "identifying\n",
      "so-called\n",
      "``\n",
      "bridging\n",
      "relationships\n",
      "''\n",
      "involving\n",
      "referring\n",
      "expressions\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "in\n",
      "a\n",
      "sentence\n",
      "such\n",
      "as\n",
      "``\n",
      "He\n",
      "entered\n",
      "John\n",
      "'s\n",
      "house\n",
      "through\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      ",\n",
      "``\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      "is\n",
      "a\n",
      "referring\n",
      "expression\n",
      "and\n",
      "the\n",
      "bridging\n",
      "relationship\n",
      "to\n",
      "be\n",
      "identified\n",
      "is\n",
      "the\n",
      "fact\n",
      "that\n",
      "the\n",
      "door\n",
      "being\n",
      "referred\n",
      "to\n",
      "is\n",
      "the\n",
      "front\n",
      "door\n",
      "of\n",
      "John\n",
      "'s\n",
      "house\n",
      "(\n",
      "rather\n",
      "than\n",
      "of\n",
      "some\n",
      "other\n",
      "structure\n",
      "that\n",
      "might\n",
      "also\n",
      "be\n",
      "referred\n",
      "to\n",
      ")\n",
      ".\n",
      "Discourse\n",
      "analysis\n",
      "This\n",
      "rubric\n",
      "includes\n",
      "several\n",
      "related\n",
      "tasks\n",
      ".\n",
      "One\n",
      "task\n",
      "is\n",
      "discourse\n",
      "parsing\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "identifying\n",
      "the\n",
      "discourse\n",
      "structure\n",
      "of\n",
      "a\n",
      "connected\n",
      "text\n",
      ",\n",
      "i.e\n",
      ".\n",
      "the\n",
      "nature\n",
      "of\n",
      "the\n",
      "discourse\n",
      "relationships\n",
      "between\n",
      "sentences\n",
      "(\n",
      "e.g\n",
      ".\n",
      "elaboration\n",
      ",\n",
      "explanation\n",
      ",\n",
      "contrast\n",
      ")\n",
      ".\n",
      "Another\n",
      "possible\n",
      "task\n",
      "is\n",
      "recognizing\n",
      "and\n",
      "classifying\n",
      "the\n",
      "speech\n",
      "acts\n",
      "in\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      "(\n",
      "e.g\n",
      ".\n",
      "yes-no\n",
      "question\n",
      ",\n",
      "content\n",
      "question\n",
      ",\n",
      "statement\n",
      ",\n",
      "assertion\n",
      ",\n",
      "etc.\n",
      ")\n",
      ".\n",
      "Implicit\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      "Given\n",
      "a\n",
      "single\n",
      "sentence\n",
      ",\n",
      "identify\n",
      "and\n",
      "disambiguate\n",
      "semantic\n",
      "predicates\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frames\n",
      ")\n",
      "and\n",
      "their\n",
      "explicit\n",
      "semantic\n",
      "roles\n",
      "in\n",
      "the\n",
      "current\n",
      "sentence\n",
      "(\n",
      "see\n",
      "Semantic\n",
      "role\n",
      "labelling\n",
      "above\n",
      ")\n",
      ".\n",
      "Then\n",
      ",\n",
      "identify\n",
      "semantic\n",
      "roles\n",
      "that\n",
      "are\n",
      "not\n",
      "explicitly\n",
      "realized\n",
      "in\n",
      "the\n",
      "current\n",
      "sentence\n",
      ",\n",
      "classify\n",
      "them\n",
      "into\n",
      "arguments\n",
      "that\n",
      "are\n",
      "explicitly\n",
      "realized\n",
      "elsewhere\n",
      "in\n",
      "the\n",
      "text\n",
      "and\n",
      "those\n",
      "that\n",
      "are\n",
      "not\n",
      "specified\n",
      ",\n",
      "and\n",
      "resolve\n",
      "the\n",
      "former\n",
      "against\n",
      "the\n",
      "local\n",
      "text\n",
      ".\n",
      "A\n",
      "closely\n",
      "related\n",
      "task\n",
      "is\n",
      "zero\n",
      "anaphora\n",
      "resolution\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "extension\n",
      "of\n",
      "coreference\n",
      "resolution\n",
      "to\n",
      "pro-drop\n",
      "languages\n",
      ".\n",
      "Recognizing\n",
      "textual\n",
      "entailment\n",
      "Given\n",
      "two\n",
      "text\n",
      "fragments\n",
      ",\n",
      "determine\n",
      "if\n",
      "one\n",
      "being\n",
      "true\n",
      "entails\n",
      "the\n",
      "other\n",
      ",\n",
      "entails\n",
      "the\n",
      "other\n",
      "'s\n",
      "negation\n",
      ",\n",
      "or\n",
      "allows\n",
      "the\n",
      "other\n",
      "to\n",
      "be\n",
      "either\n",
      "true\n",
      "or\n",
      "false\n",
      ".\n",
      "[\n",
      "25\n",
      "]\n",
      "Topic\n",
      "segmentation\n",
      "and\n",
      "recognition\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "separate\n",
      "it\n",
      "into\n",
      "segments\n",
      "each\n",
      "of\n",
      "which\n",
      "is\n",
      "devoted\n",
      "to\n",
      "a\n",
      "topic\n",
      ",\n",
      "and\n",
      "identify\n",
      "the\n",
      "topic\n",
      "of\n",
      "the\n",
      "segment\n",
      ".\n",
      "Argument\n",
      "mining\n",
      "The\n",
      "goal\n",
      "of\n",
      "argument\n",
      "mining\n",
      "is\n",
      "the\n",
      "automatic\n",
      "extraction\n",
      "and\n",
      "identification\n",
      "of\n",
      "argumentative\n",
      "structures\n",
      "from\n",
      "natural\n",
      "language\n",
      "text\n",
      "with\n",
      "the\n",
      "aid\n",
      "of\n",
      "computer\n",
      "programs\n",
      ".\n",
      "[\n",
      "26\n",
      "]\n",
      "Such\n",
      "argumentative\n",
      "structures\n",
      "include\n",
      "the\n",
      "premise\n",
      ",\n",
      "conclusions\n",
      ",\n",
      "the\n",
      "argument\n",
      "scheme\n",
      "and\n",
      "the\n",
      "relationship\n",
      "between\n",
      "the\n",
      "main\n",
      "and\n",
      "subsidiary\n",
      "argument\n",
      ",\n",
      "or\n",
      "the\n",
      "main\n",
      "and\n",
      "counter-argument\n",
      "within\n",
      "discourse\n",
      ".\n",
      "[\n",
      "27\n",
      "]\n",
      "[\n",
      "28\n",
      "]\n",
      "Higher-level\n",
      "NLP\n",
      "applications\n",
      "[\n",
      "edit\n",
      "]\n",
      "Automatic\n",
      "summarization\n",
      "(\n",
      "text\n",
      "summarization\n",
      ")\n",
      "Produce\n",
      "a\n",
      "readable\n",
      "summary\n",
      "of\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ".\n",
      "Often\n",
      "used\n",
      "to\n",
      "provide\n",
      "summaries\n",
      "of\n",
      "the\n",
      "text\n",
      "of\n",
      "a\n",
      "known\n",
      "type\n",
      ",\n",
      "such\n",
      "as\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research\n",
      "papers\n",
      ",\n",
      "articles\n",
      "in\n",
      "the\n",
      "financial\n",
      "section\n",
      "of\n",
      "a\n",
      "newspaper\n",
      ".\n",
      "Book\n",
      "generation\n",
      "Not\n",
      "an\n",
      "NLP\n",
      "task\n",
      "proper\n",
      "but\n",
      "an\n",
      "extension\n",
      "of\n",
      "natural\n",
      "language\n",
      "generation\n",
      "and\n",
      "other\n",
      "NLP\n",
      "tasks\n",
      "is\n",
      "the\n",
      "creation\n",
      "of\n",
      "full-fledged\n",
      "books\n",
      ".\n",
      "The\n",
      "first\n",
      "machine-generated\n",
      "book\n",
      "was\n",
      "created\n",
      "by\n",
      "a\n",
      "rule-based\n",
      "system\n",
      "in\n",
      "1984\n",
      "(\n",
      "Racter\n",
      ",\n",
      "The\n",
      "policeman\n",
      "'s\n",
      "beard\n",
      "is\n",
      "half-constructed\n",
      ")\n",
      ".\n",
      "[\n",
      "29\n",
      "]\n",
      "The\n",
      "first\n",
      "published\n",
      "work\n",
      "by\n",
      "a\n",
      "neural\n",
      "network\n",
      "was\n",
      "published\n",
      "in\n",
      "2018\n",
      ",\n",
      "1\n",
      "the\n",
      "Road\n",
      ",\n",
      "marketed\n",
      "as\n",
      "a\n",
      "novel\n",
      ",\n",
      "contains\n",
      "sixty\n",
      "million\n",
      "words\n",
      ".\n",
      "Both\n",
      "these\n",
      "systems\n",
      "are\n",
      "basically\n",
      "elaborate\n",
      "but\n",
      "non-sensical\n",
      "(\n",
      "semantics-free\n",
      ")\n",
      "language\n",
      "models\n",
      ".\n",
      "The\n",
      "first\n",
      "machine-generated\n",
      "science\n",
      "book\n",
      "was\n",
      "published\n",
      "in\n",
      "2019\n",
      "(\n",
      "Beta\n",
      "Writer\n",
      ",\n",
      "Lithium-Ion\n",
      "Batteries\n",
      ",\n",
      "Springer\n",
      ",\n",
      "Cham\n",
      ")\n",
      ".\n",
      "[\n",
      "30\n",
      "]\n",
      "Unlike\n",
      "Racter\n",
      "and\n",
      "1\n",
      "the\n",
      "Road\n",
      ",\n",
      "this\n",
      "is\n",
      "grounded\n",
      "on\n",
      "factual\n",
      "knowledge\n",
      "and\n",
      "based\n",
      "on\n",
      "text\n",
      "summarization\n",
      ".\n",
      "Dialogue\n",
      "management\n",
      "Computer\n",
      "systems\n",
      "intended\n",
      "to\n",
      "converse\n",
      "with\n",
      "a\n",
      "human\n",
      ".\n",
      "Document\n",
      "AI\n",
      "A\n",
      "Document\n",
      "AI\n",
      "platform\n",
      "sits\n",
      "on\n",
      "top\n",
      "of\n",
      "the\n",
      "NLP\n",
      "technology\n",
      "enabling\n",
      "users\n",
      "with\n",
      "no\n",
      "prior\n",
      "experience\n",
      "of\n",
      "artificial\n",
      "intelligence\n",
      ",\n",
      "machine\n",
      "learning\n",
      "or\n",
      "NLP\n",
      "to\n",
      "quickly\n",
      "train\n",
      "a\n",
      "computer\n",
      "to\n",
      "extract\n",
      "the\n",
      "specific\n",
      "data\n",
      "they\n",
      "need\n",
      "from\n",
      "different\n",
      "document\n",
      "types\n",
      ".\n",
      "NLP-powered\n",
      "Document\n",
      "AI\n",
      "enables\n",
      "non-technical\n",
      "teams\n",
      "to\n",
      "quickly\n",
      "access\n",
      "information\n",
      "hidden\n",
      "in\n",
      "documents\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "lawyers\n",
      ",\n",
      "business\n",
      "analysts\n",
      "and\n",
      "accountants\n",
      ".\n",
      "[\n",
      "31\n",
      "]\n",
      "Grammatical\n",
      "error\n",
      "correction\n",
      "Grammatical\n",
      "error\n",
      "detection\n",
      "and\n",
      "correction\n",
      "involves\n",
      "a\n",
      "great\n",
      "band-width\n",
      "of\n",
      "problems\n",
      "on\n",
      "all\n",
      "levels\n",
      "of\n",
      "linguistic\n",
      "analysis\n",
      "(\n",
      "phonology/orthography\n",
      ",\n",
      "morphology\n",
      ",\n",
      "syntax\n",
      ",\n",
      "semantics\n",
      ",\n",
      "pragmatics\n",
      ")\n",
      ".\n",
      "Grammatical\n",
      "error\n",
      "correction\n",
      "is\n",
      "impactful\n",
      "since\n",
      "it\n",
      "affects\n",
      "hundreds\n",
      "of\n",
      "millions\n",
      "of\n",
      "people\n",
      "that\n",
      "use\n",
      "or\n",
      "acquire\n",
      "English\n",
      "as\n",
      "a\n",
      "second\n",
      "language\n",
      ".\n",
      "It\n",
      "has\n",
      "thus\n",
      "been\n",
      "subject\n",
      "to\n",
      "a\n",
      "number\n",
      "of\n",
      "shared\n",
      "tasks\n",
      "since\n",
      "2011\n",
      ".\n",
      "[\n",
      "32\n",
      "]\n",
      "[\n",
      "33\n",
      "]\n",
      "[\n",
      "34\n",
      "]\n",
      "As\n",
      "far\n",
      "as\n",
      "orthography\n",
      ",\n",
      "morphology\n",
      ",\n",
      "syntax\n",
      "and\n",
      "certain\n",
      "aspects\n",
      "of\n",
      "semantics\n",
      "are\n",
      "concerned\n",
      ",\n",
      "and\n",
      "due\n",
      "to\n",
      "the\n",
      "development\n",
      "of\n",
      "powerful\n",
      "neural\n",
      "language\n",
      "models\n",
      "such\n",
      "as\n",
      "GPT-2\n",
      ",\n",
      "this\n",
      "can\n",
      "now\n",
      "(\n",
      "2019\n",
      ")\n",
      "be\n",
      "considered\n",
      "a\n",
      "largely\n",
      "solved\n",
      "problem\n",
      "and\n",
      "is\n",
      "being\n",
      "marketed\n",
      "in\n",
      "various\n",
      "commercial\n",
      "applications\n",
      ".\n",
      "Machine\n",
      "translation\n",
      "Automatically\n",
      "translate\n",
      "text\n",
      "from\n",
      "one\n",
      "human\n",
      "language\n",
      "to\n",
      "another\n",
      ".\n",
      "This\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "difficult\n",
      "problems\n",
      ",\n",
      "and\n",
      "is\n",
      "a\n",
      "member\n",
      "of\n",
      "a\n",
      "class\n",
      "of\n",
      "problems\n",
      "colloquially\n",
      "termed\n",
      "``\n",
      "AI-complete\n",
      "``\n",
      ",\n",
      "i.e\n",
      ".\n",
      "requiring\n",
      "all\n",
      "of\n",
      "the\n",
      "different\n",
      "types\n",
      "of\n",
      "knowledge\n",
      "that\n",
      "humans\n",
      "possess\n",
      "(\n",
      "grammar\n",
      ",\n",
      "semantics\n",
      ",\n",
      "facts\n",
      "about\n",
      "the\n",
      "real\n",
      "world\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "to\n",
      "solve\n",
      "properly\n",
      ".\n",
      "Natural\n",
      "language\n",
      "generation\n",
      "(\n",
      "NLG\n",
      ")\n",
      ":\n",
      "Convert\n",
      "information\n",
      "from\n",
      "computer\n",
      "databases\n",
      "or\n",
      "semantic\n",
      "intents\n",
      "into\n",
      "readable\n",
      "human\n",
      "language\n",
      ".\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "NLU\n",
      ")\n",
      "Convert\n",
      "chunks\n",
      "of\n",
      "text\n",
      "into\n",
      "more\n",
      "formal\n",
      "representations\n",
      "such\n",
      "as\n",
      "first-order\n",
      "logic\n",
      "structures\n",
      "that\n",
      "are\n",
      "easier\n",
      "for\n",
      "computer\n",
      "programs\n",
      "to\n",
      "manipulate\n",
      ".\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "involves\n",
      "the\n",
      "identification\n",
      "of\n",
      "the\n",
      "intended\n",
      "semantic\n",
      "from\n",
      "the\n",
      "multiple\n",
      "possible\n",
      "semantics\n",
      "which\n",
      "can\n",
      "be\n",
      "derived\n",
      "from\n",
      "a\n",
      "natural\n",
      "language\n",
      "expression\n",
      "which\n",
      "usually\n",
      "takes\n",
      "the\n",
      "form\n",
      "of\n",
      "organized\n",
      "notations\n",
      "of\n",
      "natural\n",
      "language\n",
      "concepts\n",
      ".\n",
      "Introduction\n",
      "and\n",
      "creation\n",
      "of\n",
      "language\n",
      "metamodel\n",
      "and\n",
      "ontology\n",
      "are\n",
      "efficient\n",
      "however\n",
      "empirical\n",
      "solutions\n",
      ".\n",
      "An\n",
      "explicit\n",
      "formalization\n",
      "of\n",
      "natural\n",
      "language\n",
      "semantics\n",
      "without\n",
      "confusions\n",
      "with\n",
      "implicit\n",
      "assumptions\n",
      "such\n",
      "as\n",
      "closed-world\n",
      "assumption\n",
      "(\n",
      "CWA\n",
      ")\n",
      "vs.\n",
      "open-world\n",
      "assumption\n",
      ",\n",
      "or\n",
      "subjective\n",
      "Yes/No\n",
      "vs.\n",
      "objective\n",
      "True/False\n",
      "is\n",
      "expected\n",
      "for\n",
      "the\n",
      "construction\n",
      "of\n",
      "a\n",
      "basis\n",
      "of\n",
      "semantics\n",
      "formalization\n",
      ".\n",
      "[\n",
      "35\n",
      "]\n",
      "Question\n",
      "answering\n",
      "Given\n",
      "a\n",
      "human-language\n",
      "question\n",
      ",\n",
      "determine\n",
      "its\n",
      "answer\n",
      ".\n",
      "Typical\n",
      "questions\n",
      "have\n",
      "a\n",
      "specific\n",
      "right\n",
      "answer\n",
      "(\n",
      "such\n",
      "as\n",
      "``\n",
      "What\n",
      "is\n",
      "the\n",
      "capital\n",
      "of\n",
      "Canada\n",
      "?\n",
      "``\n",
      ")\n",
      ",\n",
      "but\n",
      "sometimes\n",
      "open-ended\n",
      "questions\n",
      "are\n",
      "also\n",
      "considered\n",
      "(\n",
      "such\n",
      "as\n",
      "``\n",
      "What\n",
      "is\n",
      "the\n",
      "meaning\n",
      "of\n",
      "life\n",
      "?\n",
      "''\n",
      ")\n",
      ".\n",
      "General\n",
      "tendencies\n",
      "and\n",
      "(\n",
      "possible\n",
      ")\n",
      "future\n",
      "directions\n",
      "[\n",
      "edit\n",
      "]\n",
      "Based\n",
      "on\n",
      "long-standing\n",
      "trends\n",
      "in\n",
      "the\n",
      "field\n",
      ",\n",
      "it\n",
      "is\n",
      "possible\n",
      "to\n",
      "extrapolate\n",
      "future\n",
      "directions\n",
      "of\n",
      "NLP\n",
      ".\n",
      "As\n",
      "of\n",
      "2020\n",
      ",\n",
      "three\n",
      "trends\n",
      "among\n",
      "the\n",
      "topics\n",
      "of\n",
      "the\n",
      "long-standing\n",
      "series\n",
      "of\n",
      "CoNLL\n",
      "Shared\n",
      "Tasks\n",
      "can\n",
      "be\n",
      "observed\n",
      ":\n",
      "[\n",
      "36\n",
      "]\n",
      "Interest\n",
      "on\n",
      "increasingly\n",
      "abstract\n",
      ",\n",
      "``\n",
      "cognitive\n",
      "''\n",
      "aspects\n",
      "of\n",
      "natural\n",
      "language\n",
      "(\n",
      "1999-2001\n",
      ":\n",
      "shallow\n",
      "parsing\n",
      ",\n",
      "2002-03\n",
      ":\n",
      "named\n",
      "entity\n",
      "recognition\n",
      ",\n",
      "2006-09/2017-18\n",
      ":\n",
      "dependency\n",
      "syntax\n",
      ",\n",
      "2004-05/2008-09\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      ",\n",
      "2011-12\n",
      "coreference\n",
      ",\n",
      "2015-16\n",
      ":\n",
      "discourse\n",
      "parsing\n",
      ",\n",
      "2019\n",
      ":\n",
      "semantic\n",
      "parsing\n",
      ")\n",
      ".\n",
      "Increasing\n",
      "interest\n",
      "in\n",
      "multilinguality\n",
      ",\n",
      "and\n",
      ",\n",
      "potentially\n",
      ",\n",
      "multimodality\n",
      "(\n",
      "English\n",
      "since\n",
      "1999\n",
      ";\n",
      "Spanish\n",
      ",\n",
      "Dutch\n",
      "since\n",
      "2002\n",
      ";\n",
      "German\n",
      "since\n",
      "2003\n",
      ";\n",
      "Bulgarian\n",
      ",\n",
      "Danish\n",
      ",\n",
      "Japanese\n",
      ",\n",
      "Portuguese\n",
      ",\n",
      "Slovenian\n",
      ",\n",
      "Swedish\n",
      ",\n",
      "Turkish\n",
      "since\n",
      "2006\n",
      ";\n",
      "Basque\n",
      ",\n",
      "Catalan\n",
      ",\n",
      "Chinese\n",
      ",\n",
      "Greek\n",
      ",\n",
      "Hungarian\n",
      ",\n",
      "Italian\n",
      ",\n",
      "Turkish\n",
      "since\n",
      "2007\n",
      ";\n",
      "Czech\n",
      "since\n",
      "2009\n",
      ";\n",
      "Arabic\n",
      "since\n",
      "2012\n",
      ";\n",
      "2017\n",
      ":\n",
      "40+\n",
      "languages\n",
      ";\n",
      "2018\n",
      ":\n",
      "60+/100+\n",
      "languages\n",
      ")\n",
      "Elimination\n",
      "of\n",
      "symbolic\n",
      "representations\n",
      "(\n",
      "rule-based\n",
      "over\n",
      "supervised\n",
      "towards\n",
      "weakly\n",
      "supervised\n",
      "methods\n",
      ",\n",
      "representation\n",
      "learning\n",
      "and\n",
      "end-to-end\n",
      "systems\n",
      ")\n",
      "Cognition\n",
      "and\n",
      "NLP\n",
      "[\n",
      "edit\n",
      "]\n",
      "Most\n",
      "higher-level\n",
      "NLP\n",
      "applications\n",
      "involve\n",
      "aspects\n",
      "that\n",
      "emulate\n",
      "intelligent\n",
      "behaviour\n",
      "and\n",
      "apparent\n",
      "comprehension\n",
      "of\n",
      "natural\n",
      "language\n",
      ".\n",
      "More\n",
      "broadly\n",
      "speaking\n",
      ",\n",
      "the\n",
      "technical\n",
      "operationalization\n",
      "of\n",
      "increasingly\n",
      "advanced\n",
      "aspects\n",
      "of\n",
      "cognitive\n",
      "behaviour\n",
      "represents\n",
      "one\n",
      "of\n",
      "the\n",
      "developmental\n",
      "trajectories\n",
      "of\n",
      "NLP\n",
      "(\n",
      "see\n",
      "trends\n",
      "among\n",
      "CoNLL\n",
      "shared\n",
      "tasks\n",
      "above\n",
      ")\n",
      ".\n",
      "Cognition\n",
      "refers\n",
      "to\n",
      "``\n",
      "the\n",
      "mental\n",
      "action\n",
      "or\n",
      "process\n",
      "of\n",
      "acquiring\n",
      "knowledge\n",
      "and\n",
      "understanding\n",
      "through\n",
      "thought\n",
      ",\n",
      "experience\n",
      ",\n",
      "and\n",
      "the\n",
      "senses\n",
      ".\n",
      "''\n",
      "[\n",
      "37\n",
      "]\n",
      "Cognitive\n",
      "science\n",
      "is\n",
      "the\n",
      "interdisciplinary\n",
      ",\n",
      "scientific\n",
      "study\n",
      "of\n",
      "the\n",
      "mind\n",
      "and\n",
      "its\n",
      "processes\n",
      ".\n",
      "[\n",
      "38\n",
      "]\n",
      "Cognitive\n",
      "linguistics\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "branch\n",
      "of\n",
      "linguistics\n",
      ",\n",
      "combining\n",
      "knowledge\n",
      "and\n",
      "research\n",
      "from\n",
      "both\n",
      "psychology\n",
      "and\n",
      "linguistics\n",
      ".\n",
      "[\n",
      "39\n",
      "]\n",
      "Especially\n",
      "during\n",
      "the\n",
      "age\n",
      "of\n",
      "symbolic\n",
      "NLP\n",
      ",\n",
      "the\n",
      "area\n",
      "of\n",
      "computational\n",
      "linguistics\n",
      "maintained\n",
      "strong\n",
      "ties\n",
      "with\n",
      "cognitive\n",
      "studies\n",
      ".\n",
      "As\n",
      "an\n",
      "example\n",
      ",\n",
      "George\n",
      "Lakoff\n",
      "offers\n",
      "a\n",
      "methodology\n",
      "to\n",
      "build\n",
      "natural\n",
      "language\n",
      "processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "algorithms\n",
      "through\n",
      "the\n",
      "perspective\n",
      "of\n",
      "cognitive\n",
      "science\n",
      ",\n",
      "along\n",
      "with\n",
      "the\n",
      "findings\n",
      "of\n",
      "cognitive\n",
      "linguistics\n",
      ",\n",
      "[\n",
      "40\n",
      "]\n",
      "with\n",
      "two\n",
      "defining\n",
      "aspects\n",
      ":\n",
      "Apply\n",
      "the\n",
      "theory\n",
      "of\n",
      "conceptual\n",
      "metaphor\n",
      ",\n",
      "explained\n",
      "by\n",
      "Lakoff\n",
      "as\n",
      "“\n",
      "the\n",
      "understanding\n",
      "of\n",
      "one\n",
      "idea\n",
      ",\n",
      "in\n",
      "terms\n",
      "of\n",
      "another\n",
      "”\n",
      "which\n",
      "provides\n",
      "an\n",
      "idea\n",
      "of\n",
      "the\n",
      "intent\n",
      "of\n",
      "the\n",
      "author\n",
      ".\n",
      "[\n",
      "41\n",
      "]\n",
      "For\n",
      "example\n",
      ",\n",
      "consider\n",
      "the\n",
      "English\n",
      "word\n",
      "“\n",
      "big\n",
      "”\n",
      ".\n",
      "When\n",
      "used\n",
      "in\n",
      "a\n",
      "comparison\n",
      "(\n",
      "“\n",
      "That\n",
      "is\n",
      "a\n",
      "big\n",
      "tree\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "'s\n",
      "intent\n",
      "is\n",
      "to\n",
      "imply\n",
      "that\n",
      "the\n",
      "tree\n",
      "is\n",
      "”\n",
      "physically\n",
      "large\n",
      "”\n",
      "relative\n",
      "to\n",
      "other\n",
      "trees\n",
      "or\n",
      "the\n",
      "authors\n",
      "experience\n",
      ".\n",
      "When\n",
      "used\n",
      "metaphorically\n",
      "(\n",
      "”\n",
      "Tomorrow\n",
      "is\n",
      "a\n",
      "big\n",
      "day\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "’\n",
      "s\n",
      "intent\n",
      "to\n",
      "imply\n",
      "”\n",
      "importance\n",
      "”\n",
      ".\n",
      "The\n",
      "intent\n",
      "behind\n",
      "other\n",
      "usages\n",
      ",\n",
      "like\n",
      "in\n",
      "”\n",
      "She\n",
      "is\n",
      "a\n",
      "big\n",
      "person\n",
      "”\n",
      "will\n",
      "remain\n",
      "somewhat\n",
      "ambiguous\n",
      "to\n",
      "a\n",
      "person\n",
      "and\n",
      "a\n",
      "cognitive\n",
      "NLP\n",
      "algorithm\n",
      "alike\n",
      "without\n",
      "additional\n",
      "information\n",
      ".\n",
      "Assign\n",
      "relative\n",
      "measures\n",
      "of\n",
      "meaning\n",
      "to\n",
      "a\n",
      "word\n",
      ",\n",
      "phrase\n",
      ",\n",
      "sentence\n",
      "or\n",
      "piece\n",
      "of\n",
      "text\n",
      "based\n",
      "on\n",
      "the\n",
      "information\n",
      "presented\n",
      "before\n",
      "and\n",
      "after\n",
      "the\n",
      "piece\n",
      "of\n",
      "text\n",
      "being\n",
      "analyzed\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "by\n",
      "means\n",
      "of\n",
      "a\n",
      "probabilistic\n",
      "context-free\n",
      "grammar\n",
      "(\n",
      "PCFG\n",
      ")\n",
      ".\n",
      "The\n",
      "mathematical\n",
      "equation\n",
      "for\n",
      "such\n",
      "algorithms\n",
      "is\n",
      "presented\n",
      "in\n",
      "US\n",
      "patent\n",
      "9269353\n",
      ":\n",
      "R\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ")\n",
      "=\n",
      "P\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ")\n",
      "×\n",
      "1\n",
      "2\n",
      "d\n",
      "(\n",
      "∑\n",
      "i\n",
      "=\n",
      "−\n",
      "d\n",
      "d\n",
      "(\n",
      "(\n",
      "P\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      "−\n",
      "1\n",
      ")\n",
      "×\n",
      "P\n",
      "F\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ",\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      "−\n",
      "1\n",
      ")\n",
      ")\n",
      "i\n",
      ")\n",
      "{\n",
      "\\displaystyle\n",
      "{\n",
      "RMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ")\n",
      "}\n",
      "=\n",
      "{\n",
      "PMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ")\n",
      "}\n",
      "\\times\n",
      "{\n",
      "\\frac\n",
      "{\n",
      "1\n",
      "}\n",
      "{\n",
      "2d\n",
      "}\n",
      "}\n",
      "\\left\n",
      "(\n",
      "\\sum\n",
      "_\n",
      "{\n",
      "i=-d\n",
      "}\n",
      "^\n",
      "{\n",
      "d\n",
      "}\n",
      "{\n",
      "(\n",
      "(\n",
      "PMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N-1\n",
      "}\n",
      ")\n",
      "}\n",
      "\\times\n",
      "{\n",
      "PF\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ",\n",
      "token_\n",
      "{\n",
      "N-1\n",
      "}\n",
      ")\n",
      ")\n",
      "_\n",
      "{\n",
      "i\n",
      "}\n",
      "}\n",
      "\\right\n",
      ")\n",
      "}\n",
      "Where\n",
      ",\n",
      "RMM\n",
      ",\n",
      "is\n",
      "the\n",
      "Relative\n",
      "Measure\n",
      "of\n",
      "Meaning\n",
      "token\n",
      ",\n",
      "is\n",
      "any\n",
      "block\n",
      "of\n",
      "text\n",
      ",\n",
      "sentence\n",
      ",\n",
      "phrase\n",
      "or\n",
      "word\n",
      "N\n",
      ",\n",
      "is\n",
      "the\n",
      "number\n",
      "of\n",
      "tokens\n",
      "being\n",
      "analyzed\n",
      "PMM\n",
      ",\n",
      "is\n",
      "the\n",
      "Probable\n",
      "Measure\n",
      "of\n",
      "Meaning\n",
      "based\n",
      "on\n",
      "a\n",
      "corpora\n",
      "d\n",
      ",\n",
      "is\n",
      "the\n",
      "location\n",
      "of\n",
      "the\n",
      "token\n",
      "along\n",
      "the\n",
      "sequence\n",
      "of\n",
      "N-1\n",
      "tokens\n",
      "PF\n",
      ",\n",
      "is\n",
      "the\n",
      "Probability\n",
      "Function\n",
      "specific\n",
      "to\n",
      "a\n",
      "language\n",
      "Ties\n",
      "with\n",
      "cognitive\n",
      "linguistics\n",
      "are\n",
      "part\n",
      "of\n",
      "the\n",
      "historical\n",
      "heritage\n",
      "of\n",
      "NLP\n",
      ",\n",
      "but\n",
      "they\n",
      "have\n",
      "been\n",
      "less\n",
      "frequently\n",
      "addressed\n",
      "since\n",
      "the\n",
      "statistical\n",
      "turn\n",
      "during\n",
      "the\n",
      "1990s\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "approaches\n",
      "to\n",
      "develop\n",
      "cognitive\n",
      "models\n",
      "towards\n",
      "technically\n",
      "operationalizable\n",
      "frameworks\n",
      "have\n",
      "been\n",
      "pursued\n",
      "in\n",
      "the\n",
      "context\n",
      "of\n",
      "various\n",
      "frameworks\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "of\n",
      "cognitive\n",
      "grammar\n",
      ",\n",
      "[\n",
      "42\n",
      "]\n",
      "functional\n",
      "grammar\n",
      ",\n",
      "[\n",
      "43\n",
      "]\n",
      "construction\n",
      "grammar\n",
      ",\n",
      "[\n",
      "44\n",
      "]\n",
      "computational\n",
      "psycholinguistics\n",
      "and\n",
      "cognitive\n",
      "neuroscience\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "ACT-R\n",
      ")\n",
      ",\n",
      "however\n",
      ",\n",
      "with\n",
      "limited\n",
      "uptake\n",
      "in\n",
      "mainstream\n",
      "NLP\n",
      "(\n",
      "as\n",
      "measured\n",
      "by\n",
      "presence\n",
      "on\n",
      "major\n",
      "conferences\n",
      "[\n",
      "45\n",
      "]\n",
      "of\n",
      "the\n",
      "ACL\n",
      ")\n",
      ".\n",
      "More\n",
      "recently\n",
      ",\n",
      "ideas\n",
      "of\n",
      "cognitive\n",
      "NLP\n",
      "have\n",
      "been\n",
      "revived\n",
      "as\n",
      "an\n",
      "approach\n",
      "to\n",
      "achieve\n",
      "explainability\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "under\n",
      "the\n",
      "notion\n",
      "of\n",
      "``\n",
      "cognitive\n",
      "AI\n",
      "''\n",
      ".\n",
      "[\n",
      "46\n",
      "]\n",
      "Likewise\n",
      ",\n",
      "ideas\n",
      "of\n",
      "cognitive\n",
      "NLP\n",
      "are\n",
      "inherent\n",
      "to\n",
      "neural\n",
      "models\n",
      "multimodal\n",
      "NLP\n",
      "(\n",
      "although\n",
      "rarely\n",
      "made\n",
      "explicit\n",
      ")\n",
      ".\n",
      "[\n",
      "47\n",
      "]\n",
      "See\n",
      "also\n",
      "[\n",
      "edit\n",
      "]\n",
      "1\n",
      "the\n",
      "Road\n",
      "Automated\n",
      "essay\n",
      "scoring\n",
      "Biomedical\n",
      "text\n",
      "mining\n",
      "Compound\n",
      "term\n",
      "processing\n",
      "Computational\n",
      "linguistics\n",
      "Computer-assisted\n",
      "reviewing\n",
      "Controlled\n",
      "natural\n",
      "language\n",
      "Deep\n",
      "learning\n",
      "Deep\n",
      "linguistic\n",
      "processing\n",
      "Distributional\n",
      "semantics\n",
      "Foreign\n",
      "language\n",
      "reading\n",
      "aid\n",
      "Foreign\n",
      "language\n",
      "writing\n",
      "aid\n",
      "Information\n",
      "extraction\n",
      "Information\n",
      "retrieval\n",
      "Language\n",
      "and\n",
      "Communication\n",
      "Technologies\n",
      "Language\n",
      "technology\n",
      "Latent\n",
      "semantic\n",
      "indexing\n",
      "Native-language\n",
      "identification\n",
      "Natural\n",
      "language\n",
      "programming\n",
      "Natural\n",
      "language\n",
      "search\n",
      "Outline\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "Query\n",
      "expansion\n",
      "Query\n",
      "understanding\n",
      "Reification\n",
      "(\n",
      "linguistics\n",
      ")\n",
      "Speech\n",
      "processing\n",
      "Spoken\n",
      "dialogue\n",
      "systems\n",
      "Text-proofing\n",
      "Text\n",
      "simplification\n",
      "Transformer\n",
      "(\n",
      "machine\n",
      "learning\n",
      "model\n",
      ")\n",
      "Truecasing\n",
      "Question\n",
      "answering\n",
      "Word2vec\n",
      "References\n",
      "[\n",
      "edit\n",
      "]\n",
      "^\n",
      "Kongthon\n",
      ",\n",
      "Alisa\n",
      ";\n",
      "Sangkeettrakarn\n",
      ",\n",
      "Chatchawal\n",
      ";\n",
      "Kongyoung\n",
      ",\n",
      "Sarawoot\n",
      ";\n",
      "Haruechaiyasak\n",
      ",\n",
      "Choochart\n",
      "(\n",
      "October\n",
      "27–30\n",
      ",\n",
      "2009\n",
      ")\n",
      ".\n",
      "Implementing\n",
      "an\n",
      "online\n",
      "help\n",
      "desk\n",
      "system\n",
      "based\n",
      "on\n",
      "conversational\n",
      "agent\n",
      ".\n",
      "MEDES\n",
      "'09\n",
      ":\n",
      "The\n",
      "International\n",
      "Conference\n",
      "on\n",
      "Management\n",
      "of\n",
      "Emergent\n",
      "Digital\n",
      "EcoSystems\n",
      ".\n",
      "France\n",
      ":\n",
      "ACM\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/1643823.1643908\n",
      ".\n",
      "^\n",
      "Hutchins\n",
      ",\n",
      "J\n",
      ".\n",
      "(\n",
      "2005\n",
      ")\n",
      ".\n",
      "``\n",
      "The\n",
      "history\n",
      "of\n",
      "machine\n",
      "translation\n",
      "in\n",
      "a\n",
      "nutshell\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "[\n",
      "self-published\n",
      "source\n",
      "]\n",
      "^\n",
      "Koskenniemi\n",
      ",\n",
      "Kimmo\n",
      "(\n",
      "1983\n",
      ")\n",
      ",\n",
      "Two-level\n",
      "morphology\n",
      ":\n",
      "A\n",
      "general\n",
      "computational\n",
      "model\n",
      "of\n",
      "word-form\n",
      "recognition\n",
      "and\n",
      "production\n",
      "(\n",
      "PDF\n",
      ")\n",
      ",\n",
      "Department\n",
      "of\n",
      "General\n",
      "Linguistics\n",
      ",\n",
      "University\n",
      "of\n",
      "Helsinki\n",
      "^\n",
      "Joshi\n",
      ",\n",
      "A.\n",
      "K.\n",
      ",\n",
      "&\n",
      "Weinstein\n",
      ",\n",
      "S.\n",
      "(\n",
      "1981\n",
      ",\n",
      "August\n",
      ")\n",
      ".\n",
      "Control\n",
      "of\n",
      "Inference\n",
      ":\n",
      "Role\n",
      "of\n",
      "Some\n",
      "Aspects\n",
      "of\n",
      "Discourse\n",
      "Structure-Centering\n",
      ".\n",
      "In\n",
      "IJCAI\n",
      "(\n",
      "pp\n",
      ".\n",
      "385-387\n",
      ")\n",
      ".\n",
      "^\n",
      "Guida\n",
      ",\n",
      "G.\n",
      ";\n",
      "Mauri\n",
      ",\n",
      "G.\n",
      "(\n",
      "July\n",
      "1986\n",
      ")\n",
      ".\n",
      "``\n",
      "Evaluation\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "systems\n",
      ":\n",
      "Issues\n",
      "and\n",
      "approaches\n",
      "''\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "IEEE\n",
      ".\n",
      "74\n",
      "(\n",
      "7\n",
      ")\n",
      ":\n",
      "1026–1035\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1109/PROC.1986.13580\n",
      ".\n",
      "ISSN\n",
      "1558-2256\n",
      ".\n",
      "S2CID\n",
      "30688575\n",
      ".\n",
      "^\n",
      "Chomskyan\n",
      "linguistics\n",
      "encourages\n",
      "the\n",
      "investigation\n",
      "of\n",
      "``\n",
      "corner\n",
      "cases\n",
      "``\n",
      "that\n",
      "stress\n",
      "the\n",
      "limits\n",
      "of\n",
      "its\n",
      "theoretical\n",
      "models\n",
      "(\n",
      "comparable\n",
      "to\n",
      "pathological\n",
      "phenomena\n",
      "in\n",
      "mathematics\n",
      ")\n",
      ",\n",
      "typically\n",
      "created\n",
      "using\n",
      "thought\n",
      "experiments\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "systematic\n",
      "investigation\n",
      "of\n",
      "typical\n",
      "phenomena\n",
      "that\n",
      "occur\n",
      "in\n",
      "real-world\n",
      "data\n",
      ",\n",
      "as\n",
      "is\n",
      "the\n",
      "case\n",
      "in\n",
      "corpus\n",
      "linguistics\n",
      ".\n",
      "The\n",
      "creation\n",
      "and\n",
      "use\n",
      "of\n",
      "such\n",
      "corpora\n",
      "of\n",
      "real-world\n",
      "data\n",
      "is\n",
      "a\n",
      "fundamental\n",
      "part\n",
      "of\n",
      "machine-learning\n",
      "algorithms\n",
      "for\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "In\n",
      "addition\n",
      ",\n",
      "theoretical\n",
      "underpinnings\n",
      "of\n",
      "Chomskyan\n",
      "linguistics\n",
      "such\n",
      "as\n",
      "the\n",
      "so-called\n",
      "``\n",
      "poverty\n",
      "of\n",
      "the\n",
      "stimulus\n",
      "``\n",
      "argument\n",
      "entail\n",
      "that\n",
      "general\n",
      "learning\n",
      "algorithms\n",
      ",\n",
      "as\n",
      "are\n",
      "typically\n",
      "used\n",
      "in\n",
      "machine\n",
      "learning\n",
      ",\n",
      "can\n",
      "not\n",
      "be\n",
      "successful\n",
      "in\n",
      "language\n",
      "processing\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "the\n",
      "Chomskyan\n",
      "paradigm\n",
      "discouraged\n",
      "the\n",
      "application\n",
      "of\n",
      "such\n",
      "models\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "^\n",
      "Goldberg\n",
      ",\n",
      "Yoav\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "``\n",
      "A\n",
      "Primer\n",
      "on\n",
      "Neural\n",
      "Network\n",
      "Models\n",
      "for\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "''\n",
      ".\n",
      "Journal\n",
      "of\n",
      "Artificial\n",
      "Intelligence\n",
      "Research\n",
      ".\n",
      "57\n",
      ":\n",
      "345–420\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1807.10854\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1613/jair.4992\n",
      ".\n",
      "S2CID\n",
      "8273530\n",
      ".\n",
      "^\n",
      "Goodfellow\n",
      ",\n",
      "Ian\n",
      ";\n",
      "Bengio\n",
      ",\n",
      "Yoshua\n",
      ";\n",
      "Courville\n",
      ",\n",
      "Aaron\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Deep\n",
      "Learning\n",
      ".\n",
      "MIT\n",
      "Press\n",
      ".\n",
      "^\n",
      "Jozefowicz\n",
      ",\n",
      "Rafal\n",
      ";\n",
      "Vinyals\n",
      ",\n",
      "Oriol\n",
      ";\n",
      "Schuster\n",
      ",\n",
      "Mike\n",
      ";\n",
      "Shazeer\n",
      ",\n",
      "Noam\n",
      ";\n",
      "Wu\n",
      ",\n",
      "Yonghui\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Exploring\n",
      "the\n",
      "Limits\n",
      "of\n",
      "Language\n",
      "Modeling\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1602.02410\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "2016arXiv160202410J\n",
      ".\n",
      "^\n",
      "Choe\n",
      ",\n",
      "Do\n",
      "Kook\n",
      ";\n",
      "Charniak\n",
      ",\n",
      "Eugene\n",
      ".\n",
      "``\n",
      "Parsing\n",
      "as\n",
      "Language\n",
      "Modeling\n",
      "''\n",
      ".\n",
      "Emnlp\n",
      "2016\n",
      ".\n",
      "^\n",
      "Vinyals\n",
      ",\n",
      "Oriol\n",
      ";\n",
      "et\n",
      "al\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "Grammar\n",
      "as\n",
      "a\n",
      "Foreign\n",
      "Language\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Nips2015\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1412.7449\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "2014arXiv1412.7449V\n",
      ".\n",
      "^\n",
      "Turchin\n",
      ",\n",
      "Alexander\n",
      ";\n",
      "Florez\n",
      "Builes\n",
      ",\n",
      "Luisa\n",
      "F.\n",
      "(\n",
      "2021-03-19\n",
      ")\n",
      ".\n",
      "``\n",
      "Using\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "to\n",
      "Measure\n",
      "and\n",
      "Improve\n",
      "Quality\n",
      "of\n",
      "Diabetes\n",
      "Care\n",
      ":\n",
      "A\n",
      "Systematic\n",
      "Review\n",
      "''\n",
      ".\n",
      "Journal\n",
      "of\n",
      "Diabetes\n",
      "Science\n",
      "and\n",
      "Technology\n",
      ".\n",
      "15\n",
      "(\n",
      "3\n",
      ")\n",
      ":\n",
      "553–560\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1177/19322968211000831\n",
      ".\n",
      "ISSN\n",
      "1932-2968\n",
      ".\n",
      "PMC\n",
      "8120048\n",
      ".\n",
      "PMID\n",
      "33736486\n",
      ".\n",
      "^\n",
      "Winograd\n",
      ",\n",
      "Terry\n",
      "(\n",
      "1971\n",
      ")\n",
      ".\n",
      "Procedures\n",
      "as\n",
      "a\n",
      "Representation\n",
      "for\n",
      "Data\n",
      "in\n",
      "a\n",
      "Computer\n",
      "Program\n",
      "for\n",
      "Understanding\n",
      "Natural\n",
      "Language\n",
      "(\n",
      "Thesis\n",
      ")\n",
      ".\n",
      "^\n",
      "Schank\n",
      ",\n",
      "Roger\n",
      "C.\n",
      ";\n",
      "Abelson\n",
      ",\n",
      "Robert\n",
      "P.\n",
      "(\n",
      "1977\n",
      ")\n",
      ".\n",
      "Scripts\n",
      ",\n",
      "Plans\n",
      ",\n",
      "Goals\n",
      ",\n",
      "and\n",
      "Understanding\n",
      ":\n",
      "An\n",
      "Inquiry\n",
      "Into\n",
      "Human\n",
      "Knowledge\n",
      "Structures\n",
      ".\n",
      "Hillsdale\n",
      ":\n",
      "Erlbaum\n",
      ".\n",
      "ISBN\n",
      "0-470-99033-3\n",
      ".\n",
      "^\n",
      "Mark\n",
      "Johnson\n",
      ".\n",
      "How\n",
      "the\n",
      "statistical\n",
      "revolution\n",
      "changes\n",
      "(\n",
      "computational\n",
      ")\n",
      "linguistics\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "EACL\n",
      "2009\n",
      "Workshop\n",
      "on\n",
      "the\n",
      "Interaction\n",
      "between\n",
      "Linguistics\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ".\n",
      "^\n",
      "Philip\n",
      "Resnik\n",
      ".\n",
      "Four\n",
      "revolutions\n",
      ".\n",
      "Language\n",
      "Log\n",
      ",\n",
      "February\n",
      "5\n",
      ",\n",
      "2011\n",
      ".\n",
      "^\n",
      "``\n",
      "Investigating\n",
      "complex-valued\n",
      "representation\n",
      "in\n",
      "NLP\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "^\n",
      "Trabelsi\n",
      ",\n",
      "Chiheb\n",
      ";\n",
      "Bilaniuk\n",
      ",\n",
      "Olexa\n",
      ";\n",
      "Zhang\n",
      ",\n",
      "Ying\n",
      ";\n",
      "Serdyuk\n",
      ",\n",
      "Dmitriy\n",
      ";\n",
      "Subramanian\n",
      ",\n",
      "Sandeep\n",
      ";\n",
      "Santos\n",
      ",\n",
      "João\n",
      "Felipe\n",
      ";\n",
      "Mehri\n",
      ",\n",
      "Soroush\n",
      ";\n",
      "Rostamzadeh\n",
      ",\n",
      "Negar\n",
      ";\n",
      "Bengio\n",
      ",\n",
      "Yoshua\n",
      ";\n",
      "Pal\n",
      ",\n",
      "Christopher\n",
      "J\n",
      ".\n",
      "(\n",
      "2018-02-25\n",
      ")\n",
      ".\n",
      "``\n",
      "Deep\n",
      "Complex\n",
      "Networks\n",
      "''\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1705.09792\n",
      "[\n",
      "cs.NE\n",
      "]\n",
      ".\n",
      "^\n",
      "Socher\n",
      ",\n",
      "Richard\n",
      ".\n",
      "``\n",
      "Deep\n",
      "Learning\n",
      "For\n",
      "NLP-ACL\n",
      "2012\n",
      "Tutorial\n",
      "''\n",
      ".\n",
      "www.socher.org\n",
      ".\n",
      "Retrieved\n",
      "2020-08-17\n",
      ".\n",
      "This\n",
      "was\n",
      "an\n",
      "early\n",
      "Deep\n",
      "Learning\n",
      "tutorial\n",
      "at\n",
      "the\n",
      "ACL\n",
      "2012\n",
      "and\n",
      "met\n",
      "with\n",
      "both\n",
      "interest\n",
      "and\n",
      "(\n",
      "at\n",
      "the\n",
      "time\n",
      ")\n",
      "skepticism\n",
      "by\n",
      "most\n",
      "participants\n",
      ".\n",
      "Until\n",
      "then\n",
      ",\n",
      "neural\n",
      "learning\n",
      "was\n",
      "basically\n",
      "rejected\n",
      "because\n",
      "of\n",
      "its\n",
      "lack\n",
      "of\n",
      "statistical\n",
      "interpretability\n",
      ".\n",
      "Until\n",
      "2015\n",
      ",\n",
      "deep\n",
      "learning\n",
      "had\n",
      "evolved\n",
      "into\n",
      "the\n",
      "major\n",
      "framework\n",
      "of\n",
      "NLP\n",
      ".\n",
      "^\n",
      "Annamoradnejad\n",
      ",\n",
      "I.\n",
      "and\n",
      "Zoghi\n",
      ",\n",
      "G.\n",
      "(\n",
      "2020\n",
      ")\n",
      ".\n",
      "Colbert\n",
      ":\n",
      "Using\n",
      "bert\n",
      "sentence\n",
      "embedding\n",
      "for\n",
      "humor\n",
      "detection\n",
      ".\n",
      "arXiv\n",
      "preprint\n",
      "arXiv:2004.12765\n",
      ".\n",
      "^\n",
      "Yi\n",
      ",\n",
      "Chucai\n",
      ";\n",
      "Tian\n",
      ",\n",
      "Yingli\n",
      "(\n",
      "2012\n",
      ")\n",
      ",\n",
      "``\n",
      "Assistive\n",
      "Text\n",
      "Reading\n",
      "from\n",
      "Complex\n",
      "Background\n",
      "for\n",
      "Blind\n",
      "Persons\n",
      "''\n",
      ",\n",
      "Camera-Based\n",
      "Document\n",
      "Analysis\n",
      "and\n",
      "Recognition\n",
      ",\n",
      "Springer\n",
      "Berlin\n",
      "Heidelberg\n",
      ",\n",
      "pp\n",
      ".\n",
      "15–28\n",
      ",\n",
      "CiteSeerX\n",
      "10.1.1.668.869\n",
      ",\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-642-29364-1_2\n",
      ",\n",
      "ISBN\n",
      "9783642293634\n",
      "^\n",
      "``\n",
      "What\n",
      "is\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "?\n",
      "Intro\n",
      "to\n",
      "NLP\n",
      "in\n",
      "Machine\n",
      "Learning\n",
      "''\n",
      ".\n",
      "GyanSetu\n",
      "!\n",
      ".\n",
      "2020-12-06\n",
      ".\n",
      "Retrieved\n",
      "2021-01-09\n",
      ".\n",
      "^\n",
      "Kishorjit\n",
      ",\n",
      "N.\n",
      ";\n",
      "Vidya\n",
      ",\n",
      "Raj\n",
      "RK\n",
      ".\n",
      ";\n",
      "Nirmal\n",
      ",\n",
      "Y.\n",
      ";\n",
      "Sivaji\n",
      ",\n",
      "B\n",
      ".\n",
      "(\n",
      "2012\n",
      ")\n",
      ".\n",
      "``\n",
      "Manipuri\n",
      "Morpheme\n",
      "Identification\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "3rd\n",
      "Workshop\n",
      "on\n",
      "South\n",
      "and\n",
      "Southeast\n",
      "Asian\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "(\n",
      "SANLP\n",
      ")\n",
      ".\n",
      "COLING\n",
      "2012\n",
      ",\n",
      "Mumbai\n",
      ",\n",
      "December\n",
      "2012\n",
      ":\n",
      "95–108\n",
      ".\n",
      "CS1\n",
      "maint\n",
      ":\n",
      "location\n",
      "(\n",
      "link\n",
      ")\n",
      "^\n",
      "Klein\n",
      ",\n",
      "Dan\n",
      ";\n",
      "Manning\n",
      ",\n",
      "Christopher\n",
      "D.\n",
      "(\n",
      "2002\n",
      ")\n",
      ".\n",
      "``\n",
      "Natural\n",
      "language\n",
      "grammar\n",
      "induction\n",
      "using\n",
      "a\n",
      "constituent-context\n",
      "model\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Advances\n",
      "in\n",
      "Neural\n",
      "Information\n",
      "Processing\n",
      "Systems\n",
      ".\n",
      "^\n",
      "PASCAL\n",
      "Recognizing\n",
      "Textual\n",
      "Entailment\n",
      "Challenge\n",
      "(\n",
      "RTE-7\n",
      ")\n",
      "https\n",
      ":\n",
      "//tac.nist.gov//2011/RTE/\n",
      "^\n",
      "Lippi\n",
      ",\n",
      "Marco\n",
      ";\n",
      "Torroni\n",
      ",\n",
      "Paolo\n",
      "(\n",
      "2016-04-20\n",
      ")\n",
      ".\n",
      "``\n",
      "Argumentation\n",
      "Mining\n",
      ":\n",
      "State\n",
      "of\n",
      "the\n",
      "Art\n",
      "and\n",
      "Emerging\n",
      "Trends\n",
      "''\n",
      ".\n",
      "ACM\n",
      "Transactions\n",
      "on\n",
      "Internet\n",
      "Technology\n",
      ".\n",
      "16\n",
      "(\n",
      "2\n",
      ")\n",
      ":\n",
      "1–25\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/2850417\n",
      ".\n",
      "ISSN\n",
      "1533-5399\n",
      ".\n",
      "S2CID\n",
      "9561587\n",
      ".\n",
      "^\n",
      "``\n",
      "Argument\n",
      "Mining\n",
      "-\n",
      "IJCAI2016\n",
      "Tutorial\n",
      "''\n",
      ".\n",
      "www.i3s.unice.fr\n",
      ".\n",
      "Retrieved\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "NLP\n",
      "Approaches\n",
      "to\n",
      "Computational\n",
      "Argumentation\n",
      "–\n",
      "ACL\n",
      "2016\n",
      ",\n",
      "Berlin\n",
      "''\n",
      ".\n",
      "Retrieved\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "U\n",
      "B\n",
      "U\n",
      "W\n",
      "E\n",
      "B\n",
      ":\n",
      ":\n",
      "Racter\n",
      "''\n",
      ".\n",
      "www.ubu.com\n",
      ".\n",
      "Retrieved\n",
      "2020-08-17\n",
      ".\n",
      "^\n",
      "Writer\n",
      ",\n",
      "Beta\n",
      "(\n",
      "2019\n",
      ")\n",
      ".\n",
      "Lithium-Ion\n",
      "Batteries\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-030-16800-1\n",
      ".\n",
      "ISBN\n",
      "978-3-030-16799-8\n",
      ".\n",
      "^\n",
      "``\n",
      "Document\n",
      "Understanding\n",
      "AI\n",
      "on\n",
      "Google\n",
      "Cloud\n",
      "(\n",
      "Cloud\n",
      "Next\n",
      "'19\n",
      ")\n",
      "-\n",
      "YouTube\n",
      "''\n",
      ".\n",
      "www.youtube.com\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Administration\n",
      ".\n",
      "``\n",
      "Centre\n",
      "for\n",
      "Language\n",
      "Technology\n",
      "(\n",
      "CLT\n",
      ")\n",
      "''\n",
      ".\n",
      "Macquarie\n",
      "University\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Shared\n",
      "Task\n",
      ":\n",
      "Grammatical\n",
      "Error\n",
      "Correction\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Shared\n",
      "Task\n",
      ":\n",
      "Grammatical\n",
      "Error\n",
      "Correction\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Duan\n",
      ",\n",
      "Yucong\n",
      ";\n",
      "Cruz\n",
      ",\n",
      "Christophe\n",
      "(\n",
      "2011\n",
      ")\n",
      ".\n",
      "``\n",
      "Formalizing\n",
      "Semantic\n",
      "of\n",
      "Natural\n",
      "Language\n",
      "through\n",
      "Conceptualization\n",
      "from\n",
      "Existence\n",
      "''\n",
      ".\n",
      "International\n",
      "Journal\n",
      "of\n",
      "Innovation\n",
      ",\n",
      "Management\n",
      "and\n",
      "Technology\n",
      ".\n",
      "2\n",
      "(\n",
      "1\n",
      ")\n",
      ":\n",
      "37–42\n",
      ".\n",
      "Archived\n",
      "from\n",
      "the\n",
      "original\n",
      "on\n",
      "2011-10-09\n",
      ".\n",
      "^\n",
      "``\n",
      "Previous\n",
      "shared\n",
      "tasks\n",
      "|\n",
      "CoNLL\n",
      "''\n",
      ".\n",
      "www.conll.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Cognition\n",
      "''\n",
      ".\n",
      "Lexico\n",
      ".\n",
      "Oxford\n",
      "University\n",
      "Press\n",
      "and\n",
      "Dictionary.com\n",
      ".\n",
      "Retrieved\n",
      "6\n",
      "May\n",
      "2020\n",
      ".\n",
      "^\n",
      "``\n",
      "Ask\n",
      "the\n",
      "Cognitive\n",
      "Scientist\n",
      "''\n",
      ".\n",
      "American\n",
      "Federation\n",
      "of\n",
      "Teachers\n",
      ".\n",
      "8\n",
      "August\n",
      "2014\n",
      ".\n",
      "Cognitive\n",
      "science\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "field\n",
      "of\n",
      "researchers\n",
      "from\n",
      "Linguistics\n",
      ",\n",
      "psychology\n",
      ",\n",
      "neuroscience\n",
      ",\n",
      "philosophy\n",
      ",\n",
      "computer\n",
      "science\n",
      ",\n",
      "and\n",
      "anthropology\n",
      "that\n",
      "seek\n",
      "to\n",
      "understand\n",
      "the\n",
      "mind\n",
      ".\n",
      "^\n",
      "Robinson\n",
      ",\n",
      "Peter\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Handbook\n",
      "of\n",
      "Cognitive\n",
      "Linguistics\n",
      "and\n",
      "Second\n",
      "Language\n",
      "Acquisition\n",
      ".\n",
      "Routledge\n",
      ".\n",
      "pp\n",
      ".\n",
      "3–8\n",
      ".\n",
      "ISBN\n",
      "978-0-805-85352-0\n",
      ".\n",
      "^\n",
      "Lakoff\n",
      ",\n",
      "George\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "Philosophy\n",
      "in\n",
      "the\n",
      "Flesh\n",
      ":\n",
      "The\n",
      "Embodied\n",
      "Mind\n",
      "and\n",
      "Its\n",
      "Challenge\n",
      "to\n",
      "Western\n",
      "Philosophy\n",
      ";\n",
      "Appendix\n",
      ":\n",
      "The\n",
      "Neural\n",
      "Theory\n",
      "of\n",
      "Language\n",
      "Paradigm\n",
      ".\n",
      "New\n",
      "York\n",
      "Basic\n",
      "Books\n",
      ".\n",
      "pp\n",
      ".\n",
      "569–583\n",
      ".\n",
      "ISBN\n",
      "978-0-465-05674-3\n",
      ".\n",
      "^\n",
      "Strauss\n",
      ",\n",
      "Claudia\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "A\n",
      "Cognitive\n",
      "Theory\n",
      "of\n",
      "Cultural\n",
      "Meaning\n",
      ".\n",
      "Cambridge\n",
      "University\n",
      "Press\n",
      ".\n",
      "pp\n",
      ".\n",
      "156–164\n",
      ".\n",
      "ISBN\n",
      "978-0-521-59541-4\n",
      ".\n",
      "^\n",
      "``\n",
      "Universal\n",
      "Conceptual\n",
      "Cognitive\n",
      "Annotation\n",
      "(\n",
      "UCCA\n",
      ")\n",
      "''\n",
      ".\n",
      "Universal\n",
      "Conceptual\n",
      "Cognitive\n",
      "Annotation\n",
      "(\n",
      "UCCA\n",
      ")\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Rodríguez\n",
      ",\n",
      "F.\n",
      "C.\n",
      ",\n",
      "&\n",
      "Mairal-Usón\n",
      ",\n",
      "R.\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Building\n",
      "an\n",
      "RRG\n",
      "computational\n",
      "grammar\n",
      ".\n",
      "Onomazein\n",
      ",\n",
      "(\n",
      "34\n",
      ")\n",
      ",\n",
      "86-117\n",
      ".\n",
      "^\n",
      "``\n",
      "Fluid\n",
      "Construction\n",
      "Grammar\n",
      "–\n",
      "A\n",
      "fully\n",
      "operational\n",
      "processing\n",
      "system\n",
      "for\n",
      "construction\n",
      "grammars\n",
      "''\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "ACL\n",
      "Member\n",
      "Portal\n",
      "|\n",
      "The\n",
      "Association\n",
      "for\n",
      "Computational\n",
      "Linguistics\n",
      "Member\n",
      "Portal\n",
      "''\n",
      ".\n",
      "www.aclweb.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Chunks\n",
      "and\n",
      "Rules\n",
      "''\n",
      ".\n",
      "www.w3.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Socher\n",
      ",\n",
      "Richard\n",
      ";\n",
      "Karpathy\n",
      ",\n",
      "Andrej\n",
      ";\n",
      "Le\n",
      ",\n",
      "Quoc\n",
      "V.\n",
      ";\n",
      "Manning\n",
      ",\n",
      "Christopher\n",
      "D.\n",
      ";\n",
      "Ng\n",
      ",\n",
      "Andrew\n",
      "Y\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "Grounded\n",
      "Compositional\n",
      "Semantics\n",
      "for\n",
      "Finding\n",
      "and\n",
      "Describing\n",
      "Images\n",
      "with\n",
      "Sentences\n",
      "''\n",
      ".\n",
      "Transactions\n",
      "of\n",
      "the\n",
      "Association\n",
      "for\n",
      "Computational\n",
      "Linguistics\n",
      ".\n",
      "2\n",
      ":\n",
      "207–218\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1162/tacl_a_00177\n",
      ".\n",
      "S2CID\n",
      "2317858\n",
      ".\n",
      "Further\n",
      "reading\n",
      "[\n",
      "edit\n",
      "]\n",
      "Bates\n",
      ",\n",
      "M\n",
      "(\n",
      "1995\n",
      ")\n",
      ".\n",
      "``\n",
      "Models\n",
      "of\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "''\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "National\n",
      "Academy\n",
      "of\n",
      "Sciences\n",
      "of\n",
      "the\n",
      "United\n",
      "States\n",
      "of\n",
      "America\n",
      ".\n",
      "92\n",
      "(\n",
      "22\n",
      ")\n",
      ":\n",
      "9977–9982\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "1995PNAS\n",
      "...\n",
      "92.9977B\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1073/pnas.92.22.9977\n",
      ".\n",
      "PMC\n",
      "40721\n",
      ".\n",
      "PMID\n",
      "7479812\n",
      ".\n",
      "Steven\n",
      "Bird\n",
      ",\n",
      "Ewan\n",
      "Klein\n",
      ",\n",
      "and\n",
      "Edward\n",
      "Loper\n",
      "(\n",
      "2009\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "with\n",
      "Python\n",
      ".\n",
      "O'Reilly\n",
      "Media\n",
      ".\n",
      "ISBN\n",
      "978-0-596-51649-9\n",
      ".\n",
      "Daniel\n",
      "Jurafsky\n",
      "and\n",
      "James\n",
      "H.\n",
      "Martin\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Speech\n",
      "and\n",
      "Language\n",
      "Processing\n",
      ",\n",
      "2nd\n",
      "edition\n",
      ".\n",
      "Pearson\n",
      "Prentice\n",
      "Hall\n",
      ".\n",
      "ISBN\n",
      "978-0-13-187321-6\n",
      ".\n",
      "Mohamed\n",
      "Zakaria\n",
      "Kurdi\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ":\n",
      "speech\n",
      ",\n",
      "morphology\n",
      ",\n",
      "and\n",
      "syntax\n",
      ",\n",
      "Volume\n",
      "1\n",
      ".\n",
      "ISTE-Wiley\n",
      ".\n",
      "ISBN\n",
      "978-1848218482\n",
      ".\n",
      "Mohamed\n",
      "Zakaria\n",
      "Kurdi\n",
      "(\n",
      "2017\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ":\n",
      "semantics\n",
      ",\n",
      "discourse\n",
      ",\n",
      "and\n",
      "applications\n",
      ",\n",
      "Volume\n",
      "2\n",
      ".\n",
      "ISTE-Wiley\n",
      ".\n",
      "ISBN\n",
      "978-1848219212\n",
      ".\n",
      "Christopher\n",
      "D.\n",
      "Manning\n",
      ",\n",
      "Prabhakar\n",
      "Raghavan\n",
      ",\n",
      "and\n",
      "Hinrich\n",
      "Schütze\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Introduction\n",
      "to\n",
      "Information\n",
      "Retrieval\n",
      ".\n",
      "Cambridge\n",
      "University\n",
      "Press\n",
      ".\n",
      "ISBN\n",
      "978-0-521-86571-5\n",
      ".\n",
      "Official\n",
      "html\n",
      "and\n",
      "pdf\n",
      "versions\n",
      "available\n",
      "without\n",
      "charge\n",
      ".\n",
      "Christopher\n",
      "D.\n",
      "Manning\n",
      "and\n",
      "Hinrich\n",
      "Schütze\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "Foundations\n",
      "of\n",
      "Statistical\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      ".\n",
      "The\n",
      "MIT\n",
      "Press\n",
      ".\n",
      "ISBN\n",
      "978-0-262-13360-9\n",
      ".\n",
      "David\n",
      "M.\n",
      "W.\n",
      "Powers\n",
      "and\n",
      "Christopher\n",
      "C.\n",
      "R.\n",
      "Turk\n",
      "(\n",
      "1989\n",
      ")\n",
      ".\n",
      "Machine\n",
      "Learning\n",
      "of\n",
      "Natural\n",
      "Language\n",
      ".\n",
      "Springer-Verlag\n",
      ".\n",
      "ISBN\n",
      "978-0-387-19557-5\n",
      ".\n",
      "External\n",
      "link\n",
      "[\n",
      "edit\n",
      "]\n",
      "Media\n",
      "related\n",
      "to\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "at\n",
      "Wikimedia\n",
      "Commons\n",
      "v\n",
      "t\n",
      "e\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "General\n",
      "terms\n",
      "AI-complete\n",
      "Bag-of-words\n",
      "n-gram\n",
      "Bigram\n",
      "Trigram\n",
      "Computational\n",
      "linguistics\n",
      "Natural-language\n",
      "understanding\n",
      "Stopwords\n",
      "Text\n",
      "processing\n",
      "Text\n",
      "analysis\n",
      "Collocation\n",
      "extraction\n",
      "Concept\n",
      "mining\n",
      "Coreference\n",
      "resolution\n",
      "Deep\n",
      "linguistic\n",
      "processing\n",
      "Distant\n",
      "reading\n",
      "Information\n",
      "extraction\n",
      "Named-entity\n",
      "recognition\n",
      "Ontology\n",
      "learning\n",
      "Parsing\n",
      "Part-of-speech\n",
      "tagging\n",
      "Semantic\n",
      "role\n",
      "labeling\n",
      "Semantic\n",
      "similarity\n",
      "Sentiment\n",
      "analysis\n",
      "Terminology\n",
      "extraction\n",
      "Text\n",
      "mining\n",
      "Textual\n",
      "entailment\n",
      "Truecasing\n",
      "Word-sense\n",
      "disambiguation\n",
      "Word-sense\n",
      "induction\n",
      "Text\n",
      "segmentation\n",
      "Compound-term\n",
      "processing\n",
      "Lemmatisation\n",
      "Lexical\n",
      "analysis\n",
      "Text\n",
      "chunking\n",
      "Stemming\n",
      "Sentence\n",
      "segmentation\n",
      "Word\n",
      "segmentation\n",
      "Automatic\n",
      "summarization\n",
      "Multi-document\n",
      "summarization\n",
      "Sentence\n",
      "extraction\n",
      "Text\n",
      "simplification\n",
      "Machine\n",
      "translation\n",
      "Computer-assisted\n",
      "Example-based\n",
      "Rule-based\n",
      "Statistical\n",
      "Transfer-based\n",
      "Neural\n",
      "Distributional\n",
      "semantics\n",
      "models\n",
      "BERT\n",
      "Document-term\n",
      "matrix\n",
      "Explicit\n",
      "semantic\n",
      "analysis\n",
      "fastText\n",
      "GloVe\n",
      "Latent\n",
      "semantic\n",
      "analysis\n",
      "Word\n",
      "embedding\n",
      "Word2vec\n",
      "Language\n",
      "resources\n",
      ",\n",
      "datasets\n",
      "and\n",
      "corpora\n",
      "Types\n",
      "and\n",
      "standards\n",
      "Corpus\n",
      "linguistics\n",
      "Lexical\n",
      "resource\n",
      "Linguistic\n",
      "Linked\n",
      "Open\n",
      "Data\n",
      "Machine-readable\n",
      "dictionary\n",
      "Parallel\n",
      "text\n",
      "PropBank\n",
      "Semantic\n",
      "network\n",
      "Simple\n",
      "Knowledge\n",
      "Organization\n",
      "System\n",
      "Speech\n",
      "corpus\n",
      "Text\n",
      "corpus\n",
      "Thesaurus\n",
      "(\n",
      "information\n",
      "retrieval\n",
      ")\n",
      "Treebank\n",
      "Universal\n",
      "Dependencies\n",
      "Data\n",
      "BabelNet\n",
      "Bank\n",
      "of\n",
      "English\n",
      "DBpedia\n",
      "FrameNet\n",
      "Google\n",
      "Ngram\n",
      "Viewer\n",
      "ThoughtTreasure\n",
      "UBY\n",
      "WordNet\n",
      "Automatic\n",
      "identification\n",
      "and\n",
      "data\n",
      "capture\n",
      "Speech\n",
      "recognition\n",
      "Speech\n",
      "segmentation\n",
      "Speech\n",
      "synthesis\n",
      "Natural\n",
      "language\n",
      "generation\n",
      "Optical\n",
      "character\n",
      "recognition\n",
      "Topic\n",
      "model\n",
      "Document\n",
      "classification\n",
      "Latent\n",
      "Dirichlet\n",
      "allocation\n",
      "Pachinko\n",
      "allocation\n",
      "Computer-assisted\n",
      "reviewing\n",
      "Automated\n",
      "essay\n",
      "scoring\n",
      "Concordancer\n",
      "Grammar\n",
      "checker\n",
      "Predictive\n",
      "text\n",
      "Spell\n",
      "checker\n",
      "Syntax\n",
      "guessing\n",
      "Natural\n",
      "language\n",
      "user\n",
      "interface\n",
      "Chatbot\n",
      "Interactive\n",
      "fiction\n",
      "Question\n",
      "answering\n",
      "Virtual\n",
      "assistant\n",
      "Voice\n",
      "user\n",
      "interface\n",
      "Other\n",
      "software\n",
      "Natural\n",
      "Language\n",
      "Toolkit\n",
      "spaCy\n",
      "Authority\n",
      "control\n",
      ":\n",
      "National\n",
      "libraries\n",
      "United\n",
      "States\n",
      "Japan\n",
      "Language\n",
      "portal\n",
      "Retrieved\n",
      "from\n",
      "``\n",
      "https\n",
      ":\n",
      "//en.wikipedia.org/w/index.php\n",
      "?\n",
      "title=Natural_language_processing\n",
      "&\n",
      "oldid=1048621730\n",
      "``\n",
      "Categories\n",
      ":\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "Computational\n",
      "linguistics\n",
      "Speech\n",
      "recognition\n",
      "Computational\n",
      "fields\n",
      "of\n",
      "study\n",
      "Artificial\n",
      "intelligence\n",
      "Hidden\n",
      "categories\n",
      ":\n",
      "CS1\n",
      "maint\n",
      ":\n",
      "location\n",
      "Articles\n",
      "with\n",
      "short\n",
      "description\n",
      "Short\n",
      "description\n",
      "matches\n",
      "Wikidata\n",
      "Commons\n",
      "category\n",
      "link\n",
      "from\n",
      "Wikidata\n",
      "Articles\n",
      "with\n",
      "LCCN\n",
      "identifiers\n",
      "Articles\n",
      "with\n",
      "NDL\n",
      "identifiers\n",
      "Navigation\n",
      "menu\n",
      "Personal\n",
      "tools\n",
      "Not\n",
      "logged\n",
      "in\n",
      "Talk\n",
      "Contributions\n",
      "Create\n",
      "account\n",
      "Log\n",
      "in\n",
      "Namespaces\n",
      "Article\n",
      "Talk\n",
      "Variants\n",
      "expanded\n",
      "collapsed\n",
      "Views\n",
      "Read\n",
      "Edit\n",
      "View\n",
      "history\n",
      "More\n",
      "expanded\n",
      "collapsed\n",
      "Search\n",
      "Navigation\n",
      "Main\n",
      "page\n",
      "Contents\n",
      "Current\n",
      "events\n",
      "Random\n",
      "article\n",
      "About\n",
      "Wikipedia\n",
      "Contact\n",
      "us\n",
      "Donate\n",
      "Contribute\n",
      "Help\n",
      "Learn\n",
      "to\n",
      "edit\n",
      "Community\n",
      "portal\n",
      "Recent\n",
      "changes\n",
      "Upload\n",
      "file\n",
      "Tools\n",
      "What\n",
      "links\n",
      "here\n",
      "Related\n",
      "changes\n",
      "Upload\n",
      "file\n",
      "Special\n",
      "pages\n",
      "Permanent\n",
      "link\n",
      "Page\n",
      "information\n",
      "Cite\n",
      "this\n",
      "page\n",
      "Wikidata\n",
      "item\n",
      "Print/export\n",
      "Download\n",
      "as\n",
      "PDF\n",
      "Printable\n",
      "version\n",
      "In\n",
      "other\n",
      "projects\n",
      "Wikimedia\n",
      "Commons\n",
      "Languages\n",
      "Afrikaans\n",
      "العربية\n",
      "Azərbaycanca\n",
      "বাংলা\n",
      "Bân-lâm-gú\n",
      "Беларуская\n",
      "Беларуская\n",
      "(\n",
      "тарашкевіца\n",
      ")\n",
      "Български\n",
      "Català\n",
      "Čeština\n",
      "Dansk\n",
      "Deutsch\n",
      "Eesti\n",
      "Ελληνικά\n",
      "Español\n",
      "Euskara\n",
      "فارسی\n",
      "Français\n",
      "Galego\n",
      "한국어\n",
      "Հայերեն\n",
      "हिन्दी\n",
      "Hrvatski\n",
      "Bahasa\n",
      "Indonesia\n",
      "Íslenska\n",
      "Italiano\n",
      "עברית\n",
      "ಕನ್ನಡ\n",
      "ქართული\n",
      "Lietuvių\n",
      "Македонски\n",
      "मराठी\n",
      "مصرى\n",
      "Монгол\n",
      "မြန်မာဘာသာ\n",
      "日本語\n",
      "ଓଡ଼ିଆ\n",
      "Piemontèis\n",
      "Polski\n",
      "Português\n",
      "Română\n",
      "Русский\n",
      "Simple\n",
      "English\n",
      "کوردی\n",
      "Српски\n",
      "/\n",
      "srpski\n",
      "Srpskohrvatski\n",
      "/\n",
      "српскохрватски\n",
      "Suomi\n",
      "தமிழ்\n",
      "ไทย\n",
      "Türkçe\n",
      "Українська\n",
      "Tiếng\n",
      "Việt\n",
      "粵語\n",
      "中文\n",
      "Edit\n",
      "links\n",
      "This\n",
      "page\n",
      "was\n",
      "last\n",
      "edited\n",
      "on\n",
      "7\n",
      "October\n",
      "2021\n",
      ",\n",
      "at\n",
      "01:56\n",
      "(\n",
      "UTC\n",
      ")\n",
      ".\n",
      "Text\n",
      "is\n",
      "available\n",
      "under\n",
      "the\n",
      "Creative\n",
      "Commons\n",
      "Attribution-ShareAlike\n",
      "License\n",
      ";\n",
      "additional\n",
      "terms\n",
      "may\n",
      "apply\n",
      ".\n",
      "By\n",
      "using\n",
      "this\n",
      "site\n",
      ",\n",
      "you\n",
      "agree\n",
      "to\n",
      "the\n",
      "Terms\n",
      "of\n",
      "Use\n",
      "and\n",
      "Privacy\n",
      "Policy\n",
      ".\n",
      "Wikipedia®\n",
      "is\n",
      "a\n",
      "registered\n",
      "trademark\n",
      "of\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "Wikimedia\n",
      "Foundation\n",
      ",\n",
      "Inc.\n",
      ",\n",
      "a\n",
      "non-profit\n",
      "organization\n",
      ".\n",
      "Privacy\n",
      "policy\n",
      "About\n",
      "Wikipedia\n",
      "Disclaimers\n",
      "Contact\n",
      "Wikipedia\n",
      "Mobile\n",
      "view\n",
      "Developers\n",
      "Statistics\n",
      "Cookie\n",
      "statement\n"
     ]
    }
   ],
   "source": [
    "# called the get_words function to get words of text data.\n",
    "words = get_words(text)\n",
    "for i in words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a707c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('-', ':')\n",
      "('Wikipedia', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('From', 'IN')\n",
      "('Wikipedia', 'NNP')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('free', 'JJ')\n",
      "('encyclopedia', 'NN')\n",
      "('Jump', 'NNP')\n",
      "('to', 'TO')\n",
      "('navigation', 'VB')\n",
      "('Jump', 'NNP')\n",
      "('to', 'TO')\n",
      "('search', 'VB')\n",
      "('This', 'DT')\n",
      "('article', 'NN')\n",
      "('is', 'VBZ')\n",
      "('about', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('done', 'VBN')\n",
      "('by', 'IN')\n",
      "('computers', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('the', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('done', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "('human', 'JJ')\n",
      "('brain', 'NN')\n",
      "(',', ',')\n",
      "('see', 'VBP')\n",
      "('Language', 'JJ')\n",
      "('processing', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('brain', 'NN')\n",
      "('.', '.')\n",
      "('Field', 'NNP')\n",
      "('of', 'IN')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "('and', 'CC')\n",
      "('linguistics', 'NNS')\n",
      "('An', 'DT')\n",
      "('automated', 'JJ')\n",
      "('online', 'NN')\n",
      "('assistant', 'NN')\n",
      "('providing', 'VBG')\n",
      "('customer', 'NN')\n",
      "('service', 'NN')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('web', 'JJ')\n",
      "('page', 'NN')\n",
      "(',', ',')\n",
      "('an', 'DT')\n",
      "('example', 'NN')\n",
      "('of', 'IN')\n",
      "('an', 'DT')\n",
      "('application', 'NN')\n",
      "('where', 'WRB')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('major', 'JJ')\n",
      "('component', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('1', 'CD')\n",
      "(']', 'JJ')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('(', '(')\n",
      "('NLP', 'NNP')\n",
      "(')', ')')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('subfield', 'NN')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "('concerned', 'VBN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('interactions', 'NNS')\n",
      "('between', 'IN')\n",
      "('computers', 'NNS')\n",
      "('and', 'CC')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('particular', 'JJ')\n",
      "('how', 'WRB')\n",
      "('to', 'TO')\n",
      "('program', 'NN')\n",
      "('computers', 'NNS')\n",
      "('to', 'TO')\n",
      "('process', 'VB')\n",
      "('and', 'CC')\n",
      "('analyze', 'VB')\n",
      "('large', 'JJ')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('computer', 'NN')\n",
      "('capable', 'NN')\n",
      "('of', 'IN')\n",
      "('``', '``')\n",
      "('understanding', 'JJ')\n",
      "(\"''\", \"''\")\n",
      "('the', 'DT')\n",
      "('contents', 'NNS')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('including', 'VBG')\n",
      "('the', 'DT')\n",
      "('contextual', 'JJ')\n",
      "('nuances', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('within', 'IN')\n",
      "('them', 'PRP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('technology', 'NN')\n",
      "('can', 'MD')\n",
      "('then', 'RB')\n",
      "('accurately', 'RB')\n",
      "('extract', 'JJ')\n",
      "('information', 'NN')\n",
      "('and', 'CC')\n",
      "('insights', 'NNS')\n",
      "('contained', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('documents', 'NNS')\n",
      "('as', 'RB')\n",
      "('well', 'RB')\n",
      "('as', 'IN')\n",
      "('categorize', 'NN')\n",
      "('and', 'CC')\n",
      "('organize', 'VB')\n",
      "('the', 'DT')\n",
      "('documents', 'NNS')\n",
      "('themselves', 'PRP')\n",
      "('.', '.')\n",
      "('Challenges', 'NNS')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('frequently', 'RB')\n",
      "('involve', 'VBP')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "(',', ',')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('.', '.')\n",
      "('Contents', 'NNS')\n",
      "('1', 'CD')\n",
      "('History', 'NNP')\n",
      "('1.1', 'CD')\n",
      "('Symbolic', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('1950s', 'CD')\n",
      "('–', 'RB')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('1.2', 'CD')\n",
      "('Statistical', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('1990s–2010s', 'CD')\n",
      "(')', ')')\n",
      "('1.3', 'CD')\n",
      "('Neural', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('present', 'JJ')\n",
      "(')', ')')\n",
      "('2', 'CD')\n",
      "('Methods', 'NNS')\n",
      "(':', ':')\n",
      "('Rules', 'NNS')\n",
      "(',', ',')\n",
      "('statistics', 'NNS')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('2.1', 'CD')\n",
      "('Statistical', 'NNP')\n",
      "('methods', 'NNS')\n",
      "('2.2', 'CD')\n",
      "('Neural', 'NNP')\n",
      "('networks', 'NNS')\n",
      "('3', 'CD')\n",
      "('Common', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'VBZ')\n",
      "('3.1', 'CD')\n",
      "('Text', 'NNP')\n",
      "('and', 'CC')\n",
      "('speech', 'NN')\n",
      "('processing', 'NN')\n",
      "('3.2', 'CD')\n",
      "('Morphological', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('3.3', 'CD')\n",
      "('Syntactic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('3.4', 'CD')\n",
      "('Lexical', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "(')', ')')\n",
      "('3.5', 'CD')\n",
      "('Relational', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('3.6', 'CD')\n",
      "('Discourse', 'NNP')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('beyond', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('3.7', 'CD')\n",
      "('Higher-level', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('applications', 'NNS')\n",
      "('4', 'CD')\n",
      "('General', 'NNP')\n",
      "('tendencies', 'NNS')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('possible', 'JJ')\n",
      "(')', ')')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('4.1', 'CD')\n",
      "('Cognition', 'NNP')\n",
      "('and', 'CC')\n",
      "('NLP', 'NNP')\n",
      "('5', 'CD')\n",
      "('See', 'NNP')\n",
      "('also', 'RB')\n",
      "('6', 'CD')\n",
      "('References', 'NNS')\n",
      "('7', 'CD')\n",
      "('Further', 'NNP')\n",
      "('reading', 'VBG')\n",
      "('8', 'CD')\n",
      "('External', 'JJ')\n",
      "('link', 'NN')\n",
      "('History', 'NNP')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Further', 'NNP')\n",
      "('information', 'NN')\n",
      "(':', ':')\n",
      "('History', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('has', 'VBZ')\n",
      "('its', 'PRP$')\n",
      "('roots', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1950s', 'CD')\n",
      "('.', '.')\n",
      "('Already', 'RB')\n",
      "('in', 'IN')\n",
      "('1950', 'CD')\n",
      "(',', ',')\n",
      "('Alan', 'NNP')\n",
      "('Turing', 'NNP')\n",
      "('published', 'VBD')\n",
      "('an', 'DT')\n",
      "('article', 'NN')\n",
      "('titled', 'VBN')\n",
      "('``', '``')\n",
      "('Computing', 'JJ')\n",
      "('Machinery', 'NN')\n",
      "('and', 'CC')\n",
      "('Intelligence', 'NNP')\n",
      "('``', '``')\n",
      "('which', 'WDT')\n",
      "('proposed', 'VBD')\n",
      "('what', 'WP')\n",
      "('is', 'VBZ')\n",
      "('now', 'RB')\n",
      "('called', 'VBN')\n",
      "('the', 'DT')\n",
      "('Turing', 'NNP')\n",
      "('test', 'NN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('criterion', 'NN')\n",
      "('of', 'IN')\n",
      "('intelligence', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('task', 'NN')\n",
      "('that', 'WDT')\n",
      "('involves', 'VBZ')\n",
      "('the', 'DT')\n",
      "('automated', 'JJ')\n",
      "('interpretation', 'NN')\n",
      "('and', 'CC')\n",
      "('generation', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "('not', 'RB')\n",
      "('articulated', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('problem', 'NN')\n",
      "('separate', 'NN')\n",
      "('from', 'IN')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "('.', '.')\n",
      "('Symbolic', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('1950s', 'CD')\n",
      "('–', 'RB')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('[', 'NN')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('The', 'DT')\n",
      "('premise', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('well-summarized', 'JJ')\n",
      "('by', 'IN')\n",
      "('John', 'NNP')\n",
      "('Searle', 'NNP')\n",
      "(\"'s\", 'POS')\n",
      "('Chinese', 'JJ')\n",
      "('room', 'NN')\n",
      "('experiment', 'NN')\n",
      "(':', ':')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('collection', 'NN')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('Chinese', 'JJ')\n",
      "('phrasebook', 'NN')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('questions', 'NNS')\n",
      "('and', 'CC')\n",
      "('matching', 'VBG')\n",
      "('answers', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('computer', 'NN')\n",
      "('emulates', 'VBZ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "('or', 'CC')\n",
      "('other', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'NNS')\n",
      "(')', ')')\n",
      "('by', 'IN')\n",
      "('applying', 'VBG')\n",
      "('those', 'DT')\n",
      "('rules', 'NNS')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('data', 'NN')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('confronted', 'VBN')\n",
      "('with', 'IN')\n",
      "('.', '.')\n",
      "('1950s', 'CD')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('Georgetown', 'NNP')\n",
      "('experiment', 'NN')\n",
      "('in', 'IN')\n",
      "('1954', 'CD')\n",
      "('involved', 'JJ')\n",
      "('fully', 'RB')\n",
      "('automatic', 'JJ')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('more', 'JJR')\n",
      "('than', 'IN')\n",
      "('sixty', 'NN')\n",
      "('Russian', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "('into', 'IN')\n",
      "('English', 'NNP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('authors', 'NNS')\n",
      "('claimed', 'VBD')\n",
      "('that', 'IN')\n",
      "('within', 'IN')\n",
      "('three', 'CD')\n",
      "('or', 'CC')\n",
      "('five', 'CD')\n",
      "('years', 'NNS')\n",
      "(',', ',')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('would', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('solved', 'JJ')\n",
      "('problem', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('2', 'CD')\n",
      "(']', 'NN')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('real', 'JJ')\n",
      "('progress', 'NN')\n",
      "('was', 'VBD')\n",
      "('much', 'RB')\n",
      "('slower', 'JJR')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('after', 'IN')\n",
      "('the', 'DT')\n",
      "('ALPAC', 'NNP')\n",
      "('report', 'NN')\n",
      "('in', 'IN')\n",
      "('1966', 'CD')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('found', 'VBD')\n",
      "('that', 'IN')\n",
      "('ten-year-long', 'JJ')\n",
      "('research', 'NN')\n",
      "('had', 'VBD')\n",
      "('failed', 'VBN')\n",
      "('to', 'TO')\n",
      "('fulfill', 'VB')\n",
      "('the', 'DT')\n",
      "('expectations', 'NNS')\n",
      "(',', ',')\n",
      "('funding', 'VBG')\n",
      "('for', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('was', 'VBD')\n",
      "('dramatically', 'RB')\n",
      "('reduced', 'VBN')\n",
      "('.', '.')\n",
      "('Little', 'JJ')\n",
      "('further', 'JJ')\n",
      "('research', 'NN')\n",
      "('in', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('was', 'VBD')\n",
      "('conducted', 'VBN')\n",
      "('until', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'NNS')\n",
      "('when', 'WRB')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('developed', 'VBN')\n",
      "('.', '.')\n",
      "('1960s', 'CD')\n",
      "(':', ':')\n",
      "('Some', 'DT')\n",
      "('notably', 'RB')\n",
      "('successful', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('developed', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1960s', 'NNS')\n",
      "('were', 'VBD')\n",
      "('SHRDLU', 'NNP')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('system', 'NN')\n",
      "('working', 'VBG')\n",
      "('in', 'IN')\n",
      "('restricted', 'VBN')\n",
      "('``', '``')\n",
      "('blocks', 'NNS')\n",
      "('worlds', 'VBZ')\n",
      "('``', '``')\n",
      "('with', 'IN')\n",
      "('restricted', 'JJ')\n",
      "('vocabularies', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('ELIZA', 'NNP')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('simulation', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('Rogerian', 'JJ')\n",
      "('psychotherapist', 'NN')\n",
      "(',', ',')\n",
      "('written', 'VBN')\n",
      "('by', 'IN')\n",
      "('Joseph', 'NNP')\n",
      "('Weizenbaum', 'NNP')\n",
      "('between', 'IN')\n",
      "('1964', 'CD')\n",
      "('and', 'CC')\n",
      "('1966', 'CD')\n",
      "('.', '.')\n",
      "('Using', 'VBG')\n",
      "('almost', 'RB')\n",
      "('no', 'DT')\n",
      "('information', 'NN')\n",
      "('about', 'IN')\n",
      "('human', 'JJ')\n",
      "('thought', 'NN')\n",
      "('or', 'CC')\n",
      "('emotion', 'NN')\n",
      "(',', ',')\n",
      "('ELIZA', 'NNP')\n",
      "('sometimes', 'RB')\n",
      "('provided', 'VBD')\n",
      "('a', 'DT')\n",
      "('startlingly', 'RB')\n",
      "('human-like', 'JJ')\n",
      "('interaction', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('the', 'DT')\n",
      "('``', '``')\n",
      "('patient', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('exceeded', 'VBD')\n",
      "('the', 'DT')\n",
      "('very', 'RB')\n",
      "('small', 'JJ')\n",
      "('knowledge', 'NN')\n",
      "('base', 'NN')\n",
      "(',', ',')\n",
      "('ELIZA', 'NNP')\n",
      "('might', 'MD')\n",
      "('provide', 'VB')\n",
      "('a', 'DT')\n",
      "('generic', 'JJ')\n",
      "('response', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('responding', 'VBG')\n",
      "('to', 'TO')\n",
      "('``', '``')\n",
      "('My', 'PRP$')\n",
      "('head', 'NN')\n",
      "('hurts', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "('with', 'IN')\n",
      "('``', '``')\n",
      "('Why', 'WRB')\n",
      "('do', 'VBP')\n",
      "('you', 'PRP')\n",
      "('say', 'VB')\n",
      "('your', 'PRP$')\n",
      "('head', 'NN')\n",
      "('hurts', 'NNS')\n",
      "('?', '.')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('1970s', 'CD')\n",
      "(':', ':')\n",
      "('During', 'IN')\n",
      "('the', 'DT')\n",
      "('1970s', 'CD')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('programmers', 'NNS')\n",
      "('began', 'VBD')\n",
      "('to', 'TO')\n",
      "('write', 'VB')\n",
      "('``', '``')\n",
      "('conceptual', 'JJ')\n",
      "('ontologies', 'VBZ')\n",
      "('``', '``')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('structured', 'VBD')\n",
      "('real-world', 'NN')\n",
      "('information', 'NN')\n",
      "('into', 'IN')\n",
      "('computer-understandable', 'JJ')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('Examples', 'NNS')\n",
      "('are', 'VBP')\n",
      "('MARGIE', 'NNP')\n",
      "('(', '(')\n",
      "('Schank', 'NNP')\n",
      "(',', ',')\n",
      "('1975', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('SAM', 'NNP')\n",
      "('(', '(')\n",
      "('Cullingford', 'NNP')\n",
      "(',', ',')\n",
      "('1978', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('PAM', 'NNP')\n",
      "('(', '(')\n",
      "('Wilensky', 'NNP')\n",
      "(',', ',')\n",
      "('1978', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('TaleSpin', 'NNP')\n",
      "('(', '(')\n",
      "('Meehan', 'NNP')\n",
      "(',', ',')\n",
      "('1976', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('QUALM', 'NNP')\n",
      "('(', '(')\n",
      "('Lehnert', 'NNP')\n",
      "(',', ',')\n",
      "('1977', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('Politics', 'NNP')\n",
      "('(', '(')\n",
      "('Carbonell', 'NNP')\n",
      "(',', ',')\n",
      "('1979', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('Plot', 'NNP')\n",
      "('Units', 'NNP')\n",
      "('(', '(')\n",
      "('Lehnert', 'NNP')\n",
      "('1981', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('During', 'IN')\n",
      "('this', 'DT')\n",
      "('time', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('many', 'JJ')\n",
      "('chatterbots', 'NNS')\n",
      "('were', 'VBD')\n",
      "('written', 'VBN')\n",
      "('(', '(')\n",
      "('e.g.', 'UH')\n",
      "(',', ',')\n",
      "('PARRY', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('1980s', 'CD')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('1980s', 'CD')\n",
      "('and', 'CC')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "('mark', 'NN')\n",
      "('the', 'DT')\n",
      "('hey-day', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('.', '.')\n",
      "('Focus', 'NNP')\n",
      "('areas', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "('included', 'VBD')\n",
      "('research', 'NN')\n",
      "('on', 'IN')\n",
      "('rule-based', 'JJ')\n",
      "('parsing', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'UH')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "('HPSG', 'NNP')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('computational', 'JJ')\n",
      "('operationalization', 'NN')\n",
      "('of', 'IN')\n",
      "('generative', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('two-level', 'JJ')\n",
      "('morphology', 'NN')\n",
      "('[', 'VBZ')\n",
      "('3', 'CD')\n",
      "(']', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('Lesk', 'NNP')\n",
      "('algorithm', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('reference', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('within', 'IN')\n",
      "('Centering', 'NNP')\n",
      "('Theory', 'NNP')\n",
      "('[', 'NNP')\n",
      "('4', 'CD')\n",
      "(']', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('other', 'JJ')\n",
      "('areas', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('Rhetorical', 'JJ')\n",
      "('Structure', 'NNP')\n",
      "('Theory', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Other', 'JJ')\n",
      "('lines', 'NNS')\n",
      "('of', 'IN')\n",
      "('research', 'NN')\n",
      "('were', 'VBD')\n",
      "('continued', 'VBN')\n",
      "(',', ',')\n",
      "('e.g.', 'RB')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "('chatterbots', 'NNS')\n",
      "('with', 'IN')\n",
      "('Racter', 'NNP')\n",
      "('and', 'CC')\n",
      "('Jabberwacky', 'NNP')\n",
      "('.', '.')\n",
      "('An', 'DT')\n",
      "('important', 'JJ')\n",
      "('development', 'NN')\n",
      "('(', '(')\n",
      "('that', 'IN')\n",
      "('eventually', 'RB')\n",
      "('led', 'VBN')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('turn', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('was', 'VBD')\n",
      "('the', 'DT')\n",
      "('rising', 'VBG')\n",
      "('importance', 'NN')\n",
      "('of', 'IN')\n",
      "('quantitative', 'JJ')\n",
      "('evaluation', 'NN')\n",
      "('in', 'IN')\n",
      "('this', 'DT')\n",
      "('period', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('5', 'CD')\n",
      "(']', 'JJ')\n",
      "('Statistical', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('1990s–2010s', 'CD')\n",
      "(')', ')')\n",
      "('[', 'NN')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('Up', 'NNP')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('1980s', 'CD')\n",
      "(',', ',')\n",
      "('most', 'RBS')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('complex', 'JJ')\n",
      "('sets', 'NNS')\n",
      "('of', 'IN')\n",
      "('hand-written', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('.', '.')\n",
      "('Starting', 'VBG')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'NNS')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('was', 'VBD')\n",
      "('a', 'DT')\n",
      "('revolution', 'NN')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('introduction', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('for', 'IN')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('was', 'VBD')\n",
      "('due', 'JJ')\n",
      "('to', 'TO')\n",
      "('both', 'DT')\n",
      "('the', 'DT')\n",
      "('steady', 'JJ')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('computational', 'JJ')\n",
      "('power', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('Moore', 'NNP')\n",
      "(\"'s\", 'POS')\n",
      "('law', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('gradual', 'JJ')\n",
      "('lessening', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('dominance', 'NN')\n",
      "('of', 'IN')\n",
      "('Chomskyan', 'NNP')\n",
      "('theories', 'NNS')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('transformational', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('whose', 'WP$')\n",
      "('theoretical', 'JJ')\n",
      "('underpinnings', 'NNS')\n",
      "('discouraged', 'VBD')\n",
      "('the', 'DT')\n",
      "('sort', 'NN')\n",
      "('of', 'IN')\n",
      "('corpus', 'NN')\n",
      "('linguistics', 'NNS')\n",
      "('that', 'WDT')\n",
      "('underlies', 'VBZ')\n",
      "('the', 'DT')\n",
      "('machine-learning', 'JJ')\n",
      "('approach', 'NN')\n",
      "('to', 'TO')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('6', 'CD')\n",
      "(']', 'JJ')\n",
      "('1990s', 'CD')\n",
      "(':', ':')\n",
      "('Many', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('notable', 'JJ')\n",
      "('early', 'JJ')\n",
      "('successes', 'NNS')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('occurred', 'VBD')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "(',', ',')\n",
      "('due', 'JJ')\n",
      "('especially', 'RB')\n",
      "('to', 'TO')\n",
      "('work', 'VB')\n",
      "('at', 'IN')\n",
      "('IBM', 'NNP')\n",
      "('Research', 'NNP')\n",
      "('.', '.')\n",
      "('These', 'DT')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('able', 'JJ')\n",
      "('to', 'TO')\n",
      "('take', 'VB')\n",
      "('advantage', 'NN')\n",
      "('of', 'IN')\n",
      "('existing', 'VBG')\n",
      "('multilingual', 'JJ')\n",
      "('textual', 'JJ')\n",
      "('corpora', 'NN')\n",
      "('that', 'WDT')\n",
      "('had', 'VBD')\n",
      "('been', 'VBN')\n",
      "('produced', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "('Parliament', 'NNP')\n",
      "('of', 'IN')\n",
      "('Canada', 'NNP')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('European', 'NNP')\n",
      "('Union', 'NNP')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "('of', 'IN')\n",
      "('laws', 'NNS')\n",
      "('calling', 'VBG')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('all', 'DT')\n",
      "('governmental', 'JJ')\n",
      "('proceedings', 'NNS')\n",
      "('into', 'IN')\n",
      "('all', 'DT')\n",
      "('official', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('government', 'NN')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('most', 'JJS')\n",
      "('other', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('depended', 'VBN')\n",
      "('on', 'IN')\n",
      "('corpora', 'NNS')\n",
      "('specifically', 'RB')\n",
      "('developed', 'VBD')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('tasks', 'NNS')\n",
      "('implemented', 'VBN')\n",
      "('by', 'IN')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('was', 'VBD')\n",
      "('(', '(')\n",
      "('and', 'CC')\n",
      "('often', 'RB')\n",
      "('continues', 'VBZ')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "(')', ')')\n",
      "('a', 'DT')\n",
      "('major', 'JJ')\n",
      "('limitation', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('success', 'NN')\n",
      "('of', 'IN')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('great', 'JJ')\n",
      "('deal', 'NN')\n",
      "('of', 'IN')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('gone', 'VBN')\n",
      "('into', 'IN')\n",
      "('methods', 'NNS')\n",
      "('of', 'IN')\n",
      "('more', 'RBR')\n",
      "('effectively', 'RB')\n",
      "('learning', 'VBG')\n",
      "('from', 'IN')\n",
      "('limited', 'JJ')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('2000s', 'CD')\n",
      "(':', ':')\n",
      "('With', 'IN')\n",
      "('the', 'DT')\n",
      "('growth', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('web', 'NN')\n",
      "(',', ',')\n",
      "('increasing', 'VBG')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('raw', 'JJ')\n",
      "('(', '(')\n",
      "('unannotated', 'JJ')\n",
      "(')', ')')\n",
      "('language', 'NN')\n",
      "('data', 'NN')\n",
      "('has', 'VBZ')\n",
      "('become', 'VBN')\n",
      "('available', 'JJ')\n",
      "('since', 'IN')\n",
      "('the', 'DT')\n",
      "('mid-1990s', 'NNS')\n",
      "('.', '.')\n",
      "('Research', 'NNP')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('increasingly', 'RB')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('unsupervised', 'JJ')\n",
      "('and', 'CC')\n",
      "('semi-supervised', 'JJ')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('.', '.')\n",
      "('Such', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('can', 'MD')\n",
      "('learn', 'VB')\n",
      "('from', 'IN')\n",
      "('data', 'NNS')\n",
      "('that', 'WDT')\n",
      "('has', 'VBZ')\n",
      "('not', 'RB')\n",
      "('been', 'VBN')\n",
      "('hand-annotated', 'JJ')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('desired', 'JJ')\n",
      "('answers', 'NNS')\n",
      "('or', 'CC')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('combination', 'NN')\n",
      "('of', 'IN')\n",
      "('annotated', 'JJ')\n",
      "('and', 'CC')\n",
      "('non-annotated', 'JJ')\n",
      "('data', 'NN')\n",
      "('.', '.')\n",
      "('Generally', 'RB')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('much', 'RB')\n",
      "('more', 'RBR')\n",
      "('difficult', 'JJ')\n",
      "('than', 'IN')\n",
      "('supervised', 'JJ')\n",
      "('learning', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('typically', 'RB')\n",
      "('produces', 'VBZ')\n",
      "('less', 'JJR')\n",
      "('accurate', 'JJ')\n",
      "('results', 'NNS')\n",
      "('for', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('enormous', 'JJ')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('non-annotated', 'JJ')\n",
      "('data', 'NNS')\n",
      "('available', 'JJ')\n",
      "('(', '(')\n",
      "('including', 'VBG')\n",
      "(',', ',')\n",
      "('among', 'IN')\n",
      "('other', 'JJ')\n",
      "('things', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('entire', 'JJ')\n",
      "('content', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('World', 'NNP')\n",
      "('Wide', 'NNP')\n",
      "('Web', 'NNP')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('can', 'MD')\n",
      "('often', 'RB')\n",
      "('make', 'VB')\n",
      "('up', 'RP')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('inferior', 'JJ')\n",
      "('results', 'NNS')\n",
      "('if', 'IN')\n",
      "('the', 'DT')\n",
      "('algorithm', 'NN')\n",
      "('used', 'VBN')\n",
      "('has', 'VBZ')\n",
      "('a', 'DT')\n",
      "('low', 'JJ')\n",
      "('enough', 'JJ')\n",
      "('time', 'NN')\n",
      "('complexity', 'NN')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('practical', 'JJ')\n",
      "('.', '.')\n",
      "('Neural', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('present', 'JJ')\n",
      "(')', ')')\n",
      "('[', 'FW')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('In', 'IN')\n",
      "('the', 'DT')\n",
      "('2010s', 'CD')\n",
      "(',', ',')\n",
      "('representation', 'NN')\n",
      "('learning', 'NN')\n",
      "('and', 'CC')\n",
      "('deep', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('-style', 'JJ')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('methods', 'NNS')\n",
      "('became', 'VBD')\n",
      "('widespread', 'JJ')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "(',', ',')\n",
      "('due', 'JJ')\n",
      "('in', 'IN')\n",
      "('part', 'NN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('flurry', 'NN')\n",
      "('of', 'IN')\n",
      "('results', 'NNS')\n",
      "('showing', 'VBG')\n",
      "('that', 'IN')\n",
      "('such', 'JJ')\n",
      "('techniques', 'NNS')\n",
      "('[', 'VBP')\n",
      "('7', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('8', 'CD')\n",
      "(']', 'NNS')\n",
      "('can', 'MD')\n",
      "('achieve', 'VB')\n",
      "('state-of-the-art', 'JJ')\n",
      "('results', 'NNS')\n",
      "('in', 'IN')\n",
      "('many', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('tasks', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "('in', 'IN')\n",
      "('language', 'NN')\n",
      "('modeling', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('9', 'CD')\n",
      "(']', 'NN')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('10', 'CD')\n",
      "(']', 'NN')\n",
      "('[', 'VBD')\n",
      "('11', 'CD')\n",
      "(']', 'NNP')\n",
      "('and', 'CC')\n",
      "('many', 'JJ')\n",
      "('others', 'NNS')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('increasingly', 'RB')\n",
      "('important', 'JJ')\n",
      "('in', 'IN')\n",
      "('medicine', 'NN')\n",
      "('and', 'CC')\n",
      "('healthcare', 'NN')\n",
      "(',', ',')\n",
      "('where', 'WRB')\n",
      "('NLP', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('being', 'VBG')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('analyze', 'VB')\n",
      "('notes', 'NNS')\n",
      "('and', 'CC')\n",
      "('text', 'NN')\n",
      "('in', 'IN')\n",
      "('electronic', 'JJ')\n",
      "('health', 'NN')\n",
      "('records', 'NNS')\n",
      "('that', 'WDT')\n",
      "('would', 'MD')\n",
      "('otherwise', 'RB')\n",
      "('be', 'VB')\n",
      "('inaccessible', 'JJ')\n",
      "('for', 'IN')\n",
      "('study', 'NN')\n",
      "('when', 'WRB')\n",
      "('seeking', 'VBG')\n",
      "('to', 'TO')\n",
      "('improve', 'VB')\n",
      "('care', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('12', 'CD')\n",
      "(']', 'JJ')\n",
      "('Methods', 'NNS')\n",
      "(':', ':')\n",
      "('Rules', 'NNS')\n",
      "(',', ',')\n",
      "('statistics', 'NNS')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('In', 'IN')\n",
      "('the', 'DT')\n",
      "('early', 'JJ')\n",
      "('days', 'NNS')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('language-processing', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('designed', 'VBN')\n",
      "('by', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('i.e.', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('hand-coding', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('coupled', 'VBN')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('lookup', 'NN')\n",
      "(':', ':')\n",
      "('[', 'JJ')\n",
      "('13', 'CD')\n",
      "(']', 'JJ')\n",
      "('[', '$')\n",
      "('14', 'CD')\n",
      "(']', 'NNP')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('by', 'IN')\n",
      "('writing', 'VBG')\n",
      "('grammars', 'NNS')\n",
      "('or', 'CC')\n",
      "('devising', 'VBG')\n",
      "('heuristic', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('for', 'IN')\n",
      "('stemming', 'VBG')\n",
      "('.', '.')\n",
      "('More', 'RBR')\n",
      "('recent', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('machine-learning', 'JJ')\n",
      "('algorithms', 'NNS')\n",
      "('have', 'VBP')\n",
      "('many', 'JJ')\n",
      "('advantages', 'NNS')\n",
      "('over', 'IN')\n",
      "('hand-produced', 'JJ')\n",
      "('rules', 'NNS')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('learning', 'NN')\n",
      "('procedures', 'NNS')\n",
      "('used', 'VBN')\n",
      "('during', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('automatically', 'RB')\n",
      "('focus', 'VB')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('common', 'JJ')\n",
      "('cases', 'NNS')\n",
      "(',', ',')\n",
      "('whereas', 'NNS')\n",
      "('when', 'WRB')\n",
      "('writing', 'VBG')\n",
      "('rules', 'NNS')\n",
      "('by', 'IN')\n",
      "('hand', 'NN')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('not', 'RB')\n",
      "('at', 'IN')\n",
      "('all', 'DT')\n",
      "('obvious', 'JJ')\n",
      "('where', 'WRB')\n",
      "('the', 'DT')\n",
      "('effort', 'NN')\n",
      "('should', 'MD')\n",
      "('be', 'VB')\n",
      "('directed', 'VBN')\n",
      "('.', '.')\n",
      "('Automatic', 'NNP')\n",
      "('learning', 'NN')\n",
      "('procedures', 'NNS')\n",
      "('can', 'MD')\n",
      "('make', 'VB')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('inference', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('to', 'TO')\n",
      "('produce', 'VB')\n",
      "('models', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('robust', 'JJ')\n",
      "('to', 'TO')\n",
      "('unfamiliar', 'JJ')\n",
      "('input', 'NN')\n",
      "('(', '(')\n",
      "('e.g', 'JJ')\n",
      "('.', '.')\n",
      "('containing', 'VBG')\n",
      "('words', 'NNS')\n",
      "('or', 'CC')\n",
      "('structures', 'NNS')\n",
      "('that', 'WDT')\n",
      "('have', 'VBP')\n",
      "('not', 'RB')\n",
      "('been', 'VBN')\n",
      "('seen', 'VBN')\n",
      "('before', 'IN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('to', 'TO')\n",
      "('erroneous', 'JJ')\n",
      "('input', 'NN')\n",
      "('(', '(')\n",
      "('e.g', 'JJ')\n",
      "('.', '.')\n",
      "('with', 'IN')\n",
      "('misspelled', 'JJ')\n",
      "('words', 'NNS')\n",
      "('or', 'CC')\n",
      "('words', 'NNS')\n",
      "('accidentally', 'RB')\n",
      "('omitted', 'VBN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Generally', 'RB')\n",
      "(',', ',')\n",
      "('handling', 'VBG')\n",
      "('such', 'JJ')\n",
      "('input', 'NN')\n",
      "('gracefully', 'RB')\n",
      "('with', 'IN')\n",
      "('handwritten', 'NN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "(',', ',')\n",
      "('more', 'RBR')\n",
      "('generally', 'RB')\n",
      "(',', ',')\n",
      "('creating', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('handwritten', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('that', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('extremely', 'RB')\n",
      "('difficult', 'JJ')\n",
      "(',', ',')\n",
      "('error-prone', 'JJ')\n",
      "('and', 'CC')\n",
      "('time-consuming', 'JJ')\n",
      "('.', '.')\n",
      "('Systems', 'NNPS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('automatically', 'RB')\n",
      "('learning', 'VBG')\n",
      "('the', 'DT')\n",
      "('rules', 'NNS')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('made', 'VBN')\n",
      "('more', 'RBR')\n",
      "('accurate', 'JJ')\n",
      "('simply', 'RB')\n",
      "('by', 'IN')\n",
      "('supplying', 'VBG')\n",
      "('more', 'JJR')\n",
      "('input', 'JJ')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('handwritten', 'NNS')\n",
      "('rules', 'NNS')\n",
      "('can', 'MD')\n",
      "('only', 'RB')\n",
      "('be', 'VB')\n",
      "('made', 'VBN')\n",
      "('more', 'RBR')\n",
      "('accurate', 'JJ')\n",
      "('by', 'IN')\n",
      "('increasing', 'VBG')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('much', 'RB')\n",
      "('more', 'RBR')\n",
      "('difficult', 'JJ')\n",
      "('task', 'NN')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('particular', 'JJ')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('limit', 'NN')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('handwritten', 'NN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('beyond', 'IN')\n",
      "('which', 'WDT')\n",
      "('the', 'DT')\n",
      "('systems', 'NNS')\n",
      "('become', 'VBP')\n",
      "('more', 'JJR')\n",
      "('and', 'CC')\n",
      "('more', 'RBR')\n",
      "('unmanageable', 'JJ')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('creating', 'VBG')\n",
      "('more', 'JJR')\n",
      "('data', 'NNS')\n",
      "('to', 'TO')\n",
      "('input', 'VB')\n",
      "('to', 'TO')\n",
      "('machine-learning', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('simply', 'RB')\n",
      "('requires', 'VBZ')\n",
      "('a', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('man-hours', 'JJ')\n",
      "('worked', 'NN')\n",
      "(',', ',')\n",
      "('generally', 'RB')\n",
      "('without', 'IN')\n",
      "('significant', 'JJ')\n",
      "('increases', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('annotation', 'NN')\n",
      "('process', 'NN')\n",
      "('.', '.')\n",
      "('Despite', 'IN')\n",
      "('the', 'DT')\n",
      "('popularity', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('research', 'NN')\n",
      "(',', ',')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('are', 'VBP')\n",
      "('still', 'RB')\n",
      "('(', '(')\n",
      "('2020', 'CD')\n",
      "(')', ')')\n",
      "('commonly', 'RB')\n",
      "('used', 'VBN')\n",
      "(':', ':')\n",
      "('when', 'WRB')\n",
      "('the', 'DT')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('training', 'NN')\n",
      "('data', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('insufficient', 'JJ')\n",
      "('to', 'TO')\n",
      "('successfully', 'RB')\n",
      "('apply', 'VB')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('low-resource', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('provided', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "('Apertium', 'NNP')\n",
      "('system', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('preprocessing', 'VBG')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('pipelines', 'NNS')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('tokenization', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('for', 'IN')\n",
      "('postprocessing', 'VBG')\n",
      "('and', 'CC')\n",
      "('transforming', 'VBG')\n",
      "('the', 'DT')\n",
      "('output', 'NN')\n",
      "('of', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('pipelines', 'NNS')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('knowledge', 'NN')\n",
      "('extraction', 'NN')\n",
      "('from', 'IN')\n",
      "('syntactic', 'JJ')\n",
      "('parses', 'NNS')\n",
      "('.', '.')\n",
      "('Statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('Since', 'IN')\n",
      "('the', 'DT')\n",
      "('so-called', 'JJ')\n",
      "('``', '``')\n",
      "('statistical', 'JJ')\n",
      "('revolution', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('[', '$')\n",
      "('15', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('16', 'CD')\n",
      "(']', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'CD')\n",
      "('and', 'CC')\n",
      "('mid-1990s', 'NNS')\n",
      "(',', ',')\n",
      "('much', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('relied', 'VBN')\n",
      "('heavily', 'RB')\n",
      "('on', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('machine-learning', 'JJ')\n",
      "('paradigm', 'NN')\n",
      "('calls', 'VBZ')\n",
      "('instead', 'RB')\n",
      "('for', 'IN')\n",
      "('using', 'VBG')\n",
      "('statistical', 'JJ')\n",
      "('inference', 'NN')\n",
      "('to', 'TO')\n",
      "('automatically', 'RB')\n",
      "('learn', 'VB')\n",
      "('such', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('analysis', 'NN')\n",
      "('of', 'IN')\n",
      "('large', 'JJ')\n",
      "('corpora', 'NNS')\n",
      "('(', '(')\n",
      "('the', 'DT')\n",
      "('plural', 'JJ')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('corpus', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('possibly', 'RB')\n",
      "('with', 'IN')\n",
      "('human', 'NN')\n",
      "('or', 'CC')\n",
      "('computer', 'NN')\n",
      "('annotations', 'NNS')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('typical', 'JJ')\n",
      "('real-world', 'NN')\n",
      "('examples', 'NNS')\n",
      "('.', '.')\n",
      "('Many', 'JJ')\n",
      "('different', 'JJ')\n",
      "('classes', 'NNS')\n",
      "('of', 'IN')\n",
      "('machine-learning', 'JJ')\n",
      "('algorithms', 'NNS')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('applied', 'VBN')\n",
      "('to', 'TO')\n",
      "('natural-language-processing', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('These', 'DT')\n",
      "('algorithms', 'NNS')\n",
      "('take', 'VBP')\n",
      "('as', 'IN')\n",
      "('input', 'NN')\n",
      "('a', 'DT')\n",
      "('large', 'JJ')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('``', '``')\n",
      "('features', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('generated', 'VBN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('Increasingly', 'NNP')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "(',', ',')\n",
      "('probabilistic', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('attaching', 'VBG')\n",
      "('real-valued', 'JJ')\n",
      "('weights', 'NNS')\n",
      "('to', 'TO')\n",
      "('each', 'DT')\n",
      "('input', 'NN')\n",
      "('feature', 'NN')\n",
      "('(', '(')\n",
      "('complex-valued', 'JJ')\n",
      "('embeddings', 'NNS')\n",
      "(',', ',')\n",
      "('[', 'VBP')\n",
      "('17', 'CD')\n",
      "(']', 'NN')\n",
      "('and', 'CC')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('in', 'IN')\n",
      "('general', 'JJ')\n",
      "('have', 'VBP')\n",
      "('also', 'RB')\n",
      "('been', 'VBN')\n",
      "('proposed', 'VBN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('speech', 'NN')\n",
      "('[', 'VBD')\n",
      "('18', 'CD')\n",
      "(']', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('have', 'VBP')\n",
      "('the', 'DT')\n",
      "('advantage', 'NN')\n",
      "('that', 'IN')\n",
      "('they', 'PRP')\n",
      "('can', 'MD')\n",
      "('express', 'VB')\n",
      "('the', 'DT')\n",
      "('relative', 'JJ')\n",
      "('certainty', 'NN')\n",
      "('of', 'IN')\n",
      "('many', 'JJ')\n",
      "('different', 'JJ')\n",
      "('possible', 'JJ')\n",
      "('answers', 'NNS')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('only', 'RB')\n",
      "('one', 'CD')\n",
      "(',', ',')\n",
      "('producing', 'VBG')\n",
      "('more', 'RBR')\n",
      "('reliable', 'JJ')\n",
      "('results', 'NNS')\n",
      "('when', 'WRB')\n",
      "('such', 'PDT')\n",
      "('a', 'DT')\n",
      "('model', 'NN')\n",
      "('is', 'VBZ')\n",
      "('included', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('component', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('larger', 'JJR')\n",
      "('system', 'NN')\n",
      "('.', '.')\n",
      "('Some', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('earliest-used', 'JJ')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('algorithms', 'NNS')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('decision', 'NN')\n",
      "('trees', 'NNS')\n",
      "(',', ',')\n",
      "('produced', 'VBD')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('hard', 'JJ')\n",
      "('if-then', 'NN')\n",
      "('rules', 'NNS')\n",
      "('similar', 'JJ')\n",
      "('to', 'TO')\n",
      "('existing', 'VBG')\n",
      "('hand-written', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('part-of-speech', 'JJ')\n",
      "('tagging', 'NN')\n",
      "('introduced', 'VBD')\n",
      "('the', 'DT')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('hidden', 'JJ')\n",
      "('Markov', 'NNP')\n",
      "('models', 'NNS')\n",
      "('to', 'TO')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('increasingly', 'RB')\n",
      "(',', ',')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "(',', ',')\n",
      "('probabilistic', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('attaching', 'VBG')\n",
      "('real-valued', 'JJ')\n",
      "('weights', 'NNS')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('features', 'NNS')\n",
      "('making', 'VBG')\n",
      "('up', 'RP')\n",
      "('the', 'DT')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('cache', 'NN')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('upon', 'IN')\n",
      "('which', 'WDT')\n",
      "('many', 'JJ')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('systems', 'NNS')\n",
      "('now', 'RB')\n",
      "('rely', 'RB')\n",
      "('are', 'VBP')\n",
      "('examples', 'NNS')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "('.', '.')\n",
      "('Such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('are', 'VBP')\n",
      "('generally', 'RB')\n",
      "('more', 'RBR')\n",
      "('robust', 'JJ')\n",
      "('when', 'WRB')\n",
      "('given', 'VBN')\n",
      "('unfamiliar', 'JJ')\n",
      "('input', 'NN')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('input', 'VBP')\n",
      "('that', 'IN')\n",
      "('contains', 'VBZ')\n",
      "('errors', 'NNS')\n",
      "('(', '(')\n",
      "('as', 'IN')\n",
      "('is', 'VBZ')\n",
      "('very', 'RB')\n",
      "('common', 'JJ')\n",
      "('for', 'IN')\n",
      "('real-world', 'JJ')\n",
      "('data', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('produce', 'VB')\n",
      "('more', 'JJR')\n",
      "('reliable', 'JJ')\n",
      "('results', 'NNS')\n",
      "('when', 'WRB')\n",
      "('integrated', 'VBN')\n",
      "('into', 'IN')\n",
      "('a', 'DT')\n",
      "('larger', 'JJR')\n",
      "('system', 'NN')\n",
      "('comprising', 'VBG')\n",
      "('multiple', 'JJ')\n",
      "('subtasks', 'NNS')\n",
      "('.', '.')\n",
      "('Since', 'IN')\n",
      "('the', 'DT')\n",
      "('neural', 'JJ')\n",
      "('turn', 'NN')\n",
      "(',', ',')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('research', 'NN')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('largely', 'RB')\n",
      "('replaced', 'VBN')\n",
      "('by', 'IN')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('they', 'PRP')\n",
      "('continue', 'VBP')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('relevant', 'JJ')\n",
      "('for', 'IN')\n",
      "('contexts', 'NN')\n",
      "('in', 'IN')\n",
      "('which', 'WDT')\n",
      "('statistical', 'JJ')\n",
      "('interpretability', 'NN')\n",
      "('and', 'CC')\n",
      "('transparency', 'NN')\n",
      "('is', 'VBZ')\n",
      "('required', 'VBN')\n",
      "('.', '.')\n",
      "('Neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Further', 'NNP')\n",
      "('information', 'NN')\n",
      "(':', ':')\n",
      "('Artificial', 'NNP')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('A', 'DT')\n",
      "('major', 'JJ')\n",
      "('drawback', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('that', 'IN')\n",
      "('they', 'PRP')\n",
      "('require', 'VBP')\n",
      "('elaborate', 'JJ')\n",
      "('feature', 'NN')\n",
      "('engineering', 'NN')\n",
      "('.', '.')\n",
      "('Since', 'IN')\n",
      "('2015', 'CD')\n",
      "(',', ',')\n",
      "('[', 'VBD')\n",
      "('19', 'CD')\n",
      "(']', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('largely', 'RB')\n",
      "('abandoned', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('and', 'CC')\n",
      "('shifted', 'VBD')\n",
      "('to', 'TO')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('for', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('.', '.')\n",
      "('Popular', 'JJ')\n",
      "('techniques', 'NNS')\n",
      "('include', 'VBP')\n",
      "('the', 'DT')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('word', 'NN')\n",
      "('embeddings', 'NNS')\n",
      "('to', 'TO')\n",
      "('capture', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('properties', 'NNS')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('an', 'DT')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('end-to-end', 'JJ')\n",
      "('learning', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('higher-level', 'JJ')\n",
      "('task', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('question', 'NN')\n",
      "('answering', 'VBG')\n",
      "(')', ')')\n",
      "('instead', 'RB')\n",
      "('of', 'IN')\n",
      "('relying', 'VBG')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('pipeline', 'NN')\n",
      "('of', 'IN')\n",
      "('separate', 'JJ')\n",
      "('intermediate', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('part-of-speech', 'JJ')\n",
      "('tagging', 'NN')\n",
      "('and', 'CC')\n",
      "('dependency', 'NN')\n",
      "('parsing', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('some', 'DT')\n",
      "('areas', 'NNS')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('shift', 'NN')\n",
      "('has', 'VBZ')\n",
      "('entailed', 'VBN')\n",
      "('substantial', 'JJ')\n",
      "('changes', 'NNS')\n",
      "('in', 'IN')\n",
      "('how', 'WRB')\n",
      "('NLP', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('are', 'VBP')\n",
      "('designed', 'VBN')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('that', 'IN')\n",
      "('deep', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network-based', 'JJ')\n",
      "('approaches', 'NNS')\n",
      "('may', 'MD')\n",
      "('be', 'VB')\n",
      "('viewed', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('new', 'JJ')\n",
      "('paradigm', 'NN')\n",
      "('distinct', 'NN')\n",
      "('from', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('instance', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('term', 'NN')\n",
      "('neural', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('(', '(')\n",
      "('NMT', 'NNP')\n",
      "(')', ')')\n",
      "('emphasizes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('fact', 'NN')\n",
      "('that', 'IN')\n",
      "('deep', 'JJ')\n",
      "('learning-based', 'JJ')\n",
      "('approaches', 'NNS')\n",
      "('to', 'TO')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('directly', 'RB')\n",
      "('learn', 'VBZ')\n",
      "('sequence-to-sequence', 'NN')\n",
      "('transformations', 'NNS')\n",
      "(',', ',')\n",
      "('obviating', 'VBG')\n",
      "('the', 'DT')\n",
      "('need', 'NN')\n",
      "('for', 'IN')\n",
      "('intermediate', 'JJ')\n",
      "('steps', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('word', 'NN')\n",
      "('alignment', 'NN')\n",
      "('and', 'CC')\n",
      "('language', 'NN')\n",
      "('modeling', 'NN')\n",
      "('that', 'WDT')\n",
      "('was', 'VBD')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('(', '(')\n",
      "('SMT', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Latest', 'JJS')\n",
      "('works', 'NNS')\n",
      "('tend', 'VBP')\n",
      "('to', 'TO')\n",
      "('use', 'VB')\n",
      "('non-technical', 'JJ')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('task', 'NN')\n",
      "('to', 'TO')\n",
      "('build', 'VB')\n",
      "('proper', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('20', 'CD')\n",
      "(']', 'JJ')\n",
      "('Common', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'NNS')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('The', 'DT')\n",
      "('following', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('list', 'NN')\n",
      "('of', 'IN')\n",
      "('some', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('commonly', 'RB')\n",
      "('researched', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('Some', 'DT')\n",
      "('of', 'IN')\n",
      "('these', 'DT')\n",
      "('tasks', 'NNS')\n",
      "('have', 'VBP')\n",
      "('direct', 'JJ')\n",
      "('real-world', 'NN')\n",
      "('applications', 'NNS')\n",
      "(',', ',')\n",
      "('while', 'IN')\n",
      "('others', 'NNS')\n",
      "('more', 'RBR')\n",
      "('commonly', 'RB')\n",
      "('serve', 'VBP')\n",
      "('as', 'IN')\n",
      "('subtasks', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('aid', 'VB')\n",
      "('in', 'IN')\n",
      "('solving', 'VBG')\n",
      "('larger', 'JJR')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('Though', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('tasks', 'NNS')\n",
      "('are', 'VBP')\n",
      "('closely', 'RB')\n",
      "('intertwined', 'VBN')\n",
      "(',', ',')\n",
      "('they', 'PRP')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('subdivided', 'VBN')\n",
      "('into', 'IN')\n",
      "('categories', 'NNS')\n",
      "('for', 'IN')\n",
      "('convenience', 'NN')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('coarse', 'JJ')\n",
      "('division', 'NN')\n",
      "('is', 'VBZ')\n",
      "('given', 'VBN')\n",
      "('below', 'IN')\n",
      "('.', '.')\n",
      "('Text', 'NNP')\n",
      "('and', 'CC')\n",
      "('speech', 'NN')\n",
      "('processing', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Optical', 'NNP')\n",
      "('character', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "('OCR', 'NNP')\n",
      "(')', ')')\n",
      "('Given', 'NNP')\n",
      "('an', 'DT')\n",
      "('image', 'NN')\n",
      "('representing', 'VBG')\n",
      "('printed', 'VBN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "('Speech', 'NNP')\n",
      "('recognition', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sound', 'JJ')\n",
      "('clip', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('or', 'CC')\n",
      "('people', 'NNS')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('textual', 'JJ')\n",
      "('representation', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('opposite', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('to', 'TO')\n",
      "('speech', 'NN')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('extremely', 'RB')\n",
      "('difficult', 'JJ')\n",
      "('problems', 'NNS')\n",
      "('colloquially', 'RB')\n",
      "('termed', 'VBD')\n",
      "('``', '``')\n",
      "('AI-complete', 'JJ')\n",
      "('``', '``')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('above', 'IN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('natural', 'JJ')\n",
      "('speech', 'NN')\n",
      "('there', 'EX')\n",
      "('are', 'VBP')\n",
      "('hardly', 'RB')\n",
      "('any', 'DT')\n",
      "('pauses', 'NNS')\n",
      "('between', 'IN')\n",
      "('successive', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('thus', 'RB')\n",
      "('speech', 'JJ')\n",
      "('segmentation', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('necessary', 'JJ')\n",
      "('subtask', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('below', 'IN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('most', 'JJS')\n",
      "('spoken', 'JJ')\n",
      "('languages', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('sounds', 'NNS')\n",
      "('representing', 'VBG')\n",
      "('successive', 'JJ')\n",
      "('letters', 'NNS')\n",
      "('blend', 'VBP')\n",
      "('into', 'IN')\n",
      "('each', 'DT')\n",
      "('other', 'JJ')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('process', 'NN')\n",
      "('termed', 'VBN')\n",
      "('coarticulation', 'NN')\n",
      "(',', ',')\n",
      "('so', 'IN')\n",
      "('the', 'DT')\n",
      "('conversion', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('analog', 'NN')\n",
      "('signal', 'NN')\n",
      "('to', 'TO')\n",
      "('discrete', 'VB')\n",
      "('characters', 'NNS')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('very', 'RB')\n",
      "('difficult', 'JJ')\n",
      "('process', 'NN')\n",
      "('.', '.')\n",
      "('Also', 'RB')\n",
      "(',', ',')\n",
      "('given', 'VBN')\n",
      "('that', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('same', 'JJ')\n",
      "('language', 'NN')\n",
      "('are', 'VBP')\n",
      "('spoken', 'VBN')\n",
      "('by', 'IN')\n",
      "('people', 'NNS')\n",
      "('with', 'IN')\n",
      "('different', 'JJ')\n",
      "('accents', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('software', 'NN')\n",
      "('must', 'MD')\n",
      "('be', 'VB')\n",
      "('able', 'JJ')\n",
      "('to', 'TO')\n",
      "('recognize', 'VB')\n",
      "('the', 'DT')\n",
      "('wide', 'JJ')\n",
      "('variety', 'NN')\n",
      "('of', 'IN')\n",
      "('input', 'NN')\n",
      "('as', 'IN')\n",
      "('being', 'VBG')\n",
      "('identical', 'JJ')\n",
      "('to', 'TO')\n",
      "('each', 'DT')\n",
      "('other', 'JJ')\n",
      "('in', 'IN')\n",
      "('terms', 'NNS')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('textual', 'JJ')\n",
      "('equivalent', 'NN')\n",
      "('.', '.')\n",
      "('Speech', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sound', 'JJ')\n",
      "('clip', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('or', 'CC')\n",
      "('people', 'NNS')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('separate', 'JJ')\n",
      "('it', 'PRP')\n",
      "('into', 'IN')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('subtask', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('and', 'CC')\n",
      "('typically', 'RB')\n",
      "('grouped', 'VBD')\n",
      "('with', 'IN')\n",
      "('it', 'PRP')\n",
      "('.', '.')\n",
      "('Text-to-speech', 'JJ')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('transform', 'VB')\n",
      "('those', 'DT')\n",
      "('units', 'NNS')\n",
      "('and', 'CC')\n",
      "('produce', 'VB')\n",
      "('a', 'DT')\n",
      "('spoken', 'JJ')\n",
      "('representation', 'NN')\n",
      "('.', '.')\n",
      "('Text-to-speech', 'NN')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('aid', 'VB')\n",
      "('the', 'DT')\n",
      "('visually', 'RB')\n",
      "('impaired', 'JJ')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('21', 'CD')\n",
      "(']', 'NNP')\n",
      "('Word', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('(', '(')\n",
      "('Tokenization', 'NNP')\n",
      "(')', ')')\n",
      "('Separate', 'VBP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('continuous', 'JJ')\n",
      "('text', 'NN')\n",
      "('into', 'IN')\n",
      "('separate', 'JJ')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "('like', 'IN')\n",
      "('English', 'NNP')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('is', 'VBZ')\n",
      "('fairly', 'RB')\n",
      "('trivial', 'JJ')\n",
      "(',', ',')\n",
      "('since', 'IN')\n",
      "('words', 'NNS')\n",
      "('are', 'VBP')\n",
      "('usually', 'RB')\n",
      "('separated', 'VBN')\n",
      "('by', 'IN')\n",
      "('spaces', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('some', 'DT')\n",
      "('written', 'VBN')\n",
      "('languages', 'NNS')\n",
      "('like', 'IN')\n",
      "('Chinese', 'NNP')\n",
      "(',', ',')\n",
      "('Japanese', 'JJ')\n",
      "('and', 'CC')\n",
      "('Thai', 'NNP')\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('mark', 'VB')\n",
      "('word', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('in', 'IN')\n",
      "('such', 'JJ')\n",
      "('a', 'DT')\n",
      "('fashion', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('in', 'IN')\n",
      "('those', 'DT')\n",
      "('languages', 'NNS')\n",
      "('text', 'VBP')\n",
      "('segmentation', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('significant', 'JJ')\n",
      "('task', 'NN')\n",
      "('requiring', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('vocabulary', 'JJ')\n",
      "('and', 'CC')\n",
      "('morphology', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('Sometimes', 'RB')\n",
      "('this', 'DT')\n",
      "('process', 'NN')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('cases', 'NNS')\n",
      "('like', 'IN')\n",
      "('bag', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('(', '(')\n",
      "('BOW', 'NNP')\n",
      "(')', ')')\n",
      "('creation', 'NN')\n",
      "('in', 'IN')\n",
      "('data', 'NNS')\n",
      "('mining', 'NN')\n",
      "('.', '.')\n",
      "('Morphological', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Lemmatization', 'NNP')\n",
      "('The', 'DT')\n",
      "('task', 'NN')\n",
      "('of', 'IN')\n",
      "('removing', 'VBG')\n",
      "('inflectional', 'JJ')\n",
      "('endings', 'NNS')\n",
      "('only', 'RB')\n",
      "('and', 'CC')\n",
      "('to', 'TO')\n",
      "('return', 'VB')\n",
      "('the', 'DT')\n",
      "('base', 'NN')\n",
      "('dictionary', 'JJ')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('known', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('lemma', 'NN')\n",
      "('.', '.')\n",
      "('Lemmatization', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('another', 'DT')\n",
      "('technique', 'NN')\n",
      "('for', 'IN')\n",
      "('reducing', 'VBG')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('their', 'PRP$')\n",
      "('normalized', 'JJ')\n",
      "('form', 'NN')\n",
      "('.', '.')\n",
      "('But', 'CC')\n",
      "('in', 'IN')\n",
      "('this', 'DT')\n",
      "('case', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('transformation', 'NN')\n",
      "('actually', 'RB')\n",
      "('uses', 'VBZ')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('to', 'TO')\n",
      "('map', 'VB')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('their', 'PRP$')\n",
      "('actual', 'JJ')\n",
      "('form', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('22', 'CD')\n",
      "(']', 'JJ')\n",
      "('Morphological', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Separate', 'NNP')\n",
      "('words', 'NNS')\n",
      "('into', 'IN')\n",
      "('individual', 'JJ')\n",
      "('morphemes', 'NNS')\n",
      "('and', 'CC')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('class', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('morphemes', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('difficulty', 'NN')\n",
      "('of', 'IN')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('depends', 'VBZ')\n",
      "('greatly', 'RB')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('morphology', 'NN')\n",
      "('(', '(')\n",
      "('i.e', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('being', 'VBG')\n",
      "('considered', 'VBN')\n",
      "('.', '.')\n",
      "('English', 'NNP')\n",
      "('has', 'VBZ')\n",
      "('fairly', 'RB')\n",
      "('simple', 'JJ')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('inflectional', 'JJ')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('thus', 'RB')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('possible', 'JJ')\n",
      "('to', 'TO')\n",
      "('ignore', 'VB')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('entirely', 'RB')\n",
      "('and', 'CC')\n",
      "('simply', 'RB')\n",
      "('model', 'VB')\n",
      "('all', 'DT')\n",
      "('possible', 'JJ')\n",
      "('forms', 'NNS')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('open', 'JJ')\n",
      "(',', ',')\n",
      "('opens', 'VBZ')\n",
      "(',', ',')\n",
      "('opened', 'VBD')\n",
      "(',', ',')\n",
      "('opening', 'VBG')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "('as', 'IN')\n",
      "('separate', 'JJ')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('Turkish', 'JJ')\n",
      "('or', 'CC')\n",
      "('Meitei', 'NNP')\n",
      "(',', ',')\n",
      "('[', 'VBD')\n",
      "('23', 'CD')\n",
      "(']', 'FW')\n",
      "('a', 'DT')\n",
      "('highly', 'RB')\n",
      "('agglutinated', 'JJ')\n",
      "('Indian', 'JJ')\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('such', 'PDT')\n",
      "('an', 'DT')\n",
      "('approach', 'NN')\n",
      "('is', 'VBZ')\n",
      "('not', 'RB')\n",
      "('possible', 'JJ')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('each', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('entry', 'NN')\n",
      "('has', 'VBZ')\n",
      "('thousands', 'NNS')\n",
      "('of', 'IN')\n",
      "('possible', 'JJ')\n",
      "('word', 'NN')\n",
      "('forms', 'NNS')\n",
      "('.', '.')\n",
      "('Part-of-speech', 'JJ')\n",
      "('tagging', 'VBG')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('(', '(')\n",
      "('POS', 'NNP')\n",
      "(')', ')')\n",
      "('for', 'IN')\n",
      "('each', 'DT')\n",
      "('word', 'NN')\n",
      "('.', '.')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('common', 'JJ')\n",
      "('ones', 'NNS')\n",
      "(',', ',')\n",
      "('can', 'MD')\n",
      "('serve', 'VB')\n",
      "('as', 'IN')\n",
      "('multiple', 'JJ')\n",
      "('parts', 'NNS')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('book', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('noun', 'NN')\n",
      "('(', '(')\n",
      "('``', '``')\n",
      "('the', 'DT')\n",
      "('book', 'NN')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('table', 'NN')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "('or', 'CC')\n",
      "('verb', 'NN')\n",
      "('(', '(')\n",
      "('``', '``')\n",
      "('to', 'TO')\n",
      "('book', 'NN')\n",
      "('a', 'DT')\n",
      "('flight', 'NN')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "(';', ':')\n",
      "('``', '``')\n",
      "('set', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('noun', 'NN')\n",
      "(',', ',')\n",
      "('verb', 'NN')\n",
      "('or', 'CC')\n",
      "('adjective', 'JJ')\n",
      "(';', ':')\n",
      "('and', 'CC')\n",
      "('``', '``')\n",
      "('out', 'IN')\n",
      "(\"''\", \"''\")\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('any', 'DT')\n",
      "('of', 'IN')\n",
      "('at', 'IN')\n",
      "('least', 'JJS')\n",
      "('five', 'CD')\n",
      "('different', 'JJ')\n",
      "('parts', 'NNS')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('Stemming', 'VBG')\n",
      "('The', 'DT')\n",
      "('process', 'NN')\n",
      "('of', 'IN')\n",
      "('reducing', 'VBG')\n",
      "('inflected', 'VBN')\n",
      "('(', '(')\n",
      "('or', 'CC')\n",
      "('sometimes', 'RB')\n",
      "('derived', 'VBN')\n",
      "(')', ')')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('base', 'JJ')\n",
      "('form', 'NN')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('close', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('will', 'MD')\n",
      "('be', 'VB')\n",
      "('the', 'DT')\n",
      "('root', 'NN')\n",
      "('for', 'IN')\n",
      "('``', '``')\n",
      "('closed', 'JJ')\n",
      "(\"''\", \"''\")\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('closing', 'NN')\n",
      "(\"''\", \"''\")\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('close', 'NN')\n",
      "(\"''\", \"''\")\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('closer', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('etc.', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Stemming', 'VBG')\n",
      "('yields', 'NNS')\n",
      "('similar', 'JJ')\n",
      "('results', 'NNS')\n",
      "('as', 'IN')\n",
      "('lemmatization', 'NN')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('does', 'VBZ')\n",
      "('so', 'RB')\n",
      "('on', 'IN')\n",
      "('grounds', 'NNS')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('not', 'RB')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('.', '.')\n",
      "('Syntactic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Grammar', 'NNP')\n",
      "('induction', 'NN')\n",
      "('[', 'VBD')\n",
      "('24', 'CD')\n",
      "(']', 'NNP')\n",
      "('Generate', 'NNP')\n",
      "('a', 'DT')\n",
      "('formal', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('that', 'WDT')\n",
      "('describes', 'VBZ')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "(\"'s\", 'POS')\n",
      "('syntax', 'NN')\n",
      "('.', '.')\n",
      "('Sentence', 'NN')\n",
      "('breaking', 'NN')\n",
      "('(', '(')\n",
      "('also', 'RB')\n",
      "('known', 'VBN')\n",
      "('as', 'IN')\n",
      "('``', '``')\n",
      "('sentence', 'NN')\n",
      "('boundary', 'JJ')\n",
      "('disambiguation', 'NN')\n",
      "('``', '``')\n",
      "(')', ')')\n",
      "('Given', 'VBZ')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('find', 'VBP')\n",
      "('the', 'DT')\n",
      "('sentence', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('.', '.')\n",
      "('Sentence', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('are', 'VBP')\n",
      "('often', 'RB')\n",
      "('marked', 'VBN')\n",
      "('by', 'IN')\n",
      "('periods', 'NNS')\n",
      "('or', 'CC')\n",
      "('other', 'JJ')\n",
      "('punctuation', 'NN')\n",
      "('marks', 'NNS')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('these', 'DT')\n",
      "('same', 'JJ')\n",
      "('characters', 'NNS')\n",
      "('can', 'MD')\n",
      "('serve', 'VB')\n",
      "('other', 'JJ')\n",
      "('purposes', 'NNS')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('marking', 'VBG')\n",
      "('abbreviations', 'NNS')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Parsing', 'VBG')\n",
      "('Determine', 'NNP')\n",
      "('the', 'DT')\n",
      "('parse', 'NN')\n",
      "('tree', 'NN')\n",
      "('(', '(')\n",
      "('grammatical', 'JJ')\n",
      "('analysis', 'NN')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('sentence', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('grammar', 'NN')\n",
      "('for', 'IN')\n",
      "('natural', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('ambiguous', 'JJ')\n",
      "('and', 'CC')\n",
      "('typical', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "('have', 'VBP')\n",
      "('multiple', 'VBN')\n",
      "('possible', 'JJ')\n",
      "('analyses', 'NNS')\n",
      "(':', ':')\n",
      "('perhaps', 'RB')\n",
      "('surprisingly', 'RB')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('a', 'DT')\n",
      "('typical', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('there', 'EX')\n",
      "('may', 'MD')\n",
      "('be', 'VB')\n",
      "('thousands', 'NNS')\n",
      "('of', 'IN')\n",
      "('potential', 'JJ')\n",
      "('parses', 'NNS')\n",
      "('(', '(')\n",
      "('most', 'JJS')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('will', 'MD')\n",
      "('seem', 'VB')\n",
      "('completely', 'RB')\n",
      "('nonsensical', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('human', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('There', 'EX')\n",
      "('are', 'VBP')\n",
      "('two', 'CD')\n",
      "('primary', 'JJ')\n",
      "('types', 'NNS')\n",
      "('of', 'IN')\n",
      "('parsing', 'NN')\n",
      "(':', ':')\n",
      "('dependency', 'NN')\n",
      "('parsing', 'NN')\n",
      "('and', 'CC')\n",
      "('constituency', 'NN')\n",
      "('parsing', 'NN')\n",
      "('.', '.')\n",
      "('Dependency', 'NNP')\n",
      "('parsing', 'VBG')\n",
      "('focuses', 'NNS')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('relationships', 'NNS')\n",
      "('between', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('(', '(')\n",
      "('marking', 'VBG')\n",
      "('things', 'NNS')\n",
      "('like', 'IN')\n",
      "('primary', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('and', 'CC')\n",
      "('predicates', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('whereas', 'JJ')\n",
      "('constituency', 'NN')\n",
      "('parsing', 'VBG')\n",
      "('focuses', 'NNS')\n",
      "('on', 'IN')\n",
      "('building', 'VBG')\n",
      "('out', 'RP')\n",
      "('the', 'DT')\n",
      "('parse', 'NN')\n",
      "('tree', 'NN')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('probabilistic', 'JJ')\n",
      "('context-free', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('(', '(')\n",
      "('PCFG', 'NNP')\n",
      "(')', ')')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('stochastic', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Lexical', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "(')', ')')\n",
      "('[', 'VBZ')\n",
      "('edit', 'JJ')\n",
      "(']', 'NNP')\n",
      "('Lexical', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('computational', 'JJ')\n",
      "('meaning', 'NN')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('?', '.')\n",
      "('Distributional', 'NNP')\n",
      "('semantics', 'VBD')\n",
      "('How', 'WRB')\n",
      "('can', 'MD')\n",
      "('we', 'PRP')\n",
      "('learn', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('from', 'IN')\n",
      "('data', 'NNS')\n",
      "('?', '.')\n",
      "('Named', 'VBN')\n",
      "('entity', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "('NER', 'NNP')\n",
      "(')', ')')\n",
      "('Given', 'VBZ')\n",
      "('a', 'DT')\n",
      "('stream', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'NN')\n",
      "('which', 'WDT')\n",
      "('items', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('map', 'NN')\n",
      "('to', 'TO')\n",
      "('proper', 'VB')\n",
      "('names', 'NNS')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('people', 'NNS')\n",
      "('or', 'CC')\n",
      "('places', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('what', 'WP')\n",
      "('the', 'DT')\n",
      "('type', 'NN')\n",
      "('of', 'IN')\n",
      "('each', 'DT')\n",
      "('such', 'JJ')\n",
      "('name', 'NN')\n",
      "('is', 'VBZ')\n",
      "('(', '(')\n",
      "('e.g', 'JJ')\n",
      "('.', '.')\n",
      "('person', 'NN')\n",
      "(',', ',')\n",
      "('location', 'NN')\n",
      "(',', ',')\n",
      "('organization', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Although', 'IN')\n",
      "('capitalization', 'NN')\n",
      "('can', 'MD')\n",
      "('aid', 'VB')\n",
      "('in', 'IN')\n",
      "('recognizing', 'VBG')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "('in', 'IN')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('English', 'NNP')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('information', 'NN')\n",
      "('can', 'MD')\n",
      "('not', 'RB')\n",
      "('aid', 'VB')\n",
      "('in', 'IN')\n",
      "('determining', 'VBG')\n",
      "('the', 'DT')\n",
      "('type', 'NN')\n",
      "('of', 'IN')\n",
      "('named', 'VBN')\n",
      "('entity', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('in', 'IN')\n",
      "('any', 'DT')\n",
      "('case', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('inaccurate', 'JJ')\n",
      "('or', 'CC')\n",
      "('insufficient', 'JJ')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('letter', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('capitalized', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('named', 'VBD')\n",
      "('entities', 'NNS')\n",
      "('often', 'RB')\n",
      "('span', 'VBP')\n",
      "('several', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('only', 'RB')\n",
      "('some', 'DT')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('are', 'VBP')\n",
      "('capitalized', 'VBN')\n",
      "('.', '.')\n",
      "('Furthermore', 'NNP')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('other', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('in', 'IN')\n",
      "('non-Western', 'JJ')\n",
      "('scripts', 'NNS')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('Chinese', 'JJ')\n",
      "('or', 'CC')\n",
      "('Arabic', 'NNP')\n",
      "(')', ')')\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('have', 'VB')\n",
      "('any', 'DT')\n",
      "('capitalization', 'NN')\n",
      "('at', 'IN')\n",
      "('all', 'DT')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('even', 'RB')\n",
      "('languages', 'NNS')\n",
      "('with', 'IN')\n",
      "('capitalization', 'NN')\n",
      "('may', 'MD')\n",
      "('not', 'RB')\n",
      "('consistently', 'RB')\n",
      "('use', 'VB')\n",
      "('it', 'PRP')\n",
      "('to', 'TO')\n",
      "('distinguish', 'VB')\n",
      "('names', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('German', 'JJ')\n",
      "('capitalizes', 'VBZ')\n",
      "('all', 'DT')\n",
      "('nouns', 'NNS')\n",
      "(',', ',')\n",
      "('regardless', 'RB')\n",
      "('of', 'IN')\n",
      "('whether', 'IN')\n",
      "('they', 'PRP')\n",
      "('are', 'VBP')\n",
      "('names', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('French', 'JJ')\n",
      "('and', 'CC')\n",
      "('Spanish', 'JJ')\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('capitalize', 'VB')\n",
      "('names', 'NNS')\n",
      "('that', 'WDT')\n",
      "('serve', 'VBP')\n",
      "('as', 'IN')\n",
      "('adjectives', 'NNS')\n",
      "('.', '.')\n",
      "('Sentiment', 'NN')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('Multimodal', 'NNP')\n",
      "('sentiment', 'NN')\n",
      "('analysis', 'NN')\n",
      "(')', ')')\n",
      "('Extract', 'NNP')\n",
      "('subjective', 'JJ')\n",
      "('information', 'NN')\n",
      "('usually', 'RB')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('often', 'RB')\n",
      "('using', 'VBG')\n",
      "('online', 'JJ')\n",
      "('reviews', 'NNS')\n",
      "('to', 'TO')\n",
      "('determine', 'VB')\n",
      "('``', '``')\n",
      "('polarity', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('about', 'IN')\n",
      "('specific', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('.', '.')\n",
      "('It', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('especially', 'RB')\n",
      "('useful', 'JJ')\n",
      "('for', 'IN')\n",
      "('identifying', 'VBG')\n",
      "('trends', 'NNS')\n",
      "('of', 'IN')\n",
      "('public', 'JJ')\n",
      "('opinion', 'NN')\n",
      "('in', 'IN')\n",
      "('social', 'JJ')\n",
      "('media', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('marketing', 'NN')\n",
      "('.', '.')\n",
      "('Terminology', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('of', 'IN')\n",
      "('terminology', 'NN')\n",
      "('extraction', 'NN')\n",
      "('is', 'VBZ')\n",
      "('to', 'TO')\n",
      "('automatically', 'RB')\n",
      "('extract', 'VB')\n",
      "('relevant', 'JJ')\n",
      "('terms', 'NNS')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('corpus', 'NN')\n",
      "('.', '.')\n",
      "('Word', 'NNP')\n",
      "('sense', 'NN')\n",
      "('disambiguation', 'NN')\n",
      "('(', '(')\n",
      "('WSD', 'NNP')\n",
      "(')', ')')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "('have', 'VBP')\n",
      "('more', 'JJR')\n",
      "('than', 'IN')\n",
      "('one', 'CD')\n",
      "('meaning', 'NN')\n",
      "(';', ':')\n",
      "('we', 'PRP')\n",
      "('have', 'VBP')\n",
      "('to', 'TO')\n",
      "('select', 'VB')\n",
      "('the', 'DT')\n",
      "('meaning', 'NN')\n",
      "('which', 'WDT')\n",
      "('makes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('sense', 'NN')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('this', 'DT')\n",
      "('problem', 'NN')\n",
      "(',', ',')\n",
      "('we', 'PRP')\n",
      "('are', 'VBP')\n",
      "('typically', 'RB')\n",
      "('given', 'VBN')\n",
      "('a', 'DT')\n",
      "('list', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('and', 'CC')\n",
      "('associated', 'VBN')\n",
      "('word', 'NN')\n",
      "('senses', 'NNS')\n",
      "(',', ',')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('dictionary', 'NN')\n",
      "('or', 'CC')\n",
      "('an', 'DT')\n",
      "('online', 'JJ')\n",
      "('resource', 'NN')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('WordNet', 'NNP')\n",
      "('.', '.')\n",
      "('Entity', 'NNP')\n",
      "('linking', 'VBG')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "('-', ':')\n",
      "('typically', 'RB')\n",
      "('proper', 'JJ')\n",
      "('names', 'NNS')\n",
      "('-', ':')\n",
      "('refer', 'NN')\n",
      "('to', 'TO')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "(';', ':')\n",
      "('here', 'RB')\n",
      "('we', 'PRP')\n",
      "('have', 'VBP')\n",
      "('to', 'TO')\n",
      "('select', 'VB')\n",
      "('the', 'DT')\n",
      "('entity', 'NN')\n",
      "('(', '(')\n",
      "('a', 'DT')\n",
      "('famous', 'JJ')\n",
      "('individual', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('location', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('company', 'NN')\n",
      "(',', ',')\n",
      "('etc', 'FW')\n",
      "('.', '.')\n",
      "(')', ')')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('.', '.')\n",
      "('Relational', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('[', 'VBP')\n",
      "('edit', 'JJ')\n",
      "(']', 'NNP')\n",
      "('Relationship', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('relationships', 'NNS')\n",
      "('among', 'IN')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('who', 'WP')\n",
      "('is', 'VBZ')\n",
      "('married', 'VBN')\n",
      "('to', 'TO')\n",
      "('whom', 'WP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Semantic', 'JJ')\n",
      "('parsing', 'VBG')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('(', '(')\n",
      "('typically', 'RB')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('produce', 'VBP')\n",
      "('a', 'DT')\n",
      "('formal', 'JJ')\n",
      "('representation', 'NN')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('either', 'RB')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('graph', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('AMR', 'NNP')\n",
      "('parsing', 'VBG')\n",
      "(')', ')')\n",
      "('or', 'CC')\n",
      "('in', 'IN')\n",
      "('accordance', 'NN')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('logical', 'JJ')\n",
      "('formalism', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('DRT', 'NNP')\n",
      "('parsing', 'VBG')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('challenge', 'NN')\n",
      "('typically', 'RB')\n",
      "('includes', 'VBZ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('several', 'JJ')\n",
      "('more', 'JJR')\n",
      "('elementary', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'NNS')\n",
      "('from', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "(',', ',')\n",
      "('word', 'NN')\n",
      "('sense', 'NN')\n",
      "('disambiguation', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('extended', 'VBN')\n",
      "('to', 'TO')\n",
      "('include', 'VB')\n",
      "('full-fledged', 'JJ')\n",
      "('discourse', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('discourse', 'JJ')\n",
      "('analysis', 'NN')\n",
      "(',', ',')\n",
      "('coreference', 'NN')\n",
      "(';', ':')\n",
      "('see', 'VB')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'VBG')\n",
      "('below', 'IN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('implicit', 'JJ')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('below', 'IN')\n",
      "(')', ')')\n",
      "('Given', 'FW')\n",
      "('a', 'DT')\n",
      "('single', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'NN')\n",
      "('and', 'CC')\n",
      "('disambiguate', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('predicates', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('verbal', 'JJ')\n",
      "('frames', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('then', 'RB')\n",
      "('identify', 'VB')\n",
      "('and', 'CC')\n",
      "('classify', 'VB')\n",
      "('the', 'DT')\n",
      "('frame', 'NN')\n",
      "('elements', 'NNS')\n",
      "('(', '(')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Discourse', 'NNP')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('beyond', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('Coreference', 'NNP')\n",
      "('resolution', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('or', 'CC')\n",
      "('larger', 'JJR')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'NN')\n",
      "('which', 'WDT')\n",
      "('words', 'NNS')\n",
      "('(', '(')\n",
      "('``', '``')\n",
      "('mentions', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "('refer', 'VBP')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('same', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('(', '(')\n",
      "('``', '``')\n",
      "('entities', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Anaphora', 'NNP')\n",
      "('resolution', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('specific', 'JJ')\n",
      "('example', 'NN')\n",
      "('of', 'IN')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('specifically', 'RB')\n",
      "('concerned', 'VBN')\n",
      "('with', 'IN')\n",
      "('matching', 'VBG')\n",
      "('up', 'RP')\n",
      "('pronouns', 'NNS')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('nouns', 'NNS')\n",
      "('or', 'CC')\n",
      "('names', 'NNS')\n",
      "('to', 'TO')\n",
      "('which', 'WDT')\n",
      "('they', 'PRP')\n",
      "('refer', 'VBP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('more', 'RBR')\n",
      "('general', 'JJ')\n",
      "('task', 'NN')\n",
      "('of', 'IN')\n",
      "('coreference', 'NN')\n",
      "('resolution', 'NN')\n",
      "('also', 'RB')\n",
      "('includes', 'VBZ')\n",
      "('identifying', 'VBG')\n",
      "('so-called', 'JJ')\n",
      "('``', '``')\n",
      "('bridging', 'JJ')\n",
      "('relationships', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "('involving', 'VBG')\n",
      "('referring', 'VBG')\n",
      "('expressions', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('``', '``')\n",
      "('He', 'PRP')\n",
      "('entered', 'VBD')\n",
      "('John', 'NNP')\n",
      "(\"'s\", 'POS')\n",
      "('house', 'NN')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('front', 'JJ')\n",
      "('door', 'NN')\n",
      "(\"''\", \"''\")\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('the', 'DT')\n",
      "('front', 'NN')\n",
      "('door', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('referring', 'VBG')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('expression', 'NN')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('bridging', 'NN')\n",
      "('relationship', 'NN')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('identified', 'VBN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('fact', 'NN')\n",
      "('that', 'IN')\n",
      "('the', 'DT')\n",
      "('door', 'NN')\n",
      "('being', 'VBG')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('front', 'JJ')\n",
      "('door', 'NN')\n",
      "('of', 'IN')\n",
      "('John', 'NNP')\n",
      "(\"'s\", 'POS')\n",
      "('house', 'NN')\n",
      "('(', '(')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('of', 'IN')\n",
      "('some', 'DT')\n",
      "('other', 'JJ')\n",
      "('structure', 'NN')\n",
      "('that', 'WDT')\n",
      "('might', 'MD')\n",
      "('also', 'RB')\n",
      "('be', 'VB')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Discourse', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('This', 'DT')\n",
      "('rubric', 'JJ')\n",
      "('includes', 'VBZ')\n",
      "('several', 'JJ')\n",
      "('related', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('One', 'CD')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('discourse', 'JJ')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('i.e.', 'FW')\n",
      "(',', ',')\n",
      "('identifying', 'VBG')\n",
      "('the', 'DT')\n",
      "('discourse', 'NN')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('connected', 'JJ')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('i.e', 'NN')\n",
      "('.', '.')\n",
      "('the', 'DT')\n",
      "('nature', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('discourse', 'JJ')\n",
      "('relationships', 'NNS')\n",
      "('between', 'IN')\n",
      "('sentences', 'NNS')\n",
      "('(', '(')\n",
      "('e.g', 'NN')\n",
      "('.', '.')\n",
      "('elaboration', 'NN')\n",
      "(',', ',')\n",
      "('explanation', 'NN')\n",
      "(',', ',')\n",
      "('contrast', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Another', 'DT')\n",
      "('possible', 'JJ')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('recognizing', 'VBG')\n",
      "('and', 'CC')\n",
      "('classifying', 'VBG')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('acts', 'VBZ')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('(', '(')\n",
      "('e.g', 'JJ')\n",
      "('.', '.')\n",
      "('yes-no', 'JJ')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('content', 'JJ')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('statement', 'NN')\n",
      "(',', ',')\n",
      "('assertion', 'NN')\n",
      "(',', ',')\n",
      "('etc.', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Implicit', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('single', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'NN')\n",
      "('and', 'CC')\n",
      "('disambiguate', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('predicates', 'NNS')\n",
      "('(', '(')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('verbal', 'JJ')\n",
      "('frames', 'NNS')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('their', 'PRP$')\n",
      "('explicit', 'JJ')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('current', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('Semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('above', 'IN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Then', 'RB')\n",
      "(',', ',')\n",
      "('identify', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('not', 'RB')\n",
      "('explicitly', 'RB')\n",
      "('realized', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('current', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('classify', 'VB')\n",
      "('them', 'PRP')\n",
      "('into', 'IN')\n",
      "('arguments', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('explicitly', 'RB')\n",
      "('realized', 'VBN')\n",
      "('elsewhere', 'RB')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('and', 'CC')\n",
      "('those', 'DT')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('not', 'RB')\n",
      "('specified', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('resolve', 'VB')\n",
      "('the', 'DT')\n",
      "('former', 'JJ')\n",
      "('against', 'IN')\n",
      "('the', 'DT')\n",
      "('local', 'JJ')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('closely', 'RB')\n",
      "('related', 'JJ')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('zero', 'CD')\n",
      "('anaphora', 'JJ')\n",
      "('resolution', 'NN')\n",
      "(',', ',')\n",
      "('i.e.', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('extension', 'NN')\n",
      "('of', 'IN')\n",
      "('coreference', 'NN')\n",
      "('resolution', 'NN')\n",
      "('to', 'TO')\n",
      "('pro-drop', 'NN')\n",
      "('languages', 'NNS')\n",
      "('.', '.')\n",
      "('Recognizing', 'VBG')\n",
      "('textual', 'JJ')\n",
      "('entailment', 'NN')\n",
      "('Given', 'NNP')\n",
      "('two', 'CD')\n",
      "('text', 'NN')\n",
      "('fragments', 'NNS')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('if', 'IN')\n",
      "('one', 'CD')\n",
      "('being', 'VBG')\n",
      "('true', 'JJ')\n",
      "('entails', 'NNS')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "(',', ',')\n",
      "('entails', 'VBZ')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "(\"'s\", 'POS')\n",
      "('negation', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('allows', 'VBZ')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('either', 'RB')\n",
      "('true', 'JJ')\n",
      "('or', 'CC')\n",
      "('false', 'JJ')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('25', 'CD')\n",
      "(']', 'NNP')\n",
      "('Topic', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('and', 'CC')\n",
      "('recognition', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('separate', 'VB')\n",
      "('it', 'PRP')\n",
      "('into', 'IN')\n",
      "('segments', 'NNS')\n",
      "('each', 'DT')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('devoted', 'VBN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('topic', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('topic', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('segment', 'NN')\n",
      "('.', '.')\n",
      "('Argument', 'NN')\n",
      "('mining', 'VBG')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('of', 'IN')\n",
      "('argument', 'NN')\n",
      "('mining', 'NN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('automatic', 'JJ')\n",
      "('extraction', 'NN')\n",
      "('and', 'CC')\n",
      "('identification', 'NN')\n",
      "('of', 'IN')\n",
      "('argumentative', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('from', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('text', 'NN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('aid', 'NN')\n",
      "('of', 'IN')\n",
      "('computer', 'NN')\n",
      "('programs', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('26', 'CD')\n",
      "(']', 'NNP')\n",
      "('Such', 'JJ')\n",
      "('argumentative', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('include', 'VBP')\n",
      "('the', 'DT')\n",
      "('premise', 'NN')\n",
      "(',', ',')\n",
      "('conclusions', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('argument', 'NN')\n",
      "('scheme', 'NN')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('relationship', 'NN')\n",
      "('between', 'IN')\n",
      "('the', 'DT')\n",
      "('main', 'JJ')\n",
      "('and', 'CC')\n",
      "('subsidiary', 'NN')\n",
      "('argument', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('the', 'DT')\n",
      "('main', 'JJ')\n",
      "('and', 'CC')\n",
      "('counter-argument', 'JJ')\n",
      "('within', 'IN')\n",
      "('discourse', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('27', 'CD')\n",
      "(']', 'JJ')\n",
      "('[', '$')\n",
      "('28', 'CD')\n",
      "(']', 'JJ')\n",
      "('Higher-level', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('applications', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Automatic', 'NNP')\n",
      "('summarization', 'NN')\n",
      "('(', '(')\n",
      "('text', 'JJ')\n",
      "('summarization', 'NN')\n",
      "(')', ')')\n",
      "('Produce', 'VBP')\n",
      "('a', 'DT')\n",
      "('readable', 'JJ')\n",
      "('summary', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "('Often', 'NNP')\n",
      "('used', 'VBD')\n",
      "('to', 'TO')\n",
      "('provide', 'VB')\n",
      "('summaries', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('known', 'JJ')\n",
      "('type', 'NN')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('research', 'NN')\n",
      "('papers', 'NNS')\n",
      "(',', ',')\n",
      "('articles', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('financial', 'JJ')\n",
      "('section', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('newspaper', 'NN')\n",
      "('.', '.')\n",
      "('Book', 'NNP')\n",
      "('generation', 'NN')\n",
      "('Not', 'RB')\n",
      "('an', 'DT')\n",
      "('NLP', 'NNP')\n",
      "('task', 'NN')\n",
      "('proper', 'NN')\n",
      "('but', 'CC')\n",
      "('an', 'DT')\n",
      "('extension', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('and', 'CC')\n",
      "('other', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('creation', 'NN')\n",
      "('of', 'IN')\n",
      "('full-fledged', 'JJ')\n",
      "('books', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('machine-generated', 'JJ')\n",
      "('book', 'NN')\n",
      "('was', 'VBD')\n",
      "('created', 'VBN')\n",
      "('by', 'IN')\n",
      "('a', 'DT')\n",
      "('rule-based', 'JJ')\n",
      "('system', 'NN')\n",
      "('in', 'IN')\n",
      "('1984', 'CD')\n",
      "('(', '(')\n",
      "('Racter', 'NNP')\n",
      "(',', ',')\n",
      "('The', 'DT')\n",
      "('policeman', 'NN')\n",
      "(\"'s\", 'POS')\n",
      "('beard', 'NN')\n",
      "('is', 'VBZ')\n",
      "('half-constructed', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('29', 'CD')\n",
      "(']', 'IN')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('published', 'VBN')\n",
      "('work', 'NN')\n",
      "('by', 'IN')\n",
      "('a', 'DT')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('was', 'VBD')\n",
      "('published', 'VBN')\n",
      "('in', 'IN')\n",
      "('2018', 'CD')\n",
      "(',', ',')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "('Road', 'NNP')\n",
      "(',', ',')\n",
      "('marketed', 'VBD')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('novel', 'NN')\n",
      "(',', ',')\n",
      "('contains', 'VBZ')\n",
      "('sixty', 'JJ')\n",
      "('million', 'CD')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('Both', 'CC')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "('are', 'VBP')\n",
      "('basically', 'RB')\n",
      "('elaborate', 'JJ')\n",
      "('but', 'CC')\n",
      "('non-sensical', 'JJ')\n",
      "('(', '(')\n",
      "('semantics-free', 'JJ')\n",
      "(')', ')')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('machine-generated', 'JJ')\n",
      "('science', 'NN')\n",
      "('book', 'NN')\n",
      "('was', 'VBD')\n",
      "('published', 'VBN')\n",
      "('in', 'IN')\n",
      "('2019', 'CD')\n",
      "('(', '(')\n",
      "('Beta', 'NNP')\n",
      "('Writer', 'NNP')\n",
      "(',', ',')\n",
      "('Lithium-Ion', 'NNP')\n",
      "('Batteries', 'NNP')\n",
      "(',', ',')\n",
      "('Springer', 'NNP')\n",
      "(',', ',')\n",
      "('Cham', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('30', 'CD')\n",
      "(']', 'NNP')\n",
      "('Unlike', 'NNP')\n",
      "('Racter', 'NNP')\n",
      "('and', 'CC')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "('Road', 'NNP')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('is', 'VBZ')\n",
      "('grounded', 'VBN')\n",
      "('on', 'IN')\n",
      "('factual', 'JJ')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('text', 'JJ')\n",
      "('summarization', 'NN')\n",
      "('.', '.')\n",
      "('Dialogue', 'NNP')\n",
      "('management', 'NN')\n",
      "('Computer', 'NNP')\n",
      "('systems', 'NNS')\n",
      "('intended', 'VBD')\n",
      "('to', 'TO')\n",
      "('converse', 'VB')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('human', 'JJ')\n",
      "('.', '.')\n",
      "('Document', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('A', 'NNP')\n",
      "('Document', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('platform', 'NN')\n",
      "('sits', 'NNS')\n",
      "('on', 'IN')\n",
      "('top', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('NLP', 'NNP')\n",
      "('technology', 'NN')\n",
      "('enabling', 'VBG')\n",
      "('users', 'NNS')\n",
      "('with', 'IN')\n",
      "('no', 'DT')\n",
      "('prior', 'JJ')\n",
      "('experience', 'NN')\n",
      "('of', 'IN')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "(',', ',')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('or', 'CC')\n",
      "('NLP', 'NNP')\n",
      "('to', 'TO')\n",
      "('quickly', 'RB')\n",
      "('train', 'VB')\n",
      "('a', 'DT')\n",
      "('computer', 'NN')\n",
      "('to', 'TO')\n",
      "('extract', 'VB')\n",
      "('the', 'DT')\n",
      "('specific', 'JJ')\n",
      "('data', 'NNS')\n",
      "('they', 'PRP')\n",
      "('need', 'VBP')\n",
      "('from', 'IN')\n",
      "('different', 'JJ')\n",
      "('document', 'NN')\n",
      "('types', 'NNS')\n",
      "('.', '.')\n",
      "('NLP-powered', 'JJ')\n",
      "('Document', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('enables', 'VBZ')\n",
      "('non-technical', 'JJ')\n",
      "('teams', 'NNS')\n",
      "('to', 'TO')\n",
      "('quickly', 'RB')\n",
      "('access', 'NN')\n",
      "('information', 'NN')\n",
      "('hidden', 'NN')\n",
      "('in', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('lawyers', 'NNS')\n",
      "(',', ',')\n",
      "('business', 'NN')\n",
      "('analysts', 'NNS')\n",
      "('and', 'CC')\n",
      "('accountants', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('31', 'CD')\n",
      "(']', 'NNP')\n",
      "('Grammatical', 'NNP')\n",
      "('error', 'NN')\n",
      "('correction', 'NN')\n",
      "('Grammatical', 'NNP')\n",
      "('error', 'NN')\n",
      "('detection', 'NN')\n",
      "('and', 'CC')\n",
      "('correction', 'NN')\n",
      "('involves', 'VBZ')\n",
      "('a', 'DT')\n",
      "('great', 'JJ')\n",
      "('band-width', 'NN')\n",
      "('of', 'IN')\n",
      "('problems', 'NNS')\n",
      "('on', 'IN')\n",
      "('all', 'DT')\n",
      "('levels', 'NNS')\n",
      "('of', 'IN')\n",
      "('linguistic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('phonology/orthography', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('pragmatics', 'NNS')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Grammatical', 'JJ')\n",
      "('error', 'NN')\n",
      "('correction', 'NN')\n",
      "('is', 'VBZ')\n",
      "('impactful', 'JJ')\n",
      "('since', 'IN')\n",
      "('it', 'PRP')\n",
      "('affects', 'VBZ')\n",
      "('hundreds', 'NNS')\n",
      "('of', 'IN')\n",
      "('millions', 'NNS')\n",
      "('of', 'IN')\n",
      "('people', 'NNS')\n",
      "('that', 'WDT')\n",
      "('use', 'VBP')\n",
      "('or', 'CC')\n",
      "('acquire', 'VB')\n",
      "('English', 'JJ')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('second', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('It', 'PRP')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('been', 'VBN')\n",
      "('subject', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('shared', 'VBN')\n",
      "('tasks', 'NNS')\n",
      "('since', 'IN')\n",
      "('2011', 'CD')\n",
      "('.', '.')\n",
      "('[', 'VB')\n",
      "('32', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('33', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('34', 'CD')\n",
      "(']', 'NN')\n",
      "('As', 'RB')\n",
      "('far', 'RB')\n",
      "('as', 'IN')\n",
      "('orthography', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('syntax', 'NN')\n",
      "('and', 'CC')\n",
      "('certain', 'JJ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('are', 'VBP')\n",
      "('concerned', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('due', 'JJ')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "('powerful', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('GPT-2', 'NNP')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('can', 'MD')\n",
      "('now', 'RB')\n",
      "('(', '(')\n",
      "('2019', 'CD')\n",
      "(')', ')')\n",
      "('be', 'VB')\n",
      "('considered', 'VBN')\n",
      "('a', 'DT')\n",
      "('largely', 'RB')\n",
      "('solved', 'VBN')\n",
      "('problem', 'NN')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('being', 'VBG')\n",
      "('marketed', 'VBN')\n",
      "('in', 'IN')\n",
      "('various', 'JJ')\n",
      "('commercial', 'JJ')\n",
      "('applications', 'NNS')\n",
      "('.', '.')\n",
      "('Machine', 'NNP')\n",
      "('translation', 'NN')\n",
      "('Automatically', 'NNP')\n",
      "('translate', 'VBP')\n",
      "('text', 'NN')\n",
      "('from', 'IN')\n",
      "('one', 'CD')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "('to', 'TO')\n",
      "('another', 'DT')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('difficult', 'JJ')\n",
      "('problems', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('member', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('class', 'NN')\n",
      "('of', 'IN')\n",
      "('problems', 'NNS')\n",
      "('colloquially', 'RB')\n",
      "('termed', 'VBD')\n",
      "('``', '``')\n",
      "('AI-complete', 'JJ')\n",
      "('``', '``')\n",
      "(',', ',')\n",
      "('i.e', 'NN')\n",
      "('.', '.')\n",
      "('requiring', 'VBG')\n",
      "('all', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('different', 'JJ')\n",
      "('types', 'NNS')\n",
      "('of', 'IN')\n",
      "('knowledge', 'NN')\n",
      "('that', 'IN')\n",
      "('humans', 'VBZ')\n",
      "('possess', 'NN')\n",
      "('(', '(')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('facts', 'NNS')\n",
      "('about', 'IN')\n",
      "('the', 'DT')\n",
      "('real', 'JJ')\n",
      "('world', 'NN')\n",
      "(',', ',')\n",
      "('etc', 'FW')\n",
      "('.', '.')\n",
      "(')', ')')\n",
      "('to', 'TO')\n",
      "('solve', 'VB')\n",
      "('properly', 'RB')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('(', '(')\n",
      "('NLG', 'NNP')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('Convert', 'JJ')\n",
      "('information', 'NN')\n",
      "('from', 'IN')\n",
      "('computer', 'NN')\n",
      "('databases', 'NNS')\n",
      "('or', 'CC')\n",
      "('semantic', 'JJ')\n",
      "('intents', 'NNS')\n",
      "('into', 'IN')\n",
      "('readable', 'JJ')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "('NLU', 'NNP')\n",
      "(')', ')')\n",
      "('Convert', 'NNP')\n",
      "('chunks', 'NNS')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('into', 'IN')\n",
      "('more', 'RBR')\n",
      "('formal', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('first-order', 'JJ')\n",
      "('logic', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('easier', 'JJR')\n",
      "('for', 'IN')\n",
      "('computer', 'NN')\n",
      "('programs', 'NNS')\n",
      "('to', 'TO')\n",
      "('manipulate', 'VB')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'VBG')\n",
      "('involves', 'VBZ')\n",
      "('the', 'DT')\n",
      "('identification', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('intended', 'VBN')\n",
      "('semantic', 'NN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('multiple', 'JJ')\n",
      "('possible', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('which', 'WDT')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('derived', 'VBN')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('expression', 'NN')\n",
      "('which', 'WDT')\n",
      "('usually', 'RB')\n",
      "('takes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('organized', 'JJ')\n",
      "('notations', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('concepts', 'NNS')\n",
      "('.', '.')\n",
      "('Introduction', 'NN')\n",
      "('and', 'CC')\n",
      "('creation', 'NN')\n",
      "('of', 'IN')\n",
      "('language', 'NN')\n",
      "('metamodel', 'NN')\n",
      "('and', 'CC')\n",
      "('ontology', 'NN')\n",
      "('are', 'VBP')\n",
      "('efficient', 'JJ')\n",
      "('however', 'RB')\n",
      "('empirical', 'JJ')\n",
      "('solutions', 'NNS')\n",
      "('.', '.')\n",
      "('An', 'DT')\n",
      "('explicit', 'JJ')\n",
      "('formalization', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('semantics', 'NNS')\n",
      "('without', 'IN')\n",
      "('confusions', 'NNS')\n",
      "('with', 'IN')\n",
      "('implicit', 'JJ')\n",
      "('assumptions', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('closed-world', 'JJ')\n",
      "('assumption', 'NN')\n",
      "('(', '(')\n",
      "('CWA', 'NNP')\n",
      "(')', ')')\n",
      "('vs.', 'FW')\n",
      "('open-world', 'JJ')\n",
      "('assumption', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('subjective', 'JJ')\n",
      "('Yes/No', 'NNP')\n",
      "('vs.', 'FW')\n",
      "('objective', 'JJ')\n",
      "('True/False', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('expected', 'VBN')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('construction', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('basis', 'NN')\n",
      "('of', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('formalization', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('35', 'CD')\n",
      "(']', 'JJ')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('human-language', 'JJ')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('its', 'PRP$')\n",
      "('answer', 'NN')\n",
      "('.', '.')\n",
      "('Typical', 'JJ')\n",
      "('questions', 'NNS')\n",
      "('have', 'VBP')\n",
      "('a', 'DT')\n",
      "('specific', 'JJ')\n",
      "('right', 'NN')\n",
      "('answer', 'NN')\n",
      "('(', '(')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('``', '``')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('capital', 'NN')\n",
      "('of', 'IN')\n",
      "('Canada', 'NNP')\n",
      "('?', '.')\n",
      "('``', '``')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('sometimes', 'RB')\n",
      "('open-ended', 'JJ')\n",
      "('questions', 'NNS')\n",
      "('are', 'VBP')\n",
      "('also', 'RB')\n",
      "('considered', 'VBN')\n",
      "('(', '(')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('``', '``')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('meaning', 'NN')\n",
      "('of', 'IN')\n",
      "('life', 'NN')\n",
      "('?', '.')\n",
      "(\"''\", \"''\")\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('General', 'JJ')\n",
      "('tendencies', 'NNS')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('possible', 'JJ')\n",
      "(')', ')')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNS')\n",
      "('Based', 'VBN')\n",
      "('on', 'IN')\n",
      "('long-standing', 'JJ')\n",
      "('trends', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "(',', ',')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('possible', 'JJ')\n",
      "('to', 'TO')\n",
      "('extrapolate', 'VB')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('of', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('of', 'IN')\n",
      "('2020', 'CD')\n",
      "(',', ',')\n",
      "('three', 'CD')\n",
      "('trends', 'NNS')\n",
      "('among', 'IN')\n",
      "('the', 'DT')\n",
      "('topics', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('long-standing', 'JJ')\n",
      "('series', 'NN')\n",
      "('of', 'IN')\n",
      "('CoNLL', 'NNP')\n",
      "('Shared', 'NNP')\n",
      "('Tasks', 'NNP')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('observed', 'VBN')\n",
      "(':', ':')\n",
      "('[', 'JJ')\n",
      "('36', 'CD')\n",
      "(']', 'JJ')\n",
      "('Interest', 'NN')\n",
      "('on', 'IN')\n",
      "('increasingly', 'RB')\n",
      "('abstract', 'JJ')\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('cognitive', 'JJ')\n",
      "(\"''\", \"''\")\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('(', '(')\n",
      "('1999-2001', 'JJ')\n",
      "(':', ':')\n",
      "('shallow', 'JJ')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('2002-03', 'JJ')\n",
      "(':', ':')\n",
      "('named', 'VBN')\n",
      "('entity', 'NN')\n",
      "('recognition', 'NN')\n",
      "(',', ',')\n",
      "('2006-09/2017-18', 'JJ')\n",
      "(':', ':')\n",
      "('dependency', 'NN')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "('2004-05/2008-09', 'JJ')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "(',', ',')\n",
      "('2011-12', 'JJ')\n",
      "('coreference', 'NN')\n",
      "(',', ',')\n",
      "('2015-16', 'JJ')\n",
      "(':', ':')\n",
      "('discourse', 'NN')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('2019', 'CD')\n",
      "(':', ':')\n",
      "('semantic', 'JJ')\n",
      "('parsing', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Increasing', 'VBG')\n",
      "('interest', 'NN')\n",
      "('in', 'IN')\n",
      "('multilinguality', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(',', ',')\n",
      "('potentially', 'RB')\n",
      "(',', ',')\n",
      "('multimodality', 'NN')\n",
      "('(', '(')\n",
      "('English', 'JJ')\n",
      "('since', 'IN')\n",
      "('1999', 'CD')\n",
      "(';', ':')\n",
      "('Spanish', 'JJ')\n",
      "(',', ',')\n",
      "('Dutch', 'NNP')\n",
      "('since', 'IN')\n",
      "('2002', 'CD')\n",
      "(';', ':')\n",
      "('German', 'JJ')\n",
      "('since', 'IN')\n",
      "('2003', 'CD')\n",
      "(';', ':')\n",
      "('Bulgarian', 'NNP')\n",
      "(',', ',')\n",
      "('Danish', 'NNP')\n",
      "(',', ',')\n",
      "('Japanese', 'NNP')\n",
      "(',', ',')\n",
      "('Portuguese', 'NNP')\n",
      "(',', ',')\n",
      "('Slovenian', 'NNP')\n",
      "(',', ',')\n",
      "('Swedish', 'NNP')\n",
      "(',', ',')\n",
      "('Turkish', 'NNP')\n",
      "('since', 'IN')\n",
      "('2006', 'CD')\n",
      "(';', ':')\n",
      "('Basque', 'NNP')\n",
      "(',', ',')\n",
      "('Catalan', 'NNP')\n",
      "(',', ',')\n",
      "('Chinese', 'NNP')\n",
      "(',', ',')\n",
      "('Greek', 'NNP')\n",
      "(',', ',')\n",
      "('Hungarian', 'NNP')\n",
      "(',', ',')\n",
      "('Italian', 'NNP')\n",
      "(',', ',')\n",
      "('Turkish', 'NNP')\n",
      "('since', 'IN')\n",
      "('2007', 'CD')\n",
      "(';', ':')\n",
      "('Czech', 'NNP')\n",
      "('since', 'IN')\n",
      "('2009', 'CD')\n",
      "(';', ':')\n",
      "('Arabic', 'NNP')\n",
      "('since', 'IN')\n",
      "('2012', 'CD')\n",
      "(';', ':')\n",
      "('2017', 'CD')\n",
      "(':', ':')\n",
      "('40+', 'CD')\n",
      "('languages', 'NNS')\n",
      "(';', ':')\n",
      "('2018', 'CD')\n",
      "(':', ':')\n",
      "('60+/100+', 'CD')\n",
      "('languages', 'NNS')\n",
      "(')', ')')\n",
      "('Elimination', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('(', '(')\n",
      "('rule-based', 'JJ')\n",
      "('over', 'IN')\n",
      "('supervised', 'JJ')\n",
      "('towards', 'NNS')\n",
      "('weakly', 'RB')\n",
      "('supervised', 'VBD')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('representation', 'NN')\n",
      "('learning', 'NN')\n",
      "('and', 'CC')\n",
      "('end-to-end', 'JJ')\n",
      "('systems', 'NNS')\n",
      "(')', ')')\n",
      "('Cognition', 'NNP')\n",
      "('and', 'CC')\n",
      "('NLP', 'NNP')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'VBZ')\n",
      "('Most', 'RBS')\n",
      "('higher-level', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('applications', 'NNS')\n",
      "('involve', 'VBP')\n",
      "('aspects', 'NNS')\n",
      "('that', 'WDT')\n",
      "('emulate', 'VBP')\n",
      "('intelligent', 'JJ')\n",
      "('behaviour', 'NN')\n",
      "('and', 'CC')\n",
      "('apparent', 'JJ')\n",
      "('comprehension', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('More', 'RBR')\n",
      "('broadly', 'RB')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('technical', 'JJ')\n",
      "('operationalization', 'NN')\n",
      "('of', 'IN')\n",
      "('increasingly', 'RB')\n",
      "('advanced', 'JJ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('behaviour', 'NN')\n",
      "('represents', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('developmental', 'JJ')\n",
      "('trajectories', 'NNS')\n",
      "('of', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('trends', 'NNS')\n",
      "('among', 'IN')\n",
      "('CoNLL', 'NNP')\n",
      "('shared', 'VBD')\n",
      "('tasks', 'NNS')\n",
      "('above', 'IN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Cognition', 'NN')\n",
      "('refers', 'NNS')\n",
      "('to', 'TO')\n",
      "('``', '``')\n",
      "('the', 'DT')\n",
      "('mental', 'JJ')\n",
      "('action', 'NN')\n",
      "('or', 'CC')\n",
      "('process', 'NN')\n",
      "('of', 'IN')\n",
      "('acquiring', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('understanding', 'VBG')\n",
      "('through', 'IN')\n",
      "('thought', 'NN')\n",
      "(',', ',')\n",
      "('experience', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('senses', 'NNS')\n",
      "('.', '.')\n",
      "(\"''\", \"''\")\n",
      "('[', 'VBZ')\n",
      "('37', 'CD')\n",
      "(']', 'NN')\n",
      "('Cognitive', 'NNP')\n",
      "('science', 'NN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "(',', ',')\n",
      "('scientific', 'JJ')\n",
      "('study', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('mind', 'NN')\n",
      "('and', 'CC')\n",
      "('its', 'PRP$')\n",
      "('processes', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('38', 'CD')\n",
      "(']', 'NNP')\n",
      "('Cognitive', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "('branch', 'NN')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('combining', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('research', 'NN')\n",
      "('from', 'IN')\n",
      "('both', 'DT')\n",
      "('psychology', 'NN')\n",
      "('and', 'CC')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('39', 'CD')\n",
      "(']', 'NNP')\n",
      "('Especially', 'NNP')\n",
      "('during', 'IN')\n",
      "('the', 'DT')\n",
      "('age', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('area', 'NN')\n",
      "('of', 'IN')\n",
      "('computational', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('maintained', 'VBD')\n",
      "('strong', 'JJ')\n",
      "('ties', 'NNS')\n",
      "('with', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('studies', 'NNS')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('an', 'DT')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('George', 'NNP')\n",
      "('Lakoff', 'NNP')\n",
      "('offers', 'VBZ')\n",
      "('a', 'DT')\n",
      "('methodology', 'NN')\n",
      "('to', 'TO')\n",
      "('build', 'VB')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('(', '(')\n",
      "('NLP', 'NNP')\n",
      "(')', ')')\n",
      "('algorithms', 'VBP')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('perspective', 'NN')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('along', 'IN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('findings', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('[', 'VBP')\n",
      "('40', 'CD')\n",
      "(']', 'NNS')\n",
      "('with', 'IN')\n",
      "('two', 'CD')\n",
      "('defining', 'VBG')\n",
      "('aspects', 'NNS')\n",
      "(':', ':')\n",
      "('Apply', 'VB')\n",
      "('the', 'DT')\n",
      "('theory', 'NN')\n",
      "('of', 'IN')\n",
      "('conceptual', 'JJ')\n",
      "('metaphor', 'NN')\n",
      "(',', ',')\n",
      "('explained', 'VBN')\n",
      "('by', 'IN')\n",
      "('Lakoff', 'NNP')\n",
      "('as', 'IN')\n",
      "('“', 'NNP')\n",
      "('the', 'DT')\n",
      "('understanding', 'NN')\n",
      "('of', 'IN')\n",
      "('one', 'CD')\n",
      "('idea', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('terms', 'NNS')\n",
      "('of', 'IN')\n",
      "('another', 'DT')\n",
      "('”', 'NN')\n",
      "('which', 'WDT')\n",
      "('provides', 'VBZ')\n",
      "('an', 'DT')\n",
      "('idea', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('intent', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('41', 'CD')\n",
      "(']', 'NN')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('consider', 'VB')\n",
      "('the', 'DT')\n",
      "('English', 'NNP')\n",
      "('word', 'NN')\n",
      "('“', 'NNP')\n",
      "('big', 'JJ')\n",
      "('”', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('comparison', 'NN')\n",
      "('(', '(')\n",
      "('“', 'JJ')\n",
      "('That', 'DT')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('tree', 'NN')\n",
      "('”', 'NN')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "(\"'s\", 'POS')\n",
      "('intent', 'NN')\n",
      "('is', 'VBZ')\n",
      "('to', 'TO')\n",
      "('imply', 'VB')\n",
      "('that', 'IN')\n",
      "('the', 'DT')\n",
      "('tree', 'NN')\n",
      "('is', 'VBZ')\n",
      "('”', 'VBN')\n",
      "('physically', 'RB')\n",
      "('large', 'JJ')\n",
      "('”', 'NNP')\n",
      "('relative', 'NN')\n",
      "('to', 'TO')\n",
      "('other', 'JJ')\n",
      "('trees', 'NNS')\n",
      "('or', 'CC')\n",
      "('the', 'DT')\n",
      "('authors', 'NNS')\n",
      "('experience', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('used', 'VBN')\n",
      "('metaphorically', 'RB')\n",
      "('(', '(')\n",
      "('”', 'JJ')\n",
      "('Tomorrow', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('day', 'NN')\n",
      "('”', 'NNP')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "('’', 'NNP')\n",
      "('s', 'VBZ')\n",
      "('intent', 'NN')\n",
      "('to', 'TO')\n",
      "('imply', 'VB')\n",
      "('”', 'JJ')\n",
      "('importance', 'NN')\n",
      "('”', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('intent', 'NN')\n",
      "('behind', 'IN')\n",
      "('other', 'JJ')\n",
      "('usages', 'NNS')\n",
      "(',', ',')\n",
      "('like', 'IN')\n",
      "('in', 'IN')\n",
      "('”', 'NNP')\n",
      "('She', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('person', 'NN')\n",
      "('”', 'NNP')\n",
      "('will', 'MD')\n",
      "('remain', 'VB')\n",
      "('somewhat', 'RB')\n",
      "('ambiguous', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('and', 'CC')\n",
      "('a', 'DT')\n",
      "('cognitive', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('algorithm', 'NN')\n",
      "('alike', 'RB')\n",
      "('without', 'IN')\n",
      "('additional', 'JJ')\n",
      "('information', 'NN')\n",
      "('.', '.')\n",
      "('Assign', 'NNP')\n",
      "('relative', 'JJ')\n",
      "('measures', 'NNS')\n",
      "('of', 'IN')\n",
      "('meaning', 'VBG')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "(',', ',')\n",
      "('phrase', 'NN')\n",
      "(',', ',')\n",
      "('sentence', 'NN')\n",
      "('or', 'CC')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('information', 'NN')\n",
      "('presented', 'VBN')\n",
      "('before', 'IN')\n",
      "('and', 'CC')\n",
      "('after', 'IN')\n",
      "('the', 'DT')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('being', 'VBG')\n",
      "('analyzed', 'VBN')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('by', 'IN')\n",
      "('means', 'NNS')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('probabilistic', 'JJ')\n",
      "('context-free', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('(', '(')\n",
      "('PCFG', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('mathematical', 'JJ')\n",
      "('equation', 'NN')\n",
      "('for', 'IN')\n",
      "('such', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('is', 'VBZ')\n",
      "('presented', 'VBN')\n",
      "('in', 'IN')\n",
      "('US', 'NNP')\n",
      "('patent', 'NN')\n",
      "('9269353', 'CD')\n",
      "(':', ':')\n",
      "('R', 'NNP')\n",
      "('M', 'NNP')\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'FW')\n",
      "('N', 'NNP')\n",
      "(')', ')')\n",
      "('=', 'VBP')\n",
      "('P', 'NNP')\n",
      "('M', 'NNP')\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'FW')\n",
      "('N', 'NNP')\n",
      "(')', ')')\n",
      "('×', 'VBD')\n",
      "('1', 'CD')\n",
      "('2', 'CD')\n",
      "('d', 'NN')\n",
      "('(', '(')\n",
      "('∑', 'JJ')\n",
      "('i', 'NN')\n",
      "('=', 'VBP')\n",
      "('−', 'NNP')\n",
      "('d', 'NN')\n",
      "('d', 'NN')\n",
      "('(', '(')\n",
      "('(', '(')\n",
      "('P', 'NNP')\n",
      "('M', 'NNP')\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "('−', 'NNP')\n",
      "('1', 'CD')\n",
      "(')', ')')\n",
      "('×', 'NN')\n",
      "('P', 'NNP')\n",
      "('F', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "(',', ',')\n",
      "('t', 'NN')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "('−', 'NNP')\n",
      "('1', 'CD')\n",
      "(')', ')')\n",
      "(')', ')')\n",
      "('i', 'NN')\n",
      "(')', ')')\n",
      "('{', '(')\n",
      "('\\\\displaystyle', 'JJ')\n",
      "('{', '(')\n",
      "('RMM', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('}', ')')\n",
      "(')', ')')\n",
      "('}', ')')\n",
      "('=', '$')\n",
      "('{', '(')\n",
      "('PMM', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('}', ')')\n",
      "(')', ')')\n",
      "('}', ')')\n",
      "('\\\\times', 'VBZ')\n",
      "('{', '(')\n",
      "('\\\\frac', 'VB')\n",
      "('{', '(')\n",
      "('1', 'CD')\n",
      "('}', ')')\n",
      "('{', '(')\n",
      "('2d', 'CD')\n",
      "('}', ')')\n",
      "('}', ')')\n",
      "('\\\\left', 'NNP')\n",
      "('(', '(')\n",
      "('\\\\sum', 'NNP')\n",
      "('_', 'NNP')\n",
      "('{', '(')\n",
      "('i=-d', 'JJ')\n",
      "('}', ')')\n",
      "('^', 'NNP')\n",
      "('{', '(')\n",
      "('d', 'NN')\n",
      "('}', ')')\n",
      "('{', '(')\n",
      "('(', '(')\n",
      "('(', '(')\n",
      "('PMM', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N-1', 'NNP')\n",
      "('}', ')')\n",
      "(')', ')')\n",
      "('}', ')')\n",
      "('\\\\times', 'VBZ')\n",
      "('{', '(')\n",
      "('PF', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('}', ')')\n",
      "(',', ',')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N-1', 'NNP')\n",
      "('}', ')')\n",
      "(')', ')')\n",
      "(')', ')')\n",
      "('_', 'FW')\n",
      "('{', '(')\n",
      "('i', 'NN')\n",
      "('}', ')')\n",
      "('}', ')')\n",
      "('\\\\right', 'NNP')\n",
      "(')', ')')\n",
      "('}', ')')\n",
      "('Where', 'NNP')\n",
      "(',', ',')\n",
      "('RMM', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('Relative', 'JJ')\n",
      "('Measure', 'NN')\n",
      "('of', 'IN')\n",
      "('Meaning', 'NNP')\n",
      "('token', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('any', 'DT')\n",
      "('block', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('phrase', 'NN')\n",
      "('or', 'CC')\n",
      "('word', 'NN')\n",
      "('N', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('tokens', 'NNS')\n",
      "('being', 'VBG')\n",
      "('analyzed', 'VBN')\n",
      "('PMM', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('Probable', 'JJ')\n",
      "('Measure', 'NN')\n",
      "('of', 'IN')\n",
      "('Meaning', 'NNP')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('corpora', 'NN')\n",
      "('d', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('location', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('token', 'NN')\n",
      "('along', 'IN')\n",
      "('the', 'DT')\n",
      "('sequence', 'NN')\n",
      "('of', 'IN')\n",
      "('N-1', 'NNP')\n",
      "('tokens', 'NNS')\n",
      "('PF', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('Probability', 'NNP')\n",
      "('Function', 'NNP')\n",
      "('specific', 'NN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "('Ties', 'VBZ')\n",
      "('with', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('are', 'VBP')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('historical', 'JJ')\n",
      "('heritage', 'NN')\n",
      "('of', 'IN')\n",
      "('NLP', 'NNP')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('they', 'PRP')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('less', 'RBR')\n",
      "('frequently', 'RB')\n",
      "('addressed', 'VBN')\n",
      "('since', 'IN')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('turn', 'NN')\n",
      "('during', 'IN')\n",
      "('the', 'DT')\n",
      "('1990s', 'CD')\n",
      "('.', '.')\n",
      "('Nevertheless', 'RB')\n",
      "(',', ',')\n",
      "('approaches', 'NNS')\n",
      "('to', 'TO')\n",
      "('develop', 'VB')\n",
      "('cognitive', 'JJ')\n",
      "('models', 'NNS')\n",
      "('towards', 'NNS')\n",
      "('technically', 'RB')\n",
      "('operationalizable', 'JJ')\n",
      "('frameworks', 'NNS')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('pursued', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('context', 'NN')\n",
      "('of', 'IN')\n",
      "('various', 'JJ')\n",
      "('frameworks', 'NNS')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('42', 'CD')\n",
      "(']', 'JJ')\n",
      "('functional', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('43', 'CD')\n",
      "(']', 'JJ')\n",
      "('construction', 'NN')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('44', 'CD')\n",
      "(']', 'JJ')\n",
      "('computational', 'JJ')\n",
      "('psycholinguistics', 'NNS')\n",
      "('and', 'CC')\n",
      "('cognitive', 'JJ')\n",
      "('neuroscience', 'NN')\n",
      "('(', '(')\n",
      "('e.g.', 'JJ')\n",
      "(',', ',')\n",
      "('ACT-R', 'NNP')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('limited', 'JJ')\n",
      "('uptake', 'NN')\n",
      "('in', 'IN')\n",
      "('mainstream', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('as', 'IN')\n",
      "('measured', 'VBN')\n",
      "('by', 'IN')\n",
      "('presence', 'NN')\n",
      "('on', 'IN')\n",
      "('major', 'JJ')\n",
      "('conferences', 'NNS')\n",
      "('[', 'VBP')\n",
      "('45', 'CD')\n",
      "(']', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('ACL', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('More', 'RBR')\n",
      "('recently', 'RB')\n",
      "(',', ',')\n",
      "('ideas', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('revived', 'VBN')\n",
      "('as', 'IN')\n",
      "('an', 'DT')\n",
      "('approach', 'NN')\n",
      "('to', 'TO')\n",
      "('achieve', 'VB')\n",
      "('explainability', 'NN')\n",
      "(',', ',')\n",
      "('e.g.', 'NN')\n",
      "(',', ',')\n",
      "('under', 'IN')\n",
      "('the', 'DT')\n",
      "('notion', 'NN')\n",
      "('of', 'IN')\n",
      "('``', '``')\n",
      "('cognitive', 'JJ')\n",
      "('AI', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('[', 'VB')\n",
      "('46', 'CD')\n",
      "(']', 'NNP')\n",
      "('Likewise', 'NNP')\n",
      "(',', ',')\n",
      "('ideas', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('are', 'VBP')\n",
      "('inherent', 'JJ')\n",
      "('to', 'TO')\n",
      "('neural', 'JJ')\n",
      "('models', 'NNS')\n",
      "('multimodal', 'VBP')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('although', 'IN')\n",
      "('rarely', 'RB')\n",
      "('made', 'VBN')\n",
      "('explicit', 'NN')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('47', 'CD')\n",
      "(']', 'NNP')\n",
      "('See', 'NNP')\n",
      "('also', 'RB')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', '$')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "('Road', 'NNP')\n",
      "('Automated', 'NNP')\n",
      "('essay', 'VBP')\n",
      "('scoring', 'VBG')\n",
      "('Biomedical', 'NNP')\n",
      "('text', 'NN')\n",
      "('mining', 'NN')\n",
      "('Compound', 'NNP')\n",
      "('term', 'NN')\n",
      "('processing', 'VBG')\n",
      "('Computational', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('Computer-assisted', 'JJ')\n",
      "('reviewing', 'VBG')\n",
      "('Controlled', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('learning', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('linguistic', 'JJ')\n",
      "('processing', 'NN')\n",
      "('Distributional', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('Foreign', 'NNP')\n",
      "('language', 'NN')\n",
      "('reading', 'VBG')\n",
      "('aid', 'CC')\n",
      "('Foreign', 'NNP')\n",
      "('language', 'NN')\n",
      "('writing', 'VBG')\n",
      "('aid', 'NN')\n",
      "('Information', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Information', 'NNP')\n",
      "('retrieval', 'NN')\n",
      "('Language', 'NNP')\n",
      "('and', 'CC')\n",
      "('Communication', 'NNP')\n",
      "('Technologies', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('technology', 'NN')\n",
      "('Latent', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('indexing', 'VBG')\n",
      "('Native-language', 'JJ')\n",
      "('identification', 'NN')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('programming', 'VBG')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('search', 'NN')\n",
      "('Outline', 'NNP')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('Query', 'NNP')\n",
      "('expansion', 'NN')\n",
      "('Query', 'NNP')\n",
      "('understanding', 'NN')\n",
      "('Reification', 'NNP')\n",
      "('(', '(')\n",
      "('linguistics', 'NNS')\n",
      "(')', ')')\n",
      "('Speech', 'NNP')\n",
      "('processing', 'VBG')\n",
      "('Spoken', 'NNP')\n",
      "('dialogue', 'NN')\n",
      "('systems', 'NNS')\n",
      "('Text-proofing', 'NNP')\n",
      "('Text', 'NNP')\n",
      "('simplification', 'NN')\n",
      "('Transformer', 'NNP')\n",
      "('(', '(')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('model', 'NN')\n",
      "(')', ')')\n",
      "('Truecasing', 'VBG')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "('Word2vec', 'NNP')\n",
      "('References', 'NNP')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('^', 'NNP')\n",
      "('Kongthon', 'NNP')\n",
      "(',', ',')\n",
      "('Alisa', 'NNP')\n",
      "(';', ':')\n",
      "('Sangkeettrakarn', 'NNP')\n",
      "(',', ',')\n",
      "('Chatchawal', 'NNP')\n",
      "(';', ':')\n",
      "('Kongyoung', 'NNP')\n",
      "(',', ',')\n",
      "('Sarawoot', 'NNP')\n",
      "(';', ':')\n",
      "('Haruechaiyasak', 'NNP')\n",
      "(',', ',')\n",
      "('Choochart', 'NNP')\n",
      "('(', '(')\n",
      "('October', 'NNP')\n",
      "('27–30', 'CD')\n",
      "(',', ',')\n",
      "('2009', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Implementing', 'VBG')\n",
      "('an', 'DT')\n",
      "('online', 'NN')\n",
      "('help', 'NN')\n",
      "('desk', 'NN')\n",
      "('system', 'NN')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('conversational', 'JJ')\n",
      "('agent', 'NN')\n",
      "('.', '.')\n",
      "('MEDES', 'NNP')\n",
      "(\"'09\", 'POS')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('International', 'NNP')\n",
      "('Conference', 'NNP')\n",
      "('on', 'IN')\n",
      "('Management', 'NNP')\n",
      "('of', 'IN')\n",
      "('Emergent', 'NNP')\n",
      "('Digital', 'NNP')\n",
      "('EcoSystems', 'NNP')\n",
      "('.', '.')\n",
      "('France', 'NNP')\n",
      "(':', ':')\n",
      "('ACM', 'NNP')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1145/1643823.1643908', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Hutchins', 'NNP')\n",
      "(',', ',')\n",
      "('J', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2005', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('The', 'DT')\n",
      "('history', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('nutshell', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('[', 'JJ')\n",
      "('self-published', 'JJ')\n",
      "('source', 'NN')\n",
      "(']', 'NNP')\n",
      "('^', 'NNP')\n",
      "('Koskenniemi', 'NNP')\n",
      "(',', ',')\n",
      "('Kimmo', 'NNP')\n",
      "('(', '(')\n",
      "('1983', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('Two-level', 'JJ')\n",
      "('morphology', 'NN')\n",
      "(':', ':')\n",
      "('A', 'DT')\n",
      "('general', 'JJ')\n",
      "('computational', 'JJ')\n",
      "('model', 'NN')\n",
      "('of', 'IN')\n",
      "('word-form', 'JJ')\n",
      "('recognition', 'NN')\n",
      "('and', 'CC')\n",
      "('production', 'NN')\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('Department', 'NNP')\n",
      "('of', 'IN')\n",
      "('General', 'NNP')\n",
      "('Linguistics', 'NNP')\n",
      "(',', ',')\n",
      "('University', 'NNP')\n",
      "('of', 'IN')\n",
      "('Helsinki', 'NNP')\n",
      "('^', 'NNP')\n",
      "('Joshi', 'NNP')\n",
      "(',', ',')\n",
      "('A.', 'NNP')\n",
      "('K.', 'NNP')\n",
      "(',', ',')\n",
      "('&', 'CC')\n",
      "('Weinstein', 'NNP')\n",
      "(',', ',')\n",
      "('S.', 'NNP')\n",
      "('(', '(')\n",
      "('1981', 'CD')\n",
      "(',', ',')\n",
      "('August', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Control', 'NNP')\n",
      "('of', 'IN')\n",
      "('Inference', 'NNP')\n",
      "(':', ':')\n",
      "('Role', 'NNP')\n",
      "('of', 'IN')\n",
      "('Some', 'DT')\n",
      "('Aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('Discourse', 'NNP')\n",
      "('Structure-Centering', 'NNP')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('IJCAI', 'NNP')\n",
      "('(', '(')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('385-387', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Guida', 'NNP')\n",
      "(',', ',')\n",
      "('G.', 'NNP')\n",
      "(';', ':')\n",
      "('Mauri', 'NNP')\n",
      "(',', ',')\n",
      "('G.', 'NNP')\n",
      "('(', '(')\n",
      "('July', 'NNP')\n",
      "('1986', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Evaluation', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "(':', ':')\n",
      "('Issues', 'NNP')\n",
      "('and', 'CC')\n",
      "('approaches', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('IEEE', 'NNP')\n",
      "('.', '.')\n",
      "('74', 'CD')\n",
      "('(', '(')\n",
      "('7', 'CD')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('1026–1035', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1109/PROC.1986.13580', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NNP')\n",
      "('1558-2256', 'JJ')\n",
      "('.', '.')\n",
      "('S2CID', 'NNP')\n",
      "('30688575', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('Chomskyan', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('encourages', 'VBZ')\n",
      "('the', 'DT')\n",
      "('investigation', 'NN')\n",
      "('of', 'IN')\n",
      "('``', '``')\n",
      "('corner', 'NN')\n",
      "('cases', 'NNS')\n",
      "('``', '``')\n",
      "('that', 'WDT')\n",
      "('stress', 'VBZ')\n",
      "('the', 'DT')\n",
      "('limits', 'NNS')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('theoretical', 'JJ')\n",
      "('models', 'NNS')\n",
      "('(', '(')\n",
      "('comparable', 'JJ')\n",
      "('to', 'TO')\n",
      "('pathological', 'JJ')\n",
      "('phenomena', 'NN')\n",
      "('in', 'IN')\n",
      "('mathematics', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('typically', 'RB')\n",
      "('created', 'VBN')\n",
      "('using', 'VBG')\n",
      "('thought', 'JJ')\n",
      "('experiments', 'NNS')\n",
      "(',', ',')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('the', 'DT')\n",
      "('systematic', 'JJ')\n",
      "('investigation', 'NN')\n",
      "('of', 'IN')\n",
      "('typical', 'JJ')\n",
      "('phenomena', 'NNS')\n",
      "('that', 'WDT')\n",
      "('occur', 'VBP')\n",
      "('in', 'IN')\n",
      "('real-world', 'NN')\n",
      "('data', 'NNS')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('case', 'NN')\n",
      "('in', 'IN')\n",
      "('corpus', 'NN')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('creation', 'NN')\n",
      "('and', 'CC')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('corpora', 'NNS')\n",
      "('of', 'IN')\n",
      "('real-world', 'NN')\n",
      "('data', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('fundamental', 'JJ')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('machine-learning', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('for', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('addition', 'NN')\n",
      "(',', ',')\n",
      "('theoretical', 'JJ')\n",
      "('underpinnings', 'NNS')\n",
      "('of', 'IN')\n",
      "('Chomskyan', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('the', 'DT')\n",
      "('so-called', 'JJ')\n",
      "('``', '``')\n",
      "('poverty', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('stimulus', 'NN')\n",
      "('``', '``')\n",
      "('argument', 'JJ')\n",
      "('entail', 'NN')\n",
      "('that', 'IN')\n",
      "('general', 'JJ')\n",
      "('learning', 'VBG')\n",
      "('algorithms', 'NN')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('are', 'VBP')\n",
      "('typically', 'RB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "(',', ',')\n",
      "('can', 'MD')\n",
      "('not', 'RB')\n",
      "('be', 'VB')\n",
      "('successful', 'JJ')\n",
      "('in', 'IN')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('Chomskyan', 'NNP')\n",
      "('paradigm', 'NN')\n",
      "('discouraged', 'VBD')\n",
      "('the', 'DT')\n",
      "('application', 'NN')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('to', 'TO')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Goldberg', 'NNP')\n",
      "(',', ',')\n",
      "('Yoav', 'NNP')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('A', 'DT')\n",
      "('Primer', 'NNP')\n",
      "('on', 'IN')\n",
      "('Neural', 'NNP')\n",
      "('Network', 'NNP')\n",
      "('Models', 'NNP')\n",
      "('for', 'IN')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Journal', 'NNP')\n",
      "('of', 'IN')\n",
      "('Artificial', 'NNP')\n",
      "('Intelligence', 'NNP')\n",
      "('Research', 'NNP')\n",
      "('.', '.')\n",
      "('57', 'CD')\n",
      "(':', ':')\n",
      "('345–420', 'CD')\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1807.10854', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1613/jair.4992', 'CD')\n",
      "('.', '.')\n",
      "('S2CID', 'JJ')\n",
      "('8273530', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Goodfellow', 'NNP')\n",
      "(',', ',')\n",
      "('Ian', 'NNP')\n",
      "(';', ':')\n",
      "('Bengio', 'NNP')\n",
      "(',', ',')\n",
      "('Yoshua', 'NNP')\n",
      "(';', ':')\n",
      "('Courville', 'NNP')\n",
      "(',', ',')\n",
      "('Aaron', 'NNP')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Deep', 'JJ')\n",
      "('Learning', 'NNP')\n",
      "('.', '.')\n",
      "('MIT', 'NNP')\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('^', 'NNP')\n",
      "('Jozefowicz', 'NNP')\n",
      "(',', ',')\n",
      "('Rafal', 'NNP')\n",
      "(';', ':')\n",
      "('Vinyals', 'NNS')\n",
      "(',', ',')\n",
      "('Oriol', 'NNP')\n",
      "(';', ':')\n",
      "('Schuster', 'NNP')\n",
      "(',', ',')\n",
      "('Mike', 'NNP')\n",
      "(';', ':')\n",
      "('Shazeer', 'NNP')\n",
      "(',', ',')\n",
      "('Noam', 'NNP')\n",
      "(';', ':')\n",
      "('Wu', 'NNP')\n",
      "(',', ',')\n",
      "('Yonghui', 'NNP')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Exploring', 'VBG')\n",
      "('the', 'DT')\n",
      "('Limits', 'NNS')\n",
      "('of', 'IN')\n",
      "('Language', 'NNP')\n",
      "('Modeling', 'NNP')\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1602.02410', 'CD')\n",
      "('.', '.')\n",
      "('Bibcode', 'NN')\n",
      "(':', ':')\n",
      "('2016arXiv160202410J', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Choe', 'NNP')\n",
      "(',', ',')\n",
      "('Do', 'NNP')\n",
      "('Kook', 'NNP')\n",
      "(';', ':')\n",
      "('Charniak', 'NNP')\n",
      "(',', ',')\n",
      "('Eugene', 'NNP')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Parsing', 'VBG')\n",
      "('as', 'IN')\n",
      "('Language', 'NNP')\n",
      "('Modeling', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Emnlp', 'NNP')\n",
      "('2016', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Vinyals', 'NNS')\n",
      "(',', ',')\n",
      "('Oriol', 'NNP')\n",
      "(';', ':')\n",
      "('et', 'CC')\n",
      "('al', 'NN')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2014', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Grammar', 'NNP')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('Foreign', 'NNP')\n",
      "('Language', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Nips2015', 'NNP')\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1412.7449', 'CD')\n",
      "('.', '.')\n",
      "('Bibcode', 'NN')\n",
      "(':', ':')\n",
      "('2014arXiv1412.7449V', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Turchin', 'NNP')\n",
      "(',', ',')\n",
      "('Alexander', 'NNP')\n",
      "(';', ':')\n",
      "('Florez', 'NNP')\n",
      "('Builes', 'NNP')\n",
      "(',', ',')\n",
      "('Luisa', 'NNP')\n",
      "('F.', 'NNP')\n",
      "('(', '(')\n",
      "('2021-03-19', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Using', 'VBG')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('to', 'TO')\n",
      "('Measure', 'NNP')\n",
      "('and', 'CC')\n",
      "('Improve', 'NNP')\n",
      "('Quality', 'NNP')\n",
      "('of', 'IN')\n",
      "('Diabetes', 'NNP')\n",
      "('Care', 'NNP')\n",
      "(':', ':')\n",
      "('A', 'NNP')\n",
      "('Systematic', 'NNP')\n",
      "('Review', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Journal', 'NNP')\n",
      "('of', 'IN')\n",
      "('Diabetes', 'NNP')\n",
      "('Science', 'NNP')\n",
      "('and', 'CC')\n",
      "('Technology', 'NNP')\n",
      "('.', '.')\n",
      "('15', 'CD')\n",
      "('(', '(')\n",
      "('3', 'CD')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('553–560', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1177/19322968211000831', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NNP')\n",
      "('1932-2968', 'JJ')\n",
      "('.', '.')\n",
      "('PMC', '$')\n",
      "('8120048', 'CD')\n",
      "('.', '.')\n",
      "('PMID', 'VB')\n",
      "('33736486', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Winograd', 'NNP')\n",
      "(',', ',')\n",
      "('Terry', 'NNP')\n",
      "('(', '(')\n",
      "('1971', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Procedures', 'NNS')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('Representation', 'NN')\n",
      "('for', 'IN')\n",
      "('Data', 'NNP')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('Computer', 'NNP')\n",
      "('Program', 'NNP')\n",
      "('for', 'IN')\n",
      "('Understanding', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('(', '(')\n",
      "('Thesis', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Schank', 'NNP')\n",
      "(',', ',')\n",
      "('Roger', 'NNP')\n",
      "('C.', 'NNP')\n",
      "(';', ':')\n",
      "('Abelson', 'NNP')\n",
      "(',', ',')\n",
      "('Robert', 'NNP')\n",
      "('P.', 'NNP')\n",
      "('(', '(')\n",
      "('1977', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Scripts', 'NNP')\n",
      "(',', ',')\n",
      "('Plans', 'VBZ')\n",
      "(',', ',')\n",
      "('Goals', 'NNP')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('Understanding', 'NNP')\n",
      "(':', ':')\n",
      "('An', 'DT')\n",
      "('Inquiry', 'NNP')\n",
      "('Into', 'NNP')\n",
      "('Human', 'NNP')\n",
      "('Knowledge', 'NNP')\n",
      "('Structures', 'NNP')\n",
      "('.', '.')\n",
      "('Hillsdale', 'NNP')\n",
      "(':', ':')\n",
      "('Erlbaum', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('0-470-99033-3', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Mark', 'NNP')\n",
      "('Johnson', 'NNP')\n",
      "('.', '.')\n",
      "('How', 'WRB')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('revolution', 'NN')\n",
      "('changes', 'NNS')\n",
      "('(', '(')\n",
      "('computational', 'NN')\n",
      "(')', ')')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('EACL', 'NNP')\n",
      "('2009', 'CD')\n",
      "('Workshop', 'NNP')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('Interaction', 'NNP')\n",
      "('between', 'IN')\n",
      "('Linguistics', 'NNP')\n",
      "('and', 'CC')\n",
      "('Computational', 'NNP')\n",
      "('Linguistics', 'NNP')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('Philip', 'NNP')\n",
      "('Resnik', 'NNP')\n",
      "('.', '.')\n",
      "('Four', 'CD')\n",
      "('revolutions', 'NNS')\n",
      "('.', '.')\n",
      "('Language', 'NNP')\n",
      "('Log', 'NNP')\n",
      "(',', ',')\n",
      "('February', 'NNP')\n",
      "('5', 'CD')\n",
      "(',', ',')\n",
      "('2011', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Investigating', 'NNP')\n",
      "('complex-valued', 'JJ')\n",
      "('representation', 'NN')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Trabelsi', 'NNP')\n",
      "(',', ',')\n",
      "('Chiheb', 'NNP')\n",
      "(';', ':')\n",
      "('Bilaniuk', 'NNP')\n",
      "(',', ',')\n",
      "('Olexa', 'NNP')\n",
      "(';', ':')\n",
      "('Zhang', 'NNP')\n",
      "(',', ',')\n",
      "('Ying', 'NNP')\n",
      "(';', ':')\n",
      "('Serdyuk', 'NNP')\n",
      "(',', ',')\n",
      "('Dmitriy', 'NNP')\n",
      "(';', ':')\n",
      "('Subramanian', 'NNP')\n",
      "(',', ',')\n",
      "('Sandeep', 'NNP')\n",
      "(';', ':')\n",
      "('Santos', 'NNP')\n",
      "(',', ',')\n",
      "('João', 'NNP')\n",
      "('Felipe', 'NNP')\n",
      "(';', ':')\n",
      "('Mehri', 'NNP')\n",
      "(',', ',')\n",
      "('Soroush', 'NNP')\n",
      "(';', ':')\n",
      "('Rostamzadeh', 'NNP')\n",
      "(',', ',')\n",
      "('Negar', 'NNP')\n",
      "(';', ':')\n",
      "('Bengio', 'NNP')\n",
      "(',', ',')\n",
      "('Yoshua', 'NNP')\n",
      "(';', ':')\n",
      "('Pal', 'NNP')\n",
      "(',', ',')\n",
      "('Christopher', 'NNP')\n",
      "('J', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2018-02-25', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Deep', 'JJ')\n",
      "('Complex', 'NNP')\n",
      "('Networks', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1705.09792', 'CD')\n",
      "('[', 'NN')\n",
      "('cs.NE', 'NN')\n",
      "(']', 'NNP')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Socher', 'NNP')\n",
      "(',', ',')\n",
      "('Richard', 'NNP')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Deep', 'JJ')\n",
      "('Learning', 'NNP')\n",
      "('For', 'IN')\n",
      "('NLP-ACL', 'NNP')\n",
      "('2012', 'CD')\n",
      "('Tutorial', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.socher.org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2020-08-17', 'JJ')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('was', 'VBD')\n",
      "('an', 'DT')\n",
      "('early', 'JJ')\n",
      "('Deep', 'NNP')\n",
      "('Learning', 'NNP')\n",
      "('tutorial', 'NN')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "('ACL', 'NNP')\n",
      "('2012', 'CD')\n",
      "('and', 'CC')\n",
      "('met', 'VBD')\n",
      "('with', 'IN')\n",
      "('both', 'DT')\n",
      "('interest', 'NN')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "(')', ')')\n",
      "('skepticism', 'NN')\n",
      "('by', 'IN')\n",
      "('most', 'JJS')\n",
      "('participants', 'NNS')\n",
      "('.', '.')\n",
      "('Until', 'IN')\n",
      "('then', 'RB')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('learning', 'NN')\n",
      "('was', 'VBD')\n",
      "('basically', 'RB')\n",
      "('rejected', 'VBN')\n",
      "('because', 'IN')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('lack', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('interpretability', 'NN')\n",
      "('.', '.')\n",
      "('Until', 'IN')\n",
      "('2015', 'CD')\n",
      "(',', ',')\n",
      "('deep', 'JJ')\n",
      "('learning', 'NN')\n",
      "('had', 'VBD')\n",
      "('evolved', 'VBN')\n",
      "('into', 'IN')\n",
      "('the', 'DT')\n",
      "('major', 'JJ')\n",
      "('framework', 'NN')\n",
      "('of', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Annamoradnejad', 'NNP')\n",
      "(',', ',')\n",
      "('I.', 'NNP')\n",
      "('and', 'CC')\n",
      "('Zoghi', 'NNP')\n",
      "(',', ',')\n",
      "('G.', 'NNP')\n",
      "('(', '(')\n",
      "('2020', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Colbert', 'NN')\n",
      "(':', ':')\n",
      "('Using', 'NNP')\n",
      "('bert', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('embedding', 'VBG')\n",
      "('for', 'IN')\n",
      "('humor', 'NN')\n",
      "('detection', 'NN')\n",
      "('.', '.')\n",
      "('arXiv', 'JJ')\n",
      "('preprint', 'NN')\n",
      "('arXiv:2004.12765', 'NN')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Yi', 'NNP')\n",
      "(',', ',')\n",
      "('Chucai', 'NNP')\n",
      "(';', ':')\n",
      "('Tian', 'NNP')\n",
      "(',', ',')\n",
      "('Yingli', 'NNP')\n",
      "('(', '(')\n",
      "('2012', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('``', '``')\n",
      "('Assistive', 'JJ')\n",
      "('Text', 'NNP')\n",
      "('Reading', 'NNP')\n",
      "('from', 'IN')\n",
      "('Complex', 'NNP')\n",
      "('Background', 'NNP')\n",
      "('for', 'IN')\n",
      "('Blind', 'NNP')\n",
      "('Persons', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "(',', ',')\n",
      "('Camera-Based', 'JJ')\n",
      "('Document', 'NNP')\n",
      "('Analysis', 'NNP')\n",
      "('and', 'CC')\n",
      "('Recognition', 'NNP')\n",
      "(',', ',')\n",
      "('Springer', 'NNP')\n",
      "('Berlin', 'NNP')\n",
      "('Heidelberg', 'NNP')\n",
      "(',', ',')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('15–28', 'CD')\n",
      "(',', ',')\n",
      "('CiteSeerX', 'NNP')\n",
      "('10.1.1.668.869', 'CD')\n",
      "(',', ',')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1007/978-3-642-29364-1_2', 'JJ')\n",
      "(',', ',')\n",
      "('ISBN', 'NNP')\n",
      "('9783642293634', 'CD')\n",
      "('^', 'NN')\n",
      "('``', '``')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('Natural', 'JJ')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('?', '.')\n",
      "('Intro', 'NNP')\n",
      "('to', 'TO')\n",
      "('NLP', 'NNP')\n",
      "('in', 'IN')\n",
      "('Machine', 'NNP')\n",
      "('Learning', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('GyanSetu', 'NNP')\n",
      "('!', '.')\n",
      "('.', '.')\n",
      "('2020-12-06', 'JJ')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-09', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Kishorjit', 'NNP')\n",
      "(',', ',')\n",
      "('N.', 'NNP')\n",
      "(';', ':')\n",
      "('Vidya', 'NNP')\n",
      "(',', ',')\n",
      "('Raj', 'NNP')\n",
      "('RK', 'NNP')\n",
      "('.', '.')\n",
      "(';', ':')\n",
      "('Nirmal', 'NNP')\n",
      "(',', ',')\n",
      "('Y.', 'NNP')\n",
      "(';', ':')\n",
      "('Sivaji', 'NNP')\n",
      "(',', ',')\n",
      "('B', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2012', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Manipuri', 'NNP')\n",
      "('Morpheme', 'NNP')\n",
      "('Identification', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('3rd', 'CD')\n",
      "('Workshop', 'NNP')\n",
      "('on', 'IN')\n",
      "('South', 'NNP')\n",
      "('and', 'CC')\n",
      "('Southeast', 'NNP')\n",
      "('Asian', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('(', '(')\n",
      "('SANLP', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('COLING', 'NN')\n",
      "('2012', 'CD')\n",
      "(',', ',')\n",
      "('Mumbai', 'NNP')\n",
      "(',', ',')\n",
      "('December', 'NNP')\n",
      "('2012', 'CD')\n",
      "(':', ':')\n",
      "('95–108', 'CD')\n",
      "('.', '.')\n",
      "('CS1', 'JJ')\n",
      "('maint', 'NN')\n",
      "(':', ':')\n",
      "('location', 'NN')\n",
      "('(', '(')\n",
      "('link', 'NN')\n",
      "(')', ')')\n",
      "('^', 'NN')\n",
      "('Klein', 'NNP')\n",
      "(',', ',')\n",
      "('Dan', 'NNP')\n",
      "(';', ':')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "('Christopher', 'NNP')\n",
      "('D.', 'NNP')\n",
      "('(', '(')\n",
      "('2002', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('grammar', 'NN')\n",
      "('induction', 'NN')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('constituent-context', 'JJ')\n",
      "('model', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('(', '(')\n",
      "('PDF', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Advances', 'NNS')\n",
      "('in', 'IN')\n",
      "('Neural', 'NNP')\n",
      "('Information', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('Systems', 'NNPS')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('PASCAL', 'NNP')\n",
      "('Recognizing', 'NNP')\n",
      "('Textual', 'NNP')\n",
      "('Entailment', 'NNP')\n",
      "('Challenge', 'NNP')\n",
      "('(', '(')\n",
      "('RTE-7', 'NNP')\n",
      "(')', ')')\n",
      "('https', 'NN')\n",
      "(':', ':')\n",
      "('//tac.nist.gov//2011/RTE/', 'JJ')\n",
      "('^', 'NNP')\n",
      "('Lippi', 'NNP')\n",
      "(',', ',')\n",
      "('Marco', 'NNP')\n",
      "(';', ':')\n",
      "('Torroni', 'NNP')\n",
      "(',', ',')\n",
      "('Paolo', 'NNP')\n",
      "('(', '(')\n",
      "('2016-04-20', 'JJ')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Argumentation', 'NNP')\n",
      "('Mining', 'NN')\n",
      "(':', ':')\n",
      "('State', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('Art', 'NNP')\n",
      "('and', 'CC')\n",
      "('Emerging', 'NNP')\n",
      "('Trends', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('ACM', 'NNP')\n",
      "('Transactions', 'NNPS')\n",
      "('on', 'IN')\n",
      "('Internet', 'NNP')\n",
      "('Technology', 'NNP')\n",
      "('.', '.')\n",
      "('16', 'CD')\n",
      "('(', '(')\n",
      "('2', 'CD')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('1–25', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1145/2850417', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NNP')\n",
      "('1533-5399', 'JJ')\n",
      "('.', '.')\n",
      "('S2CID', 'NNP')\n",
      "('9561587', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Argument', 'NNP')\n",
      "('Mining', 'NNP')\n",
      "('-', ':')\n",
      "('IJCAI2016', 'NNP')\n",
      "('Tutorial', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.i3s.unice.fr', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-03-09', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('NLP', 'NNP')\n",
      "('Approaches', 'NNP')\n",
      "('to', 'TO')\n",
      "('Computational', 'NNP')\n",
      "('Argumentation', 'NNP')\n",
      "('–', 'NNP')\n",
      "('ACL', 'NNP')\n",
      "('2016', 'CD')\n",
      "(',', ',')\n",
      "('Berlin', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-03-09', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('U', 'NNP')\n",
      "('B', 'NNP')\n",
      "('U', 'NNP')\n",
      "('W', 'NNP')\n",
      "('E', 'NNP')\n",
      "('B', 'NNP')\n",
      "(':', ':')\n",
      "(':', ':')\n",
      "('Racter', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.ubu.com', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2020-08-17', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Writer', 'NNP')\n",
      "(',', ',')\n",
      "('Beta', 'NNP')\n",
      "('(', '(')\n",
      "('2019', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Lithium-Ion', 'JJ')\n",
      "('Batteries', 'NNPS')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1007/978-3-030-16800-1', 'JJ')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-3-030-16799-8', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Document', 'NNP')\n",
      "('Understanding', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('on', 'IN')\n",
      "('Google', 'NNP')\n",
      "('Cloud', 'NNP')\n",
      "('(', '(')\n",
      "('Cloud', 'NNP')\n",
      "('Next', 'NNP')\n",
      "(\"'19\", 'POS')\n",
      "(')', ')')\n",
      "('-', ':')\n",
      "('YouTube', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.youtube.com', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Administration', 'NNP')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Centre', 'NNP')\n",
      "('for', 'IN')\n",
      "('Language', 'NNP')\n",
      "('Technology', 'NNP')\n",
      "('(', '(')\n",
      "('CLT', 'NNP')\n",
      "(')', ')')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Macquarie', 'NNP')\n",
      "('University', 'NNP')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Shared', 'NNP')\n",
      "('Task', 'NN')\n",
      "(':', ':')\n",
      "('Grammatical', 'JJ')\n",
      "('Error', 'NNP')\n",
      "('Correction', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.comp.nus.edu.sg', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Shared', 'NNP')\n",
      "('Task', 'NN')\n",
      "(':', ':')\n",
      "('Grammatical', 'JJ')\n",
      "('Error', 'NNP')\n",
      "('Correction', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.comp.nus.edu.sg', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Duan', 'NNP')\n",
      "(',', ',')\n",
      "('Yucong', 'NNP')\n",
      "(';', ':')\n",
      "('Cruz', 'NNP')\n",
      "(',', ',')\n",
      "('Christophe', 'NNP')\n",
      "('(', '(')\n",
      "('2011', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Formalizing', 'NNP')\n",
      "('Semantic', 'NNP')\n",
      "('of', 'IN')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('through', 'IN')\n",
      "('Conceptualization', 'NNP')\n",
      "('from', 'IN')\n",
      "('Existence', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('International', 'NNP')\n",
      "('Journal', 'NNP')\n",
      "('of', 'IN')\n",
      "('Innovation', 'NNP')\n",
      "(',', ',')\n",
      "('Management', 'NNP')\n",
      "('and', 'CC')\n",
      "('Technology', 'NNP')\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "('(', '(')\n",
      "('1', 'CD')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('37–42', 'CD')\n",
      "('.', '.')\n",
      "('Archived', 'VBN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('original', 'JJ')\n",
      "('on', 'IN')\n",
      "('2011-10-09', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Previous', 'JJ')\n",
      "('shared', 'VBN')\n",
      "('tasks', 'NNS')\n",
      "('|', 'RBR')\n",
      "('CoNLL', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.conll.org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Cognition', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Lexico', 'NNP')\n",
      "('.', '.')\n",
      "('Oxford', 'NNP')\n",
      "('University', 'NNP')\n",
      "('Press', 'NNP')\n",
      "('and', 'CC')\n",
      "('Dictionary.com', 'NNP')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBD')\n",
      "('6', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Ask', 'NNP')\n",
      "('the', 'DT')\n",
      "('Cognitive', 'NNP')\n",
      "('Scientist', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('American', 'JJ')\n",
      "('Federation', 'NNP')\n",
      "('of', 'IN')\n",
      "('Teachers', 'NNP')\n",
      "('.', '.')\n",
      "('8', 'CD')\n",
      "('August', 'NNP')\n",
      "('2014', 'CD')\n",
      "('.', '.')\n",
      "('Cognitive', 'JJ')\n",
      "('science', 'NN')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "('field', 'NN')\n",
      "('of', 'IN')\n",
      "('researchers', 'NNS')\n",
      "('from', 'IN')\n",
      "('Linguistics', 'NNP')\n",
      "(',', ',')\n",
      "('psychology', 'NN')\n",
      "(',', ',')\n",
      "('neuroscience', 'NN')\n",
      "(',', ',')\n",
      "('philosophy', 'NN')\n",
      "(',', ',')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('anthropology', 'NN')\n",
      "('that', 'WDT')\n",
      "('seek', 'VBP')\n",
      "('to', 'TO')\n",
      "('understand', 'VB')\n",
      "('the', 'DT')\n",
      "('mind', 'NN')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Robinson', 'NNP')\n",
      "(',', ',')\n",
      "('Peter', 'NNP')\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Handbook', 'NNP')\n",
      "('of', 'IN')\n",
      "('Cognitive', 'NNP')\n",
      "('Linguistics', 'NNP')\n",
      "('and', 'CC')\n",
      "('Second', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Acquisition', 'NNP')\n",
      "('.', '.')\n",
      "('Routledge', 'NNP')\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('3–8', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-805-85352-0', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('Lakoff', 'NNP')\n",
      "(',', ',')\n",
      "('George', 'NNP')\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Philosophy', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('Flesh', 'NNP')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('Embodied', 'NNP')\n",
      "('Mind', 'NNP')\n",
      "('and', 'CC')\n",
      "('Its', 'PRP$')\n",
      "('Challenge', 'NNP')\n",
      "('to', 'TO')\n",
      "('Western', 'NNP')\n",
      "('Philosophy', 'NNP')\n",
      "(';', ':')\n",
      "('Appendix', 'NNP')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('Neural', 'NNP')\n",
      "('Theory', 'NNP')\n",
      "('of', 'IN')\n",
      "('Language', 'NNP')\n",
      "('Paradigm', 'NNP')\n",
      "('.', '.')\n",
      "('New', 'NNP')\n",
      "('York', 'NNP')\n",
      "('Basic', 'NNP')\n",
      "('Books', 'NNP')\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('569–583', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-465-05674-3', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Strauss', 'NNP')\n",
      "(',', ',')\n",
      "('Claudia', 'NNP')\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('Cognitive', 'JJ')\n",
      "('Theory', 'NN')\n",
      "('of', 'IN')\n",
      "('Cultural', 'NNP')\n",
      "('Meaning', 'NNP')\n",
      "('.', '.')\n",
      "('Cambridge', 'NNP')\n",
      "('University', 'NNP')\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('156–164', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-521-59541-4', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Universal', 'NNP')\n",
      "('Conceptual', 'NNP')\n",
      "('Cognitive', 'NNP')\n",
      "('Annotation', 'NNP')\n",
      "('(', '(')\n",
      "('UCCA', 'NNP')\n",
      "(')', ')')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Universal', 'NNP')\n",
      "('Conceptual', 'NNP')\n",
      "('Cognitive', 'NNP')\n",
      "('Annotation', 'NNP')\n",
      "('(', '(')\n",
      "('UCCA', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Rodríguez', 'NNP')\n",
      "(',', ',')\n",
      "('F.', 'NNP')\n",
      "('C.', 'NNP')\n",
      "(',', ',')\n",
      "('&', 'CC')\n",
      "('Mairal-Usón', 'NNP')\n",
      "(',', ',')\n",
      "('R.', 'NNP')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Building', 'VBG')\n",
      "('an', 'DT')\n",
      "('RRG', 'NNP')\n",
      "('computational', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('.', '.')\n",
      "('Onomazein', 'NNP')\n",
      "(',', ',')\n",
      "('(', '(')\n",
      "('34', 'CD')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('86-117', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Fluid', 'NNP')\n",
      "('Construction', 'NNP')\n",
      "('Grammar', 'NNP')\n",
      "('–', 'VBD')\n",
      "('A', 'NNP')\n",
      "('fully', 'RB')\n",
      "('operational', 'JJ')\n",
      "('processing', 'NN')\n",
      "('system', 'NN')\n",
      "('for', 'IN')\n",
      "('construction', 'NN')\n",
      "('grammars', 'NNS')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('ACL', 'NNP')\n",
      "('Member', 'NNP')\n",
      "('Portal', 'NNP')\n",
      "('|', 'NNP')\n",
      "('The', 'DT')\n",
      "('Association', 'NNP')\n",
      "('for', 'IN')\n",
      "('Computational', 'NNP')\n",
      "('Linguistics', 'NNP')\n",
      "('Member', 'NNP')\n",
      "('Portal', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.aclweb.org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('``', '``')\n",
      "('Chunks', 'NNP')\n",
      "('and', 'CC')\n",
      "('Rules', 'NNP')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('www.w3.org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021-01-11', 'JJ')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('Socher', 'NNP')\n",
      "(',', ',')\n",
      "('Richard', 'NNP')\n",
      "(';', ':')\n",
      "('Karpathy', 'NNP')\n",
      "(',', ',')\n",
      "('Andrej', 'NNP')\n",
      "(';', ':')\n",
      "('Le', 'NNP')\n",
      "(',', ',')\n",
      "('Quoc', 'NNP')\n",
      "('V.', 'NNP')\n",
      "(';', ':')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "('Christopher', 'NNP')\n",
      "('D.', 'NNP')\n",
      "(';', ':')\n",
      "('Ng', 'NNP')\n",
      "(',', ',')\n",
      "('Andrew', 'NNP')\n",
      "('Y', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2014', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Grounded', 'VBD')\n",
      "('Compositional', 'NNP')\n",
      "('Semantics', 'NNP')\n",
      "('for', 'IN')\n",
      "('Finding', 'NNP')\n",
      "('and', 'CC')\n",
      "('Describing', 'NNP')\n",
      "('Images', 'NNP')\n",
      "('with', 'IN')\n",
      "('Sentences', 'NNPS')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Transactions', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('Association', 'NNP')\n",
      "('for', 'IN')\n",
      "('Computational', 'NNP')\n",
      "('Linguistics', 'NNP')\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "(':', ':')\n",
      "('207–218', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1162/tacl_a_00177', 'CD')\n",
      "('.', '.')\n",
      "('S2CID', 'JJ')\n",
      "('2317858', 'CD')\n",
      "('.', '.')\n",
      "('Further', 'JJ')\n",
      "('reading', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Bates', 'NNP')\n",
      "(',', ',')\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('1995', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('Models', 'NNP')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "(\"''\", \"''\")\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('National', 'NNP')\n",
      "('Academy', 'NNP')\n",
      "('of', 'IN')\n",
      "('Sciences', 'NNPS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('United', 'NNP')\n",
      "('States', 'NNPS')\n",
      "('of', 'IN')\n",
      "('America', 'NNP')\n",
      "('.', '.')\n",
      "('92', 'CD')\n",
      "('(', '(')\n",
      "('22', 'CD')\n",
      "(')', ')')\n",
      "(':', ':')\n",
      "('9977–9982', 'CD')\n",
      "('.', '.')\n",
      "('Bibcode', 'NN')\n",
      "(':', ':')\n",
      "('1995PNAS', 'CD')\n",
      "('...', ':')\n",
      "('92.9977B', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10.1073/pnas.92.22.9977', 'CD')\n",
      "('.', '.')\n",
      "('PMC', 'VB')\n",
      "('40721', 'CD')\n",
      "('.', '.')\n",
      "('PMID', 'VB')\n",
      "('7479812', 'CD')\n",
      "('.', '.')\n",
      "('Steven', 'NNP')\n",
      "('Bird', 'NNP')\n",
      "(',', ',')\n",
      "('Ewan', 'NNP')\n",
      "('Klein', 'NNP')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('Edward', 'NNP')\n",
      "('Loper', 'NNP')\n",
      "('(', '(')\n",
      "('2009', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('with', 'IN')\n",
      "('Python', 'NNP')\n",
      "('.', '.')\n",
      "(\"O'Reilly\", 'RB')\n",
      "('Media', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-596-51649-9', 'JJ')\n",
      "('.', '.')\n",
      "('Daniel', 'NNP')\n",
      "('Jurafsky', 'NNP')\n",
      "('and', 'CC')\n",
      "('James', 'NNP')\n",
      "('H.', 'NNP')\n",
      "('Martin', 'NNP')\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Speech', 'NNP')\n",
      "('and', 'CC')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "(',', ',')\n",
      "('2nd', 'CD')\n",
      "('edition', 'NN')\n",
      "('.', '.')\n",
      "('Pearson', 'NNP')\n",
      "('Prentice', 'NNP')\n",
      "('Hall', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-13-187321-6', 'CD')\n",
      "('.', '.')\n",
      "('Mohamed', 'VBN')\n",
      "('Zakaria', 'NNP')\n",
      "('Kurdi', 'NNP')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('and', 'CC')\n",
      "('Computational', 'NNP')\n",
      "('Linguistics', 'NNS')\n",
      "(':', ':')\n",
      "('speech', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "('Volume', 'NN')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('ISTE-Wiley', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-1848218482', 'CD')\n",
      "('.', '.')\n",
      "('Mohamed', 'VBN')\n",
      "('Zakaria', 'NNP')\n",
      "('Kurdi', 'NNP')\n",
      "('(', '(')\n",
      "('2017', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('and', 'CC')\n",
      "('Computational', 'NNP')\n",
      "('Linguistics', 'NNS')\n",
      "(':', ':')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('discourse', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('applications', 'NNS')\n",
      "(',', ',')\n",
      "('Volume', 'NN')\n",
      "('2', 'CD')\n",
      "('.', '.')\n",
      "('ISTE-Wiley', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-1848219212', 'CD')\n",
      "('.', '.')\n",
      "('Christopher', 'NNP')\n",
      "('D.', 'NNP')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "('Prabhakar', 'NNP')\n",
      "('Raghavan', 'NNP')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('Hinrich', 'NNP')\n",
      "('Schütze', 'NNP')\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Introduction', 'NN')\n",
      "('to', 'TO')\n",
      "('Information', 'NNP')\n",
      "('Retrieval', 'NNP')\n",
      "('.', '.')\n",
      "('Cambridge', 'NNP')\n",
      "('University', 'NNP')\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-521-86571-5', 'CD')\n",
      "('.', '.')\n",
      "('Official', 'JJ')\n",
      "('html', 'NN')\n",
      "('and', 'CC')\n",
      "('pdf', 'JJ')\n",
      "('versions', 'NNS')\n",
      "('available', 'JJ')\n",
      "('without', 'IN')\n",
      "('charge', 'NN')\n",
      "('.', '.')\n",
      "('Christopher', 'NNP')\n",
      "('D.', 'NNP')\n",
      "('Manning', 'NNP')\n",
      "('and', 'CC')\n",
      "('Hinrich', 'NNP')\n",
      "('Schütze', 'NNP')\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Foundations', 'NNS')\n",
      "('of', 'IN')\n",
      "('Statistical', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('MIT', 'NNP')\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-262-13360-9', 'CD')\n",
      "('.', '.')\n",
      "('David', 'NNP')\n",
      "('M.', 'NNP')\n",
      "('W.', 'NNP')\n",
      "('Powers', 'NNP')\n",
      "('and', 'CC')\n",
      "('Christopher', 'NNP')\n",
      "('C.', 'NNP')\n",
      "('R.', 'NNP')\n",
      "('Turk', 'NNP')\n",
      "('(', '(')\n",
      "('1989', 'CD')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Machine', 'NNP')\n",
      "('Learning', 'NNP')\n",
      "('of', 'IN')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('.', '.')\n",
      "('Springer-Verlag', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978-0-387-19557-5', 'CD')\n",
      "('.', '.')\n",
      "('External', 'JJ')\n",
      "('link', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Media', 'NNP')\n",
      "('related', 'VBD')\n",
      "('to', 'TO')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('at', 'IN')\n",
      "('Wikimedia', 'NNP')\n",
      "('Commons', 'NNP')\n",
      "('v', 'NN')\n",
      "('t', 'NN')\n",
      "('e', 'VBZ')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('General', 'JJ')\n",
      "('terms', 'NNS')\n",
      "('AI-complete', 'JJ')\n",
      "('Bag-of-words', 'NNS')\n",
      "('n-gram', 'JJ')\n",
      "('Bigram', 'NNP')\n",
      "('Trigram', 'NNP')\n",
      "('Computational', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('Natural-language', 'NNP')\n",
      "('understanding', 'NN')\n",
      "('Stopwords', 'NNP')\n",
      "('Text', 'NNP')\n",
      "('processing', 'VBG')\n",
      "('Text', 'NNP')\n",
      "('analysis', 'NN')\n",
      "('Collocation', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Concept', 'NNP')\n",
      "('mining', 'NN')\n",
      "('Coreference', 'NNP')\n",
      "('resolution', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('linguistic', 'JJ')\n",
      "('processing', 'NN')\n",
      "('Distant', 'NNP')\n",
      "('reading', 'NN')\n",
      "('Information', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Named-entity', 'NNP')\n",
      "('recognition', 'NN')\n",
      "('Ontology', 'NNP')\n",
      "('learning', 'VBG')\n",
      "('Parsing', 'VBG')\n",
      "('Part-of-speech', 'JJ')\n",
      "('tagging', 'VBG')\n",
      "('Semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labeling', 'VBG')\n",
      "('Semantic', 'NNP')\n",
      "('similarity', 'NN')\n",
      "('Sentiment', 'NNP')\n",
      "('analysis', 'NN')\n",
      "('Terminology', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Text', 'NNP')\n",
      "('mining', 'NN')\n",
      "('Textual', 'NNP')\n",
      "('entailment', 'NN')\n",
      "('Truecasing', 'VBG')\n",
      "('Word-sense', 'JJ')\n",
      "('disambiguation', 'NN')\n",
      "('Word-sense', 'NNP')\n",
      "('induction', 'NN')\n",
      "('Text', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Compound-term', 'NNP')\n",
      "('processing', 'NN')\n",
      "('Lemmatisation', 'NNP')\n",
      "('Lexical', 'NNP')\n",
      "('analysis', 'NN')\n",
      "('Text', 'NNP')\n",
      "('chunking', 'VBG')\n",
      "('Stemming', 'VBG')\n",
      "('Sentence', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Word', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Automatic', 'NNP')\n",
      "('summarization', 'NN')\n",
      "('Multi-document', 'NNP')\n",
      "('summarization', 'NN')\n",
      "('Sentence', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Text', 'NNP')\n",
      "('simplification', 'NN')\n",
      "('Machine', 'NNP')\n",
      "('translation', 'NN')\n",
      "('Computer-assisted', 'JJ')\n",
      "('Example-based', 'JJ')\n",
      "('Rule-based', 'JJ')\n",
      "('Statistical', 'NNP')\n",
      "('Transfer-based', 'JJ')\n",
      "('Neural', 'NNP')\n",
      "('Distributional', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('models', 'NNS')\n",
      "('BERT', 'NNP')\n",
      "('Document-term', 'NNP')\n",
      "('matrix', 'NN')\n",
      "('Explicit', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('fastText', 'JJ')\n",
      "('GloVe', 'NNP')\n",
      "('Latent', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('Word', 'NNP')\n",
      "('embedding', 'VBG')\n",
      "('Word2vec', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('resources', 'NNS')\n",
      "(',', ',')\n",
      "('datasets', 'NNS')\n",
      "('and', 'CC')\n",
      "('corpora', 'NNS')\n",
      "('Types', 'NNP')\n",
      "('and', 'CC')\n",
      "('standards', 'NNS')\n",
      "('Corpus', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('Lexical', 'NNP')\n",
      "('resource', 'NN')\n",
      "('Linguistic', 'NNP')\n",
      "('Linked', 'NNP')\n",
      "('Open', 'NNP')\n",
      "('Data', 'NNP')\n",
      "('Machine-readable', 'NNP')\n",
      "('dictionary', 'JJ')\n",
      "('Parallel', 'NNP')\n",
      "('text', 'NN')\n",
      "('PropBank', 'NNP')\n",
      "('Semantic', 'NNP')\n",
      "('network', 'NN')\n",
      "('Simple', 'NNP')\n",
      "('Knowledge', 'NNP')\n",
      "('Organization', 'NNP')\n",
      "('System', 'NNP')\n",
      "('Speech', 'NNP')\n",
      "('corpus', 'NN')\n",
      "('Text', 'NNP')\n",
      "('corpus', 'NN')\n",
      "('Thesaurus', 'NNP')\n",
      "('(', '(')\n",
      "('information', 'NN')\n",
      "('retrieval', 'NN')\n",
      "(')', ')')\n",
      "('Treebank', 'NNP')\n",
      "('Universal', 'NNP')\n",
      "('Dependencies', 'NNP')\n",
      "('Data', 'NNP')\n",
      "('BabelNet', 'NNP')\n",
      "('Bank', 'NNP')\n",
      "('of', 'IN')\n",
      "('English', 'NNP')\n",
      "('DBpedia', 'NNP')\n",
      "('FrameNet', 'NNP')\n",
      "('Google', 'NNP')\n",
      "('Ngram', 'NNP')\n",
      "('Viewer', 'NNP')\n",
      "('ThoughtTreasure', 'NNP')\n",
      "('UBY', 'NNP')\n",
      "('WordNet', 'NNP')\n",
      "('Automatic', 'NNP')\n",
      "('identification', 'NN')\n",
      "('and', 'CC')\n",
      "('data', 'NNS')\n",
      "('capture', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('recognition', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('synthesis', 'NN')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('Optical', 'NNP')\n",
      "('character', 'NN')\n",
      "('recognition', 'NN')\n",
      "('Topic', 'NNP')\n",
      "('model', 'NN')\n",
      "('Document', 'NNP')\n",
      "('classification', 'NN')\n",
      "('Latent', 'NNP')\n",
      "('Dirichlet', 'NNP')\n",
      "('allocation', 'NN')\n",
      "('Pachinko', 'NNP')\n",
      "('allocation', 'NN')\n",
      "('Computer-assisted', 'NNP')\n",
      "('reviewing', 'NN')\n",
      "('Automated', 'NNP')\n",
      "('essay', 'VBP')\n",
      "('scoring', 'VBG')\n",
      "('Concordancer', 'NNP')\n",
      "('Grammar', 'NNP')\n",
      "('checker', 'NN')\n",
      "('Predictive', 'NNP')\n",
      "('text', 'NN')\n",
      "('Spell', 'NNP')\n",
      "('checker', 'NN')\n",
      "('Syntax', 'NNP')\n",
      "('guessing', 'VBG')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('user', 'NN')\n",
      "('interface', 'NN')\n",
      "('Chatbot', 'NNP')\n",
      "('Interactive', 'NNP')\n",
      "('fiction', 'NN')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "('Virtual', 'NNP')\n",
      "('assistant', 'NN')\n",
      "('Voice', 'NNP')\n",
      "('user', 'RB')\n",
      "('interface', 'VBZ')\n",
      "('Other', 'JJ')\n",
      "('software', 'NN')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Toolkit', 'NNP')\n",
      "('spaCy', 'JJ')\n",
      "('Authority', 'NNP')\n",
      "('control', 'NN')\n",
      "(':', ':')\n",
      "('National', 'NNP')\n",
      "('libraries', 'NNS')\n",
      "('United', 'NNP')\n",
      "('States', 'NNPS')\n",
      "('Japan', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('portal', 'JJ')\n",
      "('Retrieved', 'VBD')\n",
      "('from', 'IN')\n",
      "('``', '``')\n",
      "('https', 'NN')\n",
      "(':', ':')\n",
      "('//en.wikipedia.org/w/index.php', 'NN')\n",
      "('?', '.')\n",
      "('title=Natural_language_processing', 'VBG')\n",
      "('&', 'CC')\n",
      "('oldid=1048621730', 'IN')\n",
      "('``', '``')\n",
      "('Categories', 'NNS')\n",
      "(':', ':')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('Computational', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('Speech', 'NNP')\n",
      "('recognition', 'NN')\n",
      "('Computational', 'NNP')\n",
      "('fields', 'NNS')\n",
      "('of', 'IN')\n",
      "('study', 'NN')\n",
      "('Artificial', 'NNP')\n",
      "('intelligence', 'NN')\n",
      "('Hidden', 'NNP')\n",
      "('categories', 'NNS')\n",
      "(':', ':')\n",
      "('CS1', 'NNP')\n",
      "('maint', 'NN')\n",
      "(':', ':')\n",
      "('location', 'NN')\n",
      "('Articles', 'NNS')\n",
      "('with', 'IN')\n",
      "('short', 'JJ')\n",
      "('description', 'NN')\n",
      "('Short', 'NNP')\n",
      "('description', 'NN')\n",
      "('matches', 'NNS')\n",
      "('Wikidata', 'NNP')\n",
      "('Commons', 'NNP')\n",
      "('category', 'NN')\n",
      "('link', 'NN')\n",
      "('from', 'IN')\n",
      "('Wikidata', 'NNP')\n",
      "('Articles', 'NNP')\n",
      "('with', 'IN')\n",
      "('LCCN', 'NNP')\n",
      "('identifiers', 'NNS')\n",
      "('Articles', 'NNP')\n",
      "('with', 'IN')\n",
      "('NDL', 'NNP')\n",
      "('identifiers', 'NNS')\n",
      "('Navigation', 'NNP')\n",
      "('menu', 'VBD')\n",
      "('Personal', 'NNP')\n",
      "('tools', 'NNS')\n",
      "('Not', 'RB')\n",
      "('logged', 'VBN')\n",
      "('in', 'IN')\n",
      "('Talk', 'NNP')\n",
      "('Contributions', 'NNP')\n",
      "('Create', 'NNP')\n",
      "('account', 'NN')\n",
      "('Log', 'NNP')\n",
      "('in', 'IN')\n",
      "('Namespaces', 'NNP')\n",
      "('Article', 'NNP')\n",
      "('Talk', 'NNP')\n",
      "('Variants', 'NNP')\n",
      "('expanded', 'VBD')\n",
      "('collapsed', 'JJ')\n",
      "('Views', 'NNP')\n",
      "('Read', 'NNP')\n",
      "('Edit', 'NNP')\n",
      "('View', 'NNP')\n",
      "('history', 'NN')\n",
      "('More', 'NNP')\n",
      "('expanded', 'VBD')\n",
      "('collapsed', 'VBN')\n",
      "('Search', 'NNP')\n",
      "('Navigation', 'NNP')\n",
      "('Main', 'NNP')\n",
      "('page', 'NN')\n",
      "('Contents', 'NNP')\n",
      "('Current', 'NNP')\n",
      "('events', 'NNS')\n",
      "('Random', 'NNP')\n",
      "('article', 'NN')\n",
      "('About', 'IN')\n",
      "('Wikipedia', 'NNP')\n",
      "('Contact', 'NNP')\n",
      "('us', 'PRP')\n",
      "('Donate', 'NNP')\n",
      "('Contribute', 'NNP')\n",
      "('Help', 'NNP')\n",
      "('Learn', 'NNP')\n",
      "('to', 'TO')\n",
      "('edit', 'VB')\n",
      "('Community', 'NNP')\n",
      "('portal', 'JJ')\n",
      "('Recent', 'NNP')\n",
      "('changes', 'NNS')\n",
      "('Upload', 'NNP')\n",
      "('file', 'NN')\n",
      "('Tools', 'NNP')\n",
      "('What', 'WP')\n",
      "('links', 'VBZ')\n",
      "('here', 'RB')\n",
      "('Related', 'VBN')\n",
      "('changes', 'NNS')\n",
      "('Upload', 'NNP')\n",
      "('file', 'NN')\n",
      "('Special', 'NNP')\n",
      "('pages', 'NNS')\n",
      "('Permanent', 'NNP')\n",
      "('link', 'NN')\n",
      "('Page', 'NNP')\n",
      "('information', 'NN')\n",
      "('Cite', 'NNP')\n",
      "('this', 'DT')\n",
      "('page', 'NN')\n",
      "('Wikidata', 'NNP')\n",
      "('item', 'NN')\n",
      "('Print/export', 'NNP')\n",
      "('Download', 'NNP')\n",
      "('as', 'IN')\n",
      "('PDF', 'NNP')\n",
      "('Printable', 'NNP')\n",
      "('version', 'NN')\n",
      "('In', 'IN')\n",
      "('other', 'JJ')\n",
      "('projects', 'NNS')\n",
      "('Wikimedia', 'NNP')\n",
      "('Commons', 'NNP')\n",
      "('Languages', 'NNP')\n",
      "('Afrikaans', 'NNP')\n",
      "('العربية', 'NNP')\n",
      "('Azərbaycanca', 'NNP')\n",
      "('বাংলা', 'NNP')\n",
      "('Bân-lâm-gú', 'NNP')\n",
      "('Беларуская', 'NNP')\n",
      "('Беларуская', 'NNP')\n",
      "('(', '(')\n",
      "('тарашкевіца', 'NNP')\n",
      "(')', ')')\n",
      "('Български', 'VBP')\n",
      "('Català', 'NNP')\n",
      "('Čeština', 'NNP')\n",
      "('Dansk', 'NNP')\n",
      "('Deutsch', 'NNP')\n",
      "('Eesti', 'NNP')\n",
      "('Ελληνικά', 'NNP')\n",
      "('Español', 'NNP')\n",
      "('Euskara', 'NNP')\n",
      "('فارسی', 'NNP')\n",
      "('Français', 'NNP')\n",
      "('Galego', 'NNP')\n",
      "('한국어', 'NNP')\n",
      "('Հայերեն', 'NNP')\n",
      "('हिन्दी', 'NNP')\n",
      "('Hrvatski', 'NNP')\n",
      "('Bahasa', 'NNP')\n",
      "('Indonesia', 'NNP')\n",
      "('Íslenska', 'NNP')\n",
      "('Italiano', 'NNP')\n",
      "('עברית', 'NNP')\n",
      "('ಕನ್ನಡ', 'NNP')\n",
      "('ქართული', 'NNP')\n",
      "('Lietuvių', 'NNP')\n",
      "('Македонски', 'NNP')\n",
      "('मराठी', 'NNP')\n",
      "('مصرى', 'NNP')\n",
      "('Монгол', 'NNP')\n",
      "('မြန်မာဘာသာ', 'NNP')\n",
      "('日本語', 'NNP')\n",
      "('ଓଡ଼ିଆ', 'NNP')\n",
      "('Piemontèis', 'NNP')\n",
      "('Polski', 'NNP')\n",
      "('Português', 'NNP')\n",
      "('Română', 'NNP')\n",
      "('Русский', 'NNP')\n",
      "('Simple', 'NNP')\n",
      "('English', 'NNP')\n",
      "('کوردی', 'NNP')\n",
      "('Српски', 'NNP')\n",
      "('/', 'NNP')\n",
      "('srpski', 'VBD')\n",
      "('Srpskohrvatski', 'NNP')\n",
      "('/', 'NNP')\n",
      "('српскохрватски', 'NNP')\n",
      "('Suomi', 'NNP')\n",
      "('தமிழ்', 'NNP')\n",
      "('ไทย', 'NNP')\n",
      "('Türkçe', 'NNP')\n",
      "('Українська', 'NNP')\n",
      "('Tiếng', 'NNP')\n",
      "('Việt', 'NNP')\n",
      "('粵語', 'NNP')\n",
      "('中文', 'NNP')\n",
      "('Edit', 'NNP')\n",
      "('links', 'VBZ')\n",
      "('This', 'DT')\n",
      "('page', 'NN')\n",
      "('was', 'VBD')\n",
      "('last', 'JJ')\n",
      "('edited', 'VBN')\n",
      "('on', 'IN')\n",
      "('7', 'CD')\n",
      "('October', 'NNP')\n",
      "('2021', 'CD')\n",
      "(',', ',')\n",
      "('at', 'IN')\n",
      "('01:56', 'CD')\n",
      "('(', '(')\n",
      "('UTC', 'NNP')\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Text', 'NN')\n",
      "('is', 'VBZ')\n",
      "('available', 'JJ')\n",
      "('under', 'IN')\n",
      "('the', 'DT')\n",
      "('Creative', 'JJ')\n",
      "('Commons', 'NNP')\n",
      "('Attribution-ShareAlike', 'NNP')\n",
      "('License', 'NNP')\n",
      "(';', ':')\n",
      "('additional', 'JJ')\n",
      "('terms', 'NNS')\n",
      "('may', 'MD')\n",
      "('apply', 'VB')\n",
      "('.', '.')\n",
      "('By', 'IN')\n",
      "('using', 'VBG')\n",
      "('this', 'DT')\n",
      "('site', 'NN')\n",
      "(',', ',')\n",
      "('you', 'PRP')\n",
      "('agree', 'VBP')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('Terms', 'NNS')\n",
      "('of', 'IN')\n",
      "('Use', 'NNP')\n",
      "('and', 'CC')\n",
      "('Privacy', 'NNP')\n",
      "('Policy', 'NNP')\n",
      "('.', '.')\n",
      "('Wikipedia®', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('registered', 'JJ')\n",
      "('trademark', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('Wikimedia', 'NNP')\n",
      "('Foundation', 'NNP')\n",
      "(',', ',')\n",
      "('Inc.', 'NNP')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('non-profit', 'JJ')\n",
      "('organization', 'NN')\n",
      "('.', '.')\n",
      "('Privacy', 'NN')\n",
      "('policy', 'NN')\n",
      "('About', 'IN')\n",
      "('Wikipedia', 'NNP')\n",
      "('Disclaimers', 'NNP')\n",
      "('Contact', 'NNP')\n",
      "('Wikipedia', 'NNP')\n",
      "('Mobile', 'NNP')\n",
      "('view', 'NN')\n",
      "('Developers', 'NNP')\n",
      "('Statistics', 'NNPS')\n",
      "('Cookie', 'NNP')\n",
      "('statement', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# called the pos_tagging() to apply the parts of speech to each word and get the result.\n",
    "pos_tagged = pos_tagging(words)\n",
    "for i in pos_tagged:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0c2a4792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natur\n",
      "languag\n",
      "process\n",
      "-\n",
      "wikipedia\n",
      "natur\n",
      "languag\n",
      "process\n",
      "from\n",
      "wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "jump\n",
      "to\n",
      "navig\n",
      "jump\n",
      "to\n",
      "search\n",
      "thi\n",
      "articl\n",
      "is\n",
      "about\n",
      "natur\n",
      "languag\n",
      "process\n",
      "done\n",
      "by\n",
      "comput\n",
      ".\n",
      "for\n",
      "the\n",
      "natur\n",
      "languag\n",
      "process\n",
      "done\n",
      "by\n",
      "the\n",
      "human\n",
      "brain\n",
      ",\n",
      "see\n",
      "languag\n",
      "process\n",
      "in\n",
      "the\n",
      "brain\n",
      ".\n",
      "field\n",
      "of\n",
      "comput\n",
      "scienc\n",
      "and\n",
      "linguist\n",
      "an\n",
      "autom\n",
      "onlin\n",
      "assist\n",
      "provid\n",
      "custom\n",
      "servic\n",
      "on\n",
      "a\n",
      "web\n",
      "page\n",
      ",\n",
      "an\n",
      "exampl\n",
      "of\n",
      "an\n",
      "applic\n",
      "where\n",
      "natur\n",
      "languag\n",
      "process\n",
      "is\n",
      "a\n",
      "major\n",
      "compon\n",
      ".\n",
      "[\n",
      "1\n",
      "]\n",
      "natur\n",
      "languag\n",
      "process\n",
      "(\n",
      "nlp\n",
      ")\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "linguist\n",
      ",\n",
      "comput\n",
      "scienc\n",
      ",\n",
      "and\n",
      "artifici\n",
      "intellig\n",
      "concern\n",
      "with\n",
      "the\n",
      "interact\n",
      "between\n",
      "comput\n",
      "and\n",
      "human\n",
      "languag\n",
      ",\n",
      "in\n",
      "particular\n",
      "how\n",
      "to\n",
      "program\n",
      "comput\n",
      "to\n",
      "process\n",
      "and\n",
      "analyz\n",
      "larg\n",
      "amount\n",
      "of\n",
      "natur\n",
      "languag\n",
      "data\n",
      ".\n",
      "the\n",
      "goal\n",
      "is\n",
      "a\n",
      "comput\n",
      "capabl\n",
      "of\n",
      "``\n",
      "understand\n",
      "''\n",
      "the\n",
      "content\n",
      "of\n",
      "document\n",
      ",\n",
      "includ\n",
      "the\n",
      "contextu\n",
      "nuanc\n",
      "of\n",
      "the\n",
      "languag\n",
      "within\n",
      "them\n",
      ".\n",
      "the\n",
      "technolog\n",
      "can\n",
      "then\n",
      "accur\n",
      "extract\n",
      "inform\n",
      "and\n",
      "insight\n",
      "contain\n",
      "in\n",
      "the\n",
      "document\n",
      "as\n",
      "well\n",
      "as\n",
      "categor\n",
      "and\n",
      "organ\n",
      "the\n",
      "document\n",
      "themselv\n",
      ".\n",
      "challeng\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "frequent\n",
      "involv\n",
      "speech\n",
      "recognit\n",
      ",\n",
      "natur\n",
      "languag\n",
      "understand\n",
      ",\n",
      "and\n",
      "natur\n",
      "languag\n",
      "gener\n",
      ".\n",
      "content\n",
      "1\n",
      "histori\n",
      "1.1\n",
      "symbol\n",
      "nlp\n",
      "(\n",
      "1950\n",
      "–\n",
      "earli\n",
      "1990\n",
      ")\n",
      "1.2\n",
      "statist\n",
      "nlp\n",
      "(\n",
      "1990s–2010\n",
      ")\n",
      "1.3\n",
      "neural\n",
      "nlp\n",
      "(\n",
      "present\n",
      ")\n",
      "2\n",
      "method\n",
      ":\n",
      "rule\n",
      ",\n",
      "statist\n",
      ",\n",
      "neural\n",
      "network\n",
      "2.1\n",
      "statist\n",
      "method\n",
      "2.2\n",
      "neural\n",
      "network\n",
      "3\n",
      "common\n",
      "nlp\n",
      "task\n",
      "3.1\n",
      "text\n",
      "and\n",
      "speech\n",
      "process\n",
      "3.2\n",
      "morpholog\n",
      "analysi\n",
      "3.3\n",
      "syntact\n",
      "analysi\n",
      "3.4\n",
      "lexic\n",
      "semant\n",
      "(\n",
      "of\n",
      "individu\n",
      "word\n",
      "in\n",
      "context\n",
      ")\n",
      "3.5\n",
      "relat\n",
      "semant\n",
      "(\n",
      "semant\n",
      "of\n",
      "individu\n",
      "sentenc\n",
      ")\n",
      "3.6\n",
      "discours\n",
      "(\n",
      "semant\n",
      "beyond\n",
      "individu\n",
      "sentenc\n",
      ")\n",
      "3.7\n",
      "higher-level\n",
      "nlp\n",
      "applic\n",
      "4\n",
      "gener\n",
      "tendenc\n",
      "and\n",
      "(\n",
      "possibl\n",
      ")\n",
      "futur\n",
      "direct\n",
      "4.1\n",
      "cognit\n",
      "and\n",
      "nlp\n",
      "5\n",
      "see\n",
      "also\n",
      "6\n",
      "refer\n",
      "7\n",
      "further\n",
      "read\n",
      "8\n",
      "extern\n",
      "link\n",
      "histori\n",
      "[\n",
      "edit\n",
      "]\n",
      "further\n",
      "inform\n",
      ":\n",
      "histori\n",
      "of\n",
      "natur\n",
      "languag\n",
      "process\n",
      "natur\n",
      "languag\n",
      "process\n",
      "ha\n",
      "it\n",
      "root\n",
      "in\n",
      "the\n",
      "1950\n",
      ".\n",
      "alreadi\n",
      "in\n",
      "1950\n",
      ",\n",
      "alan\n",
      "ture\n",
      "publish\n",
      "an\n",
      "articl\n",
      "titl\n",
      "``\n",
      "comput\n",
      "machineri\n",
      "and\n",
      "intellig\n",
      "``\n",
      "which\n",
      "propos\n",
      "what\n",
      "is\n",
      "now\n",
      "call\n",
      "the\n",
      "ture\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intellig\n",
      ",\n",
      "a\n",
      "task\n",
      "that\n",
      "involv\n",
      "the\n",
      "autom\n",
      "interpret\n",
      "and\n",
      "gener\n",
      "of\n",
      "natur\n",
      "languag\n",
      ",\n",
      "but\n",
      "at\n",
      "the\n",
      "time\n",
      "not\n",
      "articul\n",
      "as\n",
      "a\n",
      "problem\n",
      "separ\n",
      "from\n",
      "artifici\n",
      "intellig\n",
      ".\n",
      "symbol\n",
      "nlp\n",
      "(\n",
      "1950\n",
      "–\n",
      "earli\n",
      "1990\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "the\n",
      "premis\n",
      "of\n",
      "symbol\n",
      "nlp\n",
      "is\n",
      "well-summar\n",
      "by\n",
      "john\n",
      "searl\n",
      "'s\n",
      "chines\n",
      "room\n",
      "experi\n",
      ":\n",
      "given\n",
      "a\n",
      "collect\n",
      "of\n",
      "rule\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "a\n",
      "chines\n",
      "phrasebook\n",
      ",\n",
      "with\n",
      "question\n",
      "and\n",
      "match\n",
      "answer\n",
      ")\n",
      ",\n",
      "the\n",
      "comput\n",
      "emul\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "(\n",
      "or\n",
      "other\n",
      "nlp\n",
      "task\n",
      ")\n",
      "by\n",
      "appli\n",
      "those\n",
      "rule\n",
      "to\n",
      "the\n",
      "data\n",
      "it\n",
      "is\n",
      "confront\n",
      "with\n",
      ".\n",
      "1950\n",
      ":\n",
      "the\n",
      "georgetown\n",
      "experi\n",
      "in\n",
      "1954\n",
      "involv\n",
      "fulli\n",
      "automat\n",
      "translat\n",
      "of\n",
      "more\n",
      "than\n",
      "sixti\n",
      "russian\n",
      "sentenc\n",
      "into\n",
      "english\n",
      ".\n",
      "the\n",
      "author\n",
      "claim\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "year\n",
      ",\n",
      "machin\n",
      "translat\n",
      "would\n",
      "be\n",
      "a\n",
      "solv\n",
      "problem\n",
      ".\n",
      "[\n",
      "2\n",
      "]\n",
      "howev\n",
      ",\n",
      "real\n",
      "progress\n",
      "wa\n",
      "much\n",
      "slower\n",
      ",\n",
      "and\n",
      "after\n",
      "the\n",
      "alpac\n",
      "report\n",
      "in\n",
      "1966\n",
      ",\n",
      "which\n",
      "found\n",
      "that\n",
      "ten-year-long\n",
      "research\n",
      "had\n",
      "fail\n",
      "to\n",
      "fulfil\n",
      "the\n",
      "expect\n",
      ",\n",
      "fund\n",
      "for\n",
      "machin\n",
      "translat\n",
      "wa\n",
      "dramat\n",
      "reduc\n",
      ".\n",
      "littl\n",
      "further\n",
      "research\n",
      "in\n",
      "machin\n",
      "translat\n",
      "wa\n",
      "conduct\n",
      "until\n",
      "the\n",
      "late\n",
      "1980\n",
      "when\n",
      "the\n",
      "first\n",
      "statist\n",
      "machin\n",
      "translat\n",
      "system\n",
      "were\n",
      "develop\n",
      ".\n",
      "1960\n",
      ":\n",
      "some\n",
      "notabl\n",
      "success\n",
      "natur\n",
      "languag\n",
      "process\n",
      "system\n",
      "develop\n",
      "in\n",
      "the\n",
      "1960\n",
      "were\n",
      "shrdlu\n",
      ",\n",
      "a\n",
      "natur\n",
      "languag\n",
      "system\n",
      "work\n",
      "in\n",
      "restrict\n",
      "``\n",
      "block\n",
      "world\n",
      "``\n",
      "with\n",
      "restrict\n",
      "vocabulari\n",
      ",\n",
      "and\n",
      "eliza\n",
      ",\n",
      "a\n",
      "simul\n",
      "of\n",
      "a\n",
      "rogerian\n",
      "psychotherapist\n",
      ",\n",
      "written\n",
      "by\n",
      "joseph\n",
      "weizenbaum\n",
      "between\n",
      "1964\n",
      "and\n",
      "1966\n",
      ".\n",
      "use\n",
      "almost\n",
      "no\n",
      "inform\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emot\n",
      ",\n",
      "eliza\n",
      "sometim\n",
      "provid\n",
      "a\n",
      "startlingli\n",
      "human-lik\n",
      "interact\n",
      ".\n",
      "when\n",
      "the\n",
      "``\n",
      "patient\n",
      "''\n",
      "exceed\n",
      "the\n",
      "veri\n",
      "small\n",
      "knowledg\n",
      "base\n",
      ",\n",
      "eliza\n",
      "might\n",
      "provid\n",
      "a\n",
      "gener\n",
      "respons\n",
      ",\n",
      "for\n",
      "exampl\n",
      ",\n",
      "respond\n",
      "to\n",
      "``\n",
      "my\n",
      "head\n",
      "hurt\n",
      "''\n",
      "with\n",
      "``\n",
      "whi\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurt\n",
      "?\n",
      "''\n",
      ".\n",
      "1970\n",
      ":\n",
      "dure\n",
      "the\n",
      "1970\n",
      ",\n",
      "mani\n",
      "programm\n",
      "began\n",
      "to\n",
      "write\n",
      "``\n",
      "conceptu\n",
      "ontolog\n",
      "``\n",
      ",\n",
      "which\n",
      "structur\n",
      "real-world\n",
      "inform\n",
      "into\n",
      "computer-understand\n",
      "data\n",
      ".\n",
      "exampl\n",
      "are\n",
      "margi\n",
      "(\n",
      "schank\n",
      ",\n",
      "1975\n",
      ")\n",
      ",\n",
      "sam\n",
      "(\n",
      "cullingford\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "pam\n",
      "(\n",
      "wilenski\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "talespin\n",
      "(\n",
      "meehan\n",
      ",\n",
      "1976\n",
      ")\n",
      ",\n",
      "qualm\n",
      "(\n",
      "lehnert\n",
      ",\n",
      "1977\n",
      ")\n",
      ",\n",
      "polit\n",
      "(\n",
      "carbonel\n",
      ",\n",
      "1979\n",
      ")\n",
      ",\n",
      "and\n",
      "plot\n",
      "unit\n",
      "(\n",
      "lehnert\n",
      "1981\n",
      ")\n",
      ".\n",
      "dure\n",
      "thi\n",
      "time\n",
      ",\n",
      "the\n",
      "first\n",
      "mani\n",
      "chatterbot\n",
      "were\n",
      "written\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "parri\n",
      ")\n",
      ".\n",
      "1980\n",
      ":\n",
      "the\n",
      "1980\n",
      "and\n",
      "earli\n",
      "1990\n",
      "mark\n",
      "the\n",
      "hey-day\n",
      "of\n",
      "symbol\n",
      "method\n",
      "in\n",
      "nlp\n",
      ".\n",
      "focu\n",
      "area\n",
      "of\n",
      "the\n",
      "time\n",
      "includ\n",
      "research\n",
      "on\n",
      "rule-bas\n",
      "pars\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "develop\n",
      "of\n",
      "hpsg\n",
      "as\n",
      "a\n",
      "comput\n",
      "operation\n",
      "of\n",
      "gener\n",
      "grammar\n",
      ")\n",
      ",\n",
      "morpholog\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "two-level\n",
      "morpholog\n",
      "[\n",
      "3\n",
      "]\n",
      ")\n",
      ",\n",
      "semant\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "lesk\n",
      "algorithm\n",
      ")\n",
      ",\n",
      "refer\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "within\n",
      "center\n",
      "theori\n",
      "[\n",
      "4\n",
      "]\n",
      ")\n",
      "and\n",
      "other\n",
      "area\n",
      "of\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "the\n",
      "rhetor\n",
      "structur\n",
      "theori\n",
      ")\n",
      ".\n",
      "other\n",
      "line\n",
      "of\n",
      "research\n",
      "were\n",
      "continu\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "develop\n",
      "of\n",
      "chatterbot\n",
      "with\n",
      "racter\n",
      "and\n",
      "jabberwacki\n",
      ".\n",
      "an\n",
      "import\n",
      "develop\n",
      "(\n",
      "that\n",
      "eventu\n",
      "led\n",
      "to\n",
      "the\n",
      "statist\n",
      "turn\n",
      "in\n",
      "the\n",
      "1990\n",
      ")\n",
      "wa\n",
      "the\n",
      "rise\n",
      "import\n",
      "of\n",
      "quantit\n",
      "evalu\n",
      "in\n",
      "thi\n",
      "period\n",
      ".\n",
      "[\n",
      "5\n",
      "]\n",
      "statist\n",
      "nlp\n",
      "(\n",
      "1990s–2010\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "up\n",
      "to\n",
      "the\n",
      "1980\n",
      ",\n",
      "most\n",
      "natur\n",
      "languag\n",
      "process\n",
      "system\n",
      "were\n",
      "base\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "start\n",
      "in\n",
      "the\n",
      "late\n",
      "1980\n",
      ",\n",
      "howev\n",
      ",\n",
      "there\n",
      "wa\n",
      "a\n",
      "revolut\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "with\n",
      "the\n",
      "introduct\n",
      "of\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "for\n",
      "languag\n",
      "process\n",
      ".\n",
      "thi\n",
      "wa\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steadi\n",
      "increas\n",
      "in\n",
      "comput\n",
      "power\n",
      "(\n",
      "see\n",
      "moor\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessen\n",
      "of\n",
      "the\n",
      "domin\n",
      "of\n",
      "chomskyan\n",
      "theori\n",
      "of\n",
      "linguist\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transform\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoret\n",
      "underpin\n",
      "discourag\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpu\n",
      "linguist\n",
      "that\n",
      "underli\n",
      "the\n",
      "machine-learn\n",
      "approach\n",
      "to\n",
      "languag\n",
      "process\n",
      ".\n",
      "[\n",
      "6\n",
      "]\n",
      "1990\n",
      ":\n",
      "mani\n",
      "of\n",
      "the\n",
      "notabl\n",
      "earli\n",
      "success\n",
      "on\n",
      "statist\n",
      "method\n",
      "in\n",
      "nlp\n",
      "occur\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machin\n",
      "translat\n",
      ",\n",
      "due\n",
      "especi\n",
      "to\n",
      "work\n",
      "at\n",
      "ibm\n",
      "research\n",
      ".\n",
      "these\n",
      "system\n",
      "were\n",
      "abl\n",
      "to\n",
      "take\n",
      "advantag\n",
      "of\n",
      "exist\n",
      "multilingu\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produc\n",
      "by\n",
      "the\n",
      "parliament\n",
      "of\n",
      "canada\n",
      "and\n",
      "the\n",
      "european\n",
      "union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "law\n",
      "call\n",
      "for\n",
      "the\n",
      "translat\n",
      "of\n",
      "all\n",
      "government\n",
      "proceed\n",
      "into\n",
      "all\n",
      "offici\n",
      "languag\n",
      "of\n",
      "the\n",
      "correspond\n",
      "system\n",
      "of\n",
      "govern\n",
      ".\n",
      "howev\n",
      ",\n",
      "most\n",
      "other\n",
      "system\n",
      "depend\n",
      "on\n",
      "corpora\n",
      "specif\n",
      "develop\n",
      "for\n",
      "the\n",
      "task\n",
      "implement\n",
      "by\n",
      "these\n",
      "system\n",
      ",\n",
      "which\n",
      "wa\n",
      "(\n",
      "and\n",
      "often\n",
      "continu\n",
      "to\n",
      "be\n",
      ")\n",
      "a\n",
      "major\n",
      "limit\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "system\n",
      ".\n",
      "as\n",
      "a\n",
      "result\n",
      ",\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "ha\n",
      "gone\n",
      "into\n",
      "method\n",
      "of\n",
      "more\n",
      "effect\n",
      "learn\n",
      "from\n",
      "limit\n",
      "amount\n",
      "of\n",
      "data\n",
      ".\n",
      "2000\n",
      ":\n",
      "with\n",
      "the\n",
      "growth\n",
      "of\n",
      "the\n",
      "web\n",
      ",\n",
      "increas\n",
      "amount\n",
      "of\n",
      "raw\n",
      "(\n",
      "unannot\n",
      ")\n",
      "languag\n",
      "data\n",
      "ha\n",
      "becom\n",
      "avail\n",
      "sinc\n",
      "the\n",
      "mid-1990\n",
      ".\n",
      "research\n",
      "ha\n",
      "thu\n",
      "increasingli\n",
      "focus\n",
      "on\n",
      "unsupervis\n",
      "and\n",
      "semi-supervis\n",
      "learn\n",
      "algorithm\n",
      ".\n",
      "such\n",
      "algorithm\n",
      "can\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "ha\n",
      "not\n",
      "been\n",
      "hand-annot\n",
      "with\n",
      "the\n",
      "desir\n",
      "answer\n",
      "or\n",
      "use\n",
      "a\n",
      "combin\n",
      "of\n",
      "annot\n",
      "and\n",
      "non-annot\n",
      "data\n",
      ".\n",
      "gener\n",
      ",\n",
      "thi\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervis\n",
      "learn\n",
      ",\n",
      "and\n",
      "typic\n",
      "produc\n",
      "less\n",
      "accur\n",
      "result\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      ".\n",
      "howev\n",
      ",\n",
      "there\n",
      "is\n",
      "an\n",
      "enorm\n",
      "amount\n",
      "of\n",
      "non-annot\n",
      "data\n",
      "avail\n",
      "(\n",
      "includ\n",
      ",\n",
      "among\n",
      "other\n",
      "thing\n",
      ",\n",
      "the\n",
      "entir\n",
      "content\n",
      "of\n",
      "the\n",
      "world\n",
      "wide\n",
      "web\n",
      ")\n",
      ",\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "result\n",
      "if\n",
      "the\n",
      "algorithm\n",
      "use\n",
      "ha\n",
      "a\n",
      "low\n",
      "enough\n",
      "time\n",
      "complex\n",
      "to\n",
      "be\n",
      "practic\n",
      ".\n",
      "neural\n",
      "nlp\n",
      "(\n",
      "present\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "in\n",
      "the\n",
      "2010\n",
      ",\n",
      "represent\n",
      "learn\n",
      "and\n",
      "deep\n",
      "neural\n",
      "network\n",
      "-style\n",
      "machin\n",
      "learn\n",
      "method\n",
      "becam\n",
      "widespread\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      ",\n",
      "due\n",
      "in\n",
      "part\n",
      "to\n",
      "a\n",
      "flurri\n",
      "of\n",
      "result\n",
      "show\n",
      "that\n",
      "such\n",
      "techniqu\n",
      "[\n",
      "7\n",
      "]\n",
      "[\n",
      "8\n",
      "]\n",
      "can\n",
      "achiev\n",
      "state-of-the-art\n",
      "result\n",
      "in\n",
      "mani\n",
      "natur\n",
      "languag\n",
      "task\n",
      ",\n",
      "for\n",
      "exampl\n",
      "in\n",
      "languag\n",
      "model\n",
      ",\n",
      "[\n",
      "9\n",
      "]\n",
      "pars\n",
      ",\n",
      "[\n",
      "10\n",
      "]\n",
      "[\n",
      "11\n",
      "]\n",
      "and\n",
      "mani\n",
      "other\n",
      ".\n",
      "thi\n",
      "is\n",
      "increasingli\n",
      "import\n",
      "in\n",
      "medicin\n",
      "and\n",
      "healthcar\n",
      ",\n",
      "where\n",
      "nlp\n",
      "is\n",
      "be\n",
      "use\n",
      "to\n",
      "analyz\n",
      "note\n",
      "and\n",
      "text\n",
      "in\n",
      "electron\n",
      "health\n",
      "record\n",
      "that\n",
      "would\n",
      "otherwis\n",
      "be\n",
      "inaccess\n",
      "for\n",
      "studi\n",
      "when\n",
      "seek\n",
      "to\n",
      "improv\n",
      "care\n",
      ".\n",
      "[\n",
      "12\n",
      "]\n",
      "method\n",
      ":\n",
      "rule\n",
      ",\n",
      "statist\n",
      ",\n",
      "neural\n",
      "network\n",
      "[\n",
      "edit\n",
      "]\n",
      "in\n",
      "the\n",
      "earli\n",
      "day\n",
      ",\n",
      "mani\n",
      "language-process\n",
      "system\n",
      "were\n",
      "design\n",
      "by\n",
      "symbol\n",
      "method\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "hand-cod\n",
      "of\n",
      "a\n",
      "set\n",
      "of\n",
      "rule\n",
      ",\n",
      "coupl\n",
      "with\n",
      "a\n",
      "dictionari\n",
      "lookup\n",
      ":\n",
      "[\n",
      "13\n",
      "]\n",
      "[\n",
      "14\n",
      "]\n",
      "such\n",
      "as\n",
      "by\n",
      "write\n",
      "grammar\n",
      "or\n",
      "devis\n",
      "heurist\n",
      "rule\n",
      "for\n",
      "stem\n",
      ".\n",
      "more\n",
      "recent\n",
      "system\n",
      "base\n",
      "on\n",
      "machine-learn\n",
      "algorithm\n",
      "have\n",
      "mani\n",
      "advantag\n",
      "over\n",
      "hand-produc\n",
      "rule\n",
      ":\n",
      "the\n",
      "learn\n",
      "procedur\n",
      "use\n",
      "dure\n",
      "machin\n",
      "learn\n",
      "automat\n",
      "focu\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "case\n",
      ",\n",
      "wherea\n",
      "when\n",
      "write\n",
      "rule\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "at\n",
      "all\n",
      "obviou\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "direct\n",
      ".\n",
      "automat\n",
      "learn\n",
      "procedur\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statist\n",
      "infer\n",
      "algorithm\n",
      "to\n",
      "produc\n",
      "model\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "contain\n",
      "word\n",
      "or\n",
      "structur\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "befor\n",
      ")\n",
      "and\n",
      "to\n",
      "erron\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "with\n",
      "misspel\n",
      "word\n",
      "or\n",
      "word\n",
      "accident\n",
      "omit\n",
      ")\n",
      ".\n",
      "gener\n",
      ",\n",
      "handl\n",
      "such\n",
      "input\n",
      "grace\n",
      "with\n",
      "handwritten\n",
      "rule\n",
      ",\n",
      "or\n",
      ",\n",
      "more\n",
      "gener\n",
      ",\n",
      "creat\n",
      "system\n",
      "of\n",
      "handwritten\n",
      "rule\n",
      "that\n",
      "make\n",
      "soft\n",
      "decis\n",
      ",\n",
      "is\n",
      "extrem\n",
      "difficult\n",
      ",\n",
      "error-pron\n",
      "and\n",
      "time-consum\n",
      ".\n",
      "system\n",
      "base\n",
      "on\n",
      "automat\n",
      "learn\n",
      "the\n",
      "rule\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accur\n",
      "simpli\n",
      "by\n",
      "suppli\n",
      "more\n",
      "input\n",
      "data\n",
      ".\n",
      "howev\n",
      ",\n",
      "system\n",
      "base\n",
      "on\n",
      "handwritten\n",
      "rule\n",
      "can\n",
      "onli\n",
      "be\n",
      "made\n",
      "more\n",
      "accur\n",
      "by\n",
      "increas\n",
      "the\n",
      "complex\n",
      "of\n",
      "the\n",
      "rule\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      ".\n",
      "in\n",
      "particular\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complex\n",
      "of\n",
      "system\n",
      "base\n",
      "on\n",
      "handwritten\n",
      "rule\n",
      ",\n",
      "beyond\n",
      "which\n",
      "the\n",
      "system\n",
      "becom\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanag\n",
      ".\n",
      "howev\n",
      ",\n",
      "creat\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learn\n",
      "system\n",
      "simpli\n",
      "requir\n",
      "a\n",
      "correspond\n",
      "increas\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hour\n",
      "work\n",
      ",\n",
      "gener\n",
      "without\n",
      "signific\n",
      "increas\n",
      "in\n",
      "the\n",
      "complex\n",
      "of\n",
      "the\n",
      "annot\n",
      "process\n",
      ".\n",
      "despit\n",
      "the\n",
      "popular\n",
      "of\n",
      "machin\n",
      "learn\n",
      "in\n",
      "nlp\n",
      "research\n",
      ",\n",
      "symbol\n",
      "method\n",
      "are\n",
      "still\n",
      "(\n",
      "2020\n",
      ")\n",
      "commonli\n",
      "use\n",
      ":\n",
      "when\n",
      "the\n",
      "amount\n",
      "of\n",
      "train\n",
      "data\n",
      "is\n",
      "insuffici\n",
      "to\n",
      "success\n",
      "appli\n",
      "machin\n",
      "learn\n",
      "method\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "the\n",
      "machin\n",
      "translat\n",
      "of\n",
      "low-resourc\n",
      "languag\n",
      "such\n",
      "as\n",
      "provid\n",
      "by\n",
      "the\n",
      "apertium\n",
      "system\n",
      ",\n",
      "for\n",
      "preprocess\n",
      "in\n",
      "nlp\n",
      "pipelin\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "token\n",
      ",\n",
      "or\n",
      "for\n",
      "postprocess\n",
      "and\n",
      "transform\n",
      "the\n",
      "output\n",
      "of\n",
      "nlp\n",
      "pipelin\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "knowledg\n",
      "extract\n",
      "from\n",
      "syntact\n",
      "pars\n",
      ".\n",
      "statist\n",
      "method\n",
      "[\n",
      "edit\n",
      "]\n",
      "sinc\n",
      "the\n",
      "so-cal\n",
      "``\n",
      "statist\n",
      "revolut\n",
      "''\n",
      "[\n",
      "15\n",
      "]\n",
      "[\n",
      "16\n",
      "]\n",
      "in\n",
      "the\n",
      "late\n",
      "1980\n",
      "and\n",
      "mid-1990\n",
      ",\n",
      "much\n",
      "natur\n",
      "languag\n",
      "process\n",
      "research\n",
      "ha\n",
      "reli\n",
      "heavili\n",
      "on\n",
      "machin\n",
      "learn\n",
      ".\n",
      "the\n",
      "machine-learn\n",
      "paradigm\n",
      "call\n",
      "instead\n",
      "for\n",
      "use\n",
      "statist\n",
      "infer\n",
      "to\n",
      "automat\n",
      "learn\n",
      "such\n",
      "rule\n",
      "through\n",
      "the\n",
      "analysi\n",
      "of\n",
      "larg\n",
      "corpora\n",
      "(\n",
      "the\n",
      "plural\n",
      "form\n",
      "of\n",
      "corpu\n",
      ",\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "document\n",
      ",\n",
      "possibl\n",
      "with\n",
      "human\n",
      "or\n",
      "comput\n",
      "annot\n",
      ")\n",
      "of\n",
      "typic\n",
      "real-world\n",
      "exampl\n",
      ".\n",
      "mani\n",
      "differ\n",
      "class\n",
      "of\n",
      "machine-learn\n",
      "algorithm\n",
      "have\n",
      "been\n",
      "appli\n",
      "to\n",
      "natural-language-process\n",
      "task\n",
      ".\n",
      "these\n",
      "algorithm\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "larg\n",
      "set\n",
      "of\n",
      "``\n",
      "featur\n",
      "''\n",
      "that\n",
      "are\n",
      "gener\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "increasingli\n",
      ",\n",
      "howev\n",
      ",\n",
      "research\n",
      "ha\n",
      "focus\n",
      "on\n",
      "statist\n",
      "model\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilist\n",
      "decis\n",
      "base\n",
      "on\n",
      "attach\n",
      "real-valu\n",
      "weight\n",
      "to\n",
      "each\n",
      "input\n",
      "featur\n",
      "(\n",
      "complex-valu\n",
      "embed\n",
      ",\n",
      "[\n",
      "17\n",
      "]\n",
      "and\n",
      "neural\n",
      "network\n",
      "in\n",
      "gener\n",
      "have\n",
      "also\n",
      "been\n",
      "propos\n",
      ",\n",
      "for\n",
      "e.g\n",
      ".\n",
      "speech\n",
      "[\n",
      "18\n",
      "]\n",
      ")\n",
      ".\n",
      "such\n",
      "model\n",
      "have\n",
      "the\n",
      "advantag\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "rel\n",
      "certainti\n",
      "of\n",
      "mani\n",
      "differ\n",
      "possibl\n",
      "answer\n",
      "rather\n",
      "than\n",
      "onli\n",
      "one\n",
      ",\n",
      "produc\n",
      "more\n",
      "reliabl\n",
      "result\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "includ\n",
      "as\n",
      "a\n",
      "compon\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      ".\n",
      "some\n",
      "of\n",
      "the\n",
      "earliest-us\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      ",\n",
      "such\n",
      "as\n",
      "decis\n",
      "tree\n",
      ",\n",
      "produc\n",
      "system\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rule\n",
      "similar\n",
      "to\n",
      "exist\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "howev\n",
      ",\n",
      "part-of-speech\n",
      "tag\n",
      "introduc\n",
      "the\n",
      "use\n",
      "of\n",
      "hidden\n",
      "markov\n",
      "model\n",
      "to\n",
      "natur\n",
      "languag\n",
      "process\n",
      ",\n",
      "and\n",
      "increasingli\n",
      ",\n",
      "research\n",
      "ha\n",
      "focus\n",
      "on\n",
      "statist\n",
      "model\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilist\n",
      "decis\n",
      "base\n",
      "on\n",
      "attach\n",
      "real-valu\n",
      "weight\n",
      "to\n",
      "the\n",
      "featur\n",
      "make\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "the\n",
      "cach\n",
      "languag\n",
      "model\n",
      "upon\n",
      "which\n",
      "mani\n",
      "speech\n",
      "recognit\n",
      "system\n",
      "now\n",
      "reli\n",
      "are\n",
      "exampl\n",
      "of\n",
      "such\n",
      "statist\n",
      "model\n",
      ".\n",
      "such\n",
      "model\n",
      "are\n",
      "gener\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      ",\n",
      "especi\n",
      "input\n",
      "that\n",
      "contain\n",
      "error\n",
      "(\n",
      "as\n",
      "is\n",
      "veri\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      ")\n",
      ",\n",
      "and\n",
      "produc\n",
      "more\n",
      "reliabl\n",
      "result\n",
      "when\n",
      "integr\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "compris\n",
      "multipl\n",
      "subtask\n",
      ".\n",
      "sinc\n",
      "the\n",
      "neural\n",
      "turn\n",
      ",\n",
      "statist\n",
      "method\n",
      "in\n",
      "nlp\n",
      "research\n",
      "have\n",
      "been\n",
      "larg\n",
      "replac\n",
      "by\n",
      "neural\n",
      "network\n",
      ".\n",
      "howev\n",
      ",\n",
      "they\n",
      "continu\n",
      "to\n",
      "be\n",
      "relev\n",
      "for\n",
      "context\n",
      "in\n",
      "which\n",
      "statist\n",
      "interpret\n",
      "and\n",
      "transpar\n",
      "is\n",
      "requir\n",
      ".\n",
      "neural\n",
      "network\n",
      "[\n",
      "edit\n",
      "]\n",
      "further\n",
      "inform\n",
      ":\n",
      "artifici\n",
      "neural\n",
      "network\n",
      "a\n",
      "major\n",
      "drawback\n",
      "of\n",
      "statist\n",
      "method\n",
      "is\n",
      "that\n",
      "they\n",
      "requir\n",
      "elabor\n",
      "featur\n",
      "engin\n",
      ".\n",
      "sinc\n",
      "2015\n",
      ",\n",
      "[\n",
      "19\n",
      "]\n",
      "the\n",
      "field\n",
      "ha\n",
      "thu\n",
      "larg\n",
      "abandon\n",
      "statist\n",
      "method\n",
      "and\n",
      "shift\n",
      "to\n",
      "neural\n",
      "network\n",
      "for\n",
      "machin\n",
      "learn\n",
      ".\n",
      "popular\n",
      "techniqu\n",
      "includ\n",
      "the\n",
      "use\n",
      "of\n",
      "word\n",
      "embed\n",
      "to\n",
      "captur\n",
      "semant\n",
      "properti\n",
      "of\n",
      "word\n",
      ",\n",
      "and\n",
      "an\n",
      "increas\n",
      "in\n",
      "end-to-end\n",
      "learn\n",
      "of\n",
      "a\n",
      "higher-level\n",
      "task\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "question\n",
      "answer\n",
      ")\n",
      "instead\n",
      "of\n",
      "reli\n",
      "on\n",
      "a\n",
      "pipelin\n",
      "of\n",
      "separ\n",
      "intermedi\n",
      "task\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "part-of-speech\n",
      "tag\n",
      "and\n",
      "depend\n",
      "pars\n",
      ")\n",
      ".\n",
      "in\n",
      "some\n",
      "area\n",
      ",\n",
      "thi\n",
      "shift\n",
      "ha\n",
      "entail\n",
      "substanti\n",
      "chang\n",
      "in\n",
      "how\n",
      "nlp\n",
      "system\n",
      "are\n",
      "design\n",
      ",\n",
      "such\n",
      "that\n",
      "deep\n",
      "neural\n",
      "network-bas\n",
      "approach\n",
      "may\n",
      "be\n",
      "view\n",
      "as\n",
      "a\n",
      "new\n",
      "paradigm\n",
      "distinct\n",
      "from\n",
      "statist\n",
      "natur\n",
      "languag\n",
      "process\n",
      ".\n",
      "for\n",
      "instanc\n",
      ",\n",
      "the\n",
      "term\n",
      "neural\n",
      "machin\n",
      "translat\n",
      "(\n",
      "nmt\n",
      ")\n",
      "emphas\n",
      "the\n",
      "fact\n",
      "that\n",
      "deep\n",
      "learning-bas\n",
      "approach\n",
      "to\n",
      "machin\n",
      "translat\n",
      "directli\n",
      "learn\n",
      "sequence-to-sequ\n",
      "transform\n",
      ",\n",
      "obviat\n",
      "the\n",
      "need\n",
      "for\n",
      "intermedi\n",
      "step\n",
      "such\n",
      "as\n",
      "word\n",
      "align\n",
      "and\n",
      "languag\n",
      "model\n",
      "that\n",
      "wa\n",
      "use\n",
      "in\n",
      "statist\n",
      "machin\n",
      "translat\n",
      "(\n",
      "smt\n",
      ")\n",
      ".\n",
      "latest\n",
      "work\n",
      "tend\n",
      "to\n",
      "use\n",
      "non-techn\n",
      "structur\n",
      "of\n",
      "a\n",
      "given\n",
      "task\n",
      "to\n",
      "build\n",
      "proper\n",
      "neural\n",
      "network\n",
      ".\n",
      "[\n",
      "20\n",
      "]\n",
      "common\n",
      "nlp\n",
      "task\n",
      "[\n",
      "edit\n",
      "]\n",
      "the\n",
      "follow\n",
      "is\n",
      "a\n",
      "list\n",
      "of\n",
      "some\n",
      "of\n",
      "the\n",
      "most\n",
      "commonli\n",
      "research\n",
      "task\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      ".\n",
      "some\n",
      "of\n",
      "these\n",
      "task\n",
      "have\n",
      "direct\n",
      "real-world\n",
      "applic\n",
      ",\n",
      "while\n",
      "other\n",
      "more\n",
      "commonli\n",
      "serv\n",
      "as\n",
      "subtask\n",
      "that\n",
      "are\n",
      "use\n",
      "to\n",
      "aid\n",
      "in\n",
      "solv\n",
      "larger\n",
      "task\n",
      ".\n",
      "though\n",
      "natur\n",
      "languag\n",
      "process\n",
      "task\n",
      "are\n",
      "close\n",
      "intertwin\n",
      ",\n",
      "they\n",
      "can\n",
      "be\n",
      "subdivid\n",
      "into\n",
      "categori\n",
      "for\n",
      "conveni\n",
      ".\n",
      "a\n",
      "coars\n",
      "divis\n",
      "is\n",
      "given\n",
      "below\n",
      ".\n",
      "text\n",
      "and\n",
      "speech\n",
      "process\n",
      "[\n",
      "edit\n",
      "]\n",
      "optic\n",
      "charact\n",
      "recognit\n",
      "(\n",
      "ocr\n",
      ")\n",
      "given\n",
      "an\n",
      "imag\n",
      "repres\n",
      "print\n",
      "text\n",
      ",\n",
      "determin\n",
      "the\n",
      "correspond\n",
      "text\n",
      ".\n",
      "speech\n",
      "recognit\n",
      "given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "peopl\n",
      "speak\n",
      ",\n",
      "determin\n",
      "the\n",
      "textual\n",
      "represent\n",
      "of\n",
      "the\n",
      "speech\n",
      ".\n",
      "thi\n",
      "is\n",
      "the\n",
      "opposit\n",
      "of\n",
      "text\n",
      "to\n",
      "speech\n",
      "and\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "extrem\n",
      "difficult\n",
      "problem\n",
      "colloqui\n",
      "term\n",
      "``\n",
      "ai-complet\n",
      "``\n",
      "(\n",
      "see\n",
      "abov\n",
      ")\n",
      ".\n",
      "in\n",
      "natur\n",
      "speech\n",
      "there\n",
      "are\n",
      "hardli\n",
      "ani\n",
      "paus\n",
      "between\n",
      "success\n",
      "word\n",
      ",\n",
      "and\n",
      "thu\n",
      "speech\n",
      "segment\n",
      "is\n",
      "a\n",
      "necessari\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognit\n",
      "(\n",
      "see\n",
      "below\n",
      ")\n",
      ".\n",
      "in\n",
      "most\n",
      "spoken\n",
      "languag\n",
      ",\n",
      "the\n",
      "sound\n",
      "repres\n",
      "success\n",
      "letter\n",
      "blend\n",
      "into\n",
      "each\n",
      "other\n",
      "in\n",
      "a\n",
      "process\n",
      "term\n",
      "coarticul\n",
      ",\n",
      "so\n",
      "the\n",
      "convers\n",
      "of\n",
      "the\n",
      "analog\n",
      "signal\n",
      "to\n",
      "discret\n",
      "charact\n",
      "can\n",
      "be\n",
      "a\n",
      "veri\n",
      "difficult\n",
      "process\n",
      ".\n",
      "also\n",
      ",\n",
      "given\n",
      "that\n",
      "word\n",
      "in\n",
      "the\n",
      "same\n",
      "languag\n",
      "are\n",
      "spoken\n",
      "by\n",
      "peopl\n",
      "with\n",
      "differ\n",
      "accent\n",
      ",\n",
      "the\n",
      "speech\n",
      "recognit\n",
      "softwar\n",
      "must\n",
      "be\n",
      "abl\n",
      "to\n",
      "recogn\n",
      "the\n",
      "wide\n",
      "varieti\n",
      "of\n",
      "input\n",
      "as\n",
      "be\n",
      "ident\n",
      "to\n",
      "each\n",
      "other\n",
      "in\n",
      "term\n",
      "of\n",
      "it\n",
      "textual\n",
      "equival\n",
      ".\n",
      "speech\n",
      "segment\n",
      "given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "peopl\n",
      "speak\n",
      ",\n",
      "separ\n",
      "it\n",
      "into\n",
      "word\n",
      ".\n",
      "a\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognit\n",
      "and\n",
      "typic\n",
      "group\n",
      "with\n",
      "it\n",
      ".\n",
      "text-to-speech\n",
      "given\n",
      "a\n",
      "text\n",
      ",\n",
      "transform\n",
      "those\n",
      "unit\n",
      "and\n",
      "produc\n",
      "a\n",
      "spoken\n",
      "represent\n",
      ".\n",
      "text-to-speech\n",
      "can\n",
      "be\n",
      "use\n",
      "to\n",
      "aid\n",
      "the\n",
      "visual\n",
      "impair\n",
      ".\n",
      "[\n",
      "21\n",
      "]\n",
      "word\n",
      "segment\n",
      "(\n",
      "token\n",
      ")\n",
      "separ\n",
      "a\n",
      "chunk\n",
      "of\n",
      "continu\n",
      "text\n",
      "into\n",
      "separ\n",
      "word\n",
      ".\n",
      "for\n",
      "a\n",
      "languag\n",
      "like\n",
      "english\n",
      ",\n",
      "thi\n",
      "is\n",
      "fairli\n",
      "trivial\n",
      ",\n",
      "sinc\n",
      "word\n",
      "are\n",
      "usual\n",
      "separ\n",
      "by\n",
      "space\n",
      ".\n",
      "howev\n",
      ",\n",
      "some\n",
      "written\n",
      "languag\n",
      "like\n",
      "chines\n",
      ",\n",
      "japanes\n",
      "and\n",
      "thai\n",
      "do\n",
      "not\n",
      "mark\n",
      "word\n",
      "boundari\n",
      "in\n",
      "such\n",
      "a\n",
      "fashion\n",
      ",\n",
      "and\n",
      "in\n",
      "those\n",
      "languag\n",
      "text\n",
      "segment\n",
      "is\n",
      "a\n",
      "signific\n",
      "task\n",
      "requir\n",
      "knowledg\n",
      "of\n",
      "the\n",
      "vocabulari\n",
      "and\n",
      "morpholog\n",
      "of\n",
      "word\n",
      "in\n",
      "the\n",
      "languag\n",
      ".\n",
      "sometim\n",
      "thi\n",
      "process\n",
      "is\n",
      "also\n",
      "use\n",
      "in\n",
      "case\n",
      "like\n",
      "bag\n",
      "of\n",
      "word\n",
      "(\n",
      "bow\n",
      ")\n",
      "creation\n",
      "in\n",
      "data\n",
      "mine\n",
      ".\n",
      "morpholog\n",
      "analysi\n",
      "[\n",
      "edit\n",
      "]\n",
      "lemmat\n",
      "the\n",
      "task\n",
      "of\n",
      "remov\n",
      "inflect\n",
      "end\n",
      "onli\n",
      "and\n",
      "to\n",
      "return\n",
      "the\n",
      "base\n",
      "dictionari\n",
      "form\n",
      "of\n",
      "a\n",
      "word\n",
      "which\n",
      "is\n",
      "also\n",
      "known\n",
      "as\n",
      "a\n",
      "lemma\n",
      ".\n",
      "lemmat\n",
      "is\n",
      "anoth\n",
      "techniqu\n",
      "for\n",
      "reduc\n",
      "word\n",
      "to\n",
      "their\n",
      "normal\n",
      "form\n",
      ".\n",
      "but\n",
      "in\n",
      "thi\n",
      "case\n",
      ",\n",
      "the\n",
      "transform\n",
      "actual\n",
      "use\n",
      "a\n",
      "dictionari\n",
      "to\n",
      "map\n",
      "word\n",
      "to\n",
      "their\n",
      "actual\n",
      "form\n",
      ".\n",
      "[\n",
      "22\n",
      "]\n",
      "morpholog\n",
      "segment\n",
      "separ\n",
      "word\n",
      "into\n",
      "individu\n",
      "morphem\n",
      "and\n",
      "identifi\n",
      "the\n",
      "class\n",
      "of\n",
      "the\n",
      "morphem\n",
      ".\n",
      "the\n",
      "difficulti\n",
      "of\n",
      "thi\n",
      "task\n",
      "depend\n",
      "greatli\n",
      "on\n",
      "the\n",
      "complex\n",
      "of\n",
      "the\n",
      "morpholog\n",
      "(\n",
      "i.e\n",
      ".\n",
      ",\n",
      "the\n",
      "structur\n",
      "of\n",
      "word\n",
      ")\n",
      "of\n",
      "the\n",
      "languag\n",
      "be\n",
      "consid\n",
      ".\n",
      "english\n",
      "ha\n",
      "fairli\n",
      "simpl\n",
      "morpholog\n",
      ",\n",
      "especi\n",
      "inflect\n",
      "morpholog\n",
      ",\n",
      "and\n",
      "thu\n",
      "it\n",
      "is\n",
      "often\n",
      "possibl\n",
      "to\n",
      "ignor\n",
      "thi\n",
      "task\n",
      "entir\n",
      "and\n",
      "simpli\n",
      "model\n",
      "all\n",
      "possibl\n",
      "form\n",
      "of\n",
      "a\n",
      "word\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "open\n",
      ",\n",
      "open\n",
      ",\n",
      "open\n",
      ",\n",
      "open\n",
      "''\n",
      ")\n",
      "as\n",
      "separ\n",
      "word\n",
      ".\n",
      "in\n",
      "languag\n",
      "such\n",
      "as\n",
      "turkish\n",
      "or\n",
      "meitei\n",
      ",\n",
      "[\n",
      "23\n",
      "]\n",
      "a\n",
      "highli\n",
      "agglutin\n",
      "indian\n",
      "languag\n",
      ",\n",
      "howev\n",
      ",\n",
      "such\n",
      "an\n",
      "approach\n",
      "is\n",
      "not\n",
      "possibl\n",
      ",\n",
      "as\n",
      "each\n",
      "dictionari\n",
      "entri\n",
      "ha\n",
      "thousand\n",
      "of\n",
      "possibl\n",
      "word\n",
      "form\n",
      ".\n",
      "part-of-speech\n",
      "tag\n",
      "given\n",
      "a\n",
      "sentenc\n",
      ",\n",
      "determin\n",
      "the\n",
      "part\n",
      "of\n",
      "speech\n",
      "(\n",
      "po\n",
      ")\n",
      "for\n",
      "each\n",
      "word\n",
      ".\n",
      "mani\n",
      "word\n",
      ",\n",
      "especi\n",
      "common\n",
      "one\n",
      ",\n",
      "can\n",
      "serv\n",
      "as\n",
      "multipl\n",
      "part\n",
      "of\n",
      "speech\n",
      ".\n",
      "for\n",
      "exampl\n",
      ",\n",
      "``\n",
      "book\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      "(\n",
      "``\n",
      "the\n",
      "book\n",
      "on\n",
      "the\n",
      "tabl\n",
      "''\n",
      ")\n",
      "or\n",
      "verb\n",
      "(\n",
      "``\n",
      "to\n",
      "book\n",
      "a\n",
      "flight\n",
      "''\n",
      ")\n",
      ";\n",
      "``\n",
      "set\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      ",\n",
      "verb\n",
      "or\n",
      "adject\n",
      ";\n",
      "and\n",
      "``\n",
      "out\n",
      "''\n",
      "can\n",
      "be\n",
      "ani\n",
      "of\n",
      "at\n",
      "least\n",
      "five\n",
      "differ\n",
      "part\n",
      "of\n",
      "speech\n",
      ".\n",
      "stem\n",
      "the\n",
      "process\n",
      "of\n",
      "reduc\n",
      "inflect\n",
      "(\n",
      "or\n",
      "sometim\n",
      "deriv\n",
      ")\n",
      "word\n",
      "to\n",
      "a\n",
      "base\n",
      "form\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      "will\n",
      "be\n",
      "the\n",
      "root\n",
      "for\n",
      "``\n",
      "close\n",
      "''\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      ",\n",
      "``\n",
      "closer\n",
      "''\n",
      "etc.\n",
      ")\n",
      ".\n",
      "stem\n",
      "yield\n",
      "similar\n",
      "result\n",
      "as\n",
      "lemmat\n",
      ",\n",
      "but\n",
      "doe\n",
      "so\n",
      "on\n",
      "ground\n",
      "of\n",
      "rule\n",
      ",\n",
      "not\n",
      "a\n",
      "dictionari\n",
      ".\n",
      "syntact\n",
      "analysi\n",
      "[\n",
      "edit\n",
      "]\n",
      "grammar\n",
      "induct\n",
      "[\n",
      "24\n",
      "]\n",
      "gener\n",
      "a\n",
      "formal\n",
      "grammar\n",
      "that\n",
      "describ\n",
      "a\n",
      "languag\n",
      "'s\n",
      "syntax\n",
      ".\n",
      "sentenc\n",
      "break\n",
      "(\n",
      "also\n",
      "known\n",
      "as\n",
      "``\n",
      "sentenc\n",
      "boundari\n",
      "disambigu\n",
      "``\n",
      ")\n",
      "given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "find\n",
      "the\n",
      "sentenc\n",
      "boundari\n",
      ".\n",
      "sentenc\n",
      "boundari\n",
      "are\n",
      "often\n",
      "mark\n",
      "by\n",
      "period\n",
      "or\n",
      "other\n",
      "punctuat\n",
      "mark\n",
      ",\n",
      "but\n",
      "these\n",
      "same\n",
      "charact\n",
      "can\n",
      "serv\n",
      "other\n",
      "purpos\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "mark\n",
      "abbrevi\n",
      ")\n",
      ".\n",
      "pars\n",
      "determin\n",
      "the\n",
      "pars\n",
      "tree\n",
      "(\n",
      "grammat\n",
      "analysi\n",
      ")\n",
      "of\n",
      "a\n",
      "given\n",
      "sentenc\n",
      ".\n",
      "the\n",
      "grammar\n",
      "for\n",
      "natur\n",
      "languag\n",
      "is\n",
      "ambigu\n",
      "and\n",
      "typic\n",
      "sentenc\n",
      "have\n",
      "multipl\n",
      "possibl\n",
      "analys\n",
      ":\n",
      "perhap\n",
      "surprisingli\n",
      ",\n",
      "for\n",
      "a\n",
      "typic\n",
      "sentenc\n",
      "there\n",
      "may\n",
      "be\n",
      "thousand\n",
      "of\n",
      "potenti\n",
      "pars\n",
      "(\n",
      "most\n",
      "of\n",
      "which\n",
      "will\n",
      "seem\n",
      "complet\n",
      "nonsens\n",
      "to\n",
      "a\n",
      "human\n",
      ")\n",
      ".\n",
      "there\n",
      "are\n",
      "two\n",
      "primari\n",
      "type\n",
      "of\n",
      "pars\n",
      ":\n",
      "depend\n",
      "pars\n",
      "and\n",
      "constitu\n",
      "pars\n",
      ".\n",
      "depend\n",
      "pars\n",
      "focus\n",
      "on\n",
      "the\n",
      "relationship\n",
      "between\n",
      "word\n",
      "in\n",
      "a\n",
      "sentenc\n",
      "(\n",
      "mark\n",
      "thing\n",
      "like\n",
      "primari\n",
      "object\n",
      "and\n",
      "predic\n",
      ")\n",
      ",\n",
      "wherea\n",
      "constitu\n",
      "pars\n",
      "focus\n",
      "on\n",
      "build\n",
      "out\n",
      "the\n",
      "pars\n",
      "tree\n",
      "use\n",
      "a\n",
      "probabilist\n",
      "context-fre\n",
      "grammar\n",
      "(\n",
      "pcfg\n",
      ")\n",
      "(\n",
      "see\n",
      "also\n",
      "stochast\n",
      "grammar\n",
      ")\n",
      ".\n",
      "lexic\n",
      "semant\n",
      "(\n",
      "of\n",
      "individu\n",
      "word\n",
      "in\n",
      "context\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "lexic\n",
      "semant\n",
      "what\n",
      "is\n",
      "the\n",
      "comput\n",
      "mean\n",
      "of\n",
      "individu\n",
      "word\n",
      "in\n",
      "context\n",
      "?\n",
      "distribut\n",
      "semant\n",
      "how\n",
      "can\n",
      "we\n",
      "learn\n",
      "semant\n",
      "represent\n",
      "from\n",
      "data\n",
      "?\n",
      "name\n",
      "entiti\n",
      "recognit\n",
      "(\n",
      "ner\n",
      ")\n",
      "given\n",
      "a\n",
      "stream\n",
      "of\n",
      "text\n",
      ",\n",
      "determin\n",
      "which\n",
      "item\n",
      "in\n",
      "the\n",
      "text\n",
      "map\n",
      "to\n",
      "proper\n",
      "name\n",
      ",\n",
      "such\n",
      "as\n",
      "peopl\n",
      "or\n",
      "place\n",
      ",\n",
      "and\n",
      "what\n",
      "the\n",
      "type\n",
      "of\n",
      "each\n",
      "such\n",
      "name\n",
      "is\n",
      "(\n",
      "e.g\n",
      ".\n",
      "person\n",
      ",\n",
      "locat\n",
      ",\n",
      "organ\n",
      ")\n",
      ".\n",
      "although\n",
      "capit\n",
      "can\n",
      "aid\n",
      "in\n",
      "recogn\n",
      "name\n",
      "entiti\n",
      "in\n",
      "languag\n",
      "such\n",
      "as\n",
      "english\n",
      ",\n",
      "thi\n",
      "inform\n",
      "can\n",
      "not\n",
      "aid\n",
      "in\n",
      "determin\n",
      "the\n",
      "type\n",
      "of\n",
      "name\n",
      "entiti\n",
      ",\n",
      "and\n",
      "in\n",
      "ani\n",
      "case\n",
      ",\n",
      "is\n",
      "often\n",
      "inaccur\n",
      "or\n",
      "insuffici\n",
      ".\n",
      "for\n",
      "exampl\n",
      ",\n",
      "the\n",
      "first\n",
      "letter\n",
      "of\n",
      "a\n",
      "sentenc\n",
      "is\n",
      "also\n",
      "capit\n",
      ",\n",
      "and\n",
      "name\n",
      "entiti\n",
      "often\n",
      "span\n",
      "sever\n",
      "word\n",
      ",\n",
      "onli\n",
      "some\n",
      "of\n",
      "which\n",
      "are\n",
      "capit\n",
      ".\n",
      "furthermor\n",
      ",\n",
      "mani\n",
      "other\n",
      "languag\n",
      "in\n",
      "non-western\n",
      "script\n",
      "(\n",
      "e.g\n",
      ".\n",
      "chines\n",
      "or\n",
      "arab\n",
      ")\n",
      "do\n",
      "not\n",
      "have\n",
      "ani\n",
      "capit\n",
      "at\n",
      "all\n",
      ",\n",
      "and\n",
      "even\n",
      "languag\n",
      "with\n",
      "capit\n",
      "may\n",
      "not\n",
      "consist\n",
      "use\n",
      "it\n",
      "to\n",
      "distinguish\n",
      "name\n",
      ".\n",
      "for\n",
      "exampl\n",
      ",\n",
      "german\n",
      "capit\n",
      "all\n",
      "noun\n",
      ",\n",
      "regardless\n",
      "of\n",
      "whether\n",
      "they\n",
      "are\n",
      "name\n",
      ",\n",
      "and\n",
      "french\n",
      "and\n",
      "spanish\n",
      "do\n",
      "not\n",
      "capit\n",
      "name\n",
      "that\n",
      "serv\n",
      "as\n",
      "adject\n",
      ".\n",
      "sentiment\n",
      "analysi\n",
      "(\n",
      "see\n",
      "also\n",
      "multimod\n",
      "sentiment\n",
      "analysi\n",
      ")\n",
      "extract\n",
      "subject\n",
      "inform\n",
      "usual\n",
      "from\n",
      "a\n",
      "set\n",
      "of\n",
      "document\n",
      ",\n",
      "often\n",
      "use\n",
      "onlin\n",
      "review\n",
      "to\n",
      "determin\n",
      "``\n",
      "polar\n",
      "''\n",
      "about\n",
      "specif\n",
      "object\n",
      ".\n",
      "it\n",
      "is\n",
      "especi\n",
      "use\n",
      "for\n",
      "identifi\n",
      "trend\n",
      "of\n",
      "public\n",
      "opinion\n",
      "in\n",
      "social\n",
      "media\n",
      ",\n",
      "for\n",
      "market\n",
      ".\n",
      "terminolog\n",
      "extract\n",
      "the\n",
      "goal\n",
      "of\n",
      "terminolog\n",
      "extract\n",
      "is\n",
      "to\n",
      "automat\n",
      "extract\n",
      "relev\n",
      "term\n",
      "from\n",
      "a\n",
      "given\n",
      "corpu\n",
      ".\n",
      "word\n",
      "sens\n",
      "disambigu\n",
      "(\n",
      "wsd\n",
      ")\n",
      "mani\n",
      "word\n",
      "have\n",
      "more\n",
      "than\n",
      "one\n",
      "mean\n",
      ";\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "mean\n",
      "which\n",
      "make\n",
      "the\n",
      "most\n",
      "sens\n",
      "in\n",
      "context\n",
      ".\n",
      "for\n",
      "thi\n",
      "problem\n",
      ",\n",
      "we\n",
      "are\n",
      "typic\n",
      "given\n",
      "a\n",
      "list\n",
      "of\n",
      "word\n",
      "and\n",
      "associ\n",
      "word\n",
      "sens\n",
      ",\n",
      "e.g\n",
      ".\n",
      "from\n",
      "a\n",
      "dictionari\n",
      "or\n",
      "an\n",
      "onlin\n",
      "resourc\n",
      "such\n",
      "as\n",
      "wordnet\n",
      ".\n",
      "entiti\n",
      "link\n",
      "mani\n",
      "word\n",
      "-\n",
      "typic\n",
      "proper\n",
      "name\n",
      "-\n",
      "refer\n",
      "to\n",
      "name\n",
      "entiti\n",
      ";\n",
      "here\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "entiti\n",
      "(\n",
      "a\n",
      "famou\n",
      "individu\n",
      ",\n",
      "a\n",
      "locat\n",
      ",\n",
      "a\n",
      "compani\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "which\n",
      "is\n",
      "refer\n",
      "to\n",
      "in\n",
      "context\n",
      ".\n",
      "relat\n",
      "semant\n",
      "(\n",
      "semant\n",
      "of\n",
      "individu\n",
      "sentenc\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "relationship\n",
      "extract\n",
      "given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "identifi\n",
      "the\n",
      "relationship\n",
      "among\n",
      "name\n",
      "entiti\n",
      "(\n",
      "e.g\n",
      ".\n",
      "who\n",
      "is\n",
      "marri\n",
      "to\n",
      "whom\n",
      ")\n",
      ".\n",
      "semant\n",
      "pars\n",
      "given\n",
      "a\n",
      "piec\n",
      "of\n",
      "text\n",
      "(\n",
      "typic\n",
      "a\n",
      "sentenc\n",
      ")\n",
      ",\n",
      "produc\n",
      "a\n",
      "formal\n",
      "represent\n",
      "of\n",
      "it\n",
      "semant\n",
      ",\n",
      "either\n",
      "as\n",
      "a\n",
      "graph\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "amr\n",
      "pars\n",
      ")\n",
      "or\n",
      "in\n",
      "accord\n",
      "with\n",
      "a\n",
      "logic\n",
      "formal\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "drt\n",
      "pars\n",
      ")\n",
      ".\n",
      "thi\n",
      "challeng\n",
      "typic\n",
      "includ\n",
      "aspect\n",
      "of\n",
      "sever\n",
      "more\n",
      "elementari\n",
      "nlp\n",
      "task\n",
      "from\n",
      "semant\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "semant\n",
      "role\n",
      "label\n",
      ",\n",
      "word\n",
      "sens\n",
      "disambigu\n",
      ")\n",
      "and\n",
      "can\n",
      "be\n",
      "extend\n",
      "to\n",
      "includ\n",
      "full-fledg\n",
      "discours\n",
      "analysi\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "discours\n",
      "analysi\n",
      ",\n",
      "corefer\n",
      ";\n",
      "see\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "below\n",
      ")\n",
      ".\n",
      "semant\n",
      "role\n",
      "label\n",
      "(\n",
      "see\n",
      "also\n",
      "implicit\n",
      "semant\n",
      "role\n",
      "label\n",
      "below\n",
      ")\n",
      "given\n",
      "a\n",
      "singl\n",
      "sentenc\n",
      ",\n",
      "identifi\n",
      "and\n",
      "disambigu\n",
      "semant\n",
      "predic\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frame\n",
      ")\n",
      ",\n",
      "then\n",
      "identifi\n",
      "and\n",
      "classifi\n",
      "the\n",
      "frame\n",
      "element\n",
      "(\n",
      "semant\n",
      "role\n",
      ")\n",
      ".\n",
      "discours\n",
      "(\n",
      "semant\n",
      "beyond\n",
      "individu\n",
      "sentenc\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "corefer\n",
      "resolut\n",
      "given\n",
      "a\n",
      "sentenc\n",
      "or\n",
      "larger\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "determin\n",
      "which\n",
      "word\n",
      "(\n",
      "``\n",
      "mention\n",
      "''\n",
      ")\n",
      "refer\n",
      "to\n",
      "the\n",
      "same\n",
      "object\n",
      "(\n",
      "``\n",
      "entiti\n",
      "''\n",
      ")\n",
      ".\n",
      "anaphora\n",
      "resolut\n",
      "is\n",
      "a\n",
      "specif\n",
      "exampl\n",
      "of\n",
      "thi\n",
      "task\n",
      ",\n",
      "and\n",
      "is\n",
      "specif\n",
      "concern\n",
      "with\n",
      "match\n",
      "up\n",
      "pronoun\n",
      "with\n",
      "the\n",
      "noun\n",
      "or\n",
      "name\n",
      "to\n",
      "which\n",
      "they\n",
      "refer\n",
      ".\n",
      "the\n",
      "more\n",
      "gener\n",
      "task\n",
      "of\n",
      "corefer\n",
      "resolut\n",
      "also\n",
      "includ\n",
      "identifi\n",
      "so-cal\n",
      "``\n",
      "bridg\n",
      "relationship\n",
      "''\n",
      "involv\n",
      "refer\n",
      "express\n",
      ".\n",
      "for\n",
      "exampl\n",
      ",\n",
      "in\n",
      "a\n",
      "sentenc\n",
      "such\n",
      "as\n",
      "``\n",
      "he\n",
      "enter\n",
      "john\n",
      "'s\n",
      "hous\n",
      "through\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      ",\n",
      "``\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      "is\n",
      "a\n",
      "refer\n",
      "express\n",
      "and\n",
      "the\n",
      "bridg\n",
      "relationship\n",
      "to\n",
      "be\n",
      "identifi\n",
      "is\n",
      "the\n",
      "fact\n",
      "that\n",
      "the\n",
      "door\n",
      "be\n",
      "refer\n",
      "to\n",
      "is\n",
      "the\n",
      "front\n",
      "door\n",
      "of\n",
      "john\n",
      "'s\n",
      "hous\n",
      "(\n",
      "rather\n",
      "than\n",
      "of\n",
      "some\n",
      "other\n",
      "structur\n",
      "that\n",
      "might\n",
      "also\n",
      "be\n",
      "refer\n",
      "to\n",
      ")\n",
      ".\n",
      "discours\n",
      "analysi\n",
      "thi\n",
      "rubric\n",
      "includ\n",
      "sever\n",
      "relat\n",
      "task\n",
      ".\n",
      "one\n",
      "task\n",
      "is\n",
      "discours\n",
      "pars\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "identifi\n",
      "the\n",
      "discours\n",
      "structur\n",
      "of\n",
      "a\n",
      "connect\n",
      "text\n",
      ",\n",
      "i.e\n",
      ".\n",
      "the\n",
      "natur\n",
      "of\n",
      "the\n",
      "discours\n",
      "relationship\n",
      "between\n",
      "sentenc\n",
      "(\n",
      "e.g\n",
      ".\n",
      "elabor\n",
      ",\n",
      "explan\n",
      ",\n",
      "contrast\n",
      ")\n",
      ".\n",
      "anoth\n",
      "possibl\n",
      "task\n",
      "is\n",
      "recogn\n",
      "and\n",
      "classifi\n",
      "the\n",
      "speech\n",
      "act\n",
      "in\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      "(\n",
      "e.g\n",
      ".\n",
      "yes-no\n",
      "question\n",
      ",\n",
      "content\n",
      "question\n",
      ",\n",
      "statement\n",
      ",\n",
      "assert\n",
      ",\n",
      "etc.\n",
      ")\n",
      ".\n",
      "implicit\n",
      "semant\n",
      "role\n",
      "label\n",
      "given\n",
      "a\n",
      "singl\n",
      "sentenc\n",
      ",\n",
      "identifi\n",
      "and\n",
      "disambigu\n",
      "semant\n",
      "predic\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frame\n",
      ")\n",
      "and\n",
      "their\n",
      "explicit\n",
      "semant\n",
      "role\n",
      "in\n",
      "the\n",
      "current\n",
      "sentenc\n",
      "(\n",
      "see\n",
      "semant\n",
      "role\n",
      "label\n",
      "abov\n",
      ")\n",
      ".\n",
      "then\n",
      ",\n",
      "identifi\n",
      "semant\n",
      "role\n",
      "that\n",
      "are\n",
      "not\n",
      "explicitli\n",
      "realiz\n",
      "in\n",
      "the\n",
      "current\n",
      "sentenc\n",
      ",\n",
      "classifi\n",
      "them\n",
      "into\n",
      "argument\n",
      "that\n",
      "are\n",
      "explicitli\n",
      "realiz\n",
      "elsewher\n",
      "in\n",
      "the\n",
      "text\n",
      "and\n",
      "those\n",
      "that\n",
      "are\n",
      "not\n",
      "specifi\n",
      ",\n",
      "and\n",
      "resolv\n",
      "the\n",
      "former\n",
      "against\n",
      "the\n",
      "local\n",
      "text\n",
      ".\n",
      "a\n",
      "close\n",
      "relat\n",
      "task\n",
      "is\n",
      "zero\n",
      "anaphora\n",
      "resolut\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "extens\n",
      "of\n",
      "corefer\n",
      "resolut\n",
      "to\n",
      "pro-drop\n",
      "languag\n",
      ".\n",
      "recogn\n",
      "textual\n",
      "entail\n",
      "given\n",
      "two\n",
      "text\n",
      "fragment\n",
      ",\n",
      "determin\n",
      "if\n",
      "one\n",
      "be\n",
      "true\n",
      "entail\n",
      "the\n",
      "other\n",
      ",\n",
      "entail\n",
      "the\n",
      "other\n",
      "'s\n",
      "negat\n",
      ",\n",
      "or\n",
      "allow\n",
      "the\n",
      "other\n",
      "to\n",
      "be\n",
      "either\n",
      "true\n",
      "or\n",
      "fals\n",
      ".\n",
      "[\n",
      "25\n",
      "]\n",
      "topic\n",
      "segment\n",
      "and\n",
      "recognit\n",
      "given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "separ\n",
      "it\n",
      "into\n",
      "segment\n",
      "each\n",
      "of\n",
      "which\n",
      "is\n",
      "devot\n",
      "to\n",
      "a\n",
      "topic\n",
      ",\n",
      "and\n",
      "identifi\n",
      "the\n",
      "topic\n",
      "of\n",
      "the\n",
      "segment\n",
      ".\n",
      "argument\n",
      "mine\n",
      "the\n",
      "goal\n",
      "of\n",
      "argument\n",
      "mine\n",
      "is\n",
      "the\n",
      "automat\n",
      "extract\n",
      "and\n",
      "identif\n",
      "of\n",
      "argument\n",
      "structur\n",
      "from\n",
      "natur\n",
      "languag\n",
      "text\n",
      "with\n",
      "the\n",
      "aid\n",
      "of\n",
      "comput\n",
      "program\n",
      ".\n",
      "[\n",
      "26\n",
      "]\n",
      "such\n",
      "argument\n",
      "structur\n",
      "includ\n",
      "the\n",
      "premis\n",
      ",\n",
      "conclus\n",
      ",\n",
      "the\n",
      "argument\n",
      "scheme\n",
      "and\n",
      "the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship\n",
      "between\n",
      "the\n",
      "main\n",
      "and\n",
      "subsidiari\n",
      "argument\n",
      ",\n",
      "or\n",
      "the\n",
      "main\n",
      "and\n",
      "counter-argu\n",
      "within\n",
      "discours\n",
      ".\n",
      "[\n",
      "27\n",
      "]\n",
      "[\n",
      "28\n",
      "]\n",
      "higher-level\n",
      "nlp\n",
      "applic\n",
      "[\n",
      "edit\n",
      "]\n",
      "automat\n",
      "summar\n",
      "(\n",
      "text\n",
      "summar\n",
      ")\n",
      "produc\n",
      "a\n",
      "readabl\n",
      "summari\n",
      "of\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ".\n",
      "often\n",
      "use\n",
      "to\n",
      "provid\n",
      "summari\n",
      "of\n",
      "the\n",
      "text\n",
      "of\n",
      "a\n",
      "known\n",
      "type\n",
      ",\n",
      "such\n",
      "as\n",
      "research\n",
      "paper\n",
      ",\n",
      "articl\n",
      "in\n",
      "the\n",
      "financi\n",
      "section\n",
      "of\n",
      "a\n",
      "newspap\n",
      ".\n",
      "book\n",
      "gener\n",
      "not\n",
      "an\n",
      "nlp\n",
      "task\n",
      "proper\n",
      "but\n",
      "an\n",
      "extens\n",
      "of\n",
      "natur\n",
      "languag\n",
      "gener\n",
      "and\n",
      "other\n",
      "nlp\n",
      "task\n",
      "is\n",
      "the\n",
      "creation\n",
      "of\n",
      "full-fledg\n",
      "book\n",
      ".\n",
      "the\n",
      "first\n",
      "machine-gener\n",
      "book\n",
      "wa\n",
      "creat\n",
      "by\n",
      "a\n",
      "rule-bas\n",
      "system\n",
      "in\n",
      "1984\n",
      "(\n",
      "racter\n",
      ",\n",
      "the\n",
      "policeman\n",
      "'s\n",
      "beard\n",
      "is\n",
      "half-construct\n",
      ")\n",
      ".\n",
      "[\n",
      "29\n",
      "]\n",
      "the\n",
      "first\n",
      "publish\n",
      "work\n",
      "by\n",
      "a\n",
      "neural\n",
      "network\n",
      "wa\n",
      "publish\n",
      "in\n",
      "2018\n",
      ",\n",
      "1\n",
      "the\n",
      "road\n",
      ",\n",
      "market\n",
      "as\n",
      "a\n",
      "novel\n",
      ",\n",
      "contain\n",
      "sixti\n",
      "million\n",
      "word\n",
      ".\n",
      "both\n",
      "these\n",
      "system\n",
      "are\n",
      "basic\n",
      "elabor\n",
      "but\n",
      "non-sens\n",
      "(\n",
      "semantics-fre\n",
      ")\n",
      "languag\n",
      "model\n",
      ".\n",
      "the\n",
      "first\n",
      "machine-gener\n",
      "scienc\n",
      "book\n",
      "wa\n",
      "publish\n",
      "in\n",
      "2019\n",
      "(\n",
      "beta\n",
      "writer\n",
      ",\n",
      "lithium-ion\n",
      "batteri\n",
      ",\n",
      "springer\n",
      ",\n",
      "cham\n",
      ")\n",
      ".\n",
      "[\n",
      "30\n",
      "]\n",
      "unlik\n",
      "racter\n",
      "and\n",
      "1\n",
      "the\n",
      "road\n",
      ",\n",
      "thi\n",
      "is\n",
      "ground\n",
      "on\n",
      "factual\n",
      "knowledg\n",
      "and\n",
      "base\n",
      "on\n",
      "text\n",
      "summar\n",
      ".\n",
      "dialogu\n",
      "manag\n",
      "comput\n",
      "system\n",
      "intend\n",
      "to\n",
      "convers\n",
      "with\n",
      "a\n",
      "human\n",
      ".\n",
      "document\n",
      "ai\n",
      "a\n",
      "document\n",
      "ai\n",
      "platform\n",
      "sit\n",
      "on\n",
      "top\n",
      "of\n",
      "the\n",
      "nlp\n",
      "technolog\n",
      "enabl\n",
      "user\n",
      "with\n",
      "no\n",
      "prior\n",
      "experi\n",
      "of\n",
      "artifici\n",
      "intellig\n",
      ",\n",
      "machin\n",
      "learn\n",
      "or\n",
      "nlp\n",
      "to\n",
      "quickli\n",
      "train\n",
      "a\n",
      "comput\n",
      "to\n",
      "extract\n",
      "the\n",
      "specif\n",
      "data\n",
      "they\n",
      "need\n",
      "from\n",
      "differ\n",
      "document\n",
      "type\n",
      ".\n",
      "nlp-power\n",
      "document\n",
      "ai\n",
      "enabl\n",
      "non-techn\n",
      "team\n",
      "to\n",
      "quickli\n",
      "access\n",
      "inform\n",
      "hidden\n",
      "in\n",
      "document\n",
      ",\n",
      "for\n",
      "exampl\n",
      ",\n",
      "lawyer\n",
      ",\n",
      "busi\n",
      "analyst\n",
      "and\n",
      "account\n",
      ".\n",
      "[\n",
      "31\n",
      "]\n",
      "grammat\n",
      "error\n",
      "correct\n",
      "grammat\n",
      "error\n",
      "detect\n",
      "and\n",
      "correct\n",
      "involv\n",
      "a\n",
      "great\n",
      "band-width\n",
      "of\n",
      "problem\n",
      "on\n",
      "all\n",
      "level\n",
      "of\n",
      "linguist\n",
      "analysi\n",
      "(\n",
      "phonology/orthographi\n",
      ",\n",
      "morpholog\n",
      ",\n",
      "syntax\n",
      ",\n",
      "semant\n",
      ",\n",
      "pragmat\n",
      ")\n",
      ".\n",
      "grammat\n",
      "error\n",
      "correct\n",
      "is\n",
      "impact\n",
      "sinc\n",
      "it\n",
      "affect\n",
      "hundr\n",
      "of\n",
      "million\n",
      "of\n",
      "peopl\n",
      "that\n",
      "use\n",
      "or\n",
      "acquir\n",
      "english\n",
      "as\n",
      "a\n",
      "second\n",
      "languag\n",
      ".\n",
      "it\n",
      "ha\n",
      "thu\n",
      "been\n",
      "subject\n",
      "to\n",
      "a\n",
      "number\n",
      "of\n",
      "share\n",
      "task\n",
      "sinc\n",
      "2011\n",
      ".\n",
      "[\n",
      "32\n",
      "]\n",
      "[\n",
      "33\n",
      "]\n",
      "[\n",
      "34\n",
      "]\n",
      "as\n",
      "far\n",
      "as\n",
      "orthographi\n",
      ",\n",
      "morpholog\n",
      ",\n",
      "syntax\n",
      "and\n",
      "certain\n",
      "aspect\n",
      "of\n",
      "semant\n",
      "are\n",
      "concern\n",
      ",\n",
      "and\n",
      "due\n",
      "to\n",
      "the\n",
      "develop\n",
      "of\n",
      "power\n",
      "neural\n",
      "languag\n",
      "model\n",
      "such\n",
      "as\n",
      "gpt-2\n",
      ",\n",
      "thi\n",
      "can\n",
      "now\n",
      "(\n",
      "2019\n",
      ")\n",
      "be\n",
      "consid\n",
      "a\n",
      "larg\n",
      "solv\n",
      "problem\n",
      "and\n",
      "is\n",
      "be\n",
      "market\n",
      "in\n",
      "variou\n",
      "commerci\n",
      "applic\n",
      ".\n",
      "machin\n",
      "translat\n",
      "automat\n",
      "translat\n",
      "text\n",
      "from\n",
      "one\n",
      "human\n",
      "languag\n",
      "to\n",
      "anoth\n",
      ".\n",
      "thi\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "difficult\n",
      "problem\n",
      ",\n",
      "and\n",
      "is\n",
      "a\n",
      "member\n",
      "of\n",
      "a\n",
      "class\n",
      "of\n",
      "problem\n",
      "colloqui\n",
      "term\n",
      "``\n",
      "ai-complet\n",
      "``\n",
      ",\n",
      "i.e\n",
      ".\n",
      "requir\n",
      "all\n",
      "of\n",
      "the\n",
      "differ\n",
      "type\n",
      "of\n",
      "knowledg\n",
      "that\n",
      "human\n",
      "possess\n",
      "(\n",
      "grammar\n",
      ",\n",
      "semant\n",
      ",\n",
      "fact\n",
      "about\n",
      "the\n",
      "real\n",
      "world\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "to\n",
      "solv\n",
      "properli\n",
      ".\n",
      "natur\n",
      "languag\n",
      "gener\n",
      "(\n",
      "nlg\n",
      ")\n",
      ":\n",
      "convert\n",
      "inform\n",
      "from\n",
      "comput\n",
      "databas\n",
      "or\n",
      "semant\n",
      "intent\n",
      "into\n",
      "readabl\n",
      "human\n",
      "languag\n",
      ".\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "(\n",
      "nlu\n",
      ")\n",
      "convert\n",
      "chunk\n",
      "of\n",
      "text\n",
      "into\n",
      "more\n",
      "formal\n",
      "represent\n",
      "such\n",
      "as\n",
      "first-ord\n",
      "logic\n",
      "structur\n",
      "that\n",
      "are\n",
      "easier\n",
      "for\n",
      "comput\n",
      "program\n",
      "to\n",
      "manipul\n",
      ".\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "involv\n",
      "the\n",
      "identif\n",
      "of\n",
      "the\n",
      "intend\n",
      "semant\n",
      "from\n",
      "the\n",
      "multipl\n",
      "possibl\n",
      "semant\n",
      "which\n",
      "can\n",
      "be\n",
      "deriv\n",
      "from\n",
      "a\n",
      "natur\n",
      "languag\n",
      "express\n",
      "which\n",
      "usual\n",
      "take\n",
      "the\n",
      "form\n",
      "of\n",
      "organ\n",
      "notat\n",
      "of\n",
      "natur\n",
      "languag\n",
      "concept\n",
      ".\n",
      "introduct\n",
      "and\n",
      "creation\n",
      "of\n",
      "languag\n",
      "metamodel\n",
      "and\n",
      "ontolog\n",
      "are\n",
      "effici\n",
      "howev\n",
      "empir\n",
      "solut\n",
      ".\n",
      "an\n",
      "explicit\n",
      "formal\n",
      "of\n",
      "natur\n",
      "languag\n",
      "semant\n",
      "without\n",
      "confus\n",
      "with\n",
      "implicit\n",
      "assumpt\n",
      "such\n",
      "as\n",
      "closed-world\n",
      "assumpt\n",
      "(\n",
      "cwa\n",
      ")\n",
      "vs.\n",
      "open-world\n",
      "assumpt\n",
      ",\n",
      "or\n",
      "subject\n",
      "yes/no\n",
      "vs.\n",
      "object\n",
      "true/fals\n",
      "is\n",
      "expect\n",
      "for\n",
      "the\n",
      "construct\n",
      "of\n",
      "a\n",
      "basi\n",
      "of\n",
      "semant\n",
      "formal\n",
      ".\n",
      "[\n",
      "35\n",
      "]\n",
      "question\n",
      "answer\n",
      "given\n",
      "a\n",
      "human-languag\n",
      "question\n",
      ",\n",
      "determin\n",
      "it\n",
      "answer\n",
      ".\n",
      "typic\n",
      "question\n",
      "have\n",
      "a\n",
      "specif\n",
      "right\n",
      "answer\n",
      "(\n",
      "such\n",
      "as\n",
      "``\n",
      "what\n",
      "is\n",
      "the\n",
      "capit\n",
      "of\n",
      "canada\n",
      "?\n",
      "``\n",
      ")\n",
      ",\n",
      "but\n",
      "sometim\n",
      "open-end\n",
      "question\n",
      "are\n",
      "also\n",
      "consid\n",
      "(\n",
      "such\n",
      "as\n",
      "``\n",
      "what\n",
      "is\n",
      "the\n",
      "mean\n",
      "of\n",
      "life\n",
      "?\n",
      "''\n",
      ")\n",
      ".\n",
      "gener\n",
      "tendenc\n",
      "and\n",
      "(\n",
      "possibl\n",
      ")\n",
      "futur\n",
      "direct\n",
      "[\n",
      "edit\n",
      "]\n",
      "base\n",
      "on\n",
      "long-stand\n",
      "trend\n",
      "in\n",
      "the\n",
      "field\n",
      ",\n",
      "it\n",
      "is\n",
      "possibl\n",
      "to\n",
      "extrapol\n",
      "futur\n",
      "direct\n",
      "of\n",
      "nlp\n",
      ".\n",
      "as\n",
      "of\n",
      "2020\n",
      ",\n",
      "three\n",
      "trend\n",
      "among\n",
      "the\n",
      "topic\n",
      "of\n",
      "the\n",
      "long-stand\n",
      "seri\n",
      "of\n",
      "conll\n",
      "share\n",
      "task\n",
      "can\n",
      "be\n",
      "observ\n",
      ":\n",
      "[\n",
      "36\n",
      "]\n",
      "interest\n",
      "on\n",
      "increasingli\n",
      "abstract\n",
      ",\n",
      "``\n",
      "cognit\n",
      "''\n",
      "aspect\n",
      "of\n",
      "natur\n",
      "languag\n",
      "(\n",
      "1999-2001\n",
      ":\n",
      "shallow\n",
      "pars\n",
      ",\n",
      "2002-03\n",
      ":\n",
      "name\n",
      "entiti\n",
      "recognit\n",
      ",\n",
      "2006-09/2017-18\n",
      ":\n",
      "depend\n",
      "syntax\n",
      ",\n",
      "2004-05/2008-09\n",
      "semant\n",
      "role\n",
      "label\n",
      ",\n",
      "2011-12\n",
      "corefer\n",
      ",\n",
      "2015-16\n",
      ":\n",
      "discours\n",
      "pars\n",
      ",\n",
      "2019\n",
      ":\n",
      "semant\n",
      "pars\n",
      ")\n",
      ".\n",
      "increas\n",
      "interest\n",
      "in\n",
      "multilingu\n",
      ",\n",
      "and\n",
      ",\n",
      "potenti\n",
      ",\n",
      "multimod\n",
      "(\n",
      "english\n",
      "sinc\n",
      "1999\n",
      ";\n",
      "spanish\n",
      ",\n",
      "dutch\n",
      "sinc\n",
      "2002\n",
      ";\n",
      "german\n",
      "sinc\n",
      "2003\n",
      ";\n",
      "bulgarian\n",
      ",\n",
      "danish\n",
      ",\n",
      "japanes\n",
      ",\n",
      "portugues\n",
      ",\n",
      "slovenian\n",
      ",\n",
      "swedish\n",
      ",\n",
      "turkish\n",
      "sinc\n",
      "2006\n",
      ";\n",
      "basqu\n",
      ",\n",
      "catalan\n",
      ",\n",
      "chines\n",
      ",\n",
      "greek\n",
      ",\n",
      "hungarian\n",
      ",\n",
      "italian\n",
      ",\n",
      "turkish\n",
      "sinc\n",
      "2007\n",
      ";\n",
      "czech\n",
      "sinc\n",
      "2009\n",
      ";\n",
      "arab\n",
      "sinc\n",
      "2012\n",
      ";\n",
      "2017\n",
      ":\n",
      "40+\n",
      "languag\n",
      ";\n",
      "2018\n",
      ":\n",
      "60+/100+\n",
      "languag\n",
      ")\n",
      "elimin\n",
      "of\n",
      "symbol\n",
      "represent\n",
      "(\n",
      "rule-bas\n",
      "over\n",
      "supervis\n",
      "toward\n",
      "weakli\n",
      "supervis\n",
      "method\n",
      ",\n",
      "represent\n",
      "learn\n",
      "and\n",
      "end-to-end\n",
      "system\n",
      ")\n",
      "cognit\n",
      "and\n",
      "nlp\n",
      "[\n",
      "edit\n",
      "]\n",
      "most\n",
      "higher-level\n",
      "nlp\n",
      "applic\n",
      "involv\n",
      "aspect\n",
      "that\n",
      "emul\n",
      "intellig\n",
      "behaviour\n",
      "and\n",
      "appar\n",
      "comprehens\n",
      "of\n",
      "natur\n",
      "languag\n",
      ".\n",
      "more\n",
      "broadli\n",
      "speak\n",
      ",\n",
      "the\n",
      "technic\n",
      "operation\n",
      "of\n",
      "increasingli\n",
      "advanc\n",
      "aspect\n",
      "of\n",
      "cognit\n",
      "behaviour\n",
      "repres\n",
      "one\n",
      "of\n",
      "the\n",
      "development\n",
      "trajectori\n",
      "of\n",
      "nlp\n",
      "(\n",
      "see\n",
      "trend\n",
      "among\n",
      "conll\n",
      "share\n",
      "task\n",
      "abov\n",
      ")\n",
      ".\n",
      "cognit\n",
      "refer\n",
      "to\n",
      "``\n",
      "the\n",
      "mental\n",
      "action\n",
      "or\n",
      "process\n",
      "of\n",
      "acquir\n",
      "knowledg\n",
      "and\n",
      "understand\n",
      "through\n",
      "thought\n",
      ",\n",
      "experi\n",
      ",\n",
      "and\n",
      "the\n",
      "sens\n",
      ".\n",
      "''\n",
      "[\n",
      "37\n",
      "]\n",
      "cognit\n",
      "scienc\n",
      "is\n",
      "the\n",
      "interdisciplinari\n",
      ",\n",
      "scientif\n",
      "studi\n",
      "of\n",
      "the\n",
      "mind\n",
      "and\n",
      "it\n",
      "process\n",
      ".\n",
      "[\n",
      "38\n",
      "]\n",
      "cognit\n",
      "linguist\n",
      "is\n",
      "an\n",
      "interdisciplinari\n",
      "branch\n",
      "of\n",
      "linguist\n",
      ",\n",
      "combin\n",
      "knowledg\n",
      "and\n",
      "research\n",
      "from\n",
      "both\n",
      "psycholog\n",
      "and\n",
      "linguist\n",
      ".\n",
      "[\n",
      "39\n",
      "]\n",
      "especi\n",
      "dure\n",
      "the\n",
      "age\n",
      "of\n",
      "symbol\n",
      "nlp\n",
      ",\n",
      "the\n",
      "area\n",
      "of\n",
      "comput\n",
      "linguist\n",
      "maintain\n",
      "strong\n",
      "tie\n",
      "with\n",
      "cognit\n",
      "studi\n",
      ".\n",
      "as\n",
      "an\n",
      "exampl\n",
      ",\n",
      "georg\n",
      "lakoff\n",
      "offer\n",
      "a\n",
      "methodolog\n",
      "to\n",
      "build\n",
      "natur\n",
      "languag\n",
      "process\n",
      "(\n",
      "nlp\n",
      ")\n",
      "algorithm\n",
      "through\n",
      "the\n",
      "perspect\n",
      "of\n",
      "cognit\n",
      "scienc\n",
      ",\n",
      "along\n",
      "with\n",
      "the\n",
      "find\n",
      "of\n",
      "cognit\n",
      "linguist\n",
      ",\n",
      "[\n",
      "40\n",
      "]\n",
      "with\n",
      "two\n",
      "defin\n",
      "aspect\n",
      ":\n",
      "appli\n",
      "the\n",
      "theori\n",
      "of\n",
      "conceptu\n",
      "metaphor\n",
      ",\n",
      "explain\n",
      "by\n",
      "lakoff\n",
      "as\n",
      "“\n",
      "the\n",
      "understand\n",
      "of\n",
      "one\n",
      "idea\n",
      ",\n",
      "in\n",
      "term\n",
      "of\n",
      "anoth\n",
      "”\n",
      "which\n",
      "provid\n",
      "an\n",
      "idea\n",
      "of\n",
      "the\n",
      "intent\n",
      "of\n",
      "the\n",
      "author\n",
      ".\n",
      "[\n",
      "41\n",
      "]\n",
      "for\n",
      "exampl\n",
      ",\n",
      "consid\n",
      "the\n",
      "english\n",
      "word\n",
      "“\n",
      "big\n",
      "”\n",
      ".\n",
      "when\n",
      "use\n",
      "in\n",
      "a\n",
      "comparison\n",
      "(\n",
      "“\n",
      "that\n",
      "is\n",
      "a\n",
      "big\n",
      "tree\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "'s\n",
      "intent\n",
      "is\n",
      "to\n",
      "impli\n",
      "that\n",
      "the\n",
      "tree\n",
      "is\n",
      "”\n",
      "physic\n",
      "larg\n",
      "”\n",
      "rel\n",
      "to\n",
      "other\n",
      "tree\n",
      "or\n",
      "the\n",
      "author\n",
      "experi\n",
      ".\n",
      "when\n",
      "use\n",
      "metaphor\n",
      "(\n",
      "”\n",
      "tomorrow\n",
      "is\n",
      "a\n",
      "big\n",
      "day\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "’\n",
      "s\n",
      "intent\n",
      "to\n",
      "impli\n",
      "”\n",
      "import\n",
      "”\n",
      ".\n",
      "the\n",
      "intent\n",
      "behind\n",
      "other\n",
      "usag\n",
      ",\n",
      "like\n",
      "in\n",
      "”\n",
      "she\n",
      "is\n",
      "a\n",
      "big\n",
      "person\n",
      "”\n",
      "will\n",
      "remain\n",
      "somewhat\n",
      "ambigu\n",
      "to\n",
      "a\n",
      "person\n",
      "and\n",
      "a\n",
      "cognit\n",
      "nlp\n",
      "algorithm\n",
      "alik\n",
      "without\n",
      "addit\n",
      "inform\n",
      ".\n",
      "assign\n",
      "rel\n",
      "measur\n",
      "of\n",
      "mean\n",
      "to\n",
      "a\n",
      "word\n",
      ",\n",
      "phrase\n",
      ",\n",
      "sentenc\n",
      "or\n",
      "piec\n",
      "of\n",
      "text\n",
      "base\n",
      "on\n",
      "the\n",
      "inform\n",
      "present\n",
      "befor\n",
      "and\n",
      "after\n",
      "the\n",
      "piec\n",
      "of\n",
      "text\n",
      "be\n",
      "analyz\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "by\n",
      "mean\n",
      "of\n",
      "a\n",
      "probabilist\n",
      "context-fre\n",
      "grammar\n",
      "(\n",
      "pcfg\n",
      ")\n",
      ".\n",
      "the\n",
      "mathemat\n",
      "equat\n",
      "for\n",
      "such\n",
      "algorithm\n",
      "is\n",
      "present\n",
      "in\n",
      "us\n",
      "patent\n",
      "9269353\n",
      ":\n",
      "r\n",
      "m\n",
      "m\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      ")\n",
      "=\n",
      "p\n",
      "m\n",
      "m\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      ")\n",
      "×\n",
      "1\n",
      "2\n",
      "d\n",
      "(\n",
      "∑\n",
      "i\n",
      "=\n",
      "−\n",
      "d\n",
      "d\n",
      "(\n",
      "(\n",
      "p\n",
      "m\n",
      "m\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      "−\n",
      "1\n",
      ")\n",
      "×\n",
      "p\n",
      "f\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      ",\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      "−\n",
      "1\n",
      ")\n",
      ")\n",
      "i\n",
      ")\n",
      "{\n",
      "\\displaystyl\n",
      "{\n",
      "rmm\n",
      "(\n",
      "token_\n",
      "{\n",
      "n\n",
      "}\n",
      ")\n",
      "}\n",
      "=\n",
      "{\n",
      "pmm\n",
      "(\n",
      "token_\n",
      "{\n",
      "n\n",
      "}\n",
      ")\n",
      "}\n",
      "\\time\n",
      "{\n",
      "\\frac\n",
      "{\n",
      "1\n",
      "}\n",
      "{\n",
      "2d\n",
      "}\n",
      "}\n",
      "\\left\n",
      "(\n",
      "\\sum\n",
      "_\n",
      "{\n",
      "i=-d\n",
      "}\n",
      "^\n",
      "{\n",
      "d\n",
      "}\n",
      "{\n",
      "(\n",
      "(\n",
      "pmm\n",
      "(\n",
      "token_\n",
      "{\n",
      "n-1\n",
      "}\n",
      ")\n",
      "}\n",
      "\\time\n",
      "{\n",
      "pf\n",
      "(\n",
      "token_\n",
      "{\n",
      "n\n",
      "}\n",
      ",\n",
      "token_\n",
      "{\n",
      "n-1\n",
      "}\n",
      ")\n",
      ")\n",
      "_\n",
      "{\n",
      "i\n",
      "}\n",
      "}\n",
      "\\right\n",
      ")\n",
      "}\n",
      "where\n",
      ",\n",
      "rmm\n",
      ",\n",
      "is\n",
      "the\n",
      "rel\n",
      "measur\n",
      "of\n",
      "mean\n",
      "token\n",
      ",\n",
      "is\n",
      "ani\n",
      "block\n",
      "of\n",
      "text\n",
      ",\n",
      "sentenc\n",
      ",\n",
      "phrase\n",
      "or\n",
      "word\n",
      "n\n",
      ",\n",
      "is\n",
      "the\n",
      "number\n",
      "of\n",
      "token\n",
      "be\n",
      "analyz\n",
      "pmm\n",
      ",\n",
      "is\n",
      "the\n",
      "probabl\n",
      "measur\n",
      "of\n",
      "mean\n",
      "base\n",
      "on\n",
      "a\n",
      "corpora\n",
      "d\n",
      ",\n",
      "is\n",
      "the\n",
      "locat\n",
      "of\n",
      "the\n",
      "token\n",
      "along\n",
      "the\n",
      "sequenc\n",
      "of\n",
      "n-1\n",
      "token\n",
      "pf\n",
      ",\n",
      "is\n",
      "the\n",
      "probabl\n",
      "function\n",
      "specif\n",
      "to\n",
      "a\n",
      "languag\n",
      "tie\n",
      "with\n",
      "cognit\n",
      "linguist\n",
      "are\n",
      "part\n",
      "of\n",
      "the\n",
      "histor\n",
      "heritag\n",
      "of\n",
      "nlp\n",
      ",\n",
      "but\n",
      "they\n",
      "have\n",
      "been\n",
      "less\n",
      "frequent\n",
      "address\n",
      "sinc\n",
      "the\n",
      "statist\n",
      "turn\n",
      "dure\n",
      "the\n",
      "1990\n",
      ".\n",
      "nevertheless\n",
      ",\n",
      "approach\n",
      "to\n",
      "develop\n",
      "cognit\n",
      "model\n",
      "toward\n",
      "technic\n",
      "operationaliz\n",
      "framework\n",
      "have\n",
      "been\n",
      "pursu\n",
      "in\n",
      "the\n",
      "context\n",
      "of\n",
      "variou\n",
      "framework\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "of\n",
      "cognit\n",
      "grammar\n",
      ",\n",
      "[\n",
      "42\n",
      "]\n",
      "function\n",
      "grammar\n",
      ",\n",
      "[\n",
      "43\n",
      "]\n",
      "construct\n",
      "grammar\n",
      ",\n",
      "[\n",
      "44\n",
      "]\n",
      "comput\n",
      "psycholinguist\n",
      "and\n",
      "cognit\n",
      "neurosci\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "act-r\n",
      ")\n",
      ",\n",
      "howev\n",
      ",\n",
      "with\n",
      "limit\n",
      "uptak\n",
      "in\n",
      "mainstream\n",
      "nlp\n",
      "(\n",
      "as\n",
      "measur\n",
      "by\n",
      "presenc\n",
      "on\n",
      "major\n",
      "confer\n",
      "[\n",
      "45\n",
      "]\n",
      "of\n",
      "the\n",
      "acl\n",
      ")\n",
      ".\n",
      "more\n",
      "recent\n",
      ",\n",
      "idea\n",
      "of\n",
      "cognit\n",
      "nlp\n",
      "have\n",
      "been\n",
      "reviv\n",
      "as\n",
      "an\n",
      "approach\n",
      "to\n",
      "achiev\n",
      "explain\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "under\n",
      "the\n",
      "notion\n",
      "of\n",
      "``\n",
      "cognit\n",
      "ai\n",
      "''\n",
      ".\n",
      "[\n",
      "46\n",
      "]\n",
      "likewis\n",
      ",\n",
      "idea\n",
      "of\n",
      "cognit\n",
      "nlp\n",
      "are\n",
      "inher\n",
      "to\n",
      "neural\n",
      "model\n",
      "multimod\n",
      "nlp\n",
      "(\n",
      "although\n",
      "rare\n",
      "made\n",
      "explicit\n",
      ")\n",
      ".\n",
      "[\n",
      "47\n",
      "]\n",
      "see\n",
      "also\n",
      "[\n",
      "edit\n",
      "]\n",
      "1\n",
      "the\n",
      "road\n",
      "autom\n",
      "essay\n",
      "score\n",
      "biomed\n",
      "text\n",
      "mine\n",
      "compound\n",
      "term\n",
      "process\n",
      "comput\n",
      "linguist\n",
      "computer-assist\n",
      "review\n",
      "control\n",
      "natur\n",
      "languag\n",
      "deep\n",
      "learn\n",
      "deep\n",
      "linguist\n",
      "process\n",
      "distribut\n",
      "semant\n",
      "foreign\n",
      "languag\n",
      "read\n",
      "aid\n",
      "foreign\n",
      "languag\n",
      "write\n",
      "aid\n",
      "inform\n",
      "extract\n",
      "inform\n",
      "retriev\n",
      "languag\n",
      "and\n",
      "commun\n",
      "technolog\n",
      "languag\n",
      "technolog\n",
      "latent\n",
      "semant\n",
      "index\n",
      "native-languag\n",
      "identif\n",
      "natur\n",
      "languag\n",
      "program\n",
      "natur\n",
      "languag\n",
      "search\n",
      "outlin\n",
      "of\n",
      "natur\n",
      "languag\n",
      "process\n",
      "queri\n",
      "expans\n",
      "queri\n",
      "understand\n",
      "reific\n",
      "(\n",
      "linguist\n",
      ")\n",
      "speech\n",
      "process\n",
      "spoken\n",
      "dialogu\n",
      "system\n",
      "text-proof\n",
      "text\n",
      "simplif\n",
      "transform\n",
      "(\n",
      "machin\n",
      "learn\n",
      "model\n",
      ")\n",
      "truecas\n",
      "question\n",
      "answer\n",
      "word2vec\n",
      "refer\n",
      "[\n",
      "edit\n",
      "]\n",
      "^\n",
      "kongthon\n",
      ",\n",
      "alisa\n",
      ";\n",
      "sangkeettrakarn\n",
      ",\n",
      "chatchaw\n",
      ";\n",
      "kongyoung\n",
      ",\n",
      "sarawoot\n",
      ";\n",
      "haruechaiyasak\n",
      ",\n",
      "choochart\n",
      "(\n",
      "octob\n",
      "27–30\n",
      ",\n",
      "2009\n",
      ")\n",
      ".\n",
      "implement\n",
      "an\n",
      "onlin\n",
      "help\n",
      "desk\n",
      "system\n",
      "base\n",
      "on\n",
      "convers\n",
      "agent\n",
      ".\n",
      "mede\n",
      "'09\n",
      ":\n",
      "the\n",
      "intern\n",
      "confer\n",
      "on\n",
      "manag\n",
      "of\n",
      "emerg\n",
      "digit\n",
      "ecosystem\n",
      ".\n",
      "franc\n",
      ":\n",
      "acm\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/1643823.1643908\n",
      ".\n",
      "^\n",
      "hutchin\n",
      ",\n",
      "j\n",
      ".\n",
      "(\n",
      "2005\n",
      ")\n",
      ".\n",
      "``\n",
      "the\n",
      "histori\n",
      "of\n",
      "machin\n",
      "translat\n",
      "in\n",
      "a\n",
      "nutshel\n",
      "''\n",
      "(\n",
      "pdf\n",
      ")\n",
      ".\n",
      "[\n",
      "self-publish\n",
      "sourc\n",
      "]\n",
      "^\n",
      "koskenniemi\n",
      ",\n",
      "kimmo\n",
      "(\n",
      "1983\n",
      ")\n",
      ",\n",
      "two-level\n",
      "morpholog\n",
      ":\n",
      "a\n",
      "gener\n",
      "comput\n",
      "model\n",
      "of\n",
      "word-form\n",
      "recognit\n",
      "and\n",
      "product\n",
      "(\n",
      "pdf\n",
      ")\n",
      ",\n",
      "depart\n",
      "of\n",
      "gener\n",
      "linguist\n",
      ",\n",
      "univers\n",
      "of\n",
      "helsinki\n",
      "^\n",
      "joshi\n",
      ",\n",
      "a.\n",
      "k.\n",
      ",\n",
      "&\n",
      "weinstein\n",
      ",\n",
      "s.\n",
      "(\n",
      "1981\n",
      ",\n",
      "august\n",
      ")\n",
      ".\n",
      "control\n",
      "of\n",
      "infer\n",
      ":\n",
      "role\n",
      "of\n",
      "some\n",
      "aspect\n",
      "of\n",
      "discours\n",
      "structure-cent\n",
      ".\n",
      "in\n",
      "ijcai\n",
      "(\n",
      "pp\n",
      ".\n",
      "385-387\n",
      ")\n",
      ".\n",
      "^\n",
      "guida\n",
      ",\n",
      "g.\n",
      ";\n",
      "mauri\n",
      ",\n",
      "g.\n",
      "(\n",
      "juli\n",
      "1986\n",
      ")\n",
      ".\n",
      "``\n",
      "evalu\n",
      "of\n",
      "natur\n",
      "languag\n",
      "process\n",
      "system\n",
      ":\n",
      "issu\n",
      "and\n",
      "approach\n",
      "''\n",
      ".\n",
      "proceed\n",
      "of\n",
      "the\n",
      "ieee\n",
      ".\n",
      "74\n",
      "(\n",
      "7\n",
      ")\n",
      ":\n",
      "1026–1035\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1109/proc.1986.13580\n",
      ".\n",
      "issn\n",
      "1558-2256\n",
      ".\n",
      "s2cid\n",
      "30688575\n",
      ".\n",
      "^\n",
      "chomskyan\n",
      "linguist\n",
      "encourag\n",
      "the\n",
      "investig\n",
      "of\n",
      "``\n",
      "corner\n",
      "case\n",
      "``\n",
      "that\n",
      "stress\n",
      "the\n",
      "limit\n",
      "of\n",
      "it\n",
      "theoret\n",
      "model\n",
      "(\n",
      "compar\n",
      "to\n",
      "patholog\n",
      "phenomena\n",
      "in\n",
      "mathemat\n",
      ")\n",
      ",\n",
      "typic\n",
      "creat\n",
      "use\n",
      "thought\n",
      "experi\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "systemat\n",
      "investig\n",
      "of\n",
      "typic\n",
      "phenomena\n",
      "that\n",
      "occur\n",
      "in\n",
      "real-world\n",
      "data\n",
      ",\n",
      "as\n",
      "is\n",
      "the\n",
      "case\n",
      "in\n",
      "corpu\n",
      "linguist\n",
      ".\n",
      "the\n",
      "creation\n",
      "and\n",
      "use\n",
      "of\n",
      "such\n",
      "corpora\n",
      "of\n",
      "real-world\n",
      "data\n",
      "is\n",
      "a\n",
      "fundament\n",
      "part\n",
      "of\n",
      "machine-learn\n",
      "algorithm\n",
      "for\n",
      "natur\n",
      "languag\n",
      "process\n",
      ".\n",
      "in\n",
      "addit\n",
      ",\n",
      "theoret\n",
      "underpin\n",
      "of\n",
      "chomskyan\n",
      "linguist\n",
      "such\n",
      "as\n",
      "the\n",
      "so-cal\n",
      "``\n",
      "poverti\n",
      "of\n",
      "the\n",
      "stimulu\n",
      "``\n",
      "argument\n",
      "entail\n",
      "that\n",
      "gener\n",
      "learn\n",
      "algorithm\n",
      ",\n",
      "as\n",
      "are\n",
      "typic\n",
      "use\n",
      "in\n",
      "machin\n",
      "learn\n",
      ",\n",
      "can\n",
      "not\n",
      "be\n",
      "success\n",
      "in\n",
      "languag\n",
      "process\n",
      ".\n",
      "as\n",
      "a\n",
      "result\n",
      ",\n",
      "the\n",
      "chomskyan\n",
      "paradigm\n",
      "discourag\n",
      "the\n",
      "applic\n",
      "of\n",
      "such\n",
      "model\n",
      "to\n",
      "languag\n",
      "process\n",
      ".\n",
      "^\n",
      "goldberg\n",
      ",\n",
      "yoav\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "``\n",
      "a\n",
      "primer\n",
      "on\n",
      "neural\n",
      "network\n",
      "model\n",
      "for\n",
      "natur\n",
      "languag\n",
      "process\n",
      "''\n",
      ".\n",
      "journal\n",
      "of\n",
      "artifici\n",
      "intellig\n",
      "research\n",
      ".\n",
      "57\n",
      ":\n",
      "345–420\n",
      ".\n",
      "arxiv\n",
      ":\n",
      "1807.10854\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1613/jair.4992\n",
      ".\n",
      "s2cid\n",
      "8273530\n",
      ".\n",
      "^\n",
      "goodfellow\n",
      ",\n",
      "ian\n",
      ";\n",
      "bengio\n",
      ",\n",
      "yoshua\n",
      ";\n",
      "courvil\n",
      ",\n",
      "aaron\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "deep\n",
      "learn\n",
      ".\n",
      "mit\n",
      "press\n",
      ".\n",
      "^\n",
      "jozefowicz\n",
      ",\n",
      "rafal\n",
      ";\n",
      "vinyal\n",
      ",\n",
      "oriol\n",
      ";\n",
      "schuster\n",
      ",\n",
      "mike\n",
      ";\n",
      "shazeer\n",
      ",\n",
      "noam\n",
      ";\n",
      "wu\n",
      ",\n",
      "yonghui\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "explor\n",
      "the\n",
      "limit\n",
      "of\n",
      "languag\n",
      "model\n",
      ".\n",
      "arxiv\n",
      ":\n",
      "1602.02410\n",
      ".\n",
      "bibcod\n",
      ":\n",
      "2016arxiv160202410j\n",
      ".\n",
      "^\n",
      "choe\n",
      ",\n",
      "do\n",
      "kook\n",
      ";\n",
      "charniak\n",
      ",\n",
      "eugen\n",
      ".\n",
      "``\n",
      "pars\n",
      "as\n",
      "languag\n",
      "model\n",
      "''\n",
      ".\n",
      "emnlp\n",
      "2016\n",
      ".\n",
      "^\n",
      "vinyal\n",
      ",\n",
      "oriol\n",
      ";\n",
      "et\n",
      "al\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "grammar\n",
      "as\n",
      "a\n",
      "foreign\n",
      "languag\n",
      "''\n",
      "(\n",
      "pdf\n",
      ")\n",
      ".\n",
      "nips2015\n",
      ".\n",
      "arxiv\n",
      ":\n",
      "1412.7449\n",
      ".\n",
      "bibcod\n",
      ":\n",
      "2014arxiv1412.7449v\n",
      ".\n",
      "^\n",
      "turchin\n",
      ",\n",
      "alexand\n",
      ";\n",
      "florez\n",
      "buil\n",
      ",\n",
      "luisa\n",
      "f.\n",
      "(\n",
      "2021-03-19\n",
      ")\n",
      ".\n",
      "``\n",
      "use\n",
      "natur\n",
      "languag\n",
      "process\n",
      "to\n",
      "measur\n",
      "and\n",
      "improv\n",
      "qualiti\n",
      "of\n",
      "diabet\n",
      "care\n",
      ":\n",
      "a\n",
      "systemat\n",
      "review\n",
      "''\n",
      ".\n",
      "journal\n",
      "of\n",
      "diabet\n",
      "scienc\n",
      "and\n",
      "technolog\n",
      ".\n",
      "15\n",
      "(\n",
      "3\n",
      ")\n",
      ":\n",
      "553–560\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1177/19322968211000831\n",
      ".\n",
      "issn\n",
      "1932-2968\n",
      ".\n",
      "pmc\n",
      "8120048\n",
      ".\n",
      "pmid\n",
      "33736486\n",
      ".\n",
      "^\n",
      "winograd\n",
      ",\n",
      "terri\n",
      "(\n",
      "1971\n",
      ")\n",
      ".\n",
      "procedur\n",
      "as\n",
      "a\n",
      "represent\n",
      "for\n",
      "data\n",
      "in\n",
      "a\n",
      "comput\n",
      "program\n",
      "for\n",
      "understand\n",
      "natur\n",
      "languag\n",
      "(\n",
      "thesi\n",
      ")\n",
      ".\n",
      "^\n",
      "schank\n",
      ",\n",
      "roger\n",
      "c.\n",
      ";\n",
      "abelson\n",
      ",\n",
      "robert\n",
      "p.\n",
      "(\n",
      "1977\n",
      ")\n",
      ".\n",
      "script\n",
      ",\n",
      "plan\n",
      ",\n",
      "goal\n",
      ",\n",
      "and\n",
      "understand\n",
      ":\n",
      "an\n",
      "inquiri\n",
      "into\n",
      "human\n",
      "knowledg\n",
      "structur\n",
      ".\n",
      "hillsdal\n",
      ":\n",
      "erlbaum\n",
      ".\n",
      "isbn\n",
      "0-470-99033-3\n",
      ".\n",
      "^\n",
      "mark\n",
      "johnson\n",
      ".\n",
      "how\n",
      "the\n",
      "statist\n",
      "revolut\n",
      "chang\n",
      "(\n",
      "comput\n",
      ")\n",
      "linguist\n",
      ".\n",
      "proceed\n",
      "of\n",
      "the\n",
      "eacl\n",
      "2009\n",
      "workshop\n",
      "on\n",
      "the\n",
      "interact\n",
      "between\n",
      "linguist\n",
      "and\n",
      "comput\n",
      "linguist\n",
      ".\n",
      "^\n",
      "philip\n",
      "resnik\n",
      ".\n",
      "four\n",
      "revolut\n",
      ".\n",
      "languag\n",
      "log\n",
      ",\n",
      "februari\n",
      "5\n",
      ",\n",
      "2011\n",
      ".\n",
      "^\n",
      "``\n",
      "investig\n",
      "complex-valu\n",
      "represent\n",
      "in\n",
      "nlp\n",
      "''\n",
      "(\n",
      "pdf\n",
      ")\n",
      ".\n",
      "^\n",
      "trabelsi\n",
      ",\n",
      "chiheb\n",
      ";\n",
      "bilaniuk\n",
      ",\n",
      "olexa\n",
      ";\n",
      "zhang\n",
      ",\n",
      "ying\n",
      ";\n",
      "serdyuk\n",
      ",\n",
      "dmitriy\n",
      ";\n",
      "subramanian\n",
      ",\n",
      "sandeep\n",
      ";\n",
      "santo\n",
      ",\n",
      "joão\n",
      "felip\n",
      ";\n",
      "mehri\n",
      ",\n",
      "soroush\n",
      ";\n",
      "rostamzadeh\n",
      ",\n",
      "negar\n",
      ";\n",
      "bengio\n",
      ",\n",
      "yoshua\n",
      ";\n",
      "pal\n",
      ",\n",
      "christoph\n",
      "j\n",
      ".\n",
      "(\n",
      "2018-02-25\n",
      ")\n",
      ".\n",
      "``\n",
      "deep\n",
      "complex\n",
      "network\n",
      "''\n",
      ".\n",
      "arxiv\n",
      ":\n",
      "1705.09792\n",
      "[\n",
      "cs.ne\n",
      "]\n",
      ".\n",
      "^\n",
      "socher\n",
      ",\n",
      "richard\n",
      ".\n",
      "``\n",
      "deep\n",
      "learn\n",
      "for\n",
      "nlp-acl\n",
      "2012\n",
      "tutori\n",
      "''\n",
      ".\n",
      "www.socher.org\n",
      ".\n",
      "retriev\n",
      "2020-08-17\n",
      ".\n",
      "thi\n",
      "wa\n",
      "an\n",
      "earli\n",
      "deep\n",
      "learn\n",
      "tutori\n",
      "at\n",
      "the\n",
      "acl\n",
      "2012\n",
      "and\n",
      "met\n",
      "with\n",
      "both\n",
      "interest\n",
      "and\n",
      "(\n",
      "at\n",
      "the\n",
      "time\n",
      ")\n",
      "skeptic\n",
      "by\n",
      "most\n",
      "particip\n",
      ".\n",
      "until\n",
      "then\n",
      ",\n",
      "neural\n",
      "learn\n",
      "wa\n",
      "basic\n",
      "reject\n",
      "becaus\n",
      "of\n",
      "it\n",
      "lack\n",
      "of\n",
      "statist\n",
      "interpret\n",
      ".\n",
      "until\n",
      "2015\n",
      ",\n",
      "deep\n",
      "learn\n",
      "had\n",
      "evolv\n",
      "into\n",
      "the\n",
      "major\n",
      "framework\n",
      "of\n",
      "nlp\n",
      ".\n",
      "^\n",
      "annamoradnejad\n",
      ",\n",
      "i.\n",
      "and\n",
      "zoghi\n",
      ",\n",
      "g.\n",
      "(\n",
      "2020\n",
      ")\n",
      ".\n",
      "colbert\n",
      ":\n",
      "use\n",
      "bert\n",
      "sentenc\n",
      "embed\n",
      "for\n",
      "humor\n",
      "detect\n",
      ".\n",
      "arxiv\n",
      "preprint\n",
      "arxiv:2004.12765\n",
      ".\n",
      "^\n",
      "yi\n",
      ",\n",
      "chucai\n",
      ";\n",
      "tian\n",
      ",\n",
      "yingli\n",
      "(\n",
      "2012\n",
      ")\n",
      ",\n",
      "``\n",
      "assist\n",
      "text\n",
      "read\n",
      "from\n",
      "complex\n",
      "background\n",
      "for\n",
      "blind\n",
      "person\n",
      "''\n",
      ",\n",
      "camera-bas\n",
      "document\n",
      "analysi\n",
      "and\n",
      "recognit\n",
      ",\n",
      "springer\n",
      "berlin\n",
      "heidelberg\n",
      ",\n",
      "pp\n",
      ".\n",
      "15–28\n",
      ",\n",
      "citeseerx\n",
      "10.1.1.668.869\n",
      ",\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-642-29364-1_2\n",
      ",\n",
      "isbn\n",
      "9783642293634\n",
      "^\n",
      "``\n",
      "what\n",
      "is\n",
      "natur\n",
      "languag\n",
      "process\n",
      "?\n",
      "intro\n",
      "to\n",
      "nlp\n",
      "in\n",
      "machin\n",
      "learn\n",
      "''\n",
      ".\n",
      "gyansetu\n",
      "!\n",
      ".\n",
      "2020-12-06\n",
      ".\n",
      "retriev\n",
      "2021-01-09\n",
      ".\n",
      "^\n",
      "kishorjit\n",
      ",\n",
      "n.\n",
      ";\n",
      "vidya\n",
      ",\n",
      "raj\n",
      "rk\n",
      ".\n",
      ";\n",
      "nirmal\n",
      ",\n",
      "y.\n",
      ";\n",
      "sivaji\n",
      ",\n",
      "b\n",
      ".\n",
      "(\n",
      "2012\n",
      ")\n",
      ".\n",
      "``\n",
      "manipuri\n",
      "morphem\n",
      "identif\n",
      "''\n",
      "(\n",
      "pdf\n",
      ")\n",
      ".\n",
      "proceed\n",
      "of\n",
      "the\n",
      "3rd\n",
      "workshop\n",
      "on\n",
      "south\n",
      "and\n",
      "southeast\n",
      "asian\n",
      "natur\n",
      "languag\n",
      "process\n",
      "(\n",
      "sanlp\n",
      ")\n",
      ".\n",
      "cole\n",
      "2012\n",
      ",\n",
      "mumbai\n",
      ",\n",
      "decemb\n",
      "2012\n",
      ":\n",
      "95–108\n",
      ".\n",
      "cs1\n",
      "maint\n",
      ":\n",
      "locat\n",
      "(\n",
      "link\n",
      ")\n",
      "^\n",
      "klein\n",
      ",\n",
      "dan\n",
      ";\n",
      "man\n",
      ",\n",
      "christoph\n",
      "d.\n",
      "(\n",
      "2002\n",
      ")\n",
      ".\n",
      "``\n",
      "natur\n",
      "languag\n",
      "grammar\n",
      "induct\n",
      "use\n",
      "a\n",
      "constituent-context\n",
      "model\n",
      "''\n",
      "(\n",
      "pdf\n",
      ")\n",
      ".\n",
      "advanc\n",
      "in\n",
      "neural\n",
      "inform\n",
      "process\n",
      "system\n",
      ".\n",
      "^\n",
      "pascal\n",
      "recogn\n",
      "textual\n",
      "entail\n",
      "challeng\n",
      "(\n",
      "rte-7\n",
      ")\n",
      "http\n",
      ":\n",
      "//tac.nist.gov//2011/rte/\n",
      "^\n",
      "lippi\n",
      ",\n",
      "marco\n",
      ";\n",
      "torroni\n",
      ",\n",
      "paolo\n",
      "(\n",
      "2016-04-20\n",
      ")\n",
      ".\n",
      "``\n",
      "argument\n",
      "mine\n",
      ":\n",
      "state\n",
      "of\n",
      "the\n",
      "art\n",
      "and\n",
      "emerg\n",
      "trend\n",
      "''\n",
      ".\n",
      "acm\n",
      "transact\n",
      "on\n",
      "internet\n",
      "technolog\n",
      ".\n",
      "16\n",
      "(\n",
      "2\n",
      ")\n",
      ":\n",
      "1–25\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/2850417\n",
      ".\n",
      "issn\n",
      "1533-5399\n",
      ".\n",
      "s2cid\n",
      "9561587\n",
      ".\n",
      "^\n",
      "``\n",
      "argument\n",
      "mine\n",
      "-\n",
      "ijcai2016\n",
      "tutori\n",
      "''\n",
      ".\n",
      "www.i3s.unice.fr\n",
      ".\n",
      "retriev\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "nlp\n",
      "approach\n",
      "to\n",
      "comput\n",
      "argument\n",
      "–\n",
      "acl\n",
      "2016\n",
      ",\n",
      "berlin\n",
      "''\n",
      ".\n",
      "retriev\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "u\n",
      "b\n",
      "u\n",
      "w\n",
      "e\n",
      "b\n",
      ":\n",
      ":\n",
      "racter\n",
      "''\n",
      ".\n",
      "www.ubu.com\n",
      ".\n",
      "retriev\n",
      "2020-08-17\n",
      ".\n",
      "^\n",
      "writer\n",
      ",\n",
      "beta\n",
      "(\n",
      "2019\n",
      ")\n",
      ".\n",
      "lithium-ion\n",
      "batteri\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-030-16800-1\n",
      ".\n",
      "isbn\n",
      "978-3-030-16799-8\n",
      ".\n",
      "^\n",
      "``\n",
      "document\n",
      "understand\n",
      "ai\n",
      "on\n",
      "googl\n",
      "cloud\n",
      "(\n",
      "cloud\n",
      "next\n",
      "'19\n",
      ")\n",
      "-\n",
      "youtub\n",
      "''\n",
      ".\n",
      "www.youtube.com\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "administr\n",
      ".\n",
      "``\n",
      "centr\n",
      "for\n",
      "languag\n",
      "technolog\n",
      "(\n",
      "clt\n",
      ")\n",
      "''\n",
      ".\n",
      "macquari\n",
      "univers\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "share\n",
      "task\n",
      ":\n",
      "grammat\n",
      "error\n",
      "correct\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "share\n",
      "task\n",
      ":\n",
      "grammat\n",
      "error\n",
      "correct\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "duan\n",
      ",\n",
      "yucong\n",
      ";\n",
      "cruz\n",
      ",\n",
      "christoph\n",
      "(\n",
      "2011\n",
      ")\n",
      ".\n",
      "``\n",
      "formal\n",
      "semant\n",
      "of\n",
      "natur\n",
      "languag\n",
      "through\n",
      "conceptu\n",
      "from\n",
      "exist\n",
      "''\n",
      ".\n",
      "intern\n",
      "journal\n",
      "of\n",
      "innov\n",
      ",\n",
      "manag\n",
      "and\n",
      "technolog\n",
      ".\n",
      "2\n",
      "(\n",
      "1\n",
      ")\n",
      ":\n",
      "37–42\n",
      ".\n",
      "archiv\n",
      "from\n",
      "the\n",
      "origin\n",
      "on\n",
      "2011-10-09\n",
      ".\n",
      "^\n",
      "``\n",
      "previou\n",
      "share\n",
      "task\n",
      "|\n",
      "conll\n",
      "''\n",
      ".\n",
      "www.conll.org\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "cognit\n",
      "''\n",
      ".\n",
      "lexico\n",
      ".\n",
      "oxford\n",
      "univers\n",
      "press\n",
      "and\n",
      "dictionary.com\n",
      ".\n",
      "retriev\n",
      "6\n",
      "may\n",
      "2020\n",
      ".\n",
      "^\n",
      "``\n",
      "ask\n",
      "the\n",
      "cognit\n",
      "scientist\n",
      "''\n",
      ".\n",
      "american\n",
      "feder\n",
      "of\n",
      "teacher\n",
      ".\n",
      "8\n",
      "august\n",
      "2014\n",
      ".\n",
      "cognit\n",
      "scienc\n",
      "is\n",
      "an\n",
      "interdisciplinari\n",
      "field\n",
      "of\n",
      "research\n",
      "from\n",
      "linguist\n",
      ",\n",
      "psycholog\n",
      ",\n",
      "neurosci\n",
      ",\n",
      "philosophi\n",
      ",\n",
      "comput\n",
      "scienc\n",
      ",\n",
      "and\n",
      "anthropolog\n",
      "that\n",
      "seek\n",
      "to\n",
      "understand\n",
      "the\n",
      "mind\n",
      ".\n",
      "^\n",
      "robinson\n",
      ",\n",
      "peter\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "handbook\n",
      "of\n",
      "cognit\n",
      "linguist\n",
      "and\n",
      "second\n",
      "languag\n",
      "acquisit\n",
      ".\n",
      "routledg\n",
      ".\n",
      "pp\n",
      ".\n",
      "3–8\n",
      ".\n",
      "isbn\n",
      "978-0-805-85352-0\n",
      ".\n",
      "^\n",
      "lakoff\n",
      ",\n",
      "georg\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "philosophi\n",
      "in\n",
      "the\n",
      "flesh\n",
      ":\n",
      "the\n",
      "embodi\n",
      "mind\n",
      "and\n",
      "it\n",
      "challeng\n",
      "to\n",
      "western\n",
      "philosophi\n",
      ";\n",
      "appendix\n",
      ":\n",
      "the\n",
      "neural\n",
      "theori\n",
      "of\n",
      "languag\n",
      "paradigm\n",
      ".\n",
      "new\n",
      "york\n",
      "basic\n",
      "book\n",
      ".\n",
      "pp\n",
      ".\n",
      "569–583\n",
      ".\n",
      "isbn\n",
      "978-0-465-05674-3\n",
      ".\n",
      "^\n",
      "strauss\n",
      ",\n",
      "claudia\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "a\n",
      "cognit\n",
      "theori\n",
      "of\n",
      "cultur\n",
      "mean\n",
      ".\n",
      "cambridg\n",
      "univers\n",
      "press\n",
      ".\n",
      "pp\n",
      ".\n",
      "156–164\n",
      ".\n",
      "isbn\n",
      "978-0-521-59541-4\n",
      ".\n",
      "^\n",
      "``\n",
      "univers\n",
      "conceptu\n",
      "cognit\n",
      "annot\n",
      "(\n",
      "ucca\n",
      ")\n",
      "''\n",
      ".\n",
      "univers\n",
      "conceptu\n",
      "cognit\n",
      "annot\n",
      "(\n",
      "ucca\n",
      ")\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "rodríguez\n",
      ",\n",
      "f.\n",
      "c.\n",
      ",\n",
      "&\n",
      "mairal-usón\n",
      ",\n",
      "r.\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "build\n",
      "an\n",
      "rrg\n",
      "comput\n",
      "grammar\n",
      ".\n",
      "onomazein\n",
      ",\n",
      "(\n",
      "34\n",
      ")\n",
      ",\n",
      "86-117\n",
      ".\n",
      "^\n",
      "``\n",
      "fluid\n",
      "construct\n",
      "grammar\n",
      "–\n",
      "a\n",
      "fulli\n",
      "oper\n",
      "process\n",
      "system\n",
      "for\n",
      "construct\n",
      "grammar\n",
      "''\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "acl\n",
      "member\n",
      "portal\n",
      "|\n",
      "the\n",
      "associ\n",
      "for\n",
      "comput\n",
      "linguist\n",
      "member\n",
      "portal\n",
      "''\n",
      ".\n",
      "www.aclweb.org\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "chunk\n",
      "and\n",
      "rule\n",
      "''\n",
      ".\n",
      "www.w3.org\n",
      ".\n",
      "retriev\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "socher\n",
      ",\n",
      "richard\n",
      ";\n",
      "karpathi\n",
      ",\n",
      "andrej\n",
      ";\n",
      "le\n",
      ",\n",
      "quoc\n",
      "v.\n",
      ";\n",
      "man\n",
      ",\n",
      "christoph\n",
      "d.\n",
      ";\n",
      "ng\n",
      ",\n",
      "andrew\n",
      "y\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "ground\n",
      "composit\n",
      "semant\n",
      "for\n",
      "find\n",
      "and\n",
      "describ\n",
      "imag\n",
      "with\n",
      "sentenc\n",
      "''\n",
      ".\n",
      "transact\n",
      "of\n",
      "the\n",
      "associ\n",
      "for\n",
      "comput\n",
      "linguist\n",
      ".\n",
      "2\n",
      ":\n",
      "207–218\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1162/tacl_a_00177\n",
      ".\n",
      "s2cid\n",
      "2317858\n",
      ".\n",
      "further\n",
      "read\n",
      "[\n",
      "edit\n",
      "]\n",
      "bate\n",
      ",\n",
      "m\n",
      "(\n",
      "1995\n",
      ")\n",
      ".\n",
      "``\n",
      "model\n",
      "of\n",
      "natur\n",
      "languag\n",
      "understand\n",
      "''\n",
      ".\n",
      "proceed\n",
      "of\n",
      "the\n",
      "nation\n",
      "academi\n",
      "of\n",
      "scienc\n",
      "of\n",
      "the\n",
      "unit\n",
      "state\n",
      "of\n",
      "america\n",
      ".\n",
      "92\n",
      "(\n",
      "22\n",
      ")\n",
      ":\n",
      "9977–9982\n",
      ".\n",
      "bibcod\n",
      ":\n",
      "1995pna\n",
      "...\n",
      "92.9977b\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1073/pnas.92.22.9977\n",
      ".\n",
      "pmc\n",
      "40721\n",
      ".\n",
      "pmid\n",
      "7479812\n",
      ".\n",
      "steven\n",
      "bird\n",
      ",\n",
      "ewan\n",
      "klein\n",
      ",\n",
      "and\n",
      "edward\n",
      "loper\n",
      "(\n",
      "2009\n",
      ")\n",
      ".\n",
      "natur\n",
      "languag\n",
      "process\n",
      "with\n",
      "python\n",
      ".\n",
      "o'reilli\n",
      "media\n",
      ".\n",
      "isbn\n",
      "978-0-596-51649-9\n",
      ".\n",
      "daniel\n",
      "jurafski\n",
      "and\n",
      "jame\n",
      "h.\n",
      "martin\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "speech\n",
      "and\n",
      "languag\n",
      "process\n",
      ",\n",
      "2nd\n",
      "edit\n",
      ".\n",
      "pearson\n",
      "prentic\n",
      "hall\n",
      ".\n",
      "isbn\n",
      "978-0-13-187321-6\n",
      ".\n",
      "moham\n",
      "zakaria\n",
      "kurdi\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "natur\n",
      "languag\n",
      "process\n",
      "and\n",
      "comput\n",
      "linguist\n",
      ":\n",
      "speech\n",
      ",\n",
      "morpholog\n",
      ",\n",
      "and\n",
      "syntax\n",
      ",\n",
      "volum\n",
      "1\n",
      ".\n",
      "iste-wiley\n",
      ".\n",
      "isbn\n",
      "978-1848218482\n",
      ".\n",
      "moham\n",
      "zakaria\n",
      "kurdi\n",
      "(\n",
      "2017\n",
      ")\n",
      ".\n",
      "natur\n",
      "languag\n",
      "process\n",
      "and\n",
      "comput\n",
      "linguist\n",
      ":\n",
      "semant\n",
      ",\n",
      "discours\n",
      ",\n",
      "and\n",
      "applic\n",
      ",\n",
      "volum\n",
      "2\n",
      ".\n",
      "iste-wiley\n",
      ".\n",
      "isbn\n",
      "978-1848219212\n",
      ".\n",
      "christoph\n",
      "d.\n",
      "man\n",
      ",\n",
      "prabhakar\n",
      "raghavan\n",
      ",\n",
      "and\n",
      "hinrich\n",
      "schütze\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "introduct\n",
      "to\n",
      "inform\n",
      "retriev\n",
      ".\n",
      "cambridg\n",
      "univers\n",
      "press\n",
      ".\n",
      "isbn\n",
      "978-0-521-86571-5\n",
      ".\n",
      "offici\n",
      "html\n",
      "and\n",
      "pdf\n",
      "version\n",
      "avail\n",
      "without\n",
      "charg\n",
      ".\n",
      "christoph\n",
      "d.\n",
      "man\n",
      "and\n",
      "hinrich\n",
      "schütze\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "foundat\n",
      "of\n",
      "statist\n",
      "natur\n",
      "languag\n",
      "process\n",
      ".\n",
      "the\n",
      "mit\n",
      "press\n",
      ".\n",
      "isbn\n",
      "978-0-262-13360-9\n",
      ".\n",
      "david\n",
      "m.\n",
      "w.\n",
      "power\n",
      "and\n",
      "christoph\n",
      "c.\n",
      "r.\n",
      "turk\n",
      "(\n",
      "1989\n",
      ")\n",
      ".\n",
      "machin\n",
      "learn\n",
      "of\n",
      "natur\n",
      "languag\n",
      ".\n",
      "springer-verlag\n",
      ".\n",
      "isbn\n",
      "978-0-387-19557-5\n",
      ".\n",
      "extern\n",
      "link\n",
      "[\n",
      "edit\n",
      "]\n",
      "media\n",
      "relat\n",
      "to\n",
      "natur\n",
      "languag\n",
      "process\n",
      "at\n",
      "wikimedia\n",
      "common\n",
      "v\n",
      "t\n",
      "e\n",
      "natur\n",
      "languag\n",
      "process\n",
      "gener\n",
      "term\n",
      "ai-complet\n",
      "bag-of-word\n",
      "n-gram\n",
      "bigram\n",
      "trigram\n",
      "comput\n",
      "linguist\n",
      "natural-languag\n",
      "understand\n",
      "stopword\n",
      "text\n",
      "process\n",
      "text\n",
      "analysi\n",
      "colloc\n",
      "extract\n",
      "concept\n",
      "mine\n",
      "corefer\n",
      "resolut\n",
      "deep\n",
      "linguist\n",
      "process\n",
      "distant\n",
      "read\n",
      "inform\n",
      "extract\n",
      "named-ent\n",
      "recognit\n",
      "ontolog\n",
      "learn\n",
      "pars\n",
      "part-of-speech\n",
      "tag\n",
      "semant\n",
      "role\n",
      "label\n",
      "semant\n",
      "similar\n",
      "sentiment\n",
      "analysi\n",
      "terminolog\n",
      "extract\n",
      "text\n",
      "mine\n",
      "textual\n",
      "entail\n",
      "truecas\n",
      "word-sens\n",
      "disambigu\n",
      "word-sens\n",
      "induct\n",
      "text\n",
      "segment\n",
      "compound-term\n",
      "process\n",
      "lemmatis\n",
      "lexic\n",
      "analysi\n",
      "text\n",
      "chunk\n",
      "stem\n",
      "sentenc\n",
      "segment\n",
      "word\n",
      "segment\n",
      "automat\n",
      "summar\n",
      "multi-docu\n",
      "summar\n",
      "sentenc\n",
      "extract\n",
      "text\n",
      "simplif\n",
      "machin\n",
      "translat\n",
      "computer-assist\n",
      "example-bas\n",
      "rule-bas\n",
      "statist\n",
      "transfer-bas\n",
      "neural\n",
      "distribut\n",
      "semant\n",
      "model\n",
      "bert\n",
      "document-term\n",
      "matrix\n",
      "explicit\n",
      "semant\n",
      "analysi\n",
      "fasttext\n",
      "glove\n",
      "latent\n",
      "semant\n",
      "analysi\n",
      "word\n",
      "embed\n",
      "word2vec\n",
      "languag\n",
      "resourc\n",
      ",\n",
      "dataset\n",
      "and\n",
      "corpora\n",
      "type\n",
      "and\n",
      "standard\n",
      "corpu\n",
      "linguist\n",
      "lexic\n",
      "resourc\n",
      "linguist\n",
      "link\n",
      "open\n",
      "data\n",
      "machine-read\n",
      "dictionari\n",
      "parallel\n",
      "text\n",
      "propbank\n",
      "semant\n",
      "network\n",
      "simpl\n",
      "knowledg\n",
      "organ\n",
      "system\n",
      "speech\n",
      "corpu\n",
      "text\n",
      "corpu\n",
      "thesauru\n",
      "(\n",
      "inform\n",
      "retriev\n",
      ")\n",
      "treebank\n",
      "univers\n",
      "depend\n",
      "data\n",
      "babelnet\n",
      "bank\n",
      "of\n",
      "english\n",
      "dbpedia\n",
      "framenet\n",
      "googl\n",
      "ngram\n",
      "viewer\n",
      "thoughttreasur\n",
      "ubi\n",
      "wordnet\n",
      "automat\n",
      "identif\n",
      "and\n",
      "data\n",
      "captur\n",
      "speech\n",
      "recognit\n",
      "speech\n",
      "segment\n",
      "speech\n",
      "synthesi\n",
      "natur\n",
      "languag\n",
      "gener\n",
      "optic\n",
      "charact\n",
      "recognit\n",
      "topic\n",
      "model\n",
      "document\n",
      "classif\n",
      "latent\n",
      "dirichlet\n",
      "alloc\n",
      "pachinko\n",
      "alloc\n",
      "computer-assist\n",
      "review\n",
      "autom\n",
      "essay\n",
      "score\n",
      "concordanc\n",
      "grammar\n",
      "checker\n",
      "predict\n",
      "text\n",
      "spell\n",
      "checker\n",
      "syntax\n",
      "guess\n",
      "natur\n",
      "languag\n",
      "user\n",
      "interfac\n",
      "chatbot\n",
      "interact\n",
      "fiction\n",
      "question\n",
      "answer\n",
      "virtual\n",
      "assist\n",
      "voic\n",
      "user\n",
      "interfac\n",
      "other\n",
      "softwar\n",
      "natur\n",
      "languag\n",
      "toolkit\n",
      "spaci\n",
      "author\n",
      "control\n",
      ":\n",
      "nation\n",
      "librari\n",
      "unit\n",
      "state\n",
      "japan\n",
      "languag\n",
      "portal\n",
      "retriev\n",
      "from\n",
      "``\n",
      "http\n",
      ":\n",
      "//en.wikipedia.org/w/index.php\n",
      "?\n",
      "title=natural_language_process\n",
      "&\n",
      "oldid=1048621730\n",
      "``\n",
      "categori\n",
      ":\n",
      "natur\n",
      "languag\n",
      "process\n",
      "comput\n",
      "linguist\n",
      "speech\n",
      "recognit\n",
      "comput\n",
      "field\n",
      "of\n",
      "studi\n",
      "artifici\n",
      "intellig\n",
      "hidden\n",
      "categori\n",
      ":\n",
      "cs1\n",
      "maint\n",
      ":\n",
      "locat\n",
      "articl\n",
      "with\n",
      "short\n",
      "descript\n",
      "short\n",
      "descript\n",
      "match\n",
      "wikidata\n",
      "common\n",
      "categori\n",
      "link\n",
      "from\n",
      "wikidata\n",
      "articl\n",
      "with\n",
      "lccn\n",
      "identifi\n",
      "articl\n",
      "with\n",
      "ndl\n",
      "identifi\n",
      "navig\n",
      "menu\n",
      "person\n",
      "tool\n",
      "not\n",
      "log\n",
      "in\n",
      "talk\n",
      "contribut\n",
      "creat\n",
      "account\n",
      "log\n",
      "in\n",
      "namespac\n",
      "articl\n",
      "talk\n",
      "variant\n",
      "expand\n",
      "collaps\n",
      "view\n",
      "read\n",
      "edit\n",
      "view\n",
      "histori\n",
      "more\n",
      "expand\n",
      "collaps\n",
      "search\n",
      "navig\n",
      "main\n",
      "page\n",
      "content\n",
      "current\n",
      "event\n",
      "random\n",
      "articl\n",
      "about\n",
      "wikipedia\n",
      "contact\n",
      "us\n",
      "donat\n",
      "contribut\n",
      "help\n",
      "learn\n",
      "to\n",
      "edit\n",
      "commun\n",
      "portal\n",
      "recent\n",
      "chang\n",
      "upload\n",
      "file\n",
      "tool\n",
      "what\n",
      "link\n",
      "here\n",
      "relat\n",
      "chang\n",
      "upload\n",
      "file\n",
      "special\n",
      "page\n",
      "perman\n",
      "link\n",
      "page\n",
      "inform\n",
      "cite\n",
      "thi\n",
      "page\n",
      "wikidata\n",
      "item\n",
      "print/export\n",
      "download\n",
      "as\n",
      "pdf\n",
      "printabl\n",
      "version\n",
      "in\n",
      "other\n",
      "project\n",
      "wikimedia\n",
      "common\n",
      "languag\n",
      "afrikaan\n",
      "العربية\n",
      "azərbaycanca\n",
      "বাংলা\n",
      "bân-lâm-gú\n",
      "беларуская\n",
      "беларуская\n",
      "(\n",
      "тарашкевіца\n",
      ")\n",
      "български\n",
      "català\n",
      "čeština\n",
      "dansk\n",
      "deutsch\n",
      "eesti\n",
      "ελληνικά\n",
      "español\n",
      "euskara\n",
      "فارسی\n",
      "françai\n",
      "galego\n",
      "한국어\n",
      "հայերեն\n",
      "हिन्दी\n",
      "hrvatski\n",
      "bahasa\n",
      "indonesia\n",
      "íslenska\n",
      "italiano\n",
      "עברית\n",
      "ಕನ್ನಡ\n",
      "ქართული\n",
      "lietuvių\n",
      "македонски\n",
      "मराठी\n",
      "مصرى\n",
      "монгол\n",
      "မြန်မာဘာသာ\n",
      "日本語\n",
      "ଓଡ଼ିଆ\n",
      "piemontèi\n",
      "polski\n",
      "portuguê\n",
      "română\n",
      "русский\n",
      "simpl\n",
      "english\n",
      "کوردی\n",
      "српски\n",
      "/\n",
      "srpski\n",
      "srpskohrvatski\n",
      "/\n",
      "српскохрватски\n",
      "suomi\n",
      "தமிழ்\n",
      "ไทย\n",
      "türkçe\n",
      "українська\n",
      "tiếng\n",
      "việt\n",
      "粵語\n",
      "中文\n",
      "edit\n",
      "link\n",
      "thi\n",
      "page\n",
      "wa\n",
      "last\n",
      "edit\n",
      "on\n",
      "7\n",
      "octob\n",
      "2021\n",
      ",\n",
      "at\n",
      "01:56\n",
      "(\n",
      "utc\n",
      ")\n",
      ".\n",
      "text\n",
      "is\n",
      "avail\n",
      "under\n",
      "the\n",
      "creativ\n",
      "common\n",
      "attribution-sharealik\n",
      "licens\n",
      ";\n",
      "addit\n",
      "term\n",
      "may\n",
      "appli\n",
      ".\n",
      "by\n",
      "use\n",
      "thi\n",
      "site\n",
      ",\n",
      "you\n",
      "agre\n",
      "to\n",
      "the\n",
      "term\n",
      "of\n",
      "use\n",
      "and\n",
      "privaci\n",
      "polici\n",
      ".\n",
      "wikipedia®\n",
      "is\n",
      "a\n",
      "regist\n",
      "trademark\n",
      "of\n",
      "the\n",
      "wikimedia\n",
      "foundat\n",
      ",\n",
      "inc.\n",
      ",\n",
      "a\n",
      "non-profit\n",
      "organ\n",
      ".\n",
      "privaci\n",
      "polici\n",
      "about\n",
      "wikipedia\n",
      "disclaim\n",
      "contact\n",
      "wikipedia\n",
      "mobil\n",
      "view\n",
      "develop\n",
      "statist\n",
      "cooki\n",
      "statement\n"
     ]
    }
   ],
   "source": [
    "# called the perform_stemming method to make stemming\n",
    "stemmed_words = perform_stemming(words)\n",
    "for i in stemmed_words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef076840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "-\n",
      "Wikipedia\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Jump\n",
      "to\n",
      "navigation\n",
      "Jump\n",
      "to\n",
      "search\n",
      "This\n",
      "article\n",
      "is\n",
      "about\n",
      "natural\n",
      "language\n",
      "processing\n",
      "done\n",
      "by\n",
      "computer\n",
      ".\n",
      "For\n",
      "the\n",
      "natural\n",
      "language\n",
      "processing\n",
      "done\n",
      "by\n",
      "the\n",
      "human\n",
      "brain\n",
      ",\n",
      "see\n",
      "Language\n",
      "processing\n",
      "in\n",
      "the\n",
      "brain\n",
      ".\n",
      "Field\n",
      "of\n",
      "computer\n",
      "science\n",
      "and\n",
      "linguistics\n",
      "An\n",
      "automated\n",
      "online\n",
      "assistant\n",
      "providing\n",
      "customer\n",
      "service\n",
      "on\n",
      "a\n",
      "web\n",
      "page\n",
      ",\n",
      "an\n",
      "example\n",
      "of\n",
      "an\n",
      "application\n",
      "where\n",
      "natural\n",
      "language\n",
      "processing\n",
      "is\n",
      "a\n",
      "major\n",
      "component\n",
      ".\n",
      "[\n",
      "1\n",
      "]\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "linguistics\n",
      ",\n",
      "computer\n",
      "science\n",
      ",\n",
      "and\n",
      "artificial\n",
      "intelligence\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interaction\n",
      "between\n",
      "computer\n",
      "and\n",
      "human\n",
      "language\n",
      ",\n",
      "in\n",
      "particular\n",
      "how\n",
      "to\n",
      "program\n",
      "computer\n",
      "to\n",
      "process\n",
      "and\n",
      "analyze\n",
      "large\n",
      "amount\n",
      "of\n",
      "natural\n",
      "language\n",
      "data\n",
      ".\n",
      "The\n",
      "goal\n",
      "is\n",
      "a\n",
      "computer\n",
      "capable\n",
      "of\n",
      "``\n",
      "understanding\n",
      "''\n",
      "the\n",
      "content\n",
      "of\n",
      "document\n",
      ",\n",
      "including\n",
      "the\n",
      "contextual\n",
      "nuance\n",
      "of\n",
      "the\n",
      "language\n",
      "within\n",
      "them\n",
      ".\n",
      "The\n",
      "technology\n",
      "can\n",
      "then\n",
      "accurately\n",
      "extract\n",
      "information\n",
      "and\n",
      "insight\n",
      "contained\n",
      "in\n",
      "the\n",
      "document\n",
      "a\n",
      "well\n",
      "a\n",
      "categorize\n",
      "and\n",
      "organize\n",
      "the\n",
      "document\n",
      "themselves\n",
      ".\n",
      "Challenges\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "frequently\n",
      "involve\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "natural\n",
      "language\n",
      "understanding\n",
      ",\n",
      "and\n",
      "natural\n",
      "language\n",
      "generation\n",
      ".\n",
      "Contents\n",
      "1\n",
      "History\n",
      "1.1\n",
      "Symbolic\n",
      "NLP\n",
      "(\n",
      "1950s\n",
      "–\n",
      "early\n",
      "1990s\n",
      ")\n",
      "1.2\n",
      "Statistical\n",
      "NLP\n",
      "(\n",
      "1990s–2010s\n",
      ")\n",
      "1.3\n",
      "Neural\n",
      "NLP\n",
      "(\n",
      "present\n",
      ")\n",
      "2\n",
      "Methods\n",
      ":\n",
      "Rules\n",
      ",\n",
      "statistic\n",
      ",\n",
      "neural\n",
      "network\n",
      "2.1\n",
      "Statistical\n",
      "method\n",
      "2.2\n",
      "Neural\n",
      "network\n",
      "3\n",
      "Common\n",
      "NLP\n",
      "task\n",
      "3.1\n",
      "Text\n",
      "and\n",
      "speech\n",
      "processing\n",
      "3.2\n",
      "Morphological\n",
      "analysis\n",
      "3.3\n",
      "Syntactic\n",
      "analysis\n",
      "3.4\n",
      "Lexical\n",
      "semantics\n",
      "(\n",
      "of\n",
      "individual\n",
      "word\n",
      "in\n",
      "context\n",
      ")\n",
      "3.5\n",
      "Relational\n",
      "semantics\n",
      "(\n",
      "semantics\n",
      "of\n",
      "individual\n",
      "sentence\n",
      ")\n",
      "3.6\n",
      "Discourse\n",
      "(\n",
      "semantics\n",
      "beyond\n",
      "individual\n",
      "sentence\n",
      ")\n",
      "3.7\n",
      "Higher-level\n",
      "NLP\n",
      "application\n",
      "4\n",
      "General\n",
      "tendency\n",
      "and\n",
      "(\n",
      "possible\n",
      ")\n",
      "future\n",
      "direction\n",
      "4.1\n",
      "Cognition\n",
      "and\n",
      "NLP\n",
      "5\n",
      "See\n",
      "also\n",
      "6\n",
      "References\n",
      "7\n",
      "Further\n",
      "reading\n",
      "8\n",
      "External\n",
      "link\n",
      "History\n",
      "[\n",
      "edit\n",
      "]\n",
      "Further\n",
      "information\n",
      ":\n",
      "History\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "ha\n",
      "it\n",
      "root\n",
      "in\n",
      "the\n",
      "1950s\n",
      ".\n",
      "Already\n",
      "in\n",
      "1950\n",
      ",\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "``\n",
      "Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\n",
      "``\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "a\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence\n",
      ",\n",
      "a\n",
      "task\n",
      "that\n",
      "involves\n",
      "the\n",
      "automated\n",
      "interpretation\n",
      "and\n",
      "generation\n",
      "of\n",
      "natural\n",
      "language\n",
      ",\n",
      "but\n",
      "at\n",
      "the\n",
      "time\n",
      "not\n",
      "articulated\n",
      "a\n",
      "a\n",
      "problem\n",
      "separate\n",
      "from\n",
      "artificial\n",
      "intelligence\n",
      ".\n",
      "Symbolic\n",
      "NLP\n",
      "(\n",
      "1950s\n",
      "–\n",
      "early\n",
      "1990s\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "The\n",
      "premise\n",
      "of\n",
      "symbolic\n",
      "NLP\n",
      "is\n",
      "well-summarized\n",
      "by\n",
      "John\n",
      "Searle\n",
      "'s\n",
      "Chinese\n",
      "room\n",
      "experiment\n",
      ":\n",
      "Given\n",
      "a\n",
      "collection\n",
      "of\n",
      "rule\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "a\n",
      "Chinese\n",
      "phrasebook\n",
      ",\n",
      "with\n",
      "question\n",
      "and\n",
      "matching\n",
      "answer\n",
      ")\n",
      ",\n",
      "the\n",
      "computer\n",
      "emulates\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "or\n",
      "other\n",
      "NLP\n",
      "task\n",
      ")\n",
      "by\n",
      "applying\n",
      "those\n",
      "rule\n",
      "to\n",
      "the\n",
      "data\n",
      "it\n",
      "is\n",
      "confronted\n",
      "with\n",
      ".\n",
      "1950s\n",
      ":\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentence\n",
      "into\n",
      "English\n",
      ".\n",
      "The\n",
      "author\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "year\n",
      ",\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem\n",
      ".\n",
      "[\n",
      "2\n",
      "]\n",
      "However\n",
      ",\n",
      "real\n",
      "progress\n",
      "wa\n",
      "much\n",
      "slower\n",
      ",\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966\n",
      ",\n",
      "which\n",
      "found\n",
      "that\n",
      "ten-year-long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectation\n",
      ",\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "wa\n",
      "dramatically\n",
      "reduced\n",
      ".\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "wa\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "system\n",
      "were\n",
      "developed\n",
      ".\n",
      "1960s\n",
      ":\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU\n",
      ",\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "``\n",
      "block\n",
      "world\n",
      "``\n",
      "with\n",
      "restricted\n",
      "vocabulary\n",
      ",\n",
      "and\n",
      "ELIZA\n",
      ",\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist\n",
      ",\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "and\n",
      "1966\n",
      ".\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion\n",
      ",\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction\n",
      ".\n",
      "When\n",
      "the\n",
      "``\n",
      "patient\n",
      "''\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base\n",
      ",\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "responding\n",
      "to\n",
      "``\n",
      "My\n",
      "head\n",
      "hurt\n",
      "''\n",
      "with\n",
      "``\n",
      "Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurt\n",
      "?\n",
      "''\n",
      ".\n",
      "1970s\n",
      ":\n",
      "During\n",
      "the\n",
      "1970s\n",
      ",\n",
      "many\n",
      "programmer\n",
      "began\n",
      "to\n",
      "write\n",
      "``\n",
      "conceptual\n",
      "ontology\n",
      "``\n",
      ",\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data\n",
      ".\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "(\n",
      "Schank\n",
      ",\n",
      "1975\n",
      ")\n",
      ",\n",
      "SAM\n",
      "(\n",
      "Cullingford\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "PAM\n",
      "(\n",
      "Wilensky\n",
      ",\n",
      "1978\n",
      ")\n",
      ",\n",
      "TaleSpin\n",
      "(\n",
      "Meehan\n",
      ",\n",
      "1976\n",
      ")\n",
      ",\n",
      "QUALM\n",
      "(\n",
      "Lehnert\n",
      ",\n",
      "1977\n",
      ")\n",
      ",\n",
      "Politics\n",
      "(\n",
      "Carbonell\n",
      ",\n",
      "1979\n",
      ")\n",
      ",\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "(\n",
      "Lehnert\n",
      "1981\n",
      ")\n",
      ".\n",
      "During\n",
      "this\n",
      "time\n",
      ",\n",
      "the\n",
      "first\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "PARRY\n",
      ")\n",
      ".\n",
      "1980s\n",
      ":\n",
      "The\n",
      "1980s\n",
      "and\n",
      "early\n",
      "1990s\n",
      "mark\n",
      "the\n",
      "hey-day\n",
      "of\n",
      "symbolic\n",
      "method\n",
      "in\n",
      "NLP\n",
      ".\n",
      "Focus\n",
      "area\n",
      "of\n",
      "the\n",
      "time\n",
      "included\n",
      "research\n",
      "on\n",
      "rule-based\n",
      "parsing\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "development\n",
      "of\n",
      "HPSG\n",
      "a\n",
      "a\n",
      "computational\n",
      "operationalization\n",
      "of\n",
      "generative\n",
      "grammar\n",
      ")\n",
      ",\n",
      "morphology\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "two-level\n",
      "morphology\n",
      "[\n",
      "3\n",
      "]\n",
      ")\n",
      ",\n",
      "semantics\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "Lesk\n",
      "algorithm\n",
      ")\n",
      ",\n",
      "reference\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "within\n",
      "Centering\n",
      "Theory\n",
      "[\n",
      "4\n",
      "]\n",
      ")\n",
      "and\n",
      "other\n",
      "area\n",
      "of\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "the\n",
      "Rhetorical\n",
      "Structure\n",
      "Theory\n",
      ")\n",
      ".\n",
      "Other\n",
      "line\n",
      "of\n",
      "research\n",
      "were\n",
      "continued\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "the\n",
      "development\n",
      "of\n",
      "chatterbots\n",
      "with\n",
      "Racter\n",
      "and\n",
      "Jabberwacky\n",
      ".\n",
      "An\n",
      "important\n",
      "development\n",
      "(\n",
      "that\n",
      "eventually\n",
      "led\n",
      "to\n",
      "the\n",
      "statistical\n",
      "turn\n",
      "in\n",
      "the\n",
      "1990s\n",
      ")\n",
      "wa\n",
      "the\n",
      "rising\n",
      "importance\n",
      "of\n",
      "quantitative\n",
      "evaluation\n",
      "in\n",
      "this\n",
      "period\n",
      ".\n",
      "[\n",
      "5\n",
      "]\n",
      "Statistical\n",
      "NLP\n",
      "(\n",
      "1990s–2010s\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "however\n",
      ",\n",
      "there\n",
      "wa\n",
      "a\n",
      "revolution\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "This\n",
      "wa\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "(\n",
      "see\n",
      "Moore\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theory\n",
      "of\n",
      "linguistics\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transformational\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "[\n",
      "6\n",
      "]\n",
      "1990s\n",
      ":\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "success\n",
      "on\n",
      "statistical\n",
      "method\n",
      "in\n",
      "NLP\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation\n",
      ",\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research\n",
      ".\n",
      "These\n",
      "system\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpus\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "a\n",
      "a\n",
      "result\n",
      "of\n",
      "law\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceeding\n",
      "into\n",
      "all\n",
      "official\n",
      "language\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "system\n",
      "of\n",
      "government\n",
      ".\n",
      "However\n",
      ",\n",
      "most\n",
      "other\n",
      "system\n",
      "depended\n",
      "on\n",
      "corpus\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "task\n",
      "implemented\n",
      "by\n",
      "these\n",
      "system\n",
      ",\n",
      "which\n",
      "wa\n",
      "(\n",
      "and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be\n",
      ")\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "system\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "ha\n",
      "gone\n",
      "into\n",
      "method\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amount\n",
      "of\n",
      "data\n",
      ".\n",
      "2000s\n",
      ":\n",
      "With\n",
      "the\n",
      "growth\n",
      "of\n",
      "the\n",
      "web\n",
      ",\n",
      "increasing\n",
      "amount\n",
      "of\n",
      "raw\n",
      "(\n",
      "unannotated\n",
      ")\n",
      "language\n",
      "data\n",
      "ha\n",
      "become\n",
      "available\n",
      "since\n",
      "the\n",
      "mid-1990s\n",
      ".\n",
      "Research\n",
      "ha\n",
      "thus\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithm\n",
      ".\n",
      "Such\n",
      "algorithm\n",
      "can\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "ha\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answer\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data\n",
      ".\n",
      "Generally\n",
      ",\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning\n",
      ",\n",
      "and\n",
      "typically\n",
      "produce\n",
      "le\n",
      "accurate\n",
      "result\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "(\n",
      "including\n",
      ",\n",
      "among\n",
      "other\n",
      "thing\n",
      ",\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web\n",
      ")\n",
      ",\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "result\n",
      "if\n",
      "the\n",
      "algorithm\n",
      "used\n",
      "ha\n",
      "a\n",
      "low\n",
      "enough\n",
      "time\n",
      "complexity\n",
      "to\n",
      "be\n",
      "practical\n",
      ".\n",
      "Neural\n",
      "NLP\n",
      "(\n",
      "present\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "In\n",
      "the\n",
      "2010s\n",
      ",\n",
      "representation\n",
      "learning\n",
      "and\n",
      "deep\n",
      "neural\n",
      "network\n",
      "-style\n",
      "machine\n",
      "learning\n",
      "method\n",
      "became\n",
      "widespread\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      ",\n",
      "due\n",
      "in\n",
      "part\n",
      "to\n",
      "a\n",
      "flurry\n",
      "of\n",
      "result\n",
      "showing\n",
      "that\n",
      "such\n",
      "technique\n",
      "[\n",
      "7\n",
      "]\n",
      "[\n",
      "8\n",
      "]\n",
      "can\n",
      "achieve\n",
      "state-of-the-art\n",
      "result\n",
      "in\n",
      "many\n",
      "natural\n",
      "language\n",
      "task\n",
      ",\n",
      "for\n",
      "example\n",
      "in\n",
      "language\n",
      "modeling\n",
      ",\n",
      "[\n",
      "9\n",
      "]\n",
      "parsing\n",
      ",\n",
      "[\n",
      "10\n",
      "]\n",
      "[\n",
      "11\n",
      "]\n",
      "and\n",
      "many\n",
      "others\n",
      ".\n",
      "This\n",
      "is\n",
      "increasingly\n",
      "important\n",
      "in\n",
      "medicine\n",
      "and\n",
      "healthcare\n",
      ",\n",
      "where\n",
      "NLP\n",
      "is\n",
      "being\n",
      "used\n",
      "to\n",
      "analyze\n",
      "note\n",
      "and\n",
      "text\n",
      "in\n",
      "electronic\n",
      "health\n",
      "record\n",
      "that\n",
      "would\n",
      "otherwise\n",
      "be\n",
      "inaccessible\n",
      "for\n",
      "study\n",
      "when\n",
      "seeking\n",
      "to\n",
      "improve\n",
      "care\n",
      ".\n",
      "[\n",
      "12\n",
      "]\n",
      "Methods\n",
      ":\n",
      "Rules\n",
      ",\n",
      "statistic\n",
      ",\n",
      "neural\n",
      "network\n",
      "[\n",
      "edit\n",
      "]\n",
      "In\n",
      "the\n",
      "early\n",
      "day\n",
      ",\n",
      "many\n",
      "language-processing\n",
      "system\n",
      "were\n",
      "designed\n",
      "by\n",
      "symbolic\n",
      "method\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "hand-coding\n",
      "of\n",
      "a\n",
      "set\n",
      "of\n",
      "rule\n",
      ",\n",
      "coupled\n",
      "with\n",
      "a\n",
      "dictionary\n",
      "lookup\n",
      ":\n",
      "[\n",
      "13\n",
      "]\n",
      "[\n",
      "14\n",
      "]\n",
      "such\n",
      "a\n",
      "by\n",
      "writing\n",
      "grammar\n",
      "or\n",
      "devising\n",
      "heuristic\n",
      "rule\n",
      "for\n",
      "stemming\n",
      ".\n",
      "More\n",
      "recent\n",
      "system\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithm\n",
      "have\n",
      "many\n",
      "advantage\n",
      "over\n",
      "hand-produced\n",
      "rule\n",
      ":\n",
      "The\n",
      "learning\n",
      "procedure\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "case\n",
      ",\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rule\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "at\n",
      "all\n",
      "obvious\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed\n",
      ".\n",
      "Automatic\n",
      "learning\n",
      "procedure\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithm\n",
      "to\n",
      "produce\n",
      "model\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "containing\n",
      "word\n",
      "or\n",
      "structure\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before\n",
      ")\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "(\n",
      "e.g\n",
      ".\n",
      "with\n",
      "misspelled\n",
      "word\n",
      "or\n",
      "word\n",
      "accidentally\n",
      "omitted\n",
      ")\n",
      ".\n",
      "Generally\n",
      ",\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "handwritten\n",
      "rule\n",
      ",\n",
      "or\n",
      ",\n",
      "more\n",
      "generally\n",
      ",\n",
      "creating\n",
      "system\n",
      "of\n",
      "handwritten\n",
      "rule\n",
      "that\n",
      "make\n",
      "soft\n",
      "decision\n",
      ",\n",
      "is\n",
      "extremely\n",
      "difficult\n",
      ",\n",
      "error-prone\n",
      "and\n",
      "time-consuming\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rule\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "system\n",
      "based\n",
      "on\n",
      "handwritten\n",
      "rule\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rule\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      ".\n",
      "In\n",
      "particular\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "system\n",
      "based\n",
      "on\n",
      "handwritten\n",
      "rule\n",
      ",\n",
      "beyond\n",
      "which\n",
      "the\n",
      "system\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable\n",
      ".\n",
      "However\n",
      ",\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "system\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked\n",
      ",\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increase\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process\n",
      ".\n",
      "Despite\n",
      "the\n",
      "popularity\n",
      "of\n",
      "machine\n",
      "learning\n",
      "in\n",
      "NLP\n",
      "research\n",
      ",\n",
      "symbolic\n",
      "method\n",
      "are\n",
      "still\n",
      "(\n",
      "2020\n",
      ")\n",
      "commonly\n",
      "used\n",
      ":\n",
      "when\n",
      "the\n",
      "amount\n",
      "of\n",
      "training\n",
      "data\n",
      "is\n",
      "insufficient\n",
      "to\n",
      "successfully\n",
      "apply\n",
      "machine\n",
      "learning\n",
      "method\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "the\n",
      "machine\n",
      "translation\n",
      "of\n",
      "low-resource\n",
      "language\n",
      "such\n",
      "a\n",
      "provided\n",
      "by\n",
      "the\n",
      "Apertium\n",
      "system\n",
      ",\n",
      "for\n",
      "preprocessing\n",
      "in\n",
      "NLP\n",
      "pipeline\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "tokenization\n",
      ",\n",
      "or\n",
      "for\n",
      "postprocessing\n",
      "and\n",
      "transforming\n",
      "the\n",
      "output\n",
      "of\n",
      "NLP\n",
      "pipeline\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "for\n",
      "knowledge\n",
      "extraction\n",
      "from\n",
      "syntactic\n",
      "par\n",
      ".\n",
      "Statistical\n",
      "method\n",
      "[\n",
      "edit\n",
      "]\n",
      "Since\n",
      "the\n",
      "so-called\n",
      "``\n",
      "statistical\n",
      "revolution\n",
      "''\n",
      "[\n",
      "15\n",
      "]\n",
      "[\n",
      "16\n",
      "]\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      "and\n",
      "mid-1990s\n",
      ",\n",
      "much\n",
      "natural\n",
      "language\n",
      "processing\n",
      "research\n",
      "ha\n",
      "relied\n",
      "heavily\n",
      "on\n",
      "machine\n",
      "learning\n",
      ".\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "call\n",
      "instead\n",
      "for\n",
      "using\n",
      "statistical\n",
      "inference\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rule\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpus\n",
      "(\n",
      "the\n",
      "plural\n",
      "form\n",
      "of\n",
      "corpus\n",
      ",\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "document\n",
      ",\n",
      "possibly\n",
      "with\n",
      "human\n",
      "or\n",
      "computer\n",
      "annotation\n",
      ")\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "example\n",
      ".\n",
      "Many\n",
      "different\n",
      "class\n",
      "of\n",
      "machine-learning\n",
      "algorithm\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "natural-language-processing\n",
      "task\n",
      ".\n",
      "These\n",
      "algorithm\n",
      "take\n",
      "a\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "``\n",
      "feature\n",
      "''\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "Increasingly\n",
      ",\n",
      "however\n",
      ",\n",
      "research\n",
      "ha\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "model\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decision\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weight\n",
      "to\n",
      "each\n",
      "input\n",
      "feature\n",
      "(\n",
      "complex-valued\n",
      "embeddings\n",
      ",\n",
      "[\n",
      "17\n",
      "]\n",
      "and\n",
      "neural\n",
      "network\n",
      "in\n",
      "general\n",
      "have\n",
      "also\n",
      "been\n",
      "proposed\n",
      ",\n",
      "for\n",
      "e.g\n",
      ".\n",
      "speech\n",
      "[\n",
      "18\n",
      "]\n",
      ")\n",
      ".\n",
      "Such\n",
      "model\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answer\n",
      "rather\n",
      "than\n",
      "only\n",
      "one\n",
      ",\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "result\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "a\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      ",\n",
      "such\n",
      "a\n",
      "decision\n",
      "tree\n",
      ",\n",
      "produced\n",
      "system\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rule\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "However\n",
      ",\n",
      "part-of-speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "hidden\n",
      "Markov\n",
      "model\n",
      "to\n",
      "natural\n",
      "language\n",
      "processing\n",
      ",\n",
      "and\n",
      "increasingly\n",
      ",\n",
      "research\n",
      "ha\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "model\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decision\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weight\n",
      "to\n",
      "the\n",
      "feature\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "The\n",
      "cache\n",
      "language\n",
      "model\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "system\n",
      "now\n",
      "rely\n",
      "are\n",
      "example\n",
      "of\n",
      "such\n",
      "statistical\n",
      "model\n",
      ".\n",
      "Such\n",
      "model\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      ",\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "error\n",
      "(\n",
      "a\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      ")\n",
      ",\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "result\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks\n",
      ".\n",
      "Since\n",
      "the\n",
      "neural\n",
      "turn\n",
      ",\n",
      "statistical\n",
      "method\n",
      "in\n",
      "NLP\n",
      "research\n",
      "have\n",
      "been\n",
      "largely\n",
      "replaced\n",
      "by\n",
      "neural\n",
      "network\n",
      ".\n",
      "However\n",
      ",\n",
      "they\n",
      "continue\n",
      "to\n",
      "be\n",
      "relevant\n",
      "for\n",
      "context\n",
      "in\n",
      "which\n",
      "statistical\n",
      "interpretability\n",
      "and\n",
      "transparency\n",
      "is\n",
      "required\n",
      ".\n",
      "Neural\n",
      "network\n",
      "[\n",
      "edit\n",
      "]\n",
      "Further\n",
      "information\n",
      ":\n",
      "Artificial\n",
      "neural\n",
      "network\n",
      "A\n",
      "major\n",
      "drawback\n",
      "of\n",
      "statistical\n",
      "method\n",
      "is\n",
      "that\n",
      "they\n",
      "require\n",
      "elaborate\n",
      "feature\n",
      "engineering\n",
      ".\n",
      "Since\n",
      "2015\n",
      ",\n",
      "[\n",
      "19\n",
      "]\n",
      "the\n",
      "field\n",
      "ha\n",
      "thus\n",
      "largely\n",
      "abandoned\n",
      "statistical\n",
      "method\n",
      "and\n",
      "shifted\n",
      "to\n",
      "neural\n",
      "network\n",
      "for\n",
      "machine\n",
      "learning\n",
      ".\n",
      "Popular\n",
      "technique\n",
      "include\n",
      "the\n",
      "use\n",
      "of\n",
      "word\n",
      "embeddings\n",
      "to\n",
      "capture\n",
      "semantic\n",
      "property\n",
      "of\n",
      "word\n",
      ",\n",
      "and\n",
      "an\n",
      "increase\n",
      "in\n",
      "end-to-end\n",
      "learning\n",
      "of\n",
      "a\n",
      "higher-level\n",
      "task\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "question\n",
      "answering\n",
      ")\n",
      "instead\n",
      "of\n",
      "relying\n",
      "on\n",
      "a\n",
      "pipeline\n",
      "of\n",
      "separate\n",
      "intermediate\n",
      "task\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "part-of-speech\n",
      "tagging\n",
      "and\n",
      "dependency\n",
      "parsing\n",
      ")\n",
      ".\n",
      "In\n",
      "some\n",
      "area\n",
      ",\n",
      "this\n",
      "shift\n",
      "ha\n",
      "entailed\n",
      "substantial\n",
      "change\n",
      "in\n",
      "how\n",
      "NLP\n",
      "system\n",
      "are\n",
      "designed\n",
      ",\n",
      "such\n",
      "that\n",
      "deep\n",
      "neural\n",
      "network-based\n",
      "approach\n",
      "may\n",
      "be\n",
      "viewed\n",
      "a\n",
      "a\n",
      "new\n",
      "paradigm\n",
      "distinct\n",
      "from\n",
      "statistical\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "For\n",
      "instance\n",
      ",\n",
      "the\n",
      "term\n",
      "neural\n",
      "machine\n",
      "translation\n",
      "(\n",
      "NMT\n",
      ")\n",
      "emphasizes\n",
      "the\n",
      "fact\n",
      "that\n",
      "deep\n",
      "learning-based\n",
      "approach\n",
      "to\n",
      "machine\n",
      "translation\n",
      "directly\n",
      "learn\n",
      "sequence-to-sequence\n",
      "transformation\n",
      ",\n",
      "obviating\n",
      "the\n",
      "need\n",
      "for\n",
      "intermediate\n",
      "step\n",
      "such\n",
      "a\n",
      "word\n",
      "alignment\n",
      "and\n",
      "language\n",
      "modeling\n",
      "that\n",
      "wa\n",
      "used\n",
      "in\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "(\n",
      "SMT\n",
      ")\n",
      ".\n",
      "Latest\n",
      "work\n",
      "tend\n",
      "to\n",
      "use\n",
      "non-technical\n",
      "structure\n",
      "of\n",
      "a\n",
      "given\n",
      "task\n",
      "to\n",
      "build\n",
      "proper\n",
      "neural\n",
      "network\n",
      ".\n",
      "[\n",
      "20\n",
      "]\n",
      "Common\n",
      "NLP\n",
      "task\n",
      "[\n",
      "edit\n",
      "]\n",
      "The\n",
      "following\n",
      "is\n",
      "a\n",
      "list\n",
      "of\n",
      "some\n",
      "of\n",
      "the\n",
      "most\n",
      "commonly\n",
      "researched\n",
      "task\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "Some\n",
      "of\n",
      "these\n",
      "task\n",
      "have\n",
      "direct\n",
      "real-world\n",
      "application\n",
      ",\n",
      "while\n",
      "others\n",
      "more\n",
      "commonly\n",
      "serve\n",
      "a\n",
      "subtasks\n",
      "that\n",
      "are\n",
      "used\n",
      "to\n",
      "aid\n",
      "in\n",
      "solving\n",
      "larger\n",
      "task\n",
      ".\n",
      "Though\n",
      "natural\n",
      "language\n",
      "processing\n",
      "task\n",
      "are\n",
      "closely\n",
      "intertwined\n",
      ",\n",
      "they\n",
      "can\n",
      "be\n",
      "subdivided\n",
      "into\n",
      "category\n",
      "for\n",
      "convenience\n",
      ".\n",
      "A\n",
      "coarse\n",
      "division\n",
      "is\n",
      "given\n",
      "below\n",
      ".\n",
      "Text\n",
      "and\n",
      "speech\n",
      "processing\n",
      "[\n",
      "edit\n",
      "]\n",
      "Optical\n",
      "character\n",
      "recognition\n",
      "(\n",
      "OCR\n",
      ")\n",
      "Given\n",
      "an\n",
      "image\n",
      "representing\n",
      "printed\n",
      "text\n",
      ",\n",
      "determine\n",
      "the\n",
      "corresponding\n",
      "text\n",
      ".\n",
      "Speech\n",
      "recognition\n",
      "Given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "people\n",
      "speaking\n",
      ",\n",
      "determine\n",
      "the\n",
      "textual\n",
      "representation\n",
      "of\n",
      "the\n",
      "speech\n",
      ".\n",
      "This\n",
      "is\n",
      "the\n",
      "opposite\n",
      "of\n",
      "text\n",
      "to\n",
      "speech\n",
      "and\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "extremely\n",
      "difficult\n",
      "problem\n",
      "colloquially\n",
      "termed\n",
      "``\n",
      "AI-complete\n",
      "``\n",
      "(\n",
      "see\n",
      "above\n",
      ")\n",
      ".\n",
      "In\n",
      "natural\n",
      "speech\n",
      "there\n",
      "are\n",
      "hardly\n",
      "any\n",
      "pause\n",
      "between\n",
      "successive\n",
      "word\n",
      ",\n",
      "and\n",
      "thus\n",
      "speech\n",
      "segmentation\n",
      "is\n",
      "a\n",
      "necessary\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognition\n",
      "(\n",
      "see\n",
      "below\n",
      ")\n",
      ".\n",
      "In\n",
      "most\n",
      "spoken\n",
      "language\n",
      ",\n",
      "the\n",
      "sound\n",
      "representing\n",
      "successive\n",
      "letter\n",
      "blend\n",
      "into\n",
      "each\n",
      "other\n",
      "in\n",
      "a\n",
      "process\n",
      "termed\n",
      "coarticulation\n",
      ",\n",
      "so\n",
      "the\n",
      "conversion\n",
      "of\n",
      "the\n",
      "analog\n",
      "signal\n",
      "to\n",
      "discrete\n",
      "character\n",
      "can\n",
      "be\n",
      "a\n",
      "very\n",
      "difficult\n",
      "process\n",
      ".\n",
      "Also\n",
      ",\n",
      "given\n",
      "that\n",
      "word\n",
      "in\n",
      "the\n",
      "same\n",
      "language\n",
      "are\n",
      "spoken\n",
      "by\n",
      "people\n",
      "with\n",
      "different\n",
      "accent\n",
      ",\n",
      "the\n",
      "speech\n",
      "recognition\n",
      "software\n",
      "must\n",
      "be\n",
      "able\n",
      "to\n",
      "recognize\n",
      "the\n",
      "wide\n",
      "variety\n",
      "of\n",
      "input\n",
      "a\n",
      "being\n",
      "identical\n",
      "to\n",
      "each\n",
      "other\n",
      "in\n",
      "term\n",
      "of\n",
      "it\n",
      "textual\n",
      "equivalent\n",
      ".\n",
      "Speech\n",
      "segmentation\n",
      "Given\n",
      "a\n",
      "sound\n",
      "clip\n",
      "of\n",
      "a\n",
      "person\n",
      "or\n",
      "people\n",
      "speaking\n",
      ",\n",
      "separate\n",
      "it\n",
      "into\n",
      "word\n",
      ".\n",
      "A\n",
      "subtask\n",
      "of\n",
      "speech\n",
      "recognition\n",
      "and\n",
      "typically\n",
      "grouped\n",
      "with\n",
      "it\n",
      ".\n",
      "Text-to-speech\n",
      "Given\n",
      "a\n",
      "text\n",
      ",\n",
      "transform\n",
      "those\n",
      "unit\n",
      "and\n",
      "produce\n",
      "a\n",
      "spoken\n",
      "representation\n",
      ".\n",
      "Text-to-speech\n",
      "can\n",
      "be\n",
      "used\n",
      "to\n",
      "aid\n",
      "the\n",
      "visually\n",
      "impaired\n",
      ".\n",
      "[\n",
      "21\n",
      "]\n",
      "Word\n",
      "segmentation\n",
      "(\n",
      "Tokenization\n",
      ")\n",
      "Separate\n",
      "a\n",
      "chunk\n",
      "of\n",
      "continuous\n",
      "text\n",
      "into\n",
      "separate\n",
      "word\n",
      ".\n",
      "For\n",
      "a\n",
      "language\n",
      "like\n",
      "English\n",
      ",\n",
      "this\n",
      "is\n",
      "fairly\n",
      "trivial\n",
      ",\n",
      "since\n",
      "word\n",
      "are\n",
      "usually\n",
      "separated\n",
      "by\n",
      "space\n",
      ".\n",
      "However\n",
      ",\n",
      "some\n",
      "written\n",
      "language\n",
      "like\n",
      "Chinese\n",
      ",\n",
      "Japanese\n",
      "and\n",
      "Thai\n",
      "do\n",
      "not\n",
      "mark\n",
      "word\n",
      "boundary\n",
      "in\n",
      "such\n",
      "a\n",
      "fashion\n",
      ",\n",
      "and\n",
      "in\n",
      "those\n",
      "language\n",
      "text\n",
      "segmentation\n",
      "is\n",
      "a\n",
      "significant\n",
      "task\n",
      "requiring\n",
      "knowledge\n",
      "of\n",
      "the\n",
      "vocabulary\n",
      "and\n",
      "morphology\n",
      "of\n",
      "word\n",
      "in\n",
      "the\n",
      "language\n",
      ".\n",
      "Sometimes\n",
      "this\n",
      "process\n",
      "is\n",
      "also\n",
      "used\n",
      "in\n",
      "case\n",
      "like\n",
      "bag\n",
      "of\n",
      "word\n",
      "(\n",
      "BOW\n",
      ")\n",
      "creation\n",
      "in\n",
      "data\n",
      "mining\n",
      ".\n",
      "Morphological\n",
      "analysis\n",
      "[\n",
      "edit\n",
      "]\n",
      "Lemmatization\n",
      "The\n",
      "task\n",
      "of\n",
      "removing\n",
      "inflectional\n",
      "ending\n",
      "only\n",
      "and\n",
      "to\n",
      "return\n",
      "the\n",
      "base\n",
      "dictionary\n",
      "form\n",
      "of\n",
      "a\n",
      "word\n",
      "which\n",
      "is\n",
      "also\n",
      "known\n",
      "a\n",
      "a\n",
      "lemma\n",
      ".\n",
      "Lemmatization\n",
      "is\n",
      "another\n",
      "technique\n",
      "for\n",
      "reducing\n",
      "word\n",
      "to\n",
      "their\n",
      "normalized\n",
      "form\n",
      ".\n",
      "But\n",
      "in\n",
      "this\n",
      "case\n",
      ",\n",
      "the\n",
      "transformation\n",
      "actually\n",
      "us\n",
      "a\n",
      "dictionary\n",
      "to\n",
      "map\n",
      "word\n",
      "to\n",
      "their\n",
      "actual\n",
      "form\n",
      ".\n",
      "[\n",
      "22\n",
      "]\n",
      "Morphological\n",
      "segmentation\n",
      "Separate\n",
      "word\n",
      "into\n",
      "individual\n",
      "morpheme\n",
      "and\n",
      "identify\n",
      "the\n",
      "class\n",
      "of\n",
      "the\n",
      "morpheme\n",
      ".\n",
      "The\n",
      "difficulty\n",
      "of\n",
      "this\n",
      "task\n",
      "depends\n",
      "greatly\n",
      "on\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "morphology\n",
      "(\n",
      "i.e\n",
      ".\n",
      ",\n",
      "the\n",
      "structure\n",
      "of\n",
      "word\n",
      ")\n",
      "of\n",
      "the\n",
      "language\n",
      "being\n",
      "considered\n",
      ".\n",
      "English\n",
      "ha\n",
      "fairly\n",
      "simple\n",
      "morphology\n",
      ",\n",
      "especially\n",
      "inflectional\n",
      "morphology\n",
      ",\n",
      "and\n",
      "thus\n",
      "it\n",
      "is\n",
      "often\n",
      "possible\n",
      "to\n",
      "ignore\n",
      "this\n",
      "task\n",
      "entirely\n",
      "and\n",
      "simply\n",
      "model\n",
      "all\n",
      "possible\n",
      "form\n",
      "of\n",
      "a\n",
      "word\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "open\n",
      ",\n",
      "open\n",
      ",\n",
      "opened\n",
      ",\n",
      "opening\n",
      "''\n",
      ")\n",
      "a\n",
      "separate\n",
      "word\n",
      ".\n",
      "In\n",
      "language\n",
      "such\n",
      "a\n",
      "Turkish\n",
      "or\n",
      "Meitei\n",
      ",\n",
      "[\n",
      "23\n",
      "]\n",
      "a\n",
      "highly\n",
      "agglutinated\n",
      "Indian\n",
      "language\n",
      ",\n",
      "however\n",
      ",\n",
      "such\n",
      "an\n",
      "approach\n",
      "is\n",
      "not\n",
      "possible\n",
      ",\n",
      "a\n",
      "each\n",
      "dictionary\n",
      "entry\n",
      "ha\n",
      "thousand\n",
      "of\n",
      "possible\n",
      "word\n",
      "form\n",
      ".\n",
      "Part-of-speech\n",
      "tagging\n",
      "Given\n",
      "a\n",
      "sentence\n",
      ",\n",
      "determine\n",
      "the\n",
      "part\n",
      "of\n",
      "speech\n",
      "(\n",
      "POS\n",
      ")\n",
      "for\n",
      "each\n",
      "word\n",
      ".\n",
      "Many\n",
      "word\n",
      ",\n",
      "especially\n",
      "common\n",
      "one\n",
      ",\n",
      "can\n",
      "serve\n",
      "a\n",
      "multiple\n",
      "part\n",
      "of\n",
      "speech\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "``\n",
      "book\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      "(\n",
      "``\n",
      "the\n",
      "book\n",
      "on\n",
      "the\n",
      "table\n",
      "''\n",
      ")\n",
      "or\n",
      "verb\n",
      "(\n",
      "``\n",
      "to\n",
      "book\n",
      "a\n",
      "flight\n",
      "''\n",
      ")\n",
      ";\n",
      "``\n",
      "set\n",
      "''\n",
      "can\n",
      "be\n",
      "a\n",
      "noun\n",
      ",\n",
      "verb\n",
      "or\n",
      "adjective\n",
      ";\n",
      "and\n",
      "``\n",
      "out\n",
      "''\n",
      "can\n",
      "be\n",
      "any\n",
      "of\n",
      "at\n",
      "least\n",
      "five\n",
      "different\n",
      "part\n",
      "of\n",
      "speech\n",
      ".\n",
      "Stemming\n",
      "The\n",
      "process\n",
      "of\n",
      "reducing\n",
      "inflected\n",
      "(\n",
      "or\n",
      "sometimes\n",
      "derived\n",
      ")\n",
      "word\n",
      "to\n",
      "a\n",
      "base\n",
      "form\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      "will\n",
      "be\n",
      "the\n",
      "root\n",
      "for\n",
      "``\n",
      "closed\n",
      "''\n",
      ",\n",
      "``\n",
      "closing\n",
      "''\n",
      ",\n",
      "``\n",
      "close\n",
      "''\n",
      ",\n",
      "``\n",
      "closer\n",
      "''\n",
      "etc.\n",
      ")\n",
      ".\n",
      "Stemming\n",
      "yield\n",
      "similar\n",
      "result\n",
      "a\n",
      "lemmatization\n",
      ",\n",
      "but\n",
      "doe\n",
      "so\n",
      "on\n",
      "ground\n",
      "of\n",
      "rule\n",
      ",\n",
      "not\n",
      "a\n",
      "dictionary\n",
      ".\n",
      "Syntactic\n",
      "analysis\n",
      "[\n",
      "edit\n",
      "]\n",
      "Grammar\n",
      "induction\n",
      "[\n",
      "24\n",
      "]\n",
      "Generate\n",
      "a\n",
      "formal\n",
      "grammar\n",
      "that\n",
      "describes\n",
      "a\n",
      "language\n",
      "'s\n",
      "syntax\n",
      ".\n",
      "Sentence\n",
      "breaking\n",
      "(\n",
      "also\n",
      "known\n",
      "a\n",
      "``\n",
      "sentence\n",
      "boundary\n",
      "disambiguation\n",
      "``\n",
      ")\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "find\n",
      "the\n",
      "sentence\n",
      "boundary\n",
      ".\n",
      "Sentence\n",
      "boundary\n",
      "are\n",
      "often\n",
      "marked\n",
      "by\n",
      "period\n",
      "or\n",
      "other\n",
      "punctuation\n",
      "mark\n",
      ",\n",
      "but\n",
      "these\n",
      "same\n",
      "character\n",
      "can\n",
      "serve\n",
      "other\n",
      "purpose\n",
      "(\n",
      "e.g\n",
      ".\n",
      ",\n",
      "marking\n",
      "abbreviation\n",
      ")\n",
      ".\n",
      "Parsing\n",
      "Determine\n",
      "the\n",
      "parse\n",
      "tree\n",
      "(\n",
      "grammatical\n",
      "analysis\n",
      ")\n",
      "of\n",
      "a\n",
      "given\n",
      "sentence\n",
      ".\n",
      "The\n",
      "grammar\n",
      "for\n",
      "natural\n",
      "language\n",
      "is\n",
      "ambiguous\n",
      "and\n",
      "typical\n",
      "sentence\n",
      "have\n",
      "multiple\n",
      "possible\n",
      "analysis\n",
      ":\n",
      "perhaps\n",
      "surprisingly\n",
      ",\n",
      "for\n",
      "a\n",
      "typical\n",
      "sentence\n",
      "there\n",
      "may\n",
      "be\n",
      "thousand\n",
      "of\n",
      "potential\n",
      "par\n",
      "(\n",
      "most\n",
      "of\n",
      "which\n",
      "will\n",
      "seem\n",
      "completely\n",
      "nonsensical\n",
      "to\n",
      "a\n",
      "human\n",
      ")\n",
      ".\n",
      "There\n",
      "are\n",
      "two\n",
      "primary\n",
      "type\n",
      "of\n",
      "parsing\n",
      ":\n",
      "dependency\n",
      "parsing\n",
      "and\n",
      "constituency\n",
      "parsing\n",
      ".\n",
      "Dependency\n",
      "parsing\n",
      "focus\n",
      "on\n",
      "the\n",
      "relationship\n",
      "between\n",
      "word\n",
      "in\n",
      "a\n",
      "sentence\n",
      "(\n",
      "marking\n",
      "thing\n",
      "like\n",
      "primary\n",
      "object\n",
      "and\n",
      "predicate\n",
      ")\n",
      ",\n",
      "whereas\n",
      "constituency\n",
      "parsing\n",
      "focus\n",
      "on\n",
      "building\n",
      "out\n",
      "the\n",
      "parse\n",
      "tree\n",
      "using\n",
      "a\n",
      "probabilistic\n",
      "context-free\n",
      "grammar\n",
      "(\n",
      "PCFG\n",
      ")\n",
      "(\n",
      "see\n",
      "also\n",
      "stochastic\n",
      "grammar\n",
      ")\n",
      ".\n",
      "Lexical\n",
      "semantics\n",
      "(\n",
      "of\n",
      "individual\n",
      "word\n",
      "in\n",
      "context\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Lexical\n",
      "semantics\n",
      "What\n",
      "is\n",
      "the\n",
      "computational\n",
      "meaning\n",
      "of\n",
      "individual\n",
      "word\n",
      "in\n",
      "context\n",
      "?\n",
      "Distributional\n",
      "semantics\n",
      "How\n",
      "can\n",
      "we\n",
      "learn\n",
      "semantic\n",
      "representation\n",
      "from\n",
      "data\n",
      "?\n",
      "Named\n",
      "entity\n",
      "recognition\n",
      "(\n",
      "NER\n",
      ")\n",
      "Given\n",
      "a\n",
      "stream\n",
      "of\n",
      "text\n",
      ",\n",
      "determine\n",
      "which\n",
      "item\n",
      "in\n",
      "the\n",
      "text\n",
      "map\n",
      "to\n",
      "proper\n",
      "name\n",
      ",\n",
      "such\n",
      "a\n",
      "people\n",
      "or\n",
      "place\n",
      ",\n",
      "and\n",
      "what\n",
      "the\n",
      "type\n",
      "of\n",
      "each\n",
      "such\n",
      "name\n",
      "is\n",
      "(\n",
      "e.g\n",
      ".\n",
      "person\n",
      ",\n",
      "location\n",
      ",\n",
      "organization\n",
      ")\n",
      ".\n",
      "Although\n",
      "capitalization\n",
      "can\n",
      "aid\n",
      "in\n",
      "recognizing\n",
      "named\n",
      "entity\n",
      "in\n",
      "language\n",
      "such\n",
      "a\n",
      "English\n",
      ",\n",
      "this\n",
      "information\n",
      "can\n",
      "not\n",
      "aid\n",
      "in\n",
      "determining\n",
      "the\n",
      "type\n",
      "of\n",
      "named\n",
      "entity\n",
      ",\n",
      "and\n",
      "in\n",
      "any\n",
      "case\n",
      ",\n",
      "is\n",
      "often\n",
      "inaccurate\n",
      "or\n",
      "insufficient\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "the\n",
      "first\n",
      "letter\n",
      "of\n",
      "a\n",
      "sentence\n",
      "is\n",
      "also\n",
      "capitalized\n",
      ",\n",
      "and\n",
      "named\n",
      "entity\n",
      "often\n",
      "span\n",
      "several\n",
      "word\n",
      ",\n",
      "only\n",
      "some\n",
      "of\n",
      "which\n",
      "are\n",
      "capitalized\n",
      ".\n",
      "Furthermore\n",
      ",\n",
      "many\n",
      "other\n",
      "language\n",
      "in\n",
      "non-Western\n",
      "script\n",
      "(\n",
      "e.g\n",
      ".\n",
      "Chinese\n",
      "or\n",
      "Arabic\n",
      ")\n",
      "do\n",
      "not\n",
      "have\n",
      "any\n",
      "capitalization\n",
      "at\n",
      "all\n",
      ",\n",
      "and\n",
      "even\n",
      "language\n",
      "with\n",
      "capitalization\n",
      "may\n",
      "not\n",
      "consistently\n",
      "use\n",
      "it\n",
      "to\n",
      "distinguish\n",
      "name\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "German\n",
      "capitalizes\n",
      "all\n",
      "noun\n",
      ",\n",
      "regardless\n",
      "of\n",
      "whether\n",
      "they\n",
      "are\n",
      "name\n",
      ",\n",
      "and\n",
      "French\n",
      "and\n",
      "Spanish\n",
      "do\n",
      "not\n",
      "capitalize\n",
      "name\n",
      "that\n",
      "serve\n",
      "a\n",
      "adjective\n",
      ".\n",
      "Sentiment\n",
      "analysis\n",
      "(\n",
      "see\n",
      "also\n",
      "Multimodal\n",
      "sentiment\n",
      "analysis\n",
      ")\n",
      "Extract\n",
      "subjective\n",
      "information\n",
      "usually\n",
      "from\n",
      "a\n",
      "set\n",
      "of\n",
      "document\n",
      ",\n",
      "often\n",
      "using\n",
      "online\n",
      "review\n",
      "to\n",
      "determine\n",
      "``\n",
      "polarity\n",
      "''\n",
      "about\n",
      "specific\n",
      "object\n",
      ".\n",
      "It\n",
      "is\n",
      "especially\n",
      "useful\n",
      "for\n",
      "identifying\n",
      "trend\n",
      "of\n",
      "public\n",
      "opinion\n",
      "in\n",
      "social\n",
      "medium\n",
      ",\n",
      "for\n",
      "marketing\n",
      ".\n",
      "Terminology\n",
      "extraction\n",
      "The\n",
      "goal\n",
      "of\n",
      "terminology\n",
      "extraction\n",
      "is\n",
      "to\n",
      "automatically\n",
      "extract\n",
      "relevant\n",
      "term\n",
      "from\n",
      "a\n",
      "given\n",
      "corpus\n",
      ".\n",
      "Word\n",
      "sense\n",
      "disambiguation\n",
      "(\n",
      "WSD\n",
      ")\n",
      "Many\n",
      "word\n",
      "have\n",
      "more\n",
      "than\n",
      "one\n",
      "meaning\n",
      ";\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "meaning\n",
      "which\n",
      "make\n",
      "the\n",
      "most\n",
      "sense\n",
      "in\n",
      "context\n",
      ".\n",
      "For\n",
      "this\n",
      "problem\n",
      ",\n",
      "we\n",
      "are\n",
      "typically\n",
      "given\n",
      "a\n",
      "list\n",
      "of\n",
      "word\n",
      "and\n",
      "associated\n",
      "word\n",
      "sens\n",
      ",\n",
      "e.g\n",
      ".\n",
      "from\n",
      "a\n",
      "dictionary\n",
      "or\n",
      "an\n",
      "online\n",
      "resource\n",
      "such\n",
      "a\n",
      "WordNet\n",
      ".\n",
      "Entity\n",
      "linking\n",
      "Many\n",
      "word\n",
      "-\n",
      "typically\n",
      "proper\n",
      "name\n",
      "-\n",
      "refer\n",
      "to\n",
      "named\n",
      "entity\n",
      ";\n",
      "here\n",
      "we\n",
      "have\n",
      "to\n",
      "select\n",
      "the\n",
      "entity\n",
      "(\n",
      "a\n",
      "famous\n",
      "individual\n",
      ",\n",
      "a\n",
      "location\n",
      ",\n",
      "a\n",
      "company\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "which\n",
      "is\n",
      "referred\n",
      "to\n",
      "in\n",
      "context\n",
      ".\n",
      "Relational\n",
      "semantics\n",
      "(\n",
      "semantics\n",
      "of\n",
      "individual\n",
      "sentence\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Relationship\n",
      "extraction\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "identify\n",
      "the\n",
      "relationship\n",
      "among\n",
      "named\n",
      "entity\n",
      "(\n",
      "e.g\n",
      ".\n",
      "who\n",
      "is\n",
      "married\n",
      "to\n",
      "whom\n",
      ")\n",
      ".\n",
      "Semantic\n",
      "parsing\n",
      "Given\n",
      "a\n",
      "piece\n",
      "of\n",
      "text\n",
      "(\n",
      "typically\n",
      "a\n",
      "sentence\n",
      ")\n",
      ",\n",
      "produce\n",
      "a\n",
      "formal\n",
      "representation\n",
      "of\n",
      "it\n",
      "semantics\n",
      ",\n",
      "either\n",
      "a\n",
      "a\n",
      "graph\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "AMR\n",
      "parsing\n",
      ")\n",
      "or\n",
      "in\n",
      "accordance\n",
      "with\n",
      "a\n",
      "logical\n",
      "formalism\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "in\n",
      "DRT\n",
      "parsing\n",
      ")\n",
      ".\n",
      "This\n",
      "challenge\n",
      "typically\n",
      "includes\n",
      "aspect\n",
      "of\n",
      "several\n",
      "more\n",
      "elementary\n",
      "NLP\n",
      "task\n",
      "from\n",
      "semantics\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      ",\n",
      "word\n",
      "sense\n",
      "disambiguation\n",
      ")\n",
      "and\n",
      "can\n",
      "be\n",
      "extended\n",
      "to\n",
      "include\n",
      "full-fledged\n",
      "discourse\n",
      "analysis\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "discourse\n",
      "analysis\n",
      ",\n",
      "coreference\n",
      ";\n",
      "see\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "below\n",
      ")\n",
      ".\n",
      "Semantic\n",
      "role\n",
      "labelling\n",
      "(\n",
      "see\n",
      "also\n",
      "implicit\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      "below\n",
      ")\n",
      "Given\n",
      "a\n",
      "single\n",
      "sentence\n",
      ",\n",
      "identify\n",
      "and\n",
      "disambiguate\n",
      "semantic\n",
      "predicate\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frame\n",
      ")\n",
      ",\n",
      "then\n",
      "identify\n",
      "and\n",
      "classify\n",
      "the\n",
      "frame\n",
      "element\n",
      "(\n",
      "semantic\n",
      "role\n",
      ")\n",
      ".\n",
      "Discourse\n",
      "(\n",
      "semantics\n",
      "beyond\n",
      "individual\n",
      "sentence\n",
      ")\n",
      "[\n",
      "edit\n",
      "]\n",
      "Coreference\n",
      "resolution\n",
      "Given\n",
      "a\n",
      "sentence\n",
      "or\n",
      "larger\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "determine\n",
      "which\n",
      "word\n",
      "(\n",
      "``\n",
      "mention\n",
      "''\n",
      ")\n",
      "refer\n",
      "to\n",
      "the\n",
      "same\n",
      "object\n",
      "(\n",
      "``\n",
      "entity\n",
      "''\n",
      ")\n",
      ".\n",
      "Anaphora\n",
      "resolution\n",
      "is\n",
      "a\n",
      "specific\n",
      "example\n",
      "of\n",
      "this\n",
      "task\n",
      ",\n",
      "and\n",
      "is\n",
      "specifically\n",
      "concerned\n",
      "with\n",
      "matching\n",
      "up\n",
      "pronoun\n",
      "with\n",
      "the\n",
      "noun\n",
      "or\n",
      "name\n",
      "to\n",
      "which\n",
      "they\n",
      "refer\n",
      ".\n",
      "The\n",
      "more\n",
      "general\n",
      "task\n",
      "of\n",
      "coreference\n",
      "resolution\n",
      "also\n",
      "includes\n",
      "identifying\n",
      "so-called\n",
      "``\n",
      "bridging\n",
      "relationship\n",
      "''\n",
      "involving\n",
      "referring\n",
      "expression\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "in\n",
      "a\n",
      "sentence\n",
      "such\n",
      "a\n",
      "``\n",
      "He\n",
      "entered\n",
      "John\n",
      "'s\n",
      "house\n",
      "through\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      ",\n",
      "``\n",
      "the\n",
      "front\n",
      "door\n",
      "''\n",
      "is\n",
      "a\n",
      "referring\n",
      "expression\n",
      "and\n",
      "the\n",
      "bridging\n",
      "relationship\n",
      "to\n",
      "be\n",
      "identified\n",
      "is\n",
      "the\n",
      "fact\n",
      "that\n",
      "the\n",
      "door\n",
      "being\n",
      "referred\n",
      "to\n",
      "is\n",
      "the\n",
      "front\n",
      "door\n",
      "of\n",
      "John\n",
      "'s\n",
      "house\n",
      "(\n",
      "rather\n",
      "than\n",
      "of\n",
      "some\n",
      "other\n",
      "structure\n",
      "that\n",
      "might\n",
      "also\n",
      "be\n",
      "referred\n",
      "to\n",
      ")\n",
      ".\n",
      "Discourse\n",
      "analysis\n",
      "This\n",
      "rubric\n",
      "includes\n",
      "several\n",
      "related\n",
      "task\n",
      ".\n",
      "One\n",
      "task\n",
      "is\n",
      "discourse\n",
      "parsing\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "identifying\n",
      "the\n",
      "discourse\n",
      "structure\n",
      "of\n",
      "a\n",
      "connected\n",
      "text\n",
      ",\n",
      "i.e\n",
      ".\n",
      "the\n",
      "nature\n",
      "of\n",
      "the\n",
      "discourse\n",
      "relationship\n",
      "between\n",
      "sentence\n",
      "(\n",
      "e.g\n",
      ".\n",
      "elaboration\n",
      ",\n",
      "explanation\n",
      ",\n",
      "contrast\n",
      ")\n",
      ".\n",
      "Another\n",
      "possible\n",
      "task\n",
      "is\n",
      "recognizing\n",
      "and\n",
      "classifying\n",
      "the\n",
      "speech\n",
      "act\n",
      "in\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      "(\n",
      "e.g\n",
      ".\n",
      "yes-no\n",
      "question\n",
      ",\n",
      "content\n",
      "question\n",
      ",\n",
      "statement\n",
      ",\n",
      "assertion\n",
      ",\n",
      "etc.\n",
      ")\n",
      ".\n",
      "Implicit\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      "Given\n",
      "a\n",
      "single\n",
      "sentence\n",
      ",\n",
      "identify\n",
      "and\n",
      "disambiguate\n",
      "semantic\n",
      "predicate\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "verbal\n",
      "frame\n",
      ")\n",
      "and\n",
      "their\n",
      "explicit\n",
      "semantic\n",
      "role\n",
      "in\n",
      "the\n",
      "current\n",
      "sentence\n",
      "(\n",
      "see\n",
      "Semantic\n",
      "role\n",
      "labelling\n",
      "above\n",
      ")\n",
      ".\n",
      "Then\n",
      ",\n",
      "identify\n",
      "semantic\n",
      "role\n",
      "that\n",
      "are\n",
      "not\n",
      "explicitly\n",
      "realized\n",
      "in\n",
      "the\n",
      "current\n",
      "sentence\n",
      ",\n",
      "classify\n",
      "them\n",
      "into\n",
      "argument\n",
      "that\n",
      "are\n",
      "explicitly\n",
      "realized\n",
      "elsewhere\n",
      "in\n",
      "the\n",
      "text\n",
      "and\n",
      "those\n",
      "that\n",
      "are\n",
      "not\n",
      "specified\n",
      ",\n",
      "and\n",
      "resolve\n",
      "the\n",
      "former\n",
      "against\n",
      "the\n",
      "local\n",
      "text\n",
      ".\n",
      "A\n",
      "closely\n",
      "related\n",
      "task\n",
      "is\n",
      "zero\n",
      "anaphora\n",
      "resolution\n",
      ",\n",
      "i.e.\n",
      ",\n",
      "the\n",
      "extension\n",
      "of\n",
      "coreference\n",
      "resolution\n",
      "to\n",
      "pro-drop\n",
      "language\n",
      ".\n",
      "Recognizing\n",
      "textual\n",
      "entailment\n",
      "Given\n",
      "two\n",
      "text\n",
      "fragment\n",
      ",\n",
      "determine\n",
      "if\n",
      "one\n",
      "being\n",
      "true\n",
      "entail\n",
      "the\n",
      "other\n",
      ",\n",
      "entail\n",
      "the\n",
      "other\n",
      "'s\n",
      "negation\n",
      ",\n",
      "or\n",
      "allows\n",
      "the\n",
      "other\n",
      "to\n",
      "be\n",
      "either\n",
      "true\n",
      "or\n",
      "false\n",
      ".\n",
      "[\n",
      "25\n",
      "]\n",
      "Topic\n",
      "segmentation\n",
      "and\n",
      "recognition\n",
      "Given\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ",\n",
      "separate\n",
      "it\n",
      "into\n",
      "segment\n",
      "each\n",
      "of\n",
      "which\n",
      "is\n",
      "devoted\n",
      "to\n",
      "a\n",
      "topic\n",
      ",\n",
      "and\n",
      "identify\n",
      "the\n",
      "topic\n",
      "of\n",
      "the\n",
      "segment\n",
      ".\n",
      "Argument\n",
      "mining\n",
      "The\n",
      "goal\n",
      "of\n",
      "argument\n",
      "mining\n",
      "is\n",
      "the\n",
      "automatic\n",
      "extraction\n",
      "and\n",
      "identification\n",
      "of\n",
      "argumentative\n",
      "structure\n",
      "from\n",
      "natural\n",
      "language\n",
      "text\n",
      "with\n",
      "the\n",
      "aid\n",
      "of\n",
      "computer\n",
      "program\n",
      ".\n",
      "[\n",
      "26\n",
      "]\n",
      "Such\n",
      "argumentative\n",
      "structure\n",
      "include\n",
      "the\n",
      "premise\n",
      ",\n",
      "conclusion\n",
      ",\n",
      "the\n",
      "argument\n",
      "scheme\n",
      "and\n",
      "the\n",
      "relationship\n",
      "between\n",
      "the\n",
      "main\n",
      "and\n",
      "subsidiary\n",
      "argument\n",
      ",\n",
      "or\n",
      "the\n",
      "main\n",
      "and\n",
      "counter-argument\n",
      "within\n",
      "discourse\n",
      ".\n",
      "[\n",
      "27\n",
      "]\n",
      "[\n",
      "28\n",
      "]\n",
      "Higher-level\n",
      "NLP\n",
      "application\n",
      "[\n",
      "edit\n",
      "]\n",
      "Automatic\n",
      "summarization\n",
      "(\n",
      "text\n",
      "summarization\n",
      ")\n",
      "Produce\n",
      "a\n",
      "readable\n",
      "summary\n",
      "of\n",
      "a\n",
      "chunk\n",
      "of\n",
      "text\n",
      ".\n",
      "Often\n",
      "used\n",
      "to\n",
      "provide\n",
      "summary\n",
      "of\n",
      "the\n",
      "text\n",
      "of\n",
      "a\n",
      "known\n",
      "type\n",
      ",\n",
      "such\n",
      "a\n",
      "research\n",
      "paper\n",
      ",\n",
      "article\n",
      "in\n",
      "the\n",
      "financial\n",
      "section\n",
      "of\n",
      "a\n",
      "newspaper\n",
      ".\n",
      "Book\n",
      "generation\n",
      "Not\n",
      "an\n",
      "NLP\n",
      "task\n",
      "proper\n",
      "but\n",
      "an\n",
      "extension\n",
      "of\n",
      "natural\n",
      "language\n",
      "generation\n",
      "and\n",
      "other\n",
      "NLP\n",
      "task\n",
      "is\n",
      "the\n",
      "creation\n",
      "of\n",
      "full-fledged\n",
      "book\n",
      ".\n",
      "The\n",
      "first\n",
      "machine-generated\n",
      "book\n",
      "wa\n",
      "created\n",
      "by\n",
      "a\n",
      "rule-based\n",
      "system\n",
      "in\n",
      "1984\n",
      "(\n",
      "Racter\n",
      ",\n",
      "The\n",
      "policeman\n",
      "'s\n",
      "beard\n",
      "is\n",
      "half-constructed\n",
      ")\n",
      ".\n",
      "[\n",
      "29\n",
      "]\n",
      "The\n",
      "first\n",
      "published\n",
      "work\n",
      "by\n",
      "a\n",
      "neural\n",
      "network\n",
      "wa\n",
      "published\n",
      "in\n",
      "2018\n",
      ",\n",
      "1\n",
      "the\n",
      "Road\n",
      ",\n",
      "marketed\n",
      "a\n",
      "a\n",
      "novel\n",
      ",\n",
      "contains\n",
      "sixty\n",
      "million\n",
      "word\n",
      ".\n",
      "Both\n",
      "these\n",
      "system\n",
      "are\n",
      "basically\n",
      "elaborate\n",
      "but\n",
      "non-sensical\n",
      "(\n",
      "semantics-free\n",
      ")\n",
      "language\n",
      "model\n",
      ".\n",
      "The\n",
      "first\n",
      "machine-generated\n",
      "science\n",
      "book\n",
      "wa\n",
      "published\n",
      "in\n",
      "2019\n",
      "(\n",
      "Beta\n",
      "Writer\n",
      ",\n",
      "Lithium-Ion\n",
      "Batteries\n",
      ",\n",
      "Springer\n",
      ",\n",
      "Cham\n",
      ")\n",
      ".\n",
      "[\n",
      "30\n",
      "]\n",
      "Unlike\n",
      "Racter\n",
      "and\n",
      "1\n",
      "the\n",
      "Road\n",
      ",\n",
      "this\n",
      "is\n",
      "grounded\n",
      "on\n",
      "factual\n",
      "knowledge\n",
      "and\n",
      "based\n",
      "on\n",
      "text\n",
      "summarization\n",
      ".\n",
      "Dialogue\n",
      "management\n",
      "Computer\n",
      "system\n",
      "intended\n",
      "to\n",
      "converse\n",
      "with\n",
      "a\n",
      "human\n",
      ".\n",
      "Document\n",
      "AI\n",
      "A\n",
      "Document\n",
      "AI\n",
      "platform\n",
      "sits\n",
      "on\n",
      "top\n",
      "of\n",
      "the\n",
      "NLP\n",
      "technology\n",
      "enabling\n",
      "user\n",
      "with\n",
      "no\n",
      "prior\n",
      "experience\n",
      "of\n",
      "artificial\n",
      "intelligence\n",
      ",\n",
      "machine\n",
      "learning\n",
      "or\n",
      "NLP\n",
      "to\n",
      "quickly\n",
      "train\n",
      "a\n",
      "computer\n",
      "to\n",
      "extract\n",
      "the\n",
      "specific\n",
      "data\n",
      "they\n",
      "need\n",
      "from\n",
      "different\n",
      "document\n",
      "type\n",
      ".\n",
      "NLP-powered\n",
      "Document\n",
      "AI\n",
      "enables\n",
      "non-technical\n",
      "team\n",
      "to\n",
      "quickly\n",
      "access\n",
      "information\n",
      "hidden\n",
      "in\n",
      "document\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "lawyer\n",
      ",\n",
      "business\n",
      "analyst\n",
      "and\n",
      "accountant\n",
      ".\n",
      "[\n",
      "31\n",
      "]\n",
      "Grammatical\n",
      "error\n",
      "correction\n",
      "Grammatical\n",
      "error\n",
      "detection\n",
      "and\n",
      "correction\n",
      "involves\n",
      "a\n",
      "great\n",
      "band-width\n",
      "of\n",
      "problem\n",
      "on\n",
      "all\n",
      "level\n",
      "of\n",
      "linguistic\n",
      "analysis\n",
      "(\n",
      "phonology/orthography\n",
      ",\n",
      "morphology\n",
      ",\n",
      "syntax\n",
      ",\n",
      "semantics\n",
      ",\n",
      "pragmatic\n",
      ")\n",
      ".\n",
      "Grammatical\n",
      "error\n",
      "correction\n",
      "is\n",
      "impactful\n",
      "since\n",
      "it\n",
      "affect\n",
      "hundred\n",
      "of\n",
      "million\n",
      "of\n",
      "people\n",
      "that\n",
      "use\n",
      "or\n",
      "acquire\n",
      "English\n",
      "a\n",
      "a\n",
      "second\n",
      "language\n",
      ".\n",
      "It\n",
      "ha\n",
      "thus\n",
      "been\n",
      "subject\n",
      "to\n",
      "a\n",
      "number\n",
      "of\n",
      "shared\n",
      "task\n",
      "since\n",
      "2011\n",
      ".\n",
      "[\n",
      "32\n",
      "]\n",
      "[\n",
      "33\n",
      "]\n",
      "[\n",
      "34\n",
      "]\n",
      "As\n",
      "far\n",
      "a\n",
      "orthography\n",
      ",\n",
      "morphology\n",
      ",\n",
      "syntax\n",
      "and\n",
      "certain\n",
      "aspect\n",
      "of\n",
      "semantics\n",
      "are\n",
      "concerned\n",
      ",\n",
      "and\n",
      "due\n",
      "to\n",
      "the\n",
      "development\n",
      "of\n",
      "powerful\n",
      "neural\n",
      "language\n",
      "model\n",
      "such\n",
      "a\n",
      "GPT-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "this\n",
      "can\n",
      "now\n",
      "(\n",
      "2019\n",
      ")\n",
      "be\n",
      "considered\n",
      "a\n",
      "largely\n",
      "solved\n",
      "problem\n",
      "and\n",
      "is\n",
      "being\n",
      "marketed\n",
      "in\n",
      "various\n",
      "commercial\n",
      "application\n",
      ".\n",
      "Machine\n",
      "translation\n",
      "Automatically\n",
      "translate\n",
      "text\n",
      "from\n",
      "one\n",
      "human\n",
      "language\n",
      "to\n",
      "another\n",
      ".\n",
      "This\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "difficult\n",
      "problem\n",
      ",\n",
      "and\n",
      "is\n",
      "a\n",
      "member\n",
      "of\n",
      "a\n",
      "class\n",
      "of\n",
      "problem\n",
      "colloquially\n",
      "termed\n",
      "``\n",
      "AI-complete\n",
      "``\n",
      ",\n",
      "i.e\n",
      ".\n",
      "requiring\n",
      "all\n",
      "of\n",
      "the\n",
      "different\n",
      "type\n",
      "of\n",
      "knowledge\n",
      "that\n",
      "human\n",
      "posse\n",
      "(\n",
      "grammar\n",
      ",\n",
      "semantics\n",
      ",\n",
      "fact\n",
      "about\n",
      "the\n",
      "real\n",
      "world\n",
      ",\n",
      "etc\n",
      ".\n",
      ")\n",
      "to\n",
      "solve\n",
      "properly\n",
      ".\n",
      "Natural\n",
      "language\n",
      "generation\n",
      "(\n",
      "NLG\n",
      ")\n",
      ":\n",
      "Convert\n",
      "information\n",
      "from\n",
      "computer\n",
      "database\n",
      "or\n",
      "semantic\n",
      "intent\n",
      "into\n",
      "readable\n",
      "human\n",
      "language\n",
      ".\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "(\n",
      "NLU\n",
      ")\n",
      "Convert\n",
      "chunk\n",
      "of\n",
      "text\n",
      "into\n",
      "more\n",
      "formal\n",
      "representation\n",
      "such\n",
      "a\n",
      "first-order\n",
      "logic\n",
      "structure\n",
      "that\n",
      "are\n",
      "easier\n",
      "for\n",
      "computer\n",
      "program\n",
      "to\n",
      "manipulate\n",
      ".\n",
      "Natural\n",
      "language\n",
      "understanding\n",
      "involves\n",
      "the\n",
      "identification\n",
      "of\n",
      "the\n",
      "intended\n",
      "semantic\n",
      "from\n",
      "the\n",
      "multiple\n",
      "possible\n",
      "semantics\n",
      "which\n",
      "can\n",
      "be\n",
      "derived\n",
      "from\n",
      "a\n",
      "natural\n",
      "language\n",
      "expression\n",
      "which\n",
      "usually\n",
      "take\n",
      "the\n",
      "form\n",
      "of\n",
      "organized\n",
      "notation\n",
      "of\n",
      "natural\n",
      "language\n",
      "concept\n",
      ".\n",
      "Introduction\n",
      "and\n",
      "creation\n",
      "of\n",
      "language\n",
      "metamodel\n",
      "and\n",
      "ontology\n",
      "are\n",
      "efficient\n",
      "however\n",
      "empirical\n",
      "solution\n",
      ".\n",
      "An\n",
      "explicit\n",
      "formalization\n",
      "of\n",
      "natural\n",
      "language\n",
      "semantics\n",
      "without\n",
      "confusion\n",
      "with\n",
      "implicit\n",
      "assumption\n",
      "such\n",
      "a\n",
      "closed-world\n",
      "assumption\n",
      "(\n",
      "CWA\n",
      ")\n",
      "vs.\n",
      "open-world\n",
      "assumption\n",
      ",\n",
      "or\n",
      "subjective\n",
      "Yes/No\n",
      "vs.\n",
      "objective\n",
      "True/False\n",
      "is\n",
      "expected\n",
      "for\n",
      "the\n",
      "construction\n",
      "of\n",
      "a\n",
      "basis\n",
      "of\n",
      "semantics\n",
      "formalization\n",
      ".\n",
      "[\n",
      "35\n",
      "]\n",
      "Question\n",
      "answering\n",
      "Given\n",
      "a\n",
      "human-language\n",
      "question\n",
      ",\n",
      "determine\n",
      "it\n",
      "answer\n",
      ".\n",
      "Typical\n",
      "question\n",
      "have\n",
      "a\n",
      "specific\n",
      "right\n",
      "answer\n",
      "(\n",
      "such\n",
      "a\n",
      "``\n",
      "What\n",
      "is\n",
      "the\n",
      "capital\n",
      "of\n",
      "Canada\n",
      "?\n",
      "``\n",
      ")\n",
      ",\n",
      "but\n",
      "sometimes\n",
      "open-ended\n",
      "question\n",
      "are\n",
      "also\n",
      "considered\n",
      "(\n",
      "such\n",
      "a\n",
      "``\n",
      "What\n",
      "is\n",
      "the\n",
      "meaning\n",
      "of\n",
      "life\n",
      "?\n",
      "''\n",
      ")\n",
      ".\n",
      "General\n",
      "tendency\n",
      "and\n",
      "(\n",
      "possible\n",
      ")\n",
      "future\n",
      "direction\n",
      "[\n",
      "edit\n",
      "]\n",
      "Based\n",
      "on\n",
      "long-standing\n",
      "trend\n",
      "in\n",
      "the\n",
      "field\n",
      ",\n",
      "it\n",
      "is\n",
      "possible\n",
      "to\n",
      "extrapolate\n",
      "future\n",
      "direction\n",
      "of\n",
      "NLP\n",
      ".\n",
      "As\n",
      "of\n",
      "2020\n",
      ",\n",
      "three\n",
      "trend\n",
      "among\n",
      "the\n",
      "topic\n",
      "of\n",
      "the\n",
      "long-standing\n",
      "series\n",
      "of\n",
      "CoNLL\n",
      "Shared\n",
      "Tasks\n",
      "can\n",
      "be\n",
      "observed\n",
      ":\n",
      "[\n",
      "36\n",
      "]\n",
      "Interest\n",
      "on\n",
      "increasingly\n",
      "abstract\n",
      ",\n",
      "``\n",
      "cognitive\n",
      "''\n",
      "aspect\n",
      "of\n",
      "natural\n",
      "language\n",
      "(\n",
      "1999-2001\n",
      ":\n",
      "shallow\n",
      "parsing\n",
      ",\n",
      "2002-03\n",
      ":\n",
      "named\n",
      "entity\n",
      "recognition\n",
      ",\n",
      "2006-09/2017-18\n",
      ":\n",
      "dependency\n",
      "syntax\n",
      ",\n",
      "2004-05/2008-09\n",
      "semantic\n",
      "role\n",
      "labelling\n",
      ",\n",
      "2011-12\n",
      "coreference\n",
      ",\n",
      "2015-16\n",
      ":\n",
      "discourse\n",
      "parsing\n",
      ",\n",
      "2019\n",
      ":\n",
      "semantic\n",
      "parsing\n",
      ")\n",
      ".\n",
      "Increasing\n",
      "interest\n",
      "in\n",
      "multilinguality\n",
      ",\n",
      "and\n",
      ",\n",
      "potentially\n",
      ",\n",
      "multimodality\n",
      "(\n",
      "English\n",
      "since\n",
      "1999\n",
      ";\n",
      "Spanish\n",
      ",\n",
      "Dutch\n",
      "since\n",
      "2002\n",
      ";\n",
      "German\n",
      "since\n",
      "2003\n",
      ";\n",
      "Bulgarian\n",
      ",\n",
      "Danish\n",
      ",\n",
      "Japanese\n",
      ",\n",
      "Portuguese\n",
      ",\n",
      "Slovenian\n",
      ",\n",
      "Swedish\n",
      ",\n",
      "Turkish\n",
      "since\n",
      "2006\n",
      ";\n",
      "Basque\n",
      ",\n",
      "Catalan\n",
      ",\n",
      "Chinese\n",
      ",\n",
      "Greek\n",
      ",\n",
      "Hungarian\n",
      ",\n",
      "Italian\n",
      ",\n",
      "Turkish\n",
      "since\n",
      "2007\n",
      ";\n",
      "Czech\n",
      "since\n",
      "2009\n",
      ";\n",
      "Arabic\n",
      "since\n",
      "2012\n",
      ";\n",
      "2017\n",
      ":\n",
      "40+\n",
      "language\n",
      ";\n",
      "2018\n",
      ":\n",
      "60+/100+\n",
      "language\n",
      ")\n",
      "Elimination\n",
      "of\n",
      "symbolic\n",
      "representation\n",
      "(\n",
      "rule-based\n",
      "over\n",
      "supervised\n",
      "towards\n",
      "weakly\n",
      "supervised\n",
      "method\n",
      ",\n",
      "representation\n",
      "learning\n",
      "and\n",
      "end-to-end\n",
      "system\n",
      ")\n",
      "Cognition\n",
      "and\n",
      "NLP\n",
      "[\n",
      "edit\n",
      "]\n",
      "Most\n",
      "higher-level\n",
      "NLP\n",
      "application\n",
      "involve\n",
      "aspect\n",
      "that\n",
      "emulate\n",
      "intelligent\n",
      "behaviour\n",
      "and\n",
      "apparent\n",
      "comprehension\n",
      "of\n",
      "natural\n",
      "language\n",
      ".\n",
      "More\n",
      "broadly\n",
      "speaking\n",
      ",\n",
      "the\n",
      "technical\n",
      "operationalization\n",
      "of\n",
      "increasingly\n",
      "advanced\n",
      "aspect\n",
      "of\n",
      "cognitive\n",
      "behaviour\n",
      "represents\n",
      "one\n",
      "of\n",
      "the\n",
      "developmental\n",
      "trajectory\n",
      "of\n",
      "NLP\n",
      "(\n",
      "see\n",
      "trend\n",
      "among\n",
      "CoNLL\n",
      "shared\n",
      "task\n",
      "above\n",
      ")\n",
      ".\n",
      "Cognition\n",
      "refers\n",
      "to\n",
      "``\n",
      "the\n",
      "mental\n",
      "action\n",
      "or\n",
      "process\n",
      "of\n",
      "acquiring\n",
      "knowledge\n",
      "and\n",
      "understanding\n",
      "through\n",
      "thought\n",
      ",\n",
      "experience\n",
      ",\n",
      "and\n",
      "the\n",
      "sens\n",
      ".\n",
      "''\n",
      "[\n",
      "37\n",
      "]\n",
      "Cognitive\n",
      "science\n",
      "is\n",
      "the\n",
      "interdisciplinary\n",
      ",\n",
      "scientific\n",
      "study\n",
      "of\n",
      "the\n",
      "mind\n",
      "and\n",
      "it\n",
      "process\n",
      ".\n",
      "[\n",
      "38\n",
      "]\n",
      "Cognitive\n",
      "linguistics\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "branch\n",
      "of\n",
      "linguistics\n",
      ",\n",
      "combining\n",
      "knowledge\n",
      "and\n",
      "research\n",
      "from\n",
      "both\n",
      "psychology\n",
      "and\n",
      "linguistics\n",
      ".\n",
      "[\n",
      "39\n",
      "]\n",
      "Especially\n",
      "during\n",
      "the\n",
      "age\n",
      "of\n",
      "symbolic\n",
      "NLP\n",
      ",\n",
      "the\n",
      "area\n",
      "of\n",
      "computational\n",
      "linguistics\n",
      "maintained\n",
      "strong\n",
      "tie\n",
      "with\n",
      "cognitive\n",
      "study\n",
      ".\n",
      "As\n",
      "an\n",
      "example\n",
      ",\n",
      "George\n",
      "Lakoff\n",
      "offer\n",
      "a\n",
      "methodology\n",
      "to\n",
      "build\n",
      "natural\n",
      "language\n",
      "processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "algorithm\n",
      "through\n",
      "the\n",
      "perspective\n",
      "of\n",
      "cognitive\n",
      "science\n",
      ",\n",
      "along\n",
      "with\n",
      "the\n",
      "finding\n",
      "of\n",
      "cognitive\n",
      "linguistics\n",
      ",\n",
      "[\n",
      "40\n",
      "]\n",
      "with\n",
      "two\n",
      "defining\n",
      "aspect\n",
      ":\n",
      "Apply\n",
      "the\n",
      "theory\n",
      "of\n",
      "conceptual\n",
      "metaphor\n",
      ",\n",
      "explained\n",
      "by\n",
      "Lakoff\n",
      "a\n",
      "“\n",
      "the\n",
      "understanding\n",
      "of\n",
      "one\n",
      "idea\n",
      ",\n",
      "in\n",
      "term\n",
      "of\n",
      "another\n",
      "”\n",
      "which\n",
      "provides\n",
      "an\n",
      "idea\n",
      "of\n",
      "the\n",
      "intent\n",
      "of\n",
      "the\n",
      "author\n",
      ".\n",
      "[\n",
      "41\n",
      "]\n",
      "For\n",
      "example\n",
      ",\n",
      "consider\n",
      "the\n",
      "English\n",
      "word\n",
      "“\n",
      "big\n",
      "”\n",
      ".\n",
      "When\n",
      "used\n",
      "in\n",
      "a\n",
      "comparison\n",
      "(\n",
      "“\n",
      "That\n",
      "is\n",
      "a\n",
      "big\n",
      "tree\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "'s\n",
      "intent\n",
      "is\n",
      "to\n",
      "imply\n",
      "that\n",
      "the\n",
      "tree\n",
      "is\n",
      "”\n",
      "physically\n",
      "large\n",
      "”\n",
      "relative\n",
      "to\n",
      "other\n",
      "tree\n",
      "or\n",
      "the\n",
      "author\n",
      "experience\n",
      ".\n",
      "When\n",
      "used\n",
      "metaphorically\n",
      "(\n",
      "”\n",
      "Tomorrow\n",
      "is\n",
      "a\n",
      "big\n",
      "day\n",
      "”\n",
      ")\n",
      ",\n",
      "the\n",
      "author\n",
      "’\n",
      "s\n",
      "intent\n",
      "to\n",
      "imply\n",
      "”\n",
      "importance\n",
      "”\n",
      ".\n",
      "The\n",
      "intent\n",
      "behind\n",
      "other\n",
      "usage\n",
      ",\n",
      "like\n",
      "in\n",
      "”\n",
      "She\n",
      "is\n",
      "a\n",
      "big\n",
      "person\n",
      "”\n",
      "will\n",
      "remain\n",
      "somewhat\n",
      "ambiguous\n",
      "to\n",
      "a\n",
      "person\n",
      "and\n",
      "a\n",
      "cognitive\n",
      "NLP\n",
      "algorithm\n",
      "alike\n",
      "without\n",
      "additional\n",
      "information\n",
      ".\n",
      "Assign\n",
      "relative\n",
      "measure\n",
      "of\n",
      "meaning\n",
      "to\n",
      "a\n",
      "word\n",
      ",\n",
      "phrase\n",
      ",\n",
      "sentence\n",
      "or\n",
      "piece\n",
      "of\n",
      "text\n",
      "based\n",
      "on\n",
      "the\n",
      "information\n",
      "presented\n",
      "before\n",
      "and\n",
      "after\n",
      "the\n",
      "piece\n",
      "of\n",
      "text\n",
      "being\n",
      "analyzed\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "by\n",
      "mean\n",
      "of\n",
      "a\n",
      "probabilistic\n",
      "context-free\n",
      "grammar\n",
      "(\n",
      "PCFG\n",
      ")\n",
      ".\n",
      "The\n",
      "mathematical\n",
      "equation\n",
      "for\n",
      "such\n",
      "algorithm\n",
      "is\n",
      "presented\n",
      "in\n",
      "US\n",
      "patent\n",
      "9269353\n",
      ":\n",
      "R\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ")\n",
      "=\n",
      "P\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ")\n",
      "×\n",
      "1\n",
      "2\n",
      "d\n",
      "(\n",
      "∑\n",
      "i\n",
      "=\n",
      "−\n",
      "d\n",
      "d\n",
      "(\n",
      "(\n",
      "P\n",
      "M\n",
      "M\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      "−\n",
      "1\n",
      ")\n",
      "×\n",
      "P\n",
      "F\n",
      "(\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      ",\n",
      "t\n",
      "o\n",
      "k\n",
      "e\n",
      "n\n",
      "N\n",
      "−\n",
      "1\n",
      ")\n",
      ")\n",
      "i\n",
      ")\n",
      "{\n",
      "\\displaystyle\n",
      "{\n",
      "RMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ")\n",
      "}\n",
      "=\n",
      "{\n",
      "PMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ")\n",
      "}\n",
      "\\times\n",
      "{\n",
      "\\frac\n",
      "{\n",
      "1\n",
      "}\n",
      "{\n",
      "2d\n",
      "}\n",
      "}\n",
      "\\left\n",
      "(\n",
      "\\sum\n",
      "_\n",
      "{\n",
      "i=-d\n",
      "}\n",
      "^\n",
      "{\n",
      "d\n",
      "}\n",
      "{\n",
      "(\n",
      "(\n",
      "PMM\n",
      "(\n",
      "token_\n",
      "{\n",
      "N-1\n",
      "}\n",
      ")\n",
      "}\n",
      "\\times\n",
      "{\n",
      "PF\n",
      "(\n",
      "token_\n",
      "{\n",
      "N\n",
      "}\n",
      ",\n",
      "token_\n",
      "{\n",
      "N-1\n",
      "}\n",
      ")\n",
      ")\n",
      "_\n",
      "{\n",
      "i\n",
      "}\n",
      "}\n",
      "\\right\n",
      ")\n",
      "}\n",
      "Where\n",
      ",\n",
      "RMM\n",
      ",\n",
      "is\n",
      "the\n",
      "Relative\n",
      "Measure\n",
      "of\n",
      "Meaning\n",
      "token\n",
      ",\n",
      "is\n",
      "any\n",
      "block\n",
      "of\n",
      "text\n",
      ",\n",
      "sentence\n",
      ",\n",
      "phrase\n",
      "or\n",
      "word\n",
      "N\n",
      ",\n",
      "is\n",
      "the\n",
      "number\n",
      "of\n",
      "token\n",
      "being\n",
      "analyzed\n",
      "PMM\n",
      ",\n",
      "is\n",
      "the\n",
      "Probable\n",
      "Measure\n",
      "of\n",
      "Meaning\n",
      "based\n",
      "on\n",
      "a\n",
      "corpus\n",
      "d\n",
      ",\n",
      "is\n",
      "the\n",
      "location\n",
      "of\n",
      "the\n",
      "token\n",
      "along\n",
      "the\n",
      "sequence\n",
      "of\n",
      "N-1\n",
      "token\n",
      "PF\n",
      ",\n",
      "is\n",
      "the\n",
      "Probability\n",
      "Function\n",
      "specific\n",
      "to\n",
      "a\n",
      "language\n",
      "Ties\n",
      "with\n",
      "cognitive\n",
      "linguistics\n",
      "are\n",
      "part\n",
      "of\n",
      "the\n",
      "historical\n",
      "heritage\n",
      "of\n",
      "NLP\n",
      ",\n",
      "but\n",
      "they\n",
      "have\n",
      "been\n",
      "le\n",
      "frequently\n",
      "addressed\n",
      "since\n",
      "the\n",
      "statistical\n",
      "turn\n",
      "during\n",
      "the\n",
      "1990s\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "approach\n",
      "to\n",
      "develop\n",
      "cognitive\n",
      "model\n",
      "towards\n",
      "technically\n",
      "operationalizable\n",
      "framework\n",
      "have\n",
      "been\n",
      "pursued\n",
      "in\n",
      "the\n",
      "context\n",
      "of\n",
      "various\n",
      "framework\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "of\n",
      "cognitive\n",
      "grammar\n",
      ",\n",
      "[\n",
      "42\n",
      "]\n",
      "functional\n",
      "grammar\n",
      ",\n",
      "[\n",
      "43\n",
      "]\n",
      "construction\n",
      "grammar\n",
      ",\n",
      "[\n",
      "44\n",
      "]\n",
      "computational\n",
      "psycholinguistics\n",
      "and\n",
      "cognitive\n",
      "neuroscience\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "ACT-R\n",
      ")\n",
      ",\n",
      "however\n",
      ",\n",
      "with\n",
      "limited\n",
      "uptake\n",
      "in\n",
      "mainstream\n",
      "NLP\n",
      "(\n",
      "a\n",
      "measured\n",
      "by\n",
      "presence\n",
      "on\n",
      "major\n",
      "conference\n",
      "[\n",
      "45\n",
      "]\n",
      "of\n",
      "the\n",
      "ACL\n",
      ")\n",
      ".\n",
      "More\n",
      "recently\n",
      ",\n",
      "idea\n",
      "of\n",
      "cognitive\n",
      "NLP\n",
      "have\n",
      "been\n",
      "revived\n",
      "a\n",
      "an\n",
      "approach\n",
      "to\n",
      "achieve\n",
      "explainability\n",
      ",\n",
      "e.g.\n",
      ",\n",
      "under\n",
      "the\n",
      "notion\n",
      "of\n",
      "``\n",
      "cognitive\n",
      "AI\n",
      "''\n",
      ".\n",
      "[\n",
      "46\n",
      "]\n",
      "Likewise\n",
      ",\n",
      "idea\n",
      "of\n",
      "cognitive\n",
      "NLP\n",
      "are\n",
      "inherent\n",
      "to\n",
      "neural\n",
      "model\n",
      "multimodal\n",
      "NLP\n",
      "(\n",
      "although\n",
      "rarely\n",
      "made\n",
      "explicit\n",
      ")\n",
      ".\n",
      "[\n",
      "47\n",
      "]\n",
      "See\n",
      "also\n",
      "[\n",
      "edit\n",
      "]\n",
      "1\n",
      "the\n",
      "Road\n",
      "Automated\n",
      "essay\n",
      "scoring\n",
      "Biomedical\n",
      "text\n",
      "mining\n",
      "Compound\n",
      "term\n",
      "processing\n",
      "Computational\n",
      "linguistics\n",
      "Computer-assisted\n",
      "reviewing\n",
      "Controlled\n",
      "natural\n",
      "language\n",
      "Deep\n",
      "learning\n",
      "Deep\n",
      "linguistic\n",
      "processing\n",
      "Distributional\n",
      "semantics\n",
      "Foreign\n",
      "language\n",
      "reading\n",
      "aid\n",
      "Foreign\n",
      "language\n",
      "writing\n",
      "aid\n",
      "Information\n",
      "extraction\n",
      "Information\n",
      "retrieval\n",
      "Language\n",
      "and\n",
      "Communication\n",
      "Technologies\n",
      "Language\n",
      "technology\n",
      "Latent\n",
      "semantic\n",
      "indexing\n",
      "Native-language\n",
      "identification\n",
      "Natural\n",
      "language\n",
      "programming\n",
      "Natural\n",
      "language\n",
      "search\n",
      "Outline\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "Query\n",
      "expansion\n",
      "Query\n",
      "understanding\n",
      "Reification\n",
      "(\n",
      "linguistics\n",
      ")\n",
      "Speech\n",
      "processing\n",
      "Spoken\n",
      "dialogue\n",
      "system\n",
      "Text-proofing\n",
      "Text\n",
      "simplification\n",
      "Transformer\n",
      "(\n",
      "machine\n",
      "learning\n",
      "model\n",
      ")\n",
      "Truecasing\n",
      "Question\n",
      "answering\n",
      "Word2vec\n",
      "References\n",
      "[\n",
      "edit\n",
      "]\n",
      "^\n",
      "Kongthon\n",
      ",\n",
      "Alisa\n",
      ";\n",
      "Sangkeettrakarn\n",
      ",\n",
      "Chatchawal\n",
      ";\n",
      "Kongyoung\n",
      ",\n",
      "Sarawoot\n",
      ";\n",
      "Haruechaiyasak\n",
      ",\n",
      "Choochart\n",
      "(\n",
      "October\n",
      "27–30\n",
      ",\n",
      "2009\n",
      ")\n",
      ".\n",
      "Implementing\n",
      "an\n",
      "online\n",
      "help\n",
      "desk\n",
      "system\n",
      "based\n",
      "on\n",
      "conversational\n",
      "agent\n",
      ".\n",
      "MEDES\n",
      "'09\n",
      ":\n",
      "The\n",
      "International\n",
      "Conference\n",
      "on\n",
      "Management\n",
      "of\n",
      "Emergent\n",
      "Digital\n",
      "EcoSystems\n",
      ".\n",
      "France\n",
      ":\n",
      "ACM\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/1643823.1643908\n",
      ".\n",
      "^\n",
      "Hutchins\n",
      ",\n",
      "J\n",
      ".\n",
      "(\n",
      "2005\n",
      ")\n",
      ".\n",
      "``\n",
      "The\n",
      "history\n",
      "of\n",
      "machine\n",
      "translation\n",
      "in\n",
      "a\n",
      "nutshell\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "[\n",
      "self-published\n",
      "source\n",
      "]\n",
      "^\n",
      "Koskenniemi\n",
      ",\n",
      "Kimmo\n",
      "(\n",
      "1983\n",
      ")\n",
      ",\n",
      "Two-level\n",
      "morphology\n",
      ":\n",
      "A\n",
      "general\n",
      "computational\n",
      "model\n",
      "of\n",
      "word-form\n",
      "recognition\n",
      "and\n",
      "production\n",
      "(\n",
      "PDF\n",
      ")\n",
      ",\n",
      "Department\n",
      "of\n",
      "General\n",
      "Linguistics\n",
      ",\n",
      "University\n",
      "of\n",
      "Helsinki\n",
      "^\n",
      "Joshi\n",
      ",\n",
      "A.\n",
      "K.\n",
      ",\n",
      "&\n",
      "Weinstein\n",
      ",\n",
      "S.\n",
      "(\n",
      "1981\n",
      ",\n",
      "August\n",
      ")\n",
      ".\n",
      "Control\n",
      "of\n",
      "Inference\n",
      ":\n",
      "Role\n",
      "of\n",
      "Some\n",
      "Aspects\n",
      "of\n",
      "Discourse\n",
      "Structure-Centering\n",
      ".\n",
      "In\n",
      "IJCAI\n",
      "(\n",
      "pp\n",
      ".\n",
      "385-387\n",
      ")\n",
      ".\n",
      "^\n",
      "Guida\n",
      ",\n",
      "G.\n",
      ";\n",
      "Mauri\n",
      ",\n",
      "G.\n",
      "(\n",
      "July\n",
      "1986\n",
      ")\n",
      ".\n",
      "``\n",
      "Evaluation\n",
      "of\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      ":\n",
      "Issues\n",
      "and\n",
      "approach\n",
      "''\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "IEEE\n",
      ".\n",
      "74\n",
      "(\n",
      "7\n",
      ")\n",
      ":\n",
      "1026–1035\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1109/PROC.1986.13580\n",
      ".\n",
      "ISSN\n",
      "1558-2256\n",
      ".\n",
      "S2CID\n",
      "30688575\n",
      ".\n",
      "^\n",
      "Chomskyan\n",
      "linguistics\n",
      "encourages\n",
      "the\n",
      "investigation\n",
      "of\n",
      "``\n",
      "corner\n",
      "case\n",
      "``\n",
      "that\n",
      "stress\n",
      "the\n",
      "limit\n",
      "of\n",
      "it\n",
      "theoretical\n",
      "model\n",
      "(\n",
      "comparable\n",
      "to\n",
      "pathological\n",
      "phenomenon\n",
      "in\n",
      "mathematics\n",
      ")\n",
      ",\n",
      "typically\n",
      "created\n",
      "using\n",
      "thought\n",
      "experiment\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "systematic\n",
      "investigation\n",
      "of\n",
      "typical\n",
      "phenomenon\n",
      "that\n",
      "occur\n",
      "in\n",
      "real-world\n",
      "data\n",
      ",\n",
      "a\n",
      "is\n",
      "the\n",
      "case\n",
      "in\n",
      "corpus\n",
      "linguistics\n",
      ".\n",
      "The\n",
      "creation\n",
      "and\n",
      "use\n",
      "of\n",
      "such\n",
      "corpus\n",
      "of\n",
      "real-world\n",
      "data\n",
      "is\n",
      "a\n",
      "fundamental\n",
      "part\n",
      "of\n",
      "machine-learning\n",
      "algorithm\n",
      "for\n",
      "natural\n",
      "language\n",
      "processing\n",
      ".\n",
      "In\n",
      "addition\n",
      ",\n",
      "theoretical\n",
      "underpinnings\n",
      "of\n",
      "Chomskyan\n",
      "linguistics\n",
      "such\n",
      "a\n",
      "the\n",
      "so-called\n",
      "``\n",
      "poverty\n",
      "of\n",
      "the\n",
      "stimulus\n",
      "``\n",
      "argument\n",
      "entail\n",
      "that\n",
      "general\n",
      "learning\n",
      "algorithm\n",
      ",\n",
      "a\n",
      "are\n",
      "typically\n",
      "used\n",
      "in\n",
      "machine\n",
      "learning\n",
      ",\n",
      "can\n",
      "not\n",
      "be\n",
      "successful\n",
      "in\n",
      "language\n",
      "processing\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "the\n",
      "Chomskyan\n",
      "paradigm\n",
      "discouraged\n",
      "the\n",
      "application\n",
      "of\n",
      "such\n",
      "model\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "^\n",
      "Goldberg\n",
      ",\n",
      "Yoav\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "``\n",
      "A\n",
      "Primer\n",
      "on\n",
      "Neural\n",
      "Network\n",
      "Models\n",
      "for\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "''\n",
      ".\n",
      "Journal\n",
      "of\n",
      "Artificial\n",
      "Intelligence\n",
      "Research\n",
      ".\n",
      "57\n",
      ":\n",
      "345–420\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1807.10854\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1613/jair.4992\n",
      ".\n",
      "S2CID\n",
      "8273530\n",
      ".\n",
      "^\n",
      "Goodfellow\n",
      ",\n",
      "Ian\n",
      ";\n",
      "Bengio\n",
      ",\n",
      "Yoshua\n",
      ";\n",
      "Courville\n",
      ",\n",
      "Aaron\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Deep\n",
      "Learning\n",
      ".\n",
      "MIT\n",
      "Press\n",
      ".\n",
      "^\n",
      "Jozefowicz\n",
      ",\n",
      "Rafal\n",
      ";\n",
      "Vinyals\n",
      ",\n",
      "Oriol\n",
      ";\n",
      "Schuster\n",
      ",\n",
      "Mike\n",
      ";\n",
      "Shazeer\n",
      ",\n",
      "Noam\n",
      ";\n",
      "Wu\n",
      ",\n",
      "Yonghui\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Exploring\n",
      "the\n",
      "Limits\n",
      "of\n",
      "Language\n",
      "Modeling\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1602.02410\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "2016arXiv160202410J\n",
      ".\n",
      "^\n",
      "Choe\n",
      ",\n",
      "Do\n",
      "Kook\n",
      ";\n",
      "Charniak\n",
      ",\n",
      "Eugene\n",
      ".\n",
      "``\n",
      "Parsing\n",
      "a\n",
      "Language\n",
      "Modeling\n",
      "''\n",
      ".\n",
      "Emnlp\n",
      "2016\n",
      ".\n",
      "^\n",
      "Vinyals\n",
      ",\n",
      "Oriol\n",
      ";\n",
      "et\n",
      "al\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "Grammar\n",
      "a\n",
      "a\n",
      "Foreign\n",
      "Language\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Nips2015\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1412.7449\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "2014arXiv1412.7449V\n",
      ".\n",
      "^\n",
      "Turchin\n",
      ",\n",
      "Alexander\n",
      ";\n",
      "Florez\n",
      "Builes\n",
      ",\n",
      "Luisa\n",
      "F.\n",
      "(\n",
      "2021-03-19\n",
      ")\n",
      ".\n",
      "``\n",
      "Using\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "to\n",
      "Measure\n",
      "and\n",
      "Improve\n",
      "Quality\n",
      "of\n",
      "Diabetes\n",
      "Care\n",
      ":\n",
      "A\n",
      "Systematic\n",
      "Review\n",
      "''\n",
      ".\n",
      "Journal\n",
      "of\n",
      "Diabetes\n",
      "Science\n",
      "and\n",
      "Technology\n",
      ".\n",
      "15\n",
      "(\n",
      "3\n",
      ")\n",
      ":\n",
      "553–560\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1177/19322968211000831\n",
      ".\n",
      "ISSN\n",
      "1932-2968\n",
      ".\n",
      "PMC\n",
      "8120048\n",
      ".\n",
      "PMID\n",
      "33736486\n",
      ".\n",
      "^\n",
      "Winograd\n",
      ",\n",
      "Terry\n",
      "(\n",
      "1971\n",
      ")\n",
      ".\n",
      "Procedures\n",
      "a\n",
      "a\n",
      "Representation\n",
      "for\n",
      "Data\n",
      "in\n",
      "a\n",
      "Computer\n",
      "Program\n",
      "for\n",
      "Understanding\n",
      "Natural\n",
      "Language\n",
      "(\n",
      "Thesis\n",
      ")\n",
      ".\n",
      "^\n",
      "Schank\n",
      ",\n",
      "Roger\n",
      "C.\n",
      ";\n",
      "Abelson\n",
      ",\n",
      "Robert\n",
      "P.\n",
      "(\n",
      "1977\n",
      ")\n",
      ".\n",
      "Scripts\n",
      ",\n",
      "Plans\n",
      ",\n",
      "Goals\n",
      ",\n",
      "and\n",
      "Understanding\n",
      ":\n",
      "An\n",
      "Inquiry\n",
      "Into\n",
      "Human\n",
      "Knowledge\n",
      "Structures\n",
      ".\n",
      "Hillsdale\n",
      ":\n",
      "Erlbaum\n",
      ".\n",
      "ISBN\n",
      "0-470-99033-3\n",
      ".\n",
      "^\n",
      "Mark\n",
      "Johnson\n",
      ".\n",
      "How\n",
      "the\n",
      "statistical\n",
      "revolution\n",
      "change\n",
      "(\n",
      "computational\n",
      ")\n",
      "linguistics\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "EACL\n",
      "2009\n",
      "Workshop\n",
      "on\n",
      "the\n",
      "Interaction\n",
      "between\n",
      "Linguistics\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ".\n",
      "^\n",
      "Philip\n",
      "Resnik\n",
      ".\n",
      "Four\n",
      "revolution\n",
      ".\n",
      "Language\n",
      "Log\n",
      ",\n",
      "February\n",
      "5\n",
      ",\n",
      "2011\n",
      ".\n",
      "^\n",
      "``\n",
      "Investigating\n",
      "complex-valued\n",
      "representation\n",
      "in\n",
      "NLP\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "^\n",
      "Trabelsi\n",
      ",\n",
      "Chiheb\n",
      ";\n",
      "Bilaniuk\n",
      ",\n",
      "Olexa\n",
      ";\n",
      "Zhang\n",
      ",\n",
      "Ying\n",
      ";\n",
      "Serdyuk\n",
      ",\n",
      "Dmitriy\n",
      ";\n",
      "Subramanian\n",
      ",\n",
      "Sandeep\n",
      ";\n",
      "Santos\n",
      ",\n",
      "João\n",
      "Felipe\n",
      ";\n",
      "Mehri\n",
      ",\n",
      "Soroush\n",
      ";\n",
      "Rostamzadeh\n",
      ",\n",
      "Negar\n",
      ";\n",
      "Bengio\n",
      ",\n",
      "Yoshua\n",
      ";\n",
      "Pal\n",
      ",\n",
      "Christopher\n",
      "J\n",
      ".\n",
      "(\n",
      "2018-02-25\n",
      ")\n",
      ".\n",
      "``\n",
      "Deep\n",
      "Complex\n",
      "Networks\n",
      "''\n",
      ".\n",
      "arXiv\n",
      ":\n",
      "1705.09792\n",
      "[\n",
      "cs.NE\n",
      "]\n",
      ".\n",
      "^\n",
      "Socher\n",
      ",\n",
      "Richard\n",
      ".\n",
      "``\n",
      "Deep\n",
      "Learning\n",
      "For\n",
      "NLP-ACL\n",
      "2012\n",
      "Tutorial\n",
      "''\n",
      ".\n",
      "www.socher.org\n",
      ".\n",
      "Retrieved\n",
      "2020-08-17\n",
      ".\n",
      "This\n",
      "wa\n",
      "an\n",
      "early\n",
      "Deep\n",
      "Learning\n",
      "tutorial\n",
      "at\n",
      "the\n",
      "ACL\n",
      "2012\n",
      "and\n",
      "met\n",
      "with\n",
      "both\n",
      "interest\n",
      "and\n",
      "(\n",
      "at\n",
      "the\n",
      "time\n",
      ")\n",
      "skepticism\n",
      "by\n",
      "most\n",
      "participant\n",
      ".\n",
      "Until\n",
      "then\n",
      ",\n",
      "neural\n",
      "learning\n",
      "wa\n",
      "basically\n",
      "rejected\n",
      "because\n",
      "of\n",
      "it\n",
      "lack\n",
      "of\n",
      "statistical\n",
      "interpretability\n",
      ".\n",
      "Until\n",
      "2015\n",
      ",\n",
      "deep\n",
      "learning\n",
      "had\n",
      "evolved\n",
      "into\n",
      "the\n",
      "major\n",
      "framework\n",
      "of\n",
      "NLP\n",
      ".\n",
      "^\n",
      "Annamoradnejad\n",
      ",\n",
      "I.\n",
      "and\n",
      "Zoghi\n",
      ",\n",
      "G.\n",
      "(\n",
      "2020\n",
      ")\n",
      ".\n",
      "Colbert\n",
      ":\n",
      "Using\n",
      "bert\n",
      "sentence\n",
      "embedding\n",
      "for\n",
      "humor\n",
      "detection\n",
      ".\n",
      "arXiv\n",
      "preprint\n",
      "arXiv:2004.12765\n",
      ".\n",
      "^\n",
      "Yi\n",
      ",\n",
      "Chucai\n",
      ";\n",
      "Tian\n",
      ",\n",
      "Yingli\n",
      "(\n",
      "2012\n",
      ")\n",
      ",\n",
      "``\n",
      "Assistive\n",
      "Text\n",
      "Reading\n",
      "from\n",
      "Complex\n",
      "Background\n",
      "for\n",
      "Blind\n",
      "Persons\n",
      "''\n",
      ",\n",
      "Camera-Based\n",
      "Document\n",
      "Analysis\n",
      "and\n",
      "Recognition\n",
      ",\n",
      "Springer\n",
      "Berlin\n",
      "Heidelberg\n",
      ",\n",
      "pp\n",
      ".\n",
      "15–28\n",
      ",\n",
      "CiteSeerX\n",
      "10.1.1.668.869\n",
      ",\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-642-29364-1_2\n",
      ",\n",
      "ISBN\n",
      "9783642293634\n",
      "^\n",
      "``\n",
      "What\n",
      "is\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "?\n",
      "Intro\n",
      "to\n",
      "NLP\n",
      "in\n",
      "Machine\n",
      "Learning\n",
      "''\n",
      ".\n",
      "GyanSetu\n",
      "!\n",
      ".\n",
      "2020-12-06\n",
      ".\n",
      "Retrieved\n",
      "2021-01-09\n",
      ".\n",
      "^\n",
      "Kishorjit\n",
      ",\n",
      "N.\n",
      ";\n",
      "Vidya\n",
      ",\n",
      "Raj\n",
      "RK\n",
      ".\n",
      ";\n",
      "Nirmal\n",
      ",\n",
      "Y.\n",
      ";\n",
      "Sivaji\n",
      ",\n",
      "B\n",
      ".\n",
      "(\n",
      "2012\n",
      ")\n",
      ".\n",
      "``\n",
      "Manipuri\n",
      "Morpheme\n",
      "Identification\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "3rd\n",
      "Workshop\n",
      "on\n",
      "South\n",
      "and\n",
      "Southeast\n",
      "Asian\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "(\n",
      "SANLP\n",
      ")\n",
      ".\n",
      "COLING\n",
      "2012\n",
      ",\n",
      "Mumbai\n",
      ",\n",
      "December\n",
      "2012\n",
      ":\n",
      "95–108\n",
      ".\n",
      "CS1\n",
      "maint\n",
      ":\n",
      "location\n",
      "(\n",
      "link\n",
      ")\n",
      "^\n",
      "Klein\n",
      ",\n",
      "Dan\n",
      ";\n",
      "Manning\n",
      ",\n",
      "Christopher\n",
      "D.\n",
      "(\n",
      "2002\n",
      ")\n",
      ".\n",
      "``\n",
      "Natural\n",
      "language\n",
      "grammar\n",
      "induction\n",
      "using\n",
      "a\n",
      "constituent-context\n",
      "model\n",
      "''\n",
      "(\n",
      "PDF\n",
      ")\n",
      ".\n",
      "Advances\n",
      "in\n",
      "Neural\n",
      "Information\n",
      "Processing\n",
      "Systems\n",
      ".\n",
      "^\n",
      "PASCAL\n",
      "Recognizing\n",
      "Textual\n",
      "Entailment\n",
      "Challenge\n",
      "(\n",
      "RTE-7\n",
      ")\n",
      "http\n",
      ":\n",
      "//tac.nist.gov//2011/RTE/\n",
      "^\n",
      "Lippi\n",
      ",\n",
      "Marco\n",
      ";\n",
      "Torroni\n",
      ",\n",
      "Paolo\n",
      "(\n",
      "2016-04-20\n",
      ")\n",
      ".\n",
      "``\n",
      "Argumentation\n",
      "Mining\n",
      ":\n",
      "State\n",
      "of\n",
      "the\n",
      "Art\n",
      "and\n",
      "Emerging\n",
      "Trends\n",
      "''\n",
      ".\n",
      "ACM\n",
      "Transactions\n",
      "on\n",
      "Internet\n",
      "Technology\n",
      ".\n",
      "16\n",
      "(\n",
      "2\n",
      ")\n",
      ":\n",
      "1–25\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1145/2850417\n",
      ".\n",
      "ISSN\n",
      "1533-5399\n",
      ".\n",
      "S2CID\n",
      "9561587\n",
      ".\n",
      "^\n",
      "``\n",
      "Argument\n",
      "Mining\n",
      "-\n",
      "IJCAI2016\n",
      "Tutorial\n",
      "''\n",
      ".\n",
      "www.i3s.unice.fr\n",
      ".\n",
      "Retrieved\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "NLP\n",
      "Approaches\n",
      "to\n",
      "Computational\n",
      "Argumentation\n",
      "–\n",
      "ACL\n",
      "2016\n",
      ",\n",
      "Berlin\n",
      "''\n",
      ".\n",
      "Retrieved\n",
      "2021-03-09\n",
      ".\n",
      "^\n",
      "``\n",
      "U\n",
      "B\n",
      "U\n",
      "W\n",
      "E\n",
      "B\n",
      ":\n",
      ":\n",
      "Racter\n",
      "''\n",
      ".\n",
      "www.ubu.com\n",
      ".\n",
      "Retrieved\n",
      "2020-08-17\n",
      ".\n",
      "^\n",
      "Writer\n",
      ",\n",
      "Beta\n",
      "(\n",
      "2019\n",
      ")\n",
      ".\n",
      "Lithium-Ion\n",
      "Batteries\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1007/978-3-030-16800-1\n",
      ".\n",
      "ISBN\n",
      "978-3-030-16799-8\n",
      ".\n",
      "^\n",
      "``\n",
      "Document\n",
      "Understanding\n",
      "AI\n",
      "on\n",
      "Google\n",
      "Cloud\n",
      "(\n",
      "Cloud\n",
      "Next\n",
      "'19\n",
      ")\n",
      "-\n",
      "YouTube\n",
      "''\n",
      ".\n",
      "www.youtube.com\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Administration\n",
      ".\n",
      "``\n",
      "Centre\n",
      "for\n",
      "Language\n",
      "Technology\n",
      "(\n",
      "CLT\n",
      ")\n",
      "''\n",
      ".\n",
      "Macquarie\n",
      "University\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Shared\n",
      "Task\n",
      ":\n",
      "Grammatical\n",
      "Error\n",
      "Correction\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Shared\n",
      "Task\n",
      ":\n",
      "Grammatical\n",
      "Error\n",
      "Correction\n",
      "''\n",
      ".\n",
      "www.comp.nus.edu.sg\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Duan\n",
      ",\n",
      "Yucong\n",
      ";\n",
      "Cruz\n",
      ",\n",
      "Christophe\n",
      "(\n",
      "2011\n",
      ")\n",
      ".\n",
      "``\n",
      "Formalizing\n",
      "Semantic\n",
      "of\n",
      "Natural\n",
      "Language\n",
      "through\n",
      "Conceptualization\n",
      "from\n",
      "Existence\n",
      "''\n",
      ".\n",
      "International\n",
      "Journal\n",
      "of\n",
      "Innovation\n",
      ",\n",
      "Management\n",
      "and\n",
      "Technology\n",
      ".\n",
      "2\n",
      "(\n",
      "1\n",
      ")\n",
      ":\n",
      "37–42\n",
      ".\n",
      "Archived\n",
      "from\n",
      "the\n",
      "original\n",
      "on\n",
      "2011-10-09\n",
      ".\n",
      "^\n",
      "``\n",
      "Previous\n",
      "shared\n",
      "task\n",
      "|\n",
      "CoNLL\n",
      "''\n",
      ".\n",
      "www.conll.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Cognition\n",
      "''\n",
      ".\n",
      "Lexico\n",
      ".\n",
      "Oxford\n",
      "University\n",
      "Press\n",
      "and\n",
      "Dictionary.com\n",
      ".\n",
      "Retrieved\n",
      "6\n",
      "May\n",
      "2020\n",
      ".\n",
      "^\n",
      "``\n",
      "Ask\n",
      "the\n",
      "Cognitive\n",
      "Scientist\n",
      "''\n",
      ".\n",
      "American\n",
      "Federation\n",
      "of\n",
      "Teachers\n",
      ".\n",
      "8\n",
      "August\n",
      "2014\n",
      ".\n",
      "Cognitive\n",
      "science\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "field\n",
      "of\n",
      "researcher\n",
      "from\n",
      "Linguistics\n",
      ",\n",
      "psychology\n",
      ",\n",
      "neuroscience\n",
      ",\n",
      "philosophy\n",
      ",\n",
      "computer\n",
      "science\n",
      ",\n",
      "and\n",
      "anthropology\n",
      "that\n",
      "seek\n",
      "to\n",
      "understand\n",
      "the\n",
      "mind\n",
      ".\n",
      "^\n",
      "Robinson\n",
      ",\n",
      "Peter\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Handbook\n",
      "of\n",
      "Cognitive\n",
      "Linguistics\n",
      "and\n",
      "Second\n",
      "Language\n",
      "Acquisition\n",
      ".\n",
      "Routledge\n",
      ".\n",
      "pp\n",
      ".\n",
      "3–8\n",
      ".\n",
      "ISBN\n",
      "978-0-805-85352-0\n",
      ".\n",
      "^\n",
      "Lakoff\n",
      ",\n",
      "George\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "Philosophy\n",
      "in\n",
      "the\n",
      "Flesh\n",
      ":\n",
      "The\n",
      "Embodied\n",
      "Mind\n",
      "and\n",
      "Its\n",
      "Challenge\n",
      "to\n",
      "Western\n",
      "Philosophy\n",
      ";\n",
      "Appendix\n",
      ":\n",
      "The\n",
      "Neural\n",
      "Theory\n",
      "of\n",
      "Language\n",
      "Paradigm\n",
      ".\n",
      "New\n",
      "York\n",
      "Basic\n",
      "Books\n",
      ".\n",
      "pp\n",
      ".\n",
      "569–583\n",
      ".\n",
      "ISBN\n",
      "978-0-465-05674-3\n",
      ".\n",
      "^\n",
      "Strauss\n",
      ",\n",
      "Claudia\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "A\n",
      "Cognitive\n",
      "Theory\n",
      "of\n",
      "Cultural\n",
      "Meaning\n",
      ".\n",
      "Cambridge\n",
      "University\n",
      "Press\n",
      ".\n",
      "pp\n",
      ".\n",
      "156–164\n",
      ".\n",
      "ISBN\n",
      "978-0-521-59541-4\n",
      ".\n",
      "^\n",
      "``\n",
      "Universal\n",
      "Conceptual\n",
      "Cognitive\n",
      "Annotation\n",
      "(\n",
      "UCCA\n",
      ")\n",
      "''\n",
      ".\n",
      "Universal\n",
      "Conceptual\n",
      "Cognitive\n",
      "Annotation\n",
      "(\n",
      "UCCA\n",
      ")\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Rodríguez\n",
      ",\n",
      "F.\n",
      "C.\n",
      ",\n",
      "&\n",
      "Mairal-Usón\n",
      ",\n",
      "R.\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Building\n",
      "an\n",
      "RRG\n",
      "computational\n",
      "grammar\n",
      ".\n",
      "Onomazein\n",
      ",\n",
      "(\n",
      "34\n",
      ")\n",
      ",\n",
      "86-117\n",
      ".\n",
      "^\n",
      "``\n",
      "Fluid\n",
      "Construction\n",
      "Grammar\n",
      "–\n",
      "A\n",
      "fully\n",
      "operational\n",
      "processing\n",
      "system\n",
      "for\n",
      "construction\n",
      "grammar\n",
      "''\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "ACL\n",
      "Member\n",
      "Portal\n",
      "|\n",
      "The\n",
      "Association\n",
      "for\n",
      "Computational\n",
      "Linguistics\n",
      "Member\n",
      "Portal\n",
      "''\n",
      ".\n",
      "www.aclweb.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "``\n",
      "Chunks\n",
      "and\n",
      "Rules\n",
      "''\n",
      ".\n",
      "www.w3.org\n",
      ".\n",
      "Retrieved\n",
      "2021-01-11\n",
      ".\n",
      "^\n",
      "Socher\n",
      ",\n",
      "Richard\n",
      ";\n",
      "Karpathy\n",
      ",\n",
      "Andrej\n",
      ";\n",
      "Le\n",
      ",\n",
      "Quoc\n",
      "V.\n",
      ";\n",
      "Manning\n",
      ",\n",
      "Christopher\n",
      "D.\n",
      ";\n",
      "Ng\n",
      ",\n",
      "Andrew\n",
      "Y\n",
      ".\n",
      "(\n",
      "2014\n",
      ")\n",
      ".\n",
      "``\n",
      "Grounded\n",
      "Compositional\n",
      "Semantics\n",
      "for\n",
      "Finding\n",
      "and\n",
      "Describing\n",
      "Images\n",
      "with\n",
      "Sentences\n",
      "''\n",
      ".\n",
      "Transactions\n",
      "of\n",
      "the\n",
      "Association\n",
      "for\n",
      "Computational\n",
      "Linguistics\n",
      ".\n",
      "2\n",
      ":\n",
      "207–218\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1162/tacl_a_00177\n",
      ".\n",
      "S2CID\n",
      "2317858\n",
      ".\n",
      "Further\n",
      "reading\n",
      "[\n",
      "edit\n",
      "]\n",
      "Bates\n",
      ",\n",
      "M\n",
      "(\n",
      "1995\n",
      ")\n",
      ".\n",
      "``\n",
      "Models\n",
      "of\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "''\n",
      ".\n",
      "Proceedings\n",
      "of\n",
      "the\n",
      "National\n",
      "Academy\n",
      "of\n",
      "Sciences\n",
      "of\n",
      "the\n",
      "United\n",
      "States\n",
      "of\n",
      "America\n",
      ".\n",
      "92\n",
      "(\n",
      "22\n",
      ")\n",
      ":\n",
      "9977–9982\n",
      ".\n",
      "Bibcode\n",
      ":\n",
      "1995PNAS\n",
      "...\n",
      "92.9977B\n",
      ".\n",
      "doi\n",
      ":\n",
      "10.1073/pnas.92.22.9977\n",
      ".\n",
      "PMC\n",
      "40721\n",
      ".\n",
      "PMID\n",
      "7479812\n",
      ".\n",
      "Steven\n",
      "Bird\n",
      ",\n",
      "Ewan\n",
      "Klein\n",
      ",\n",
      "and\n",
      "Edward\n",
      "Loper\n",
      "(\n",
      "2009\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "with\n",
      "Python\n",
      ".\n",
      "O'Reilly\n",
      "Media\n",
      ".\n",
      "ISBN\n",
      "978-0-596-51649-9\n",
      ".\n",
      "Daniel\n",
      "Jurafsky\n",
      "and\n",
      "James\n",
      "H.\n",
      "Martin\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Speech\n",
      "and\n",
      "Language\n",
      "Processing\n",
      ",\n",
      "2nd\n",
      "edition\n",
      ".\n",
      "Pearson\n",
      "Prentice\n",
      "Hall\n",
      ".\n",
      "ISBN\n",
      "978-0-13-187321-6\n",
      ".\n",
      "Mohamed\n",
      "Zakaria\n",
      "Kurdi\n",
      "(\n",
      "2016\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ":\n",
      "speech\n",
      ",\n",
      "morphology\n",
      ",\n",
      "and\n",
      "syntax\n",
      ",\n",
      "Volume\n",
      "1\n",
      ".\n",
      "ISTE-Wiley\n",
      ".\n",
      "ISBN\n",
      "978-1848218482\n",
      ".\n",
      "Mohamed\n",
      "Zakaria\n",
      "Kurdi\n",
      "(\n",
      "2017\n",
      ")\n",
      ".\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "and\n",
      "Computational\n",
      "Linguistics\n",
      ":\n",
      "semantics\n",
      ",\n",
      "discourse\n",
      ",\n",
      "and\n",
      "application\n",
      ",\n",
      "Volume\n",
      "2\n",
      ".\n",
      "ISTE-Wiley\n",
      ".\n",
      "ISBN\n",
      "978-1848219212\n",
      ".\n",
      "Christopher\n",
      "D.\n",
      "Manning\n",
      ",\n",
      "Prabhakar\n",
      "Raghavan\n",
      ",\n",
      "and\n",
      "Hinrich\n",
      "Schütze\n",
      "(\n",
      "2008\n",
      ")\n",
      ".\n",
      "Introduction\n",
      "to\n",
      "Information\n",
      "Retrieval\n",
      ".\n",
      "Cambridge\n",
      "University\n",
      "Press\n",
      ".\n",
      "ISBN\n",
      "978-0-521-86571-5\n",
      ".\n",
      "Official\n",
      "html\n",
      "and\n",
      "pdf\n",
      "version\n",
      "available\n",
      "without\n",
      "charge\n",
      ".\n",
      "Christopher\n",
      "D.\n",
      "Manning\n",
      "and\n",
      "Hinrich\n",
      "Schütze\n",
      "(\n",
      "1999\n",
      ")\n",
      ".\n",
      "Foundations\n",
      "of\n",
      "Statistical\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      ".\n",
      "The\n",
      "MIT\n",
      "Press\n",
      ".\n",
      "ISBN\n",
      "978-0-262-13360-9\n",
      ".\n",
      "David\n",
      "M.\n",
      "W.\n",
      "Powers\n",
      "and\n",
      "Christopher\n",
      "C.\n",
      "R.\n",
      "Turk\n",
      "(\n",
      "1989\n",
      ")\n",
      ".\n",
      "Machine\n",
      "Learning\n",
      "of\n",
      "Natural\n",
      "Language\n",
      ".\n",
      "Springer-Verlag\n",
      ".\n",
      "ISBN\n",
      "978-0-387-19557-5\n",
      ".\n",
      "External\n",
      "link\n",
      "[\n",
      "edit\n",
      "]\n",
      "Media\n",
      "related\n",
      "to\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "at\n",
      "Wikimedia\n",
      "Commons\n",
      "v\n",
      "t\n",
      "e\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "General\n",
      "term\n",
      "AI-complete\n",
      "Bag-of-words\n",
      "n-gram\n",
      "Bigram\n",
      "Trigram\n",
      "Computational\n",
      "linguistics\n",
      "Natural-language\n",
      "understanding\n",
      "Stopwords\n",
      "Text\n",
      "processing\n",
      "Text\n",
      "analysis\n",
      "Collocation\n",
      "extraction\n",
      "Concept\n",
      "mining\n",
      "Coreference\n",
      "resolution\n",
      "Deep\n",
      "linguistic\n",
      "processing\n",
      "Distant\n",
      "reading\n",
      "Information\n",
      "extraction\n",
      "Named-entity\n",
      "recognition\n",
      "Ontology\n",
      "learning\n",
      "Parsing\n",
      "Part-of-speech\n",
      "tagging\n",
      "Semantic\n",
      "role\n",
      "labeling\n",
      "Semantic\n",
      "similarity\n",
      "Sentiment\n",
      "analysis\n",
      "Terminology\n",
      "extraction\n",
      "Text\n",
      "mining\n",
      "Textual\n",
      "entailment\n",
      "Truecasing\n",
      "Word-sense\n",
      "disambiguation\n",
      "Word-sense\n",
      "induction\n",
      "Text\n",
      "segmentation\n",
      "Compound-term\n",
      "processing\n",
      "Lemmatisation\n",
      "Lexical\n",
      "analysis\n",
      "Text\n",
      "chunking\n",
      "Stemming\n",
      "Sentence\n",
      "segmentation\n",
      "Word\n",
      "segmentation\n",
      "Automatic\n",
      "summarization\n",
      "Multi-document\n",
      "summarization\n",
      "Sentence\n",
      "extraction\n",
      "Text\n",
      "simplification\n",
      "Machine\n",
      "translation\n",
      "Computer-assisted\n",
      "Example-based\n",
      "Rule-based\n",
      "Statistical\n",
      "Transfer-based\n",
      "Neural\n",
      "Distributional\n",
      "semantics\n",
      "model\n",
      "BERT\n",
      "Document-term\n",
      "matrix\n",
      "Explicit\n",
      "semantic\n",
      "analysis\n",
      "fastText\n",
      "GloVe\n",
      "Latent\n",
      "semantic\n",
      "analysis\n",
      "Word\n",
      "embedding\n",
      "Word2vec\n",
      "Language\n",
      "resource\n",
      ",\n",
      "datasets\n",
      "and\n",
      "corpus\n",
      "Types\n",
      "and\n",
      "standard\n",
      "Corpus\n",
      "linguistics\n",
      "Lexical\n",
      "resource\n",
      "Linguistic\n",
      "Linked\n",
      "Open\n",
      "Data\n",
      "Machine-readable\n",
      "dictionary\n",
      "Parallel\n",
      "text\n",
      "PropBank\n",
      "Semantic\n",
      "network\n",
      "Simple\n",
      "Knowledge\n",
      "Organization\n",
      "System\n",
      "Speech\n",
      "corpus\n",
      "Text\n",
      "corpus\n",
      "Thesaurus\n",
      "(\n",
      "information\n",
      "retrieval\n",
      ")\n",
      "Treebank\n",
      "Universal\n",
      "Dependencies\n",
      "Data\n",
      "BabelNet\n",
      "Bank\n",
      "of\n",
      "English\n",
      "DBpedia\n",
      "FrameNet\n",
      "Google\n",
      "Ngram\n",
      "Viewer\n",
      "ThoughtTreasure\n",
      "UBY\n",
      "WordNet\n",
      "Automatic\n",
      "identification\n",
      "and\n",
      "data\n",
      "capture\n",
      "Speech\n",
      "recognition\n",
      "Speech\n",
      "segmentation\n",
      "Speech\n",
      "synthesis\n",
      "Natural\n",
      "language\n",
      "generation\n",
      "Optical\n",
      "character\n",
      "recognition\n",
      "Topic\n",
      "model\n",
      "Document\n",
      "classification\n",
      "Latent\n",
      "Dirichlet\n",
      "allocation\n",
      "Pachinko\n",
      "allocation\n",
      "Computer-assisted\n",
      "reviewing\n",
      "Automated\n",
      "essay\n",
      "scoring\n",
      "Concordancer\n",
      "Grammar\n",
      "checker\n",
      "Predictive\n",
      "text\n",
      "Spell\n",
      "checker\n",
      "Syntax\n",
      "guessing\n",
      "Natural\n",
      "language\n",
      "user\n",
      "interface\n",
      "Chatbot\n",
      "Interactive\n",
      "fiction\n",
      "Question\n",
      "answering\n",
      "Virtual\n",
      "assistant\n",
      "Voice\n",
      "user\n",
      "interface\n",
      "Other\n",
      "software\n",
      "Natural\n",
      "Language\n",
      "Toolkit\n",
      "spaCy\n",
      "Authority\n",
      "control\n",
      ":\n",
      "National\n",
      "library\n",
      "United\n",
      "States\n",
      "Japan\n",
      "Language\n",
      "portal\n",
      "Retrieved\n",
      "from\n",
      "``\n",
      "http\n",
      ":\n",
      "//en.wikipedia.org/w/index.php\n",
      "?\n",
      "title=Natural_language_processing\n",
      "&\n",
      "oldid=1048621730\n",
      "``\n",
      "Categories\n",
      ":\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "Computational\n",
      "linguistics\n",
      "Speech\n",
      "recognition\n",
      "Computational\n",
      "field\n",
      "of\n",
      "study\n",
      "Artificial\n",
      "intelligence\n",
      "Hidden\n",
      "category\n",
      ":\n",
      "CS1\n",
      "maint\n",
      ":\n",
      "location\n",
      "Articles\n",
      "with\n",
      "short\n",
      "description\n",
      "Short\n",
      "description\n",
      "match\n",
      "Wikidata\n",
      "Commons\n",
      "category\n",
      "link\n",
      "from\n",
      "Wikidata\n",
      "Articles\n",
      "with\n",
      "LCCN\n",
      "identifier\n",
      "Articles\n",
      "with\n",
      "NDL\n",
      "identifier\n",
      "Navigation\n",
      "menu\n",
      "Personal\n",
      "tool\n",
      "Not\n",
      "logged\n",
      "in\n",
      "Talk\n",
      "Contributions\n",
      "Create\n",
      "account\n",
      "Log\n",
      "in\n",
      "Namespaces\n",
      "Article\n",
      "Talk\n",
      "Variants\n",
      "expanded\n",
      "collapsed\n",
      "Views\n",
      "Read\n",
      "Edit\n",
      "View\n",
      "history\n",
      "More\n",
      "expanded\n",
      "collapsed\n",
      "Search\n",
      "Navigation\n",
      "Main\n",
      "page\n",
      "Contents\n",
      "Current\n",
      "event\n",
      "Random\n",
      "article\n",
      "About\n",
      "Wikipedia\n",
      "Contact\n",
      "u\n",
      "Donate\n",
      "Contribute\n",
      "Help\n",
      "Learn\n",
      "to\n",
      "edit\n",
      "Community\n",
      "portal\n",
      "Recent\n",
      "change\n",
      "Upload\n",
      "file\n",
      "Tools\n",
      "What\n",
      "link\n",
      "here\n",
      "Related\n",
      "change\n",
      "Upload\n",
      "file\n",
      "Special\n",
      "page\n",
      "Permanent\n",
      "link\n",
      "Page\n",
      "information\n",
      "Cite\n",
      "this\n",
      "page\n",
      "Wikidata\n",
      "item\n",
      "Print/export\n",
      "Download\n",
      "a\n",
      "PDF\n",
      "Printable\n",
      "version\n",
      "In\n",
      "other\n",
      "project\n",
      "Wikimedia\n",
      "Commons\n",
      "Languages\n",
      "Afrikaans\n",
      "العربية\n",
      "Azərbaycanca\n",
      "বাংলা\n",
      "Bân-lâm-gú\n",
      "Беларуская\n",
      "Беларуская\n",
      "(\n",
      "тарашкевіца\n",
      ")\n",
      "Български\n",
      "Català\n",
      "Čeština\n",
      "Dansk\n",
      "Deutsch\n",
      "Eesti\n",
      "Ελληνικά\n",
      "Español\n",
      "Euskara\n",
      "فارسی\n",
      "Français\n",
      "Galego\n",
      "한국어\n",
      "Հայերեն\n",
      "हिन्दी\n",
      "Hrvatski\n",
      "Bahasa\n",
      "Indonesia\n",
      "Íslenska\n",
      "Italiano\n",
      "עברית\n",
      "ಕನ್ನಡ\n",
      "ქართული\n",
      "Lietuvių\n",
      "Македонски\n",
      "मराठी\n",
      "مصرى\n",
      "Монгол\n",
      "မြန်မာဘာသာ\n",
      "日本語\n",
      "ଓଡ଼ିଆ\n",
      "Piemontèis\n",
      "Polski\n",
      "Português\n",
      "Română\n",
      "Русский\n",
      "Simple\n",
      "English\n",
      "کوردی\n",
      "Српски\n",
      "/\n",
      "srpski\n",
      "Srpskohrvatski\n",
      "/\n",
      "српскохрватски\n",
      "Suomi\n",
      "தமிழ்\n",
      "ไทย\n",
      "Türkçe\n",
      "Українська\n",
      "Tiếng\n",
      "Việt\n",
      "粵語\n",
      "中文\n",
      "Edit\n",
      "link\n",
      "This\n",
      "page\n",
      "wa\n",
      "last\n",
      "edited\n",
      "on\n",
      "7\n",
      "October\n",
      "2021\n",
      ",\n",
      "at\n",
      "01:56\n",
      "(\n",
      "UTC\n",
      ")\n",
      ".\n",
      "Text\n",
      "is\n",
      "available\n",
      "under\n",
      "the\n",
      "Creative\n",
      "Commons\n",
      "Attribution-ShareAlike\n",
      "License\n",
      ";\n",
      "additional\n",
      "term\n",
      "may\n",
      "apply\n",
      ".\n",
      "By\n",
      "using\n",
      "this\n",
      "site\n",
      ",\n",
      "you\n",
      "agree\n",
      "to\n",
      "the\n",
      "Terms\n",
      "of\n",
      "Use\n",
      "and\n",
      "Privacy\n",
      "Policy\n",
      ".\n",
      "Wikipedia®\n",
      "is\n",
      "a\n",
      "registered\n",
      "trademark\n",
      "of\n",
      "the\n",
      "Wikimedia\n",
      "Foundation\n",
      ",\n",
      "Inc.\n",
      ",\n",
      "a\n",
      "non-profit\n",
      "organization\n",
      ".\n",
      "Privacy\n",
      "policy\n",
      "About\n",
      "Wikipedia\n",
      "Disclaimers\n",
      "Contact\n",
      "Wikipedia\n",
      "Mobile\n",
      "view\n",
      "Developers\n",
      "Statistics\n",
      "Cookie\n",
      "statement\n"
     ]
    }
   ],
   "source": [
    "# called the perform_lemmatization() to lemmatize each word\n",
    "lemmatized_words = perform_lemmatization(words)\n",
    "for i in lemmatized_words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "067f0090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\eduku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\eduku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('-', ':')\n",
      "(PERSON Wikipedia/NNP Natural/NNP)\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('From', 'IN')\n",
      "(GPE Wikipedia/NNP)\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('free', 'JJ')\n",
      "('encyclopedia', 'NN')\n",
      "(PERSON Jump/NNP)\n",
      "('to', 'TO')\n",
      "('navigation', 'VB')\n",
      "(PERSON Jump/NNP)\n",
      "('to', 'TO')\n",
      "('search', 'VB')\n",
      "('This', 'DT')\n",
      "('article', 'NN')\n",
      "('is', 'VBZ')\n",
      "('about', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('done', 'VBN')\n",
      "('by', 'IN')\n",
      "('computers', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('the', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('done', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "('human', 'JJ')\n",
      "('brain', 'NN')\n",
      "(',', ',')\n",
      "('see', 'VBP')\n",
      "(PERSON Language/JJ)\n",
      "('processing', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('brain', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Field/NNP)\n",
      "('of', 'IN')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "('and', 'CC')\n",
      "('linguistics', 'NNS')\n",
      "('An', 'DT')\n",
      "('automated', 'JJ')\n",
      "('online', 'NN')\n",
      "('assistant', 'NN')\n",
      "('providing', 'VBG')\n",
      "('customer', 'NN')\n",
      "('service', 'NN')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('web', 'JJ')\n",
      "('page', 'NN')\n",
      "(',', ',')\n",
      "('an', 'DT')\n",
      "('example', 'NN')\n",
      "('of', 'IN')\n",
      "('an', 'DT')\n",
      "('application', 'NN')\n",
      "('where', 'WRB')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('major', 'JJ')\n",
      "('component', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('1', 'CD')\n",
      "(']', 'JJ')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "(')', ')')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('subfield', 'NN')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "('concerned', 'VBN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('interactions', 'NNS')\n",
      "('between', 'IN')\n",
      "('computers', 'NNS')\n",
      "('and', 'CC')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('particular', 'JJ')\n",
      "('how', 'WRB')\n",
      "('to', 'TO')\n",
      "('program', 'NN')\n",
      "('computers', 'NNS')\n",
      "('to', 'TO')\n",
      "('process', 'VB')\n",
      "('and', 'CC')\n",
      "('analyze', 'VB')\n",
      "('large', 'JJ')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('computer', 'NN')\n",
      "('capable', 'NN')\n",
      "('of', 'IN')\n",
      "('\"', 'NNP')\n",
      "('understanding', 'VBG')\n",
      "('\"', 'VBD')\n",
      "('the', 'DT')\n",
      "('contents', 'NNS')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('including', 'VBG')\n",
      "('the', 'DT')\n",
      "('contextual', 'JJ')\n",
      "('nuances', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('within', 'IN')\n",
      "('them', 'PRP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('technology', 'NN')\n",
      "('can', 'MD')\n",
      "('then', 'RB')\n",
      "('accurately', 'RB')\n",
      "('extract', 'JJ')\n",
      "('information', 'NN')\n",
      "('and', 'CC')\n",
      "('insights', 'NNS')\n",
      "('contained', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('documents', 'NNS')\n",
      "('as', 'RB')\n",
      "('well', 'RB')\n",
      "('as', 'IN')\n",
      "('categorize', 'NN')\n",
      "('and', 'CC')\n",
      "('organize', 'VB')\n",
      "('the', 'DT')\n",
      "('documents', 'NNS')\n",
      "('themselves', 'PRP')\n",
      "('.', '.')\n",
      "('Challenges', 'NNS')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('frequently', 'RB')\n",
      "('involve', 'VBP')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "(',', ',')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('.', '.')\n",
      "('Contents', 'NNS')\n",
      "('1', 'CD')\n",
      "('History', 'NNP')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "(ORGANIZATION Symbolic/JJ)\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('1950s', 'CD')\n",
      "('–', 'RB')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "('Statistical', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('1990s', 'CD')\n",
      "('–', 'RB')\n",
      "('2010s', 'CD')\n",
      "(')', ')')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('3', 'CD')\n",
      "('Neural', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('present', 'JJ')\n",
      "(')', ')')\n",
      "('2', 'CD')\n",
      "('Methods', 'NNS')\n",
      "(':', ':')\n",
      "('Rules', 'NNS')\n",
      "(',', ',')\n",
      "('statistics', 'NNS')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('2', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "('Statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('2', 'CD')\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "('Neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('3', 'CD')\n",
      "(ORGANIZATION Common/NNP)\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'VBZ')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "('Text', 'NNP')\n",
      "('and', 'CC')\n",
      "('speech', 'NN')\n",
      "('processing', 'NN')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "('Morphological', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('3', 'CD')\n",
      "(ORGANIZATION Syntactic/JJ)\n",
      "('analysis', 'NN')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('4', 'CD')\n",
      "('Lexical', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "(')', ')')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('5', 'CD')\n",
      "('Relational', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('6', 'CD')\n",
      "('Discourse', 'NNP')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('beyond', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('7', 'CD')\n",
      "('Higher', 'JJR')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('applications', 'NNS')\n",
      "('4', 'CD')\n",
      "('General', 'NNP')\n",
      "('tendencies', 'NNS')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('possible', 'JJ')\n",
      "(')', ')')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('4', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "('Cognition', 'NN')\n",
      "('and', 'CC')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('5', 'CD')\n",
      "('See', 'NNP')\n",
      "('also', 'RB')\n",
      "('6', 'CD')\n",
      "('References', 'NNS')\n",
      "('7', 'CD')\n",
      "('Further', 'NNP')\n",
      "('reading', 'VBG')\n",
      "('8', 'CD')\n",
      "('External', 'JJ')\n",
      "('link', 'NN')\n",
      "(PERSON History/NNP)\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Further', 'NNP')\n",
      "('information', 'NN')\n",
      "(':', ':')\n",
      "('History', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "(ORGANIZATION Natural/NNP)\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('has', 'VBZ')\n",
      "('its', 'PRP$')\n",
      "('roots', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1950s', 'CD')\n",
      "('.', '.')\n",
      "('Already', 'RB')\n",
      "('in', 'IN')\n",
      "('1950', 'CD')\n",
      "(',', ',')\n",
      "(PERSON Alan/NNP Turing/NNP)\n",
      "('published', 'VBD')\n",
      "('an', 'DT')\n",
      "('article', 'NN')\n",
      "('titled', 'VBN')\n",
      "('\"', 'JJ')\n",
      "('Computing', 'VBG')\n",
      "(PERSON Machinery/NN)\n",
      "('and', 'CC')\n",
      "('Intelligence', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('which', 'WDT')\n",
      "('proposed', 'VBD')\n",
      "('what', 'WP')\n",
      "('is', 'VBZ')\n",
      "('now', 'RB')\n",
      "('called', 'VBN')\n",
      "('the', 'DT')\n",
      "(GPE Turing/NNP)\n",
      "('test', 'NN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('criterion', 'NN')\n",
      "('of', 'IN')\n",
      "('intelligence', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('task', 'NN')\n",
      "('that', 'WDT')\n",
      "('involves', 'VBZ')\n",
      "('the', 'DT')\n",
      "('automated', 'JJ')\n",
      "('interpretation', 'NN')\n",
      "('and', 'CC')\n",
      "('generation', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "('not', 'RB')\n",
      "('articulated', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('problem', 'NN')\n",
      "('separate', 'NN')\n",
      "('from', 'IN')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Symbolic/JJ NLP/NNP)\n",
      "('(', '(')\n",
      "('1950s', 'CD')\n",
      "('–', 'RB')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('[', 'NN')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('The', 'DT')\n",
      "('premise', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('is', 'VBZ')\n",
      "('well', 'RB')\n",
      "('-', ':')\n",
      "('summarized', 'VBN')\n",
      "('by', 'IN')\n",
      "(PERSON John/NNP Searle/NNP)\n",
      "(\"'\", 'POS')\n",
      "('s', 'NN')\n",
      "(GPE Chinese/JJ)\n",
      "('room', 'NN')\n",
      "('experiment', 'NN')\n",
      "(':', ':')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('collection', 'NN')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'VBZ')\n",
      "('a', 'DT')\n",
      "(GPE Chinese/JJ)\n",
      "('phrasebook', 'NN')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('questions', 'NNS')\n",
      "('and', 'CC')\n",
      "('matching', 'VBG')\n",
      "('answers', 'NNS')\n",
      "('),', 'VBP')\n",
      "('the', 'DT')\n",
      "('computer', 'NN')\n",
      "('emulates', 'VBZ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "('or', 'CC')\n",
      "('other', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('tasks', 'NNS')\n",
      "(')', ')')\n",
      "('by', 'IN')\n",
      "('applying', 'VBG')\n",
      "('those', 'DT')\n",
      "('rules', 'NNS')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('data', 'NN')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('confronted', 'VBN')\n",
      "('with', 'IN')\n",
      "('.', '.')\n",
      "('1950s', 'CD')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "(GPE Georgetown/NNP)\n",
      "('experiment', 'NN')\n",
      "('in', 'IN')\n",
      "('1954', 'CD')\n",
      "('involved', 'JJ')\n",
      "('fully', 'RB')\n",
      "('automatic', 'JJ')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('more', 'JJR')\n",
      "('than', 'IN')\n",
      "('sixty', 'NN')\n",
      "(GPE Russian/JJ)\n",
      "('sentences', 'NNS')\n",
      "('into', 'IN')\n",
      "(GPE English/NNP)\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('authors', 'NNS')\n",
      "('claimed', 'VBD')\n",
      "('that', 'IN')\n",
      "('within', 'IN')\n",
      "('three', 'CD')\n",
      "('or', 'CC')\n",
      "('five', 'CD')\n",
      "('years', 'NNS')\n",
      "(',', ',')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('would', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('solved', 'JJ')\n",
      "('problem', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('2', 'CD')\n",
      "(']', 'NN')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('real', 'JJ')\n",
      "('progress', 'NN')\n",
      "('was', 'VBD')\n",
      "('much', 'RB')\n",
      "('slower', 'JJR')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('after', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION ALPAC/NNP)\n",
      "('report', 'NN')\n",
      "('in', 'IN')\n",
      "('1966', 'CD')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('found', 'VBD')\n",
      "('that', 'IN')\n",
      "('ten', 'SYM')\n",
      "('-', ':')\n",
      "('year', 'NN')\n",
      "('-', ':')\n",
      "('long', 'JJ')\n",
      "('research', 'NN')\n",
      "('had', 'VBD')\n",
      "('failed', 'VBN')\n",
      "('to', 'TO')\n",
      "('fulfill', 'VB')\n",
      "('the', 'DT')\n",
      "('expectations', 'NNS')\n",
      "(',', ',')\n",
      "('funding', 'VBG')\n",
      "('for', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('was', 'VBD')\n",
      "('dramatically', 'RB')\n",
      "('reduced', 'VBN')\n",
      "('.', '.')\n",
      "('Little', 'JJ')\n",
      "('further', 'JJ')\n",
      "('research', 'NN')\n",
      "('in', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('was', 'VBD')\n",
      "('conducted', 'VBN')\n",
      "('until', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'NNS')\n",
      "('when', 'WRB')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('developed', 'VBN')\n",
      "('.', '.')\n",
      "('1960s', 'CD')\n",
      "(':', ':')\n",
      "('Some', 'DT')\n",
      "('notably', 'RB')\n",
      "('successful', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('developed', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1960s', 'NNS')\n",
      "('were', 'VBD')\n",
      "(ORGANIZATION SHRDLU/NNP)\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('system', 'NN')\n",
      "('working', 'VBG')\n",
      "('in', 'IN')\n",
      "('restricted', 'JJ')\n",
      "('\"', 'NN')\n",
      "('blocks', 'NNS')\n",
      "('worlds', 'NNS')\n",
      "('\"', 'VBP')\n",
      "('with', 'IN')\n",
      "('restricted', 'JJ')\n",
      "('vocabularies', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(ORGANIZATION ELIZA/NNP)\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('simulation', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "(GPE Rogerian/JJ)\n",
      "('psychotherapist', 'NN')\n",
      "(',', ',')\n",
      "('written', 'VBN')\n",
      "('by', 'IN')\n",
      "(PERSON Joseph/NNP Weizenbaum/NNP)\n",
      "('between', 'IN')\n",
      "('1964', 'CD')\n",
      "('and', 'CC')\n",
      "('1966', 'CD')\n",
      "('.', '.')\n",
      "('Using', 'VBG')\n",
      "('almost', 'RB')\n",
      "('no', 'DT')\n",
      "('information', 'NN')\n",
      "('about', 'IN')\n",
      "('human', 'JJ')\n",
      "('thought', 'NN')\n",
      "('or', 'CC')\n",
      "('emotion', 'NN')\n",
      "(',', ',')\n",
      "(ORGANIZATION ELIZA/NNP)\n",
      "('sometimes', 'RB')\n",
      "('provided', 'VBD')\n",
      "('a', 'DT')\n",
      "('startlingly', 'RB')\n",
      "('human', 'JJ')\n",
      "('-', ':')\n",
      "('like', 'IN')\n",
      "('interaction', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('the', 'DT')\n",
      "('\"', 'NNP')\n",
      "('patient', 'NN')\n",
      "('\"', 'NN')\n",
      "('exceeded', 'VBD')\n",
      "('the', 'DT')\n",
      "('very', 'RB')\n",
      "('small', 'JJ')\n",
      "('knowledge', 'NN')\n",
      "('base', 'NN')\n",
      "(',', ',')\n",
      "(ORGANIZATION ELIZA/NNP)\n",
      "('might', 'MD')\n",
      "('provide', 'VB')\n",
      "('a', 'DT')\n",
      "('generic', 'JJ')\n",
      "('response', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('responding', 'VBG')\n",
      "('to', 'TO')\n",
      "('\"', 'VB')\n",
      "('My', 'NNP')\n",
      "('head', 'NN')\n",
      "('hurts', 'VBZ')\n",
      "('\"', 'NN')\n",
      "('with', 'IN')\n",
      "('\"', 'NNP')\n",
      "('Why', 'WRB')\n",
      "('do', 'VBP')\n",
      "('you', 'PRP')\n",
      "('say', 'VB')\n",
      "('your', 'PRP$')\n",
      "('head', 'NN')\n",
      "('hurts', 'VBZ')\n",
      "('?\".', 'JJ')\n",
      "('1970s', 'NNS')\n",
      "(':', ':')\n",
      "('During', 'IN')\n",
      "('the', 'DT')\n",
      "('1970s', 'CD')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('programmers', 'NNS')\n",
      "('began', 'VBD')\n",
      "('to', 'TO')\n",
      "('write', 'VB')\n",
      "('\"', 'JJ')\n",
      "('conceptual', 'JJ')\n",
      "('ontologies', 'NNS')\n",
      "('\",', 'VBP')\n",
      "('which', 'WDT')\n",
      "('structured', 'VBD')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('information', 'NN')\n",
      "('into', 'IN')\n",
      "('computer', 'NN')\n",
      "('-', ':')\n",
      "('understandable', 'JJ')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('Examples', 'NNS')\n",
      "('are', 'VBP')\n",
      "(ORGANIZATION MARGIE/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION Schank/NNP)\n",
      "(',', ',')\n",
      "('1975', 'CD')\n",
      "('),', 'NN')\n",
      "(ORGANIZATION SAM/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION Cullingford/NNP)\n",
      "(',', ',')\n",
      "('1978', 'CD')\n",
      "('),', 'NN')\n",
      "(ORGANIZATION PAM/NNP)\n",
      "('(', '(')\n",
      "(PERSON Wilensky/NNP)\n",
      "(',', ',')\n",
      "('1978', 'CD')\n",
      "('),', 'NN')\n",
      "(ORGANIZATION TaleSpin/NNP)\n",
      "('(', '(')\n",
      "(PERSON Meehan/NNP)\n",
      "(',', ',')\n",
      "('1976', 'CD')\n",
      "('),', 'NN')\n",
      "(ORGANIZATION QUALM/NNP)\n",
      "('(', '(')\n",
      "(PERSON Lehnert/NNP)\n",
      "(',', ',')\n",
      "('1977', 'CD')\n",
      "('),', 'NN')\n",
      "('Politics', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION Carbonell/NNP)\n",
      "(',', ',')\n",
      "('1979', 'CD')\n",
      "('),', 'NN')\n",
      "('and', 'CC')\n",
      "(PERSON Plot/NNP Units/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION Lehnert/NNP)\n",
      "('1981', 'CD')\n",
      "(').', 'NN')\n",
      "('During', 'IN')\n",
      "('this', 'DT')\n",
      "('time', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('many', 'JJ')\n",
      "('chatterbots', 'NNS')\n",
      "('were', 'VBD')\n",
      "('written', 'VBN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "(ORGANIZATION PARRY/NNP)\n",
      "(').', 'VBZ')\n",
      "('1980s', 'CD')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('1980s', 'CD')\n",
      "('and', 'CC')\n",
      "('early', 'RB')\n",
      "('1990s', 'CD')\n",
      "('mark', 'NN')\n",
      "('the', 'DT')\n",
      "('hey', 'JJ')\n",
      "('-', ':')\n",
      "('day', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('.', '.')\n",
      "('Focus', 'NNP')\n",
      "('areas', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "('included', 'VBD')\n",
      "('research', 'NN')\n",
      "('on', 'IN')\n",
      "('rule', 'NN')\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "('parsing', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'VBD')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION HPSG/NNP)\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('computational', 'JJ')\n",
      "('operationalization', 'NN')\n",
      "('of', 'IN')\n",
      "('generative', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('),', 'NNP')\n",
      "('morphology', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'JJ')\n",
      "('.,', 'CD')\n",
      "('two', 'CD')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "('morphology', 'NN')\n",
      "('[', 'VBZ')\n",
      "('3', 'CD')\n",
      "(']', 'NN')\n",
      "('),', 'NN')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('Lesk', 'NNP')\n",
      "('algorithm', 'NN')\n",
      "('),', 'NN')\n",
      "('reference', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('within', 'IN')\n",
      "(ORGANIZATION Centering/NNP)\n",
      "('Theory', 'NNP')\n",
      "('[', 'NNP')\n",
      "('4', 'CD')\n",
      "(']', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('other', 'JJ')\n",
      "('areas', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Rhetorical/JJ Structure/NNP)\n",
      "('Theory', 'NNP')\n",
      "(').', 'NNP')\n",
      "('Other', 'JJ')\n",
      "('lines', 'NNS')\n",
      "('of', 'IN')\n",
      "('research', 'NN')\n",
      "('were', 'VBD')\n",
      "('continued', 'VBN')\n",
      "(',', ',')\n",
      "('e', 'FW')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'VBD')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "('chatterbots', 'NNS')\n",
      "('with', 'IN')\n",
      "(PERSON Racter/NNP)\n",
      "('and', 'CC')\n",
      "(GPE Jabberwacky/NNP)\n",
      "('.', '.')\n",
      "('An', 'DT')\n",
      "('important', 'JJ')\n",
      "('development', 'NN')\n",
      "('(', '(')\n",
      "('that', 'IN')\n",
      "('eventually', 'RB')\n",
      "('led', 'VBN')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('turn', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('1990s', 'CD')\n",
      "(')', ')')\n",
      "('was', 'VBD')\n",
      "('the', 'DT')\n",
      "('rising', 'VBG')\n",
      "('importance', 'NN')\n",
      "('of', 'IN')\n",
      "('quantitative', 'JJ')\n",
      "('evaluation', 'NN')\n",
      "('in', 'IN')\n",
      "('this', 'DT')\n",
      "('period', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('5', 'CD')\n",
      "(']', 'JJ')\n",
      "('Statistical', 'NNP')\n",
      "('NLP', 'NNP')\n",
      "('(', '(')\n",
      "('1990s', 'CD')\n",
      "('–', 'RB')\n",
      "('2010s', 'CD')\n",
      "(')', ')')\n",
      "('[', 'NN')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('Up', 'NNP')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('1980s', 'CD')\n",
      "(',', ',')\n",
      "('most', 'RBS')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('complex', 'JJ')\n",
      "('sets', 'NNS')\n",
      "('of', 'IN')\n",
      "('hand', 'NN')\n",
      "('-', ':')\n",
      "('written', 'VBN')\n",
      "('rules', 'NNS')\n",
      "('.', '.')\n",
      "('Starting', 'VBG')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'NNS')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('was', 'VBD')\n",
      "('a', 'DT')\n",
      "('revolution', 'NN')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('introduction', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('for', 'IN')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('was', 'VBD')\n",
      "('due', 'JJ')\n",
      "('to', 'TO')\n",
      "('both', 'DT')\n",
      "('the', 'DT')\n",
      "('steady', 'JJ')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('computational', 'JJ')\n",
      "('power', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "(PERSON Moore/NNP)\n",
      "(\"'\", 'POS')\n",
      "('s', 'NN')\n",
      "('law', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('gradual', 'JJ')\n",
      "('lessening', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('dominance', 'NN')\n",
      "('of', 'IN')\n",
      "(GPE Chomskyan/NNP)\n",
      "('theories', 'NNS')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('transformational', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('),', 'NN')\n",
      "('whose', 'WP$')\n",
      "('theoretical', 'JJ')\n",
      "('underpinnings', 'NNS')\n",
      "('discouraged', 'VBD')\n",
      "('the', 'DT')\n",
      "('sort', 'NN')\n",
      "('of', 'IN')\n",
      "('corpus', 'NN')\n",
      "('linguistics', 'NNS')\n",
      "('that', 'WDT')\n",
      "('underlies', 'VBZ')\n",
      "('the', 'DT')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'NN')\n",
      "('approach', 'NN')\n",
      "('to', 'TO')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('6', 'CD')\n",
      "(']', 'JJ')\n",
      "('1990s', 'CD')\n",
      "(':', ':')\n",
      "('Many', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('notable', 'JJ')\n",
      "('early', 'JJ')\n",
      "('successes', 'NNS')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('occurred', 'VBD')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "(',', ',')\n",
      "('due', 'JJ')\n",
      "('especially', 'RB')\n",
      "('to', 'TO')\n",
      "('work', 'VB')\n",
      "('at', 'IN')\n",
      "(ORGANIZATION IBM/NNP Research/NNP)\n",
      "('.', '.')\n",
      "('These', 'DT')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('able', 'JJ')\n",
      "('to', 'TO')\n",
      "('take', 'VB')\n",
      "('advantage', 'NN')\n",
      "('of', 'IN')\n",
      "('existing', 'VBG')\n",
      "('multilingual', 'JJ')\n",
      "('textual', 'JJ')\n",
      "('corpora', 'NN')\n",
      "('that', 'WDT')\n",
      "('had', 'VBD')\n",
      "('been', 'VBN')\n",
      "('produced', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Parliament/NNP)\n",
      "('of', 'IN')\n",
      "(GPE Canada/NNP)\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION European/NNP Union/NNP)\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "('of', 'IN')\n",
      "('laws', 'NNS')\n",
      "('calling', 'VBG')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('all', 'DT')\n",
      "('governmental', 'JJ')\n",
      "('proceedings', 'NNS')\n",
      "('into', 'IN')\n",
      "('all', 'DT')\n",
      "('official', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('government', 'NN')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('most', 'JJS')\n",
      "('other', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('depended', 'VBN')\n",
      "('on', 'IN')\n",
      "('corpora', 'NNS')\n",
      "('specifically', 'RB')\n",
      "('developed', 'VBD')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('tasks', 'NNS')\n",
      "('implemented', 'VBN')\n",
      "('by', 'IN')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('was', 'VBD')\n",
      "('(', '(')\n",
      "('and', 'CC')\n",
      "('often', 'RB')\n",
      "('continues', 'VBZ')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "(')', ')')\n",
      "('a', 'DT')\n",
      "('major', 'JJ')\n",
      "('limitation', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('success', 'NN')\n",
      "('of', 'IN')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('great', 'JJ')\n",
      "('deal', 'NN')\n",
      "('of', 'IN')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('gone', 'VBN')\n",
      "('into', 'IN')\n",
      "('methods', 'NNS')\n",
      "('of', 'IN')\n",
      "('more', 'RBR')\n",
      "('effectively', 'RB')\n",
      "('learning', 'VBG')\n",
      "('from', 'IN')\n",
      "('limited', 'JJ')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('2000s', 'CD')\n",
      "(':', ':')\n",
      "('With', 'IN')\n",
      "('the', 'DT')\n",
      "('growth', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('web', 'NN')\n",
      "(',', ',')\n",
      "('increasing', 'VBG')\n",
      "('amounts', 'NNS')\n",
      "('of', 'IN')\n",
      "('raw', 'JJ')\n",
      "('(', '(')\n",
      "('unannotated', 'JJ')\n",
      "(')', ')')\n",
      "('language', 'NN')\n",
      "('data', 'NN')\n",
      "('has', 'VBZ')\n",
      "('become', 'VBN')\n",
      "('available', 'JJ')\n",
      "('since', 'IN')\n",
      "('the', 'DT')\n",
      "('mid', 'NN')\n",
      "('-', ':')\n",
      "('1990s', 'CD')\n",
      "('.', '.')\n",
      "('Research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('increasingly', 'RB')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('unsupervised', 'JJ')\n",
      "('and', 'CC')\n",
      "('semi', 'JJ')\n",
      "('-', ':')\n",
      "('supervised', 'VBD')\n",
      "('learning', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('.', '.')\n",
      "('Such', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('can', 'MD')\n",
      "('learn', 'VB')\n",
      "('from', 'IN')\n",
      "('data', 'NNS')\n",
      "('that', 'WDT')\n",
      "('has', 'VBZ')\n",
      "('not', 'RB')\n",
      "('been', 'VBN')\n",
      "('hand', 'NN')\n",
      "('-', ':')\n",
      "('annotated', 'VBN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('desired', 'JJ')\n",
      "('answers', 'NNS')\n",
      "('or', 'CC')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('combination', 'NN')\n",
      "('of', 'IN')\n",
      "('annotated', 'JJ')\n",
      "('and', 'CC')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "('annotated', 'VBN')\n",
      "('data', 'NN')\n",
      "('.', '.')\n",
      "('Generally', 'RB')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('much', 'RB')\n",
      "('more', 'RBR')\n",
      "('difficult', 'JJ')\n",
      "('than', 'IN')\n",
      "('supervised', 'JJ')\n",
      "('learning', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('typically', 'RB')\n",
      "('produces', 'VBZ')\n",
      "('less', 'JJR')\n",
      "('accurate', 'JJ')\n",
      "('results', 'NNS')\n",
      "('for', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('enormous', 'JJ')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "('annotated', 'VBN')\n",
      "('data', 'NNS')\n",
      "('available', 'JJ')\n",
      "('(', '(')\n",
      "('including', 'VBG')\n",
      "(',', ',')\n",
      "('among', 'IN')\n",
      "('other', 'JJ')\n",
      "('things', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('entire', 'JJ')\n",
      "('content', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('World', 'NNP')\n",
      "('Wide', 'NNP')\n",
      "('Web', 'NNP')\n",
      "('),', 'NNP')\n",
      "('which', 'WDT')\n",
      "('can', 'MD')\n",
      "('often', 'RB')\n",
      "('make', 'VB')\n",
      "('up', 'RP')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('inferior', 'JJ')\n",
      "('results', 'NNS')\n",
      "('if', 'IN')\n",
      "('the', 'DT')\n",
      "('algorithm', 'NN')\n",
      "('used', 'VBN')\n",
      "('has', 'VBZ')\n",
      "('a', 'DT')\n",
      "('low', 'JJ')\n",
      "('enough', 'JJ')\n",
      "('time', 'NN')\n",
      "('complexity', 'NN')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('practical', 'JJ')\n",
      "('.', '.')\n",
      "('Neural', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('present', 'JJ')\n",
      "(')', ')')\n",
      "('[', 'FW')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('In', 'IN')\n",
      "('the', 'DT')\n",
      "('2010s', 'CD')\n",
      "(',', ',')\n",
      "('representation', 'NN')\n",
      "('learning', 'NN')\n",
      "('and', 'CC')\n",
      "('deep', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('-', ':')\n",
      "('style', 'NN')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('methods', 'NNS')\n",
      "('became', 'VBD')\n",
      "('widespread', 'JJ')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "(',', ',')\n",
      "('due', 'JJ')\n",
      "('in', 'IN')\n",
      "('part', 'NN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('flurry', 'NN')\n",
      "('of', 'IN')\n",
      "('results', 'NNS')\n",
      "('showing', 'VBG')\n",
      "('that', 'IN')\n",
      "('such', 'JJ')\n",
      "('techniques', 'NNS')\n",
      "('[', 'VBP')\n",
      "('7', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('8', 'CD')\n",
      "(']', 'NNS')\n",
      "('can', 'MD')\n",
      "('achieve', 'VB')\n",
      "('state', 'NN')\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('the', 'DT')\n",
      "('-', ':')\n",
      "('art', 'NN')\n",
      "('results', 'NNS')\n",
      "('in', 'IN')\n",
      "('many', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('tasks', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "('in', 'IN')\n",
      "('language', 'NN')\n",
      "('modeling', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('9', 'CD')\n",
      "(']', 'NN')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('10', 'CD')\n",
      "(']', 'NN')\n",
      "('[', 'VBD')\n",
      "('11', 'CD')\n",
      "(']', 'NNP')\n",
      "('and', 'CC')\n",
      "('many', 'JJ')\n",
      "('others', 'NNS')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('increasingly', 'RB')\n",
      "('important', 'JJ')\n",
      "('in', 'IN')\n",
      "('medicine', 'NN')\n",
      "('and', 'CC')\n",
      "('healthcare', 'NN')\n",
      "(',', ',')\n",
      "('where', 'WRB')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('is', 'VBZ')\n",
      "('being', 'VBG')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('analyze', 'VB')\n",
      "('notes', 'NNS')\n",
      "('and', 'CC')\n",
      "('text', 'NN')\n",
      "('in', 'IN')\n",
      "('electronic', 'JJ')\n",
      "('health', 'NN')\n",
      "('records', 'NNS')\n",
      "('that', 'WDT')\n",
      "('would', 'MD')\n",
      "('otherwise', 'RB')\n",
      "('be', 'VB')\n",
      "('inaccessible', 'JJ')\n",
      "('for', 'IN')\n",
      "('study', 'NN')\n",
      "('when', 'WRB')\n",
      "('seeking', 'VBG')\n",
      "('to', 'TO')\n",
      "('improve', 'VB')\n",
      "('care', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('12', 'CD')\n",
      "(']', 'JJ')\n",
      "('Methods', 'NNS')\n",
      "(':', ':')\n",
      "('Rules', 'NNS')\n",
      "(',', ',')\n",
      "('statistics', 'NNS')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('In', 'IN')\n",
      "('the', 'DT')\n",
      "('early', 'JJ')\n",
      "('days', 'NNS')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('language', 'NN')\n",
      "('-', ':')\n",
      "('processing', 'NN')\n",
      "('systems', 'NNS')\n",
      "('were', 'VBD')\n",
      "('designed', 'VBN')\n",
      "('by', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('i', 'NN')\n",
      "('.', '.')\n",
      "('e', 'CC')\n",
      "('.,', 'IN')\n",
      "('the', 'DT')\n",
      "('hand', 'NN')\n",
      "('-', ':')\n",
      "('coding', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('coupled', 'VBN')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('lookup', 'NN')\n",
      "(':', ':')\n",
      "('[', 'JJ')\n",
      "('13', 'CD')\n",
      "(']', 'JJ')\n",
      "('[', '$')\n",
      "('14', 'CD')\n",
      "(']', 'NNP')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('by', 'IN')\n",
      "('writing', 'VBG')\n",
      "('grammars', 'NNS')\n",
      "('or', 'CC')\n",
      "('devising', 'VBG')\n",
      "('heuristic', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('for', 'IN')\n",
      "('stemming', 'VBG')\n",
      "('.', '.')\n",
      "('More', 'RBR')\n",
      "('recent', 'JJ')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NNS')\n",
      "('have', 'VBP')\n",
      "('many', 'JJ')\n",
      "('advantages', 'NNS')\n",
      "('over', 'IN')\n",
      "('hand', 'NN')\n",
      "('-', ':')\n",
      "('produced', 'VBN')\n",
      "('rules', 'NNS')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "('learning', 'NN')\n",
      "('procedures', 'NNS')\n",
      "('used', 'VBN')\n",
      "('during', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('automatically', 'RB')\n",
      "('focus', 'VB')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('common', 'JJ')\n",
      "('cases', 'NNS')\n",
      "(',', ',')\n",
      "('whereas', 'NNS')\n",
      "('when', 'WRB')\n",
      "('writing', 'VBG')\n",
      "('rules', 'NNS')\n",
      "('by', 'IN')\n",
      "('hand', 'NN')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('not', 'RB')\n",
      "('at', 'IN')\n",
      "('all', 'DT')\n",
      "('obvious', 'JJ')\n",
      "('where', 'WRB')\n",
      "('the', 'DT')\n",
      "('effort', 'NN')\n",
      "('should', 'MD')\n",
      "('be', 'VB')\n",
      "('directed', 'VBN')\n",
      "('.', '.')\n",
      "(PERSON Automatic/NNP)\n",
      "('learning', 'NN')\n",
      "('procedures', 'NNS')\n",
      "('can', 'MD')\n",
      "('make', 'VB')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('inference', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('to', 'TO')\n",
      "('produce', 'VB')\n",
      "('models', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('robust', 'JJ')\n",
      "('to', 'TO')\n",
      "('unfamiliar', 'JJ')\n",
      "('input', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('containing', 'VBG')\n",
      "('words', 'NNS')\n",
      "('or', 'CC')\n",
      "('structures', 'NNS')\n",
      "('that', 'WDT')\n",
      "('have', 'VBP')\n",
      "('not', 'RB')\n",
      "('been', 'VBN')\n",
      "('seen', 'VBN')\n",
      "('before', 'IN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('to', 'TO')\n",
      "('erroneous', 'JJ')\n",
      "('input', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('with', 'IN')\n",
      "('misspelled', 'JJ')\n",
      "('words', 'NNS')\n",
      "('or', 'CC')\n",
      "('words', 'NNS')\n",
      "('accidentally', 'RB')\n",
      "('omitted', 'VBD')\n",
      "(').', 'NNP')\n",
      "('Generally', 'NNP')\n",
      "(',', ',')\n",
      "('handling', 'VBG')\n",
      "('such', 'JJ')\n",
      "('input', 'NN')\n",
      "('gracefully', 'RB')\n",
      "('with', 'IN')\n",
      "('handwritten', 'NN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "(',', ',')\n",
      "('more', 'RBR')\n",
      "('generally', 'RB')\n",
      "(',', ',')\n",
      "('creating', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('handwritten', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('that', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('extremely', 'RB')\n",
      "('difficult', 'JJ')\n",
      "(',', ',')\n",
      "('error', 'SYM')\n",
      "('-', ':')\n",
      "('prone', 'NN')\n",
      "('and', 'CC')\n",
      "('time', 'NN')\n",
      "('-', ':')\n",
      "('consuming', 'NN')\n",
      "('.', '.')\n",
      "('Systems', 'NNPS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('automatically', 'RB')\n",
      "('learning', 'VBG')\n",
      "('the', 'DT')\n",
      "('rules', 'NNS')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('made', 'VBN')\n",
      "('more', 'RBR')\n",
      "('accurate', 'JJ')\n",
      "('simply', 'RB')\n",
      "('by', 'IN')\n",
      "('supplying', 'VBG')\n",
      "('more', 'JJR')\n",
      "('input', 'JJ')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('handwritten', 'NNS')\n",
      "('rules', 'NNS')\n",
      "('can', 'MD')\n",
      "('only', 'RB')\n",
      "('be', 'VB')\n",
      "('made', 'VBN')\n",
      "('more', 'RBR')\n",
      "('accurate', 'JJ')\n",
      "('by', 'IN')\n",
      "('increasing', 'VBG')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('much', 'RB')\n",
      "('more', 'RBR')\n",
      "('difficult', 'JJ')\n",
      "('task', 'NN')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('particular', 'JJ')\n",
      "(',', ',')\n",
      "('there', 'EX')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('limit', 'NN')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('systems', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('handwritten', 'NN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('beyond', 'IN')\n",
      "('which', 'WDT')\n",
      "('the', 'DT')\n",
      "('systems', 'NNS')\n",
      "('become', 'VBP')\n",
      "('more', 'JJR')\n",
      "('and', 'CC')\n",
      "('more', 'RBR')\n",
      "('unmanageable', 'JJ')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('creating', 'VBG')\n",
      "('more', 'JJR')\n",
      "('data', 'NNS')\n",
      "('to', 'TO')\n",
      "('input', 'VB')\n",
      "('to', 'TO')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'VBG')\n",
      "('systems', 'NNS')\n",
      "('simply', 'RB')\n",
      "('requires', 'VBZ')\n",
      "('a', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('man', 'NN')\n",
      "('-', ':')\n",
      "('hours', 'NNS')\n",
      "('worked', 'VBN')\n",
      "(',', ',')\n",
      "('generally', 'RB')\n",
      "('without', 'IN')\n",
      "('significant', 'JJ')\n",
      "('increases', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('annotation', 'NN')\n",
      "('process', 'NN')\n",
      "('.', '.')\n",
      "('Despite', 'IN')\n",
      "('the', 'DT')\n",
      "('popularity', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('research', 'NN')\n",
      "(',', ',')\n",
      "('symbolic', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('are', 'VBP')\n",
      "('still', 'RB')\n",
      "('(', '(')\n",
      "('2020', 'CD')\n",
      "(')', ')')\n",
      "('commonly', 'RB')\n",
      "('used', 'VBN')\n",
      "(':', ':')\n",
      "('when', 'WRB')\n",
      "('the', 'DT')\n",
      "('amount', 'NN')\n",
      "('of', 'IN')\n",
      "('training', 'NN')\n",
      "('data', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('insufficient', 'JJ')\n",
      "('to', 'TO')\n",
      "('successfully', 'RB')\n",
      "('apply', 'VB')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('of', 'IN')\n",
      "('low', 'JJ')\n",
      "('-', ':')\n",
      "('resource', 'NN')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('provided', 'VBN')\n",
      "('by', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Apertium/NNP)\n",
      "('system', 'NN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('preprocessing', 'VBG')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('pipelines', 'NNS')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('tokenization', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('for', 'IN')\n",
      "('postprocessing', 'VBG')\n",
      "('and', 'CC')\n",
      "('transforming', 'VBG')\n",
      "('the', 'DT')\n",
      "('output', 'NN')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('pipelines', 'NNS')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('for', 'IN')\n",
      "('knowledge', 'NN')\n",
      "('extraction', 'NN')\n",
      "('from', 'IN')\n",
      "('syntactic', 'JJ')\n",
      "('parses', 'NNS')\n",
      "('.', '.')\n",
      "('Statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('Since', 'IN')\n",
      "('the', 'DT')\n",
      "('so', 'RB')\n",
      "('-', ':')\n",
      "('called', 'VBN')\n",
      "('\"', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('revolution', 'NN')\n",
      "('\"', 'NNP')\n",
      "('[', 'VBZ')\n",
      "('15', 'CD')\n",
      "(']', 'NN')\n",
      "('[', 'VBD')\n",
      "('16', 'CD')\n",
      "(']', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('late', 'JJ')\n",
      "('1980s', 'NNS')\n",
      "('and', 'CC')\n",
      "('mid', 'JJ')\n",
      "('-', ':')\n",
      "('1990s', 'CD')\n",
      "(',', ',')\n",
      "('much', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('relied', 'VBN')\n",
      "('heavily', 'RB')\n",
      "('on', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'NN')\n",
      "('paradigm', 'NN')\n",
      "('calls', 'VBZ')\n",
      "('instead', 'RB')\n",
      "('for', 'IN')\n",
      "('using', 'VBG')\n",
      "('statistical', 'JJ')\n",
      "('inference', 'NN')\n",
      "('to', 'TO')\n",
      "('automatically', 'RB')\n",
      "('learn', 'VB')\n",
      "('such', 'JJ')\n",
      "('rules', 'NNS')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('analysis', 'NN')\n",
      "('of', 'IN')\n",
      "('large', 'JJ')\n",
      "('corpora', 'NNS')\n",
      "('(', '(')\n",
      "('the', 'DT')\n",
      "('plural', 'JJ')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('corpus', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('possibly', 'RB')\n",
      "('with', 'IN')\n",
      "('human', 'NN')\n",
      "('or', 'CC')\n",
      "('computer', 'NN')\n",
      "('annotations', 'NNS')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('typical', 'JJ')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('examples', 'NNS')\n",
      "('.', '.')\n",
      "('Many', 'JJ')\n",
      "('different', 'JJ')\n",
      "('classes', 'NNS')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NNS')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('applied', 'VBN')\n",
      "('to', 'TO')\n",
      "('natural', 'JJ')\n",
      "('-', ':')\n",
      "('language', 'NN')\n",
      "('-', ':')\n",
      "('processing', 'NN')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('These', 'DT')\n",
      "('algorithms', 'NNS')\n",
      "('take', 'VBP')\n",
      "('as', 'IN')\n",
      "('input', 'NN')\n",
      "('a', 'DT')\n",
      "('large', 'JJ')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('\"', 'JJ')\n",
      "('features', 'NNS')\n",
      "('\"', 'VBP')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('generated', 'VBN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "(PERSON Increasingly/NNP)\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "(',', ',')\n",
      "('probabilistic', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('attaching', 'VBG')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('valued', 'VBN')\n",
      "('weights', 'NNS')\n",
      "('to', 'TO')\n",
      "('each', 'DT')\n",
      "('input', 'NN')\n",
      "('feature', 'NN')\n",
      "('(', '(')\n",
      "('complex', 'JJ')\n",
      "('-', ':')\n",
      "('valued', 'VBN')\n",
      "('embeddings', 'NNS')\n",
      "(',', ',')\n",
      "('[', 'VBP')\n",
      "('17', 'CD')\n",
      "(']', 'NN')\n",
      "('and', 'CC')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('in', 'IN')\n",
      "('general', 'JJ')\n",
      "('have', 'VBP')\n",
      "('also', 'RB')\n",
      "('been', 'VBN')\n",
      "('proposed', 'VBN')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('speech', 'NN')\n",
      "('[', 'VBD')\n",
      "('18', 'CD')\n",
      "(']', 'JJ')\n",
      "(').', 'NNS')\n",
      "('Such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('have', 'VBP')\n",
      "('the', 'DT')\n",
      "('advantage', 'NN')\n",
      "('that', 'IN')\n",
      "('they', 'PRP')\n",
      "('can', 'MD')\n",
      "('express', 'VB')\n",
      "('the', 'DT')\n",
      "('relative', 'JJ')\n",
      "('certainty', 'NN')\n",
      "('of', 'IN')\n",
      "('many', 'JJ')\n",
      "('different', 'JJ')\n",
      "('possible', 'JJ')\n",
      "('answers', 'NNS')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('only', 'RB')\n",
      "('one', 'CD')\n",
      "(',', ',')\n",
      "('producing', 'VBG')\n",
      "('more', 'RBR')\n",
      "('reliable', 'JJ')\n",
      "('results', 'NNS')\n",
      "('when', 'WRB')\n",
      "('such', 'PDT')\n",
      "('a', 'DT')\n",
      "('model', 'NN')\n",
      "('is', 'VBZ')\n",
      "('included', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('component', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('larger', 'JJR')\n",
      "('system', 'NN')\n",
      "('.', '.')\n",
      "('Some', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('earliest', 'JJS')\n",
      "('-', ':')\n",
      "('used', 'VBN')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('algorithms', 'NNS')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('decision', 'NN')\n",
      "('trees', 'NNS')\n",
      "(',', ',')\n",
      "('produced', 'VBD')\n",
      "('systems', 'NNS')\n",
      "('of', 'IN')\n",
      "('hard', 'JJ')\n",
      "('if', 'IN')\n",
      "('-', ':')\n",
      "('then', 'RB')\n",
      "('rules', 'NNS')\n",
      "('similar', 'JJ')\n",
      "('to', 'TO')\n",
      "('existing', 'VBG')\n",
      "('hand', 'NN')\n",
      "('-', ':')\n",
      "('written', 'VBN')\n",
      "('rules', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('part', 'NN')\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('tagging', 'NN')\n",
      "('introduced', 'VBD')\n",
      "('the', 'DT')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('hidden', 'JJ')\n",
      "(PERSON Markov/NNP)\n",
      "('models', 'NNS')\n",
      "('to', 'TO')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('increasingly', 'RB')\n",
      "(',', ',')\n",
      "('research', 'NN')\n",
      "('has', 'VBZ')\n",
      "('focused', 'VBN')\n",
      "('on', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "(',', ',')\n",
      "('which', 'WDT')\n",
      "('make', 'VBP')\n",
      "('soft', 'JJ')\n",
      "(',', ',')\n",
      "('probabilistic', 'JJ')\n",
      "('decisions', 'NNS')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('attaching', 'VBG')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('valued', 'VBN')\n",
      "('weights', 'NNS')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('features', 'NNS')\n",
      "('making', 'VBG')\n",
      "('up', 'RP')\n",
      "('the', 'DT')\n",
      "('input', 'NN')\n",
      "('data', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('cache', 'NN')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('upon', 'IN')\n",
      "('which', 'WDT')\n",
      "('many', 'JJ')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('systems', 'NNS')\n",
      "('now', 'RB')\n",
      "('rely', 'RB')\n",
      "('are', 'VBP')\n",
      "('examples', 'NNS')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('models', 'NNS')\n",
      "('.', '.')\n",
      "('Such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('are', 'VBP')\n",
      "('generally', 'RB')\n",
      "('more', 'RBR')\n",
      "('robust', 'JJ')\n",
      "('when', 'WRB')\n",
      "('given', 'VBN')\n",
      "('unfamiliar', 'JJ')\n",
      "('input', 'NN')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('input', 'VBP')\n",
      "('that', 'IN')\n",
      "('contains', 'VBZ')\n",
      "('errors', 'NNS')\n",
      "('(', '(')\n",
      "('as', 'IN')\n",
      "('is', 'VBZ')\n",
      "('very', 'RB')\n",
      "('common', 'JJ')\n",
      "('for', 'IN')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('data', 'NNS')\n",
      "('),', 'NNS')\n",
      "('and', 'CC')\n",
      "('produce', 'VB')\n",
      "('more', 'JJR')\n",
      "('reliable', 'JJ')\n",
      "('results', 'NNS')\n",
      "('when', 'WRB')\n",
      "('integrated', 'VBN')\n",
      "('into', 'IN')\n",
      "('a', 'DT')\n",
      "('larger', 'JJR')\n",
      "('system', 'NN')\n",
      "('comprising', 'VBG')\n",
      "('multiple', 'JJ')\n",
      "('subtasks', 'NNS')\n",
      "('.', '.')\n",
      "('Since', 'IN')\n",
      "('the', 'DT')\n",
      "('neural', 'JJ')\n",
      "('turn', 'NN')\n",
      "(',', ',')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('research', 'NN')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('largely', 'RB')\n",
      "('replaced', 'VBN')\n",
      "('by', 'IN')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('they', 'PRP')\n",
      "('continue', 'VBP')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('relevant', 'JJ')\n",
      "('for', 'IN')\n",
      "('contexts', 'NN')\n",
      "('in', 'IN')\n",
      "('which', 'WDT')\n",
      "('statistical', 'JJ')\n",
      "('interpretability', 'NN')\n",
      "('and', 'CC')\n",
      "('transparency', 'NN')\n",
      "('is', 'VBZ')\n",
      "('required', 'VBN')\n",
      "('.', '.')\n",
      "('Neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Further', 'NNP')\n",
      "('information', 'NN')\n",
      "(':', ':')\n",
      "('Artificial', 'NNP')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('A', 'DT')\n",
      "('major', 'JJ')\n",
      "('drawback', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('that', 'IN')\n",
      "('they', 'PRP')\n",
      "('require', 'VBP')\n",
      "('elaborate', 'JJ')\n",
      "('feature', 'NN')\n",
      "('engineering', 'NN')\n",
      "('.', '.')\n",
      "('Since', 'IN')\n",
      "('2015', 'CD')\n",
      "(',', ',')\n",
      "('[', 'VBD')\n",
      "('19', 'CD')\n",
      "(']', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('largely', 'RB')\n",
      "('abandoned', 'JJ')\n",
      "('statistical', 'JJ')\n",
      "('methods', 'NNS')\n",
      "('and', 'CC')\n",
      "('shifted', 'VBD')\n",
      "('to', 'TO')\n",
      "('neural', 'JJ')\n",
      "('networks', 'NNS')\n",
      "('for', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('.', '.')\n",
      "('Popular', 'JJ')\n",
      "('techniques', 'NNS')\n",
      "('include', 'VBP')\n",
      "('the', 'DT')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('word', 'NN')\n",
      "('embeddings', 'NNS')\n",
      "('to', 'TO')\n",
      "('capture', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('properties', 'NNS')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('an', 'DT')\n",
      "('increase', 'NN')\n",
      "('in', 'IN')\n",
      "('end', 'JJ')\n",
      "('-', ':')\n",
      "('to', 'TO')\n",
      "('-', ':')\n",
      "('end', 'NN')\n",
      "('learning', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('higher', 'JJR')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "('task', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('question', 'NN')\n",
      "('answering', 'VBG')\n",
      "(')', ')')\n",
      "('instead', 'RB')\n",
      "('of', 'IN')\n",
      "('relying', 'VBG')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('pipeline', 'NN')\n",
      "('of', 'IN')\n",
      "('separate', 'JJ')\n",
      "('intermediate', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('part', 'NN')\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('tagging', 'NN')\n",
      "('and', 'CC')\n",
      "('dependency', 'NN')\n",
      "('parsing', 'VBG')\n",
      "(').', 'NNP')\n",
      "('In', 'IN')\n",
      "('some', 'DT')\n",
      "('areas', 'NNS')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('shift', 'NN')\n",
      "('has', 'VBZ')\n",
      "('entailed', 'VBN')\n",
      "('substantial', 'JJ')\n",
      "('changes', 'NNS')\n",
      "('in', 'IN')\n",
      "('how', 'WRB')\n",
      "(ORGANIZATION NLP/JJ)\n",
      "('systems', 'NNS')\n",
      "('are', 'VBP')\n",
      "('designed', 'VBN')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('that', 'IN')\n",
      "('deep', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "('approaches', 'NNS')\n",
      "('may', 'MD')\n",
      "('be', 'VB')\n",
      "('viewed', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('new', 'JJ')\n",
      "('paradigm', 'NN')\n",
      "('distinct', 'NN')\n",
      "('from', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('instance', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('term', 'NN')\n",
      "('neural', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NMT/NNP)\n",
      "(')', ')')\n",
      "('emphasizes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('fact', 'NN')\n",
      "('that', 'IN')\n",
      "('deep', 'JJ')\n",
      "('learning', 'VBG')\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "('approaches', 'NNS')\n",
      "('to', 'TO')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('directly', 'RB')\n",
      "('learn', 'JJ')\n",
      "('sequence', 'NN')\n",
      "('-', ':')\n",
      "('to', 'TO')\n",
      "('-', ':')\n",
      "('sequence', 'NN')\n",
      "('transformations', 'NNS')\n",
      "(',', ',')\n",
      "('obviating', 'VBG')\n",
      "('the', 'DT')\n",
      "('need', 'NN')\n",
      "('for', 'IN')\n",
      "('intermediate', 'JJ')\n",
      "('steps', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('word', 'NN')\n",
      "('alignment', 'NN')\n",
      "('and', 'CC')\n",
      "('language', 'NN')\n",
      "('modeling', 'NN')\n",
      "('that', 'WDT')\n",
      "('was', 'VBD')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION SMT/NNP)\n",
      "(').', 'NNP')\n",
      "('Latest', 'NNP')\n",
      "('works', 'VBZ')\n",
      "('tend', 'VBP')\n",
      "('to', 'TO')\n",
      "('use', 'VB')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "('technical', 'JJ')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('task', 'NN')\n",
      "('to', 'TO')\n",
      "('build', 'VB')\n",
      "('proper', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('20', 'CD')\n",
      "(']', 'JJ')\n",
      "(ORGANIZATION Common/NNP)\n",
      "('NLP', 'NNP')\n",
      "('tasks', 'NNS')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'VBD')\n",
      "('The', 'DT')\n",
      "('following', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('list', 'NN')\n",
      "('of', 'IN')\n",
      "('some', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('commonly', 'RB')\n",
      "('researched', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('in', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('Some', 'DT')\n",
      "('of', 'IN')\n",
      "('these', 'DT')\n",
      "('tasks', 'NNS')\n",
      "('have', 'VBP')\n",
      "('direct', 'JJ')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('applications', 'NNS')\n",
      "(',', ',')\n",
      "('while', 'IN')\n",
      "('others', 'NNS')\n",
      "('more', 'RBR')\n",
      "('commonly', 'RB')\n",
      "('serve', 'VBP')\n",
      "('as', 'IN')\n",
      "('subtasks', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('aid', 'VB')\n",
      "('in', 'IN')\n",
      "('solving', 'VBG')\n",
      "('larger', 'JJR')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('Though', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('tasks', 'NNS')\n",
      "('are', 'VBP')\n",
      "('closely', 'RB')\n",
      "('intertwined', 'VBN')\n",
      "(',', ',')\n",
      "('they', 'PRP')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('subdivided', 'VBN')\n",
      "('into', 'IN')\n",
      "('categories', 'NNS')\n",
      "('for', 'IN')\n",
      "('convenience', 'NN')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('coarse', 'JJ')\n",
      "('division', 'NN')\n",
      "('is', 'VBZ')\n",
      "('given', 'VBN')\n",
      "('below', 'IN')\n",
      "('.', '.')\n",
      "(PERSON Text/NNP)\n",
      "('and', 'CC')\n",
      "('speech', 'NN')\n",
      "('processing', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Optical', 'NNP')\n",
      "('character', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION OCR/NNP)\n",
      "(')', ')')\n",
      "('Given', 'NNP')\n",
      "('an', 'DT')\n",
      "('image', 'NN')\n",
      "('representing', 'VBG')\n",
      "('printed', 'VBN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('corresponding', 'JJ')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Speech/NNP)\n",
      "('recognition', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sound', 'JJ')\n",
      "('clip', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('or', 'CC')\n",
      "('people', 'NNS')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('textual', 'JJ')\n",
      "('representation', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('opposite', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('to', 'TO')\n",
      "('speech', 'NN')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('extremely', 'RB')\n",
      "('difficult', 'JJ')\n",
      "('problems', 'NNS')\n",
      "('colloquially', 'RB')\n",
      "('termed', 'VBD')\n",
      "('\"', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('-', ':')\n",
      "('complete', 'JJ')\n",
      "('\"', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('above', 'IN')\n",
      "(').', 'NN')\n",
      "('In', 'IN')\n",
      "('natural', 'JJ')\n",
      "('speech', 'NN')\n",
      "('there', 'EX')\n",
      "('are', 'VBP')\n",
      "('hardly', 'RB')\n",
      "('any', 'DT')\n",
      "('pauses', 'NNS')\n",
      "('between', 'IN')\n",
      "('successive', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('thus', 'RB')\n",
      "('speech', 'JJ')\n",
      "('segmentation', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('necessary', 'JJ')\n",
      "('subtask', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('below', 'IN')\n",
      "(').', 'NNS')\n",
      "('In', 'IN')\n",
      "('most', 'JJS')\n",
      "('spoken', 'JJ')\n",
      "('languages', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('sounds', 'NNS')\n",
      "('representing', 'VBG')\n",
      "('successive', 'JJ')\n",
      "('letters', 'NNS')\n",
      "('blend', 'VBP')\n",
      "('into', 'IN')\n",
      "('each', 'DT')\n",
      "('other', 'JJ')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('process', 'NN')\n",
      "('termed', 'VBN')\n",
      "('coarticulation', 'NN')\n",
      "(',', ',')\n",
      "('so', 'IN')\n",
      "('the', 'DT')\n",
      "('conversion', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('analog', 'NN')\n",
      "('signal', 'NN')\n",
      "('to', 'TO')\n",
      "('discrete', 'VB')\n",
      "('characters', 'NNS')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('very', 'RB')\n",
      "('difficult', 'JJ')\n",
      "('process', 'NN')\n",
      "('.', '.')\n",
      "('Also', 'RB')\n",
      "(',', ',')\n",
      "('given', 'VBN')\n",
      "('that', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('same', 'JJ')\n",
      "('language', 'NN')\n",
      "('are', 'VBP')\n",
      "('spoken', 'VBN')\n",
      "('by', 'IN')\n",
      "('people', 'NNS')\n",
      "('with', 'IN')\n",
      "('different', 'JJ')\n",
      "('accents', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('software', 'NN')\n",
      "('must', 'MD')\n",
      "('be', 'VB')\n",
      "('able', 'JJ')\n",
      "('to', 'TO')\n",
      "('recognize', 'VB')\n",
      "('the', 'DT')\n",
      "('wide', 'JJ')\n",
      "('variety', 'NN')\n",
      "('of', 'IN')\n",
      "('input', 'NN')\n",
      "('as', 'IN')\n",
      "('being', 'VBG')\n",
      "('identical', 'JJ')\n",
      "('to', 'TO')\n",
      "('each', 'DT')\n",
      "('other', 'JJ')\n",
      "('in', 'IN')\n",
      "('terms', 'NNS')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('textual', 'JJ')\n",
      "('equivalent', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Speech/NNP)\n",
      "('segmentation', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sound', 'JJ')\n",
      "('clip', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('or', 'CC')\n",
      "('people', 'NNS')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('separate', 'JJ')\n",
      "('it', 'PRP')\n",
      "('into', 'IN')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('subtask', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('recognition', 'NN')\n",
      "('and', 'CC')\n",
      "('typically', 'RB')\n",
      "('grouped', 'VBD')\n",
      "('with', 'IN')\n",
      "('it', 'PRP')\n",
      "('.', '.')\n",
      "(PERSON Text/NNP)\n",
      "('-', ':')\n",
      "('to', 'TO')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('Given', 'VBZ')\n",
      "('a', 'DT')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('transform', 'VB')\n",
      "('those', 'DT')\n",
      "('units', 'NNS')\n",
      "('and', 'CC')\n",
      "('produce', 'VB')\n",
      "('a', 'DT')\n",
      "('spoken', 'JJ')\n",
      "('representation', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Text/NNP)\n",
      "('-', ':')\n",
      "('to', 'TO')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('used', 'VBN')\n",
      "('to', 'TO')\n",
      "('aid', 'VB')\n",
      "('the', 'DT')\n",
      "('visually', 'RB')\n",
      "('impaired', 'JJ')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('21', 'CD')\n",
      "(']', 'NNP')\n",
      "('Word', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('(', '(')\n",
      "('Tokenization', 'NNP')\n",
      "(')', ')')\n",
      "('Separate', 'VBP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('continuous', 'JJ')\n",
      "('text', 'NN')\n",
      "('into', 'IN')\n",
      "('separate', 'JJ')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "('like', 'IN')\n",
      "(GPE English/NNP)\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('is', 'VBZ')\n",
      "('fairly', 'RB')\n",
      "('trivial', 'JJ')\n",
      "(',', ',')\n",
      "('since', 'IN')\n",
      "('words', 'NNS')\n",
      "('are', 'VBP')\n",
      "('usually', 'RB')\n",
      "('separated', 'VBN')\n",
      "('by', 'IN')\n",
      "('spaces', 'NNS')\n",
      "('.', '.')\n",
      "('However', 'RB')\n",
      "(',', ',')\n",
      "('some', 'DT')\n",
      "('written', 'VBN')\n",
      "('languages', 'NNS')\n",
      "('like', 'IN')\n",
      "(GPE Chinese/NNP)\n",
      "(',', ',')\n",
      "(GPE Japanese/JJ)\n",
      "('and', 'CC')\n",
      "(GPE Thai/NNP)\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('mark', 'VB')\n",
      "('word', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('in', 'IN')\n",
      "('such', 'JJ')\n",
      "('a', 'DT')\n",
      "('fashion', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('in', 'IN')\n",
      "('those', 'DT')\n",
      "('languages', 'NNS')\n",
      "('text', 'VBP')\n",
      "('segmentation', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('significant', 'JJ')\n",
      "('task', 'NN')\n",
      "('requiring', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('vocabulary', 'JJ')\n",
      "('and', 'CC')\n",
      "('morphology', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('Sometimes', 'RB')\n",
      "('this', 'DT')\n",
      "('process', 'NN')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('cases', 'NNS')\n",
      "('like', 'IN')\n",
      "('bag', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('(', '(')\n",
      "(ORGANIZATION BOW/NNP)\n",
      "(')', ')')\n",
      "('creation', 'NN')\n",
      "('in', 'IN')\n",
      "('data', 'NNS')\n",
      "('mining', 'NN')\n",
      "('.', '.')\n",
      "('Morphological', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Lemmatization', 'NNP')\n",
      "('The', 'DT')\n",
      "('task', 'NN')\n",
      "('of', 'IN')\n",
      "('removing', 'VBG')\n",
      "('inflectional', 'JJ')\n",
      "('endings', 'NNS')\n",
      "('only', 'RB')\n",
      "('and', 'CC')\n",
      "('to', 'TO')\n",
      "('return', 'VB')\n",
      "('the', 'DT')\n",
      "('base', 'NN')\n",
      "('dictionary', 'JJ')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('known', 'VBN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('lemma', 'NN')\n",
      "('.', '.')\n",
      "('Lemmatization', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('another', 'DT')\n",
      "('technique', 'NN')\n",
      "('for', 'IN')\n",
      "('reducing', 'VBG')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('their', 'PRP$')\n",
      "('normalized', 'JJ')\n",
      "('form', 'NN')\n",
      "('.', '.')\n",
      "('But', 'CC')\n",
      "('in', 'IN')\n",
      "('this', 'DT')\n",
      "('case', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('transformation', 'NN')\n",
      "('actually', 'RB')\n",
      "('uses', 'VBZ')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('to', 'TO')\n",
      "('map', 'VB')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('their', 'PRP$')\n",
      "('actual', 'JJ')\n",
      "('form', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('22', 'CD')\n",
      "(']', 'JJ')\n",
      "('Morphological', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Separate', 'NNP')\n",
      "('words', 'NNS')\n",
      "('into', 'IN')\n",
      "('individual', 'JJ')\n",
      "('morphemes', 'NNS')\n",
      "('and', 'CC')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('class', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('morphemes', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('difficulty', 'NN')\n",
      "('of', 'IN')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('depends', 'VBZ')\n",
      "('greatly', 'RB')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('complexity', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('morphology', 'NN')\n",
      "('(', '(')\n",
      "('i', 'JJ')\n",
      "('.', '.')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('language', 'NN')\n",
      "('being', 'VBG')\n",
      "('considered', 'VBN')\n",
      "('.', '.')\n",
      "(PERSON English/NNP)\n",
      "('has', 'VBZ')\n",
      "('fairly', 'RB')\n",
      "('simple', 'JJ')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('inflectional', 'JJ')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('thus', 'RB')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('possible', 'JJ')\n",
      "('to', 'TO')\n",
      "('ignore', 'VB')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "('entirely', 'RB')\n",
      "('and', 'CC')\n",
      "('simply', 'RB')\n",
      "('model', 'VB')\n",
      "('all', 'DT')\n",
      "('possible', 'JJ')\n",
      "('forms', 'NNS')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('\"', 'JJ')\n",
      "('open', 'JJ')\n",
      "(',', ',')\n",
      "('opens', 'VBZ')\n",
      "(',', ',')\n",
      "('opened', 'VBD')\n",
      "(',', ',')\n",
      "('opening', 'VBG')\n",
      "('\")', 'NN')\n",
      "('as', 'IN')\n",
      "('separate', 'JJ')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "(GPE Turkish/JJ)\n",
      "('or', 'CC')\n",
      "(GPE Meitei/NNP)\n",
      "(',', ',')\n",
      "('[', 'VBD')\n",
      "('23', 'CD')\n",
      "(']', 'FW')\n",
      "('a', 'DT')\n",
      "('highly', 'RB')\n",
      "('agglutinated', 'JJ')\n",
      "(GPE Indian/JJ)\n",
      "('language', 'NN')\n",
      "(',', ',')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('such', 'PDT')\n",
      "('an', 'DT')\n",
      "('approach', 'NN')\n",
      "('is', 'VBZ')\n",
      "('not', 'RB')\n",
      "('possible', 'JJ')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('each', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('entry', 'NN')\n",
      "('has', 'VBZ')\n",
      "('thousands', 'NNS')\n",
      "('of', 'IN')\n",
      "('possible', 'JJ')\n",
      "('word', 'NN')\n",
      "('forms', 'NNS')\n",
      "('.', '.')\n",
      "(PERSON Part/NNP)\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('tagging', 'VBG')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('the', 'DT')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION POS/NNP)\n",
      "(')', ')')\n",
      "('for', 'IN')\n",
      "('each', 'DT')\n",
      "('word', 'NN')\n",
      "('.', '.')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('especially', 'RB')\n",
      "('common', 'JJ')\n",
      "('ones', 'NNS')\n",
      "(',', ',')\n",
      "('can', 'MD')\n",
      "('serve', 'VB')\n",
      "('as', 'IN')\n",
      "('multiple', 'JJ')\n",
      "('parts', 'NNS')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('\"', 'NNP')\n",
      "('book', 'NN')\n",
      "('\"', 'NN')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('noun', 'JJ')\n",
      "('(\"', 'NN')\n",
      "('the', 'DT')\n",
      "('book', 'NN')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('table', 'NN')\n",
      "('\")', 'NN')\n",
      "('or', 'CC')\n",
      "('verb', 'NN')\n",
      "('(\"', 'NN')\n",
      "('to', 'TO')\n",
      "('book', 'NN')\n",
      "('a', 'DT')\n",
      "('flight', 'NN')\n",
      "('\");', 'NN')\n",
      "('\"', 'NN')\n",
      "('set', 'VBN')\n",
      "('\"', 'NNS')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('a', 'DT')\n",
      "('noun', 'NN')\n",
      "(',', ',')\n",
      "('verb', 'NN')\n",
      "('or', 'CC')\n",
      "('adjective', 'JJ')\n",
      "(';', ':')\n",
      "('and', 'CC')\n",
      "('\"', 'VB')\n",
      "('out', 'RP')\n",
      "('\"', 'NN')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('any', 'DT')\n",
      "('of', 'IN')\n",
      "('at', 'IN')\n",
      "('least', 'JJS')\n",
      "('five', 'CD')\n",
      "('different', 'JJ')\n",
      "('parts', 'NNS')\n",
      "('of', 'IN')\n",
      "('speech', 'NN')\n",
      "('.', '.')\n",
      "('Stemming', 'VBG')\n",
      "('The', 'DT')\n",
      "('process', 'NN')\n",
      "('of', 'IN')\n",
      "('reducing', 'VBG')\n",
      "('inflected', 'VBN')\n",
      "('(', '(')\n",
      "('or', 'CC')\n",
      "('sometimes', 'RB')\n",
      "('derived', 'VBN')\n",
      "(')', ')')\n",
      "('words', 'NNS')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('base', 'JJ')\n",
      "('form', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('\"', 'VBD')\n",
      "('close', 'JJ')\n",
      "('\"', 'NNP')\n",
      "('will', 'MD')\n",
      "('be', 'VB')\n",
      "('the', 'DT')\n",
      "('root', 'NN')\n",
      "('for', 'IN')\n",
      "('\"', 'NN')\n",
      "('closed', 'VBD')\n",
      "('\",', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('closing', 'NN')\n",
      "('\",', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('close', 'RB')\n",
      "('\",', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('closer', 'VBD')\n",
      "('\"', 'NNP')\n",
      "('etc', 'FW')\n",
      "('.).', 'NNP')\n",
      "('Stemming', 'VBG')\n",
      "('yields', 'NNS')\n",
      "('similar', 'JJ')\n",
      "('results', 'NNS')\n",
      "('as', 'IN')\n",
      "('lemmatization', 'NN')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('does', 'VBZ')\n",
      "('so', 'RB')\n",
      "('on', 'IN')\n",
      "('grounds', 'NNS')\n",
      "('of', 'IN')\n",
      "('rules', 'NNS')\n",
      "(',', ',')\n",
      "('not', 'RB')\n",
      "('a', 'DT')\n",
      "('dictionary', 'JJ')\n",
      "('.', '.')\n",
      "(PERSON Syntactic/JJ)\n",
      "('analysis', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Grammar', 'NNP')\n",
      "('induction', 'NN')\n",
      "('[', 'VBD')\n",
      "('24', 'CD')\n",
      "(']', 'NNP')\n",
      "('Generate', 'NNP')\n",
      "('a', 'DT')\n",
      "('formal', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('that', 'WDT')\n",
      "('describes', 'VBZ')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "(\"'\", 'POS')\n",
      "('s', 'JJ')\n",
      "('syntax', 'NN')\n",
      "('.', '.')\n",
      "('Sentence', 'NN')\n",
      "('breaking', 'NN')\n",
      "('(', '(')\n",
      "('also', 'RB')\n",
      "('known', 'VBN')\n",
      "('as', 'IN')\n",
      "('\"', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('boundary', 'JJ')\n",
      "('disambiguation', 'NN')\n",
      "('\")', 'NNP')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('find', 'VBP')\n",
      "('the', 'DT')\n",
      "('sentence', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('.', '.')\n",
      "('Sentence', 'NN')\n",
      "('boundaries', 'NNS')\n",
      "('are', 'VBP')\n",
      "('often', 'RB')\n",
      "('marked', 'VBN')\n",
      "('by', 'IN')\n",
      "('periods', 'NNS')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('or', 'CC')\n",
      "('other', 'JJ')\n",
      "('punctuation', 'NN')\n",
      "('marks', 'NNS')\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('these', 'DT')\n",
      "('same', 'JJ')\n",
      "('characters', 'NNS')\n",
      "('can', 'MD')\n",
      "('serve', 'VB')\n",
      "('other', 'JJ')\n",
      "('purposes', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('marking', 'VBG')\n",
      "('abbreviations', 'NNS')\n",
      "(').', 'VBP')\n",
      "('Parsing', 'VBG')\n",
      "('Determine', 'NNP')\n",
      "('the', 'DT')\n",
      "('parse', 'NN')\n",
      "('tree', 'NN')\n",
      "('(', '(')\n",
      "('grammatical', 'JJ')\n",
      "('analysis', 'NN')\n",
      "(')', ')')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('sentence', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('grammar', 'NN')\n",
      "('for', 'IN')\n",
      "('natural', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('ambiguous', 'JJ')\n",
      "('and', 'CC')\n",
      "('typical', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "('have', 'VBP')\n",
      "('multiple', 'VBN')\n",
      "('possible', 'JJ')\n",
      "('analyses', 'NNS')\n",
      "(':', ':')\n",
      "('perhaps', 'RB')\n",
      "('surprisingly', 'RB')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('a', 'DT')\n",
      "('typical', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('there', 'EX')\n",
      "('may', 'MD')\n",
      "('be', 'VB')\n",
      "('thousands', 'NNS')\n",
      "('of', 'IN')\n",
      "('potential', 'JJ')\n",
      "('parses', 'NNS')\n",
      "('(', '(')\n",
      "('most', 'JJS')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('will', 'MD')\n",
      "('seem', 'VB')\n",
      "('completely', 'RB')\n",
      "('nonsensical', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('human', 'JJ')\n",
      "(').', 'NN')\n",
      "('There', 'EX')\n",
      "('are', 'VBP')\n",
      "('two', 'CD')\n",
      "('primary', 'JJ')\n",
      "('types', 'NNS')\n",
      "('of', 'IN')\n",
      "('parsing', 'NN')\n",
      "(':', ':')\n",
      "('dependency', 'NN')\n",
      "('parsing', 'NN')\n",
      "('and', 'CC')\n",
      "('constituency', 'NN')\n",
      "('parsing', 'NN')\n",
      "('.', '.')\n",
      "('Dependency', 'NNP')\n",
      "('parsing', 'VBG')\n",
      "('focuses', 'NNS')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('relationships', 'NNS')\n",
      "('between', 'IN')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('(', '(')\n",
      "('marking', 'VBG')\n",
      "('things', 'NNS')\n",
      "('like', 'IN')\n",
      "('primary', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('and', 'CC')\n",
      "('predicates', 'NNS')\n",
      "('),', 'VBP')\n",
      "('whereas', 'JJ')\n",
      "('constituency', 'NN')\n",
      "('parsing', 'VBG')\n",
      "('focuses', 'NNS')\n",
      "('on', 'IN')\n",
      "('building', 'VBG')\n",
      "('out', 'RP')\n",
      "('the', 'DT')\n",
      "('parse', 'NN')\n",
      "('tree', 'NN')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('probabilistic', 'JJ')\n",
      "('context', 'NN')\n",
      "('-', ':')\n",
      "('free', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION PCFG/NNP)\n",
      "(')', ')')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('stochastic', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(').', 'NNP')\n",
      "('Lexical', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "(')', ')')\n",
      "('[', 'VBZ')\n",
      "('edit', 'JJ')\n",
      "(']', 'NNP')\n",
      "('Lexical', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('computational', 'JJ')\n",
      "('meaning', 'NN')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('words', 'NNS')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('?', '.')\n",
      "('Distributional', 'NNP')\n",
      "('semantics', 'VBD')\n",
      "('How', 'WRB')\n",
      "('can', 'MD')\n",
      "('we', 'PRP')\n",
      "('learn', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('from', 'IN')\n",
      "('data', 'NNS')\n",
      "('?', '.')\n",
      "('Named', 'VBN')\n",
      "('entity', 'NN')\n",
      "('recognition', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NER/NNP)\n",
      "(')', ')')\n",
      "('Given', 'VBZ')\n",
      "('a', 'DT')\n",
      "('stream', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'NN')\n",
      "('which', 'WDT')\n",
      "('items', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('map', 'NN')\n",
      "('to', 'TO')\n",
      "('proper', 'VB')\n",
      "('names', 'NNS')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('people', 'NNS')\n",
      "('or', 'CC')\n",
      "('places', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('what', 'WP')\n",
      "('the', 'DT')\n",
      "('type', 'NN')\n",
      "('of', 'IN')\n",
      "('each', 'DT')\n",
      "('such', 'JJ')\n",
      "('name', 'NN')\n",
      "('is', 'VBZ')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('person', 'NN')\n",
      "(',', ',')\n",
      "('location', 'NN')\n",
      "(',', ',')\n",
      "('organization', 'NN')\n",
      "(').', 'NNP')\n",
      "('Although', 'IN')\n",
      "('capitalization', 'NN')\n",
      "('can', 'MD')\n",
      "('aid', 'VB')\n",
      "('in', 'IN')\n",
      "('recognizing', 'VBG')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "('in', 'IN')\n",
      "('languages', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "(GPE English/NNP)\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('information', 'NN')\n",
      "('cannot', 'NN')\n",
      "('aid', 'NN')\n",
      "('in', 'IN')\n",
      "('determining', 'VBG')\n",
      "('the', 'DT')\n",
      "('type', 'NN')\n",
      "('of', 'IN')\n",
      "('named', 'VBN')\n",
      "('entity', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('in', 'IN')\n",
      "('any', 'DT')\n",
      "('case', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('often', 'RB')\n",
      "('inaccurate', 'JJ')\n",
      "('or', 'CC')\n",
      "('insufficient', 'JJ')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "('letter', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('is', 'VBZ')\n",
      "('also', 'RB')\n",
      "('capitalized', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('named', 'VBD')\n",
      "('entities', 'NNS')\n",
      "('often', 'RB')\n",
      "('span', 'VBP')\n",
      "('several', 'JJ')\n",
      "('words', 'NNS')\n",
      "(',', ',')\n",
      "('only', 'RB')\n",
      "('some', 'DT')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('are', 'VBP')\n",
      "('capitalized', 'VBN')\n",
      "('.', '.')\n",
      "('Furthermore', 'NNP')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('other', 'JJ')\n",
      "('languages', 'NNS')\n",
      "('in', 'IN')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "(GPE Western/JJ)\n",
      "('scripts', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('Chinese', 'JJ')\n",
      "('or', 'CC')\n",
      "(PERSON Arabic/NNP)\n",
      "(')', ')')\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('have', 'VB')\n",
      "('any', 'DT')\n",
      "('capitalization', 'NN')\n",
      "('at', 'IN')\n",
      "('all', 'DT')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('even', 'RB')\n",
      "('languages', 'NNS')\n",
      "('with', 'IN')\n",
      "('capitalization', 'NN')\n",
      "('may', 'MD')\n",
      "('not', 'RB')\n",
      "('consistently', 'RB')\n",
      "('use', 'VB')\n",
      "('it', 'PRP')\n",
      "('to', 'TO')\n",
      "('distinguish', 'VB')\n",
      "('names', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "(GPE German/JJ)\n",
      "('capitalizes', 'VBZ')\n",
      "('all', 'DT')\n",
      "('nouns', 'NNS')\n",
      "(',', ',')\n",
      "('regardless', 'RB')\n",
      "('of', 'IN')\n",
      "('whether', 'IN')\n",
      "('they', 'PRP')\n",
      "('are', 'VBP')\n",
      "('names', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(GPE French/JJ)\n",
      "('and', 'CC')\n",
      "(GPE Spanish/JJ)\n",
      "('do', 'VBP')\n",
      "('not', 'RB')\n",
      "('capitalize', 'VB')\n",
      "('names', 'NNS')\n",
      "('that', 'WDT')\n",
      "('serve', 'VBP')\n",
      "('as', 'IN')\n",
      "('adjectives', 'NNS')\n",
      "('.', '.')\n",
      "('Sentiment', 'NN')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('Multimodal', 'NNP')\n",
      "('sentiment', 'NN')\n",
      "('analysis', 'NN')\n",
      "(')', ')')\n",
      "('Extract', 'NNP')\n",
      "('subjective', 'JJ')\n",
      "('information', 'NN')\n",
      "('usually', 'RB')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('set', 'NN')\n",
      "('of', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('often', 'RB')\n",
      "('using', 'VBG')\n",
      "('online', 'JJ')\n",
      "('reviews', 'NNS')\n",
      "('to', 'TO')\n",
      "('determine', 'VB')\n",
      "('\"', 'NNP')\n",
      "('polarity', 'NN')\n",
      "('\"', 'NN')\n",
      "('about', 'IN')\n",
      "('specific', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('.', '.')\n",
      "('It', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('especially', 'RB')\n",
      "('useful', 'JJ')\n",
      "('for', 'IN')\n",
      "('identifying', 'VBG')\n",
      "('trends', 'NNS')\n",
      "('of', 'IN')\n",
      "('public', 'JJ')\n",
      "('opinion', 'NN')\n",
      "('in', 'IN')\n",
      "('social', 'JJ')\n",
      "('media', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('marketing', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Terminology/NNP)\n",
      "('extraction', 'NN')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('of', 'IN')\n",
      "('terminology', 'NN')\n",
      "('extraction', 'NN')\n",
      "('is', 'VBZ')\n",
      "('to', 'TO')\n",
      "('automatically', 'RB')\n",
      "('extract', 'VB')\n",
      "('relevant', 'JJ')\n",
      "('terms', 'NNS')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('given', 'VBN')\n",
      "('corpus', 'NN')\n",
      "('.', '.')\n",
      "('Word', 'NNP')\n",
      "('sense', 'NN')\n",
      "('disambiguation', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION WSD/NNP)\n",
      "(')', ')')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "('have', 'VBP')\n",
      "('more', 'JJR')\n",
      "('than', 'IN')\n",
      "('one', 'CD')\n",
      "('meaning', 'NN')\n",
      "(';', ':')\n",
      "('we', 'PRP')\n",
      "('have', 'VBP')\n",
      "('to', 'TO')\n",
      "('select', 'VB')\n",
      "('the', 'DT')\n",
      "('meaning', 'NN')\n",
      "('which', 'WDT')\n",
      "('makes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('sense', 'NN')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('this', 'DT')\n",
      "('problem', 'NN')\n",
      "(',', ',')\n",
      "('we', 'PRP')\n",
      "('are', 'VBP')\n",
      "('typically', 'RB')\n",
      "('given', 'VBN')\n",
      "('a', 'DT')\n",
      "('list', 'NN')\n",
      "('of', 'IN')\n",
      "('words', 'NNS')\n",
      "('and', 'CC')\n",
      "('associated', 'VBN')\n",
      "('word', 'NN')\n",
      "('senses', 'NNS')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('dictionary', 'NN')\n",
      "('or', 'CC')\n",
      "('an', 'DT')\n",
      "('online', 'JJ')\n",
      "('resource', 'NN')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "(ORGANIZATION WordNet/NNP)\n",
      "('.', '.')\n",
      "('Entity', 'NNP')\n",
      "('linking', 'VBG')\n",
      "('Many', 'JJ')\n",
      "('words', 'NNS')\n",
      "('-', ':')\n",
      "('typically', 'RB')\n",
      "('proper', 'JJ')\n",
      "('names', 'NNS')\n",
      "('-', ':')\n",
      "('refer', 'NN')\n",
      "('to', 'TO')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "(';', ':')\n",
      "('here', 'RB')\n",
      "('we', 'PRP')\n",
      "('have', 'VBP')\n",
      "('to', 'TO')\n",
      "('select', 'VB')\n",
      "('the', 'DT')\n",
      "('entity', 'NN')\n",
      "('(', '(')\n",
      "('a', 'DT')\n",
      "('famous', 'JJ')\n",
      "('individual', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('location', 'NN')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('company', 'NN')\n",
      "(',', ',')\n",
      "('etc', 'FW')\n",
      "('.)', 'CD')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "('in', 'IN')\n",
      "('context', 'NN')\n",
      "('.', '.')\n",
      "('Relational', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('of', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('[', 'VBP')\n",
      "('edit', 'JJ')\n",
      "(']', 'NNP')\n",
      "('Relationship', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('relationships', 'NNS')\n",
      "('among', 'IN')\n",
      "('named', 'VBN')\n",
      "('entities', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('who', 'WP')\n",
      "('is', 'VBZ')\n",
      "('married', 'VBN')\n",
      "('to', 'TO')\n",
      "('whom', 'WP')\n",
      "(').', 'NNP')\n",
      "('Semantic', 'NNP')\n",
      "('parsing', 'VBG')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('(', '(')\n",
      "('typically', 'RB')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('),', 'NN')\n",
      "('produce', 'VBP')\n",
      "('a', 'DT')\n",
      "('formal', 'JJ')\n",
      "('representation', 'NN')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('either', 'RB')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('graph', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION AMR/NNP)\n",
      "('parsing', 'VBG')\n",
      "(')', ')')\n",
      "('or', 'CC')\n",
      "('in', 'IN')\n",
      "('accordance', 'NN')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('logical', 'JJ')\n",
      "('formalism', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('in', 'IN')\n",
      "(ORGANIZATION DRT/NNP)\n",
      "('parsing', 'VBG')\n",
      "(').', 'NN')\n",
      "('This', 'DT')\n",
      "('challenge', 'NN')\n",
      "('typically', 'RB')\n",
      "('includes', 'VBZ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('several', 'JJ')\n",
      "('more', 'JJR')\n",
      "('elementary', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('tasks', 'NNS')\n",
      "('from', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "(',', ',')\n",
      "('word', 'NN')\n",
      "('sense', 'NN')\n",
      "('disambiguation', 'NN')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('extended', 'VBN')\n",
      "('to', 'TO')\n",
      "('include', 'VB')\n",
      "('full', 'JJ')\n",
      "('-', ':')\n",
      "('fledged', 'JJ')\n",
      "('discourse', 'NN')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('discourse', 'NN')\n",
      "('analysis', 'NN')\n",
      "(',', ',')\n",
      "('coreference', 'NN')\n",
      "(';', ':')\n",
      "('see', 'VB')\n",
      "(ORGANIZATION Natural/JJ)\n",
      "('language', 'NN')\n",
      "('understanding', 'VBG')\n",
      "('below', 'IN')\n",
      "(').', 'NNP')\n",
      "('Semantic', 'NNP')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('also', 'RB')\n",
      "('implicit', 'JJ')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('below', 'IN')\n",
      "(')', ')')\n",
      "('Given', 'FW')\n",
      "('a', 'DT')\n",
      "('single', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'NN')\n",
      "('and', 'CC')\n",
      "('disambiguate', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('predicates', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('verbal', 'JJ')\n",
      "('frames', 'NNS')\n",
      "('),', 'VBP')\n",
      "('then', 'RB')\n",
      "('identify', 'VB')\n",
      "('and', 'CC')\n",
      "('classify', 'VB')\n",
      "('the', 'DT')\n",
      "('frame', 'NN')\n",
      "('elements', 'NNS')\n",
      "('(', '(')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "(').', 'VBP')\n",
      "(GPE Discourse/NNP)\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('beyond', 'IN')\n",
      "('individual', 'JJ')\n",
      "('sentences', 'NNS')\n",
      "(')', ')')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NN')\n",
      "('Coreference', 'NNP')\n",
      "('resolution', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('or', 'CC')\n",
      "('larger', 'JJR')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'NN')\n",
      "('which', 'WDT')\n",
      "('words', 'NNS')\n",
      "('(\"', 'VBP')\n",
      "('mentions', 'NNS')\n",
      "('\")', 'VBP')\n",
      "('refer', 'NN')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('same', 'JJ')\n",
      "('objects', 'NNS')\n",
      "('(\"', 'JJ')\n",
      "('entities', 'NNS')\n",
      "('\").', 'VBP')\n",
      "(PERSON Anaphora/NNP)\n",
      "('resolution', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('specific', 'JJ')\n",
      "('example', 'NN')\n",
      "('of', 'IN')\n",
      "('this', 'DT')\n",
      "('task', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('specifically', 'RB')\n",
      "('concerned', 'VBN')\n",
      "('with', 'IN')\n",
      "('matching', 'VBG')\n",
      "('up', 'RP')\n",
      "('pronouns', 'NNS')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('nouns', 'NNS')\n",
      "('or', 'CC')\n",
      "('names', 'NNS')\n",
      "('to', 'TO')\n",
      "('which', 'WDT')\n",
      "('they', 'PRP')\n",
      "('refer', 'VBP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('more', 'RBR')\n",
      "('general', 'JJ')\n",
      "('task', 'NN')\n",
      "('of', 'IN')\n",
      "('coreference', 'NN')\n",
      "('resolution', 'NN')\n",
      "('also', 'RB')\n",
      "('includes', 'VBZ')\n",
      "('identifying', 'VBG')\n",
      "('so', 'RB')\n",
      "('-', ':')\n",
      "('called', 'VBN')\n",
      "('\"', 'NN')\n",
      "('bridging', 'VBG')\n",
      "('relationships', 'NNS')\n",
      "('\"', 'RB')\n",
      "('involving', 'VBG')\n",
      "('referring', 'VBG')\n",
      "('expressions', 'NNS')\n",
      "('.', '.')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('sentence', 'NN')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('\"', 'NN')\n",
      "('He', 'PRP')\n",
      "('entered', 'VBD')\n",
      "(PERSON John/NNP)\n",
      "(\"'\", 'POS')\n",
      "('s', 'NN')\n",
      "('house', 'NN')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('front', 'JJ')\n",
      "('door', 'NN')\n",
      "('\",', 'NNP')\n",
      "('\"', 'VBZ')\n",
      "('the', 'DT')\n",
      "('front', 'JJ')\n",
      "('door', 'NN')\n",
      "('\"', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('referring', 'VBG')\n",
      "('expression', 'NN')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('bridging', 'NN')\n",
      "('relationship', 'NN')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('identified', 'VBN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('fact', 'NN')\n",
      "('that', 'IN')\n",
      "('the', 'DT')\n",
      "('door', 'NN')\n",
      "('being', 'VBG')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('front', 'JJ')\n",
      "('door', 'NN')\n",
      "('of', 'IN')\n",
      "(PERSON John/NNP)\n",
      "(\"'\", 'POS')\n",
      "('s', 'NN')\n",
      "('house', 'NN')\n",
      "('(', '(')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('of', 'IN')\n",
      "('some', 'DT')\n",
      "('other', 'JJ')\n",
      "('structure', 'NN')\n",
      "('that', 'WDT')\n",
      "('might', 'MD')\n",
      "('also', 'RB')\n",
      "('be', 'VB')\n",
      "('referred', 'VBN')\n",
      "('to', 'TO')\n",
      "(').', 'VB')\n",
      "(PERSON Discourse/NNP)\n",
      "('analysis', 'NN')\n",
      "('This', 'DT')\n",
      "('rubric', 'JJ')\n",
      "('includes', 'VBZ')\n",
      "('several', 'JJ')\n",
      "('related', 'JJ')\n",
      "('tasks', 'NNS')\n",
      "('.', '.')\n",
      "('One', 'CD')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('discourse', 'JJ')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('i', 'NN')\n",
      "('.', '.')\n",
      "('e', 'CC')\n",
      "('.,', 'JJ')\n",
      "('identifying', 'VBG')\n",
      "('the', 'DT')\n",
      "('discourse', 'NN')\n",
      "('structure', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('connected', 'JJ')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('i', 'NN')\n",
      "('.', '.')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('the', 'DT')\n",
      "('nature', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('discourse', 'JJ')\n",
      "('relationships', 'NNS')\n",
      "('between', 'IN')\n",
      "('sentences', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('elaboration', 'NN')\n",
      "(',', ',')\n",
      "('explanation', 'NN')\n",
      "(',', ',')\n",
      "('contrast', 'NN')\n",
      "(').', 'NN')\n",
      "('Another', 'DT')\n",
      "('possible', 'JJ')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('recognizing', 'VBG')\n",
      "('and', 'CC')\n",
      "('classifying', 'VBG')\n",
      "('the', 'DT')\n",
      "('speech', 'NN')\n",
      "('acts', 'VBZ')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.', '.')\n",
      "('yes', 'UH')\n",
      "('-', ':')\n",
      "('no', 'DT')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('content', 'JJ')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('statement', 'NN')\n",
      "(',', ',')\n",
      "('assertion', 'NN')\n",
      "(',', ',')\n",
      "('etc', 'FW')\n",
      "('.).', 'FW')\n",
      "('Implicit', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('single', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('identify', 'NN')\n",
      "('and', 'CC')\n",
      "('disambiguate', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('predicates', 'NNS')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'JJ')\n",
      "('verbal', 'JJ')\n",
      "('frames', 'NNS')\n",
      "(')', ')')\n",
      "('and', 'CC')\n",
      "('their', 'PRP$')\n",
      "('explicit', 'JJ')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('current', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "(ORGANIZATION Semantic/JJ)\n",
      "('role', 'NN')\n",
      "('labelling', 'VBG')\n",
      "('above', 'IN')\n",
      "(').', 'NNP')\n",
      "('Then', 'RB')\n",
      "(',', ',')\n",
      "('identify', 'VB')\n",
      "('semantic', 'JJ')\n",
      "('roles', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('not', 'RB')\n",
      "('explicitly', 'RB')\n",
      "('realized', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('current', 'JJ')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('classify', 'VB')\n",
      "('them', 'PRP')\n",
      "('into', 'IN')\n",
      "('arguments', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('explicitly', 'RB')\n",
      "('realized', 'VBN')\n",
      "('elsewhere', 'RB')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('and', 'CC')\n",
      "('those', 'DT')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('not', 'RB')\n",
      "('specified', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('resolve', 'VB')\n",
      "('the', 'DT')\n",
      "('former', 'JJ')\n",
      "('against', 'IN')\n",
      "('the', 'DT')\n",
      "('local', 'JJ')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "('A', 'DT')\n",
      "('closely', 'RB')\n",
      "('related', 'JJ')\n",
      "('task', 'NN')\n",
      "('is', 'VBZ')\n",
      "('zero', 'CD')\n",
      "('anaphora', 'JJ')\n",
      "('resolution', 'NN')\n",
      "(',', ',')\n",
      "('i', 'NN')\n",
      "('.', '.')\n",
      "('e', 'CC')\n",
      "('.,', 'VBD')\n",
      "('the', 'DT')\n",
      "('extension', 'NN')\n",
      "('of', 'IN')\n",
      "('coreference', 'NN')\n",
      "('resolution', 'NN')\n",
      "('to', 'TO')\n",
      "('pro', 'VB')\n",
      "('-', ':')\n",
      "('drop', 'NN')\n",
      "('languages', 'NNS')\n",
      "('.', '.')\n",
      "('Recognizing', 'VBG')\n",
      "('textual', 'JJ')\n",
      "('entailment', 'NN')\n",
      "('Given', 'NNP')\n",
      "('two', 'CD')\n",
      "('text', 'NN')\n",
      "('fragments', 'NNS')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('if', 'IN')\n",
      "('one', 'CD')\n",
      "('being', 'VBG')\n",
      "('true', 'JJ')\n",
      "('entails', 'NNS')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "(',', ',')\n",
      "('entails', 'VBZ')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "(\"'\", 'POS')\n",
      "('s', 'JJ')\n",
      "('negation', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('allows', 'VBZ')\n",
      "('the', 'DT')\n",
      "('other', 'JJ')\n",
      "('to', 'TO')\n",
      "('be', 'VB')\n",
      "('either', 'RB')\n",
      "('true', 'JJ')\n",
      "('or', 'CC')\n",
      "('false', 'JJ')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('25', 'CD')\n",
      "(']', 'NNP')\n",
      "('Topic', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('and', 'CC')\n",
      "('recognition', 'NN')\n",
      "('Given', 'NNP')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('separate', 'VB')\n",
      "('it', 'PRP')\n",
      "('into', 'IN')\n",
      "('segments', 'NNS')\n",
      "('each', 'DT')\n",
      "('of', 'IN')\n",
      "('which', 'WDT')\n",
      "('is', 'VBZ')\n",
      "('devoted', 'VBN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('topic', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('identify', 'VB')\n",
      "('the', 'DT')\n",
      "('topic', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('segment', 'NN')\n",
      "('.', '.')\n",
      "('Argument', 'NN')\n",
      "('mining', 'VBG')\n",
      "('The', 'DT')\n",
      "('goal', 'NN')\n",
      "('of', 'IN')\n",
      "('argument', 'NN')\n",
      "('mining', 'NN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('automatic', 'JJ')\n",
      "('extraction', 'NN')\n",
      "('and', 'CC')\n",
      "('identification', 'NN')\n",
      "('of', 'IN')\n",
      "('argumentative', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('from', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('text', 'NN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('aid', 'NN')\n",
      "('of', 'IN')\n",
      "('computer', 'NN')\n",
      "('programs', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('26', 'CD')\n",
      "(']', 'NNP')\n",
      "('Such', 'JJ')\n",
      "('argumentative', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('include', 'VBP')\n",
      "('the', 'DT')\n",
      "('premise', 'NN')\n",
      "(',', ',')\n",
      "('conclusions', 'NNS')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('argument', 'NN')\n",
      "('scheme', 'NN')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('relationship', 'NN')\n",
      "('between', 'IN')\n",
      "('the', 'DT')\n",
      "('main', 'JJ')\n",
      "('and', 'CC')\n",
      "('subsidiary', 'NN')\n",
      "('argument', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('the', 'DT')\n",
      "('main', 'JJ')\n",
      "('and', 'CC')\n",
      "('counter', 'JJ')\n",
      "('-', ':')\n",
      "('argument', 'NN')\n",
      "('within', 'IN')\n",
      "('discourse', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('27', 'CD')\n",
      "(']', 'JJ')\n",
      "('[', '$')\n",
      "('28', 'CD')\n",
      "(']', 'NN')\n",
      "('Higher', 'JJR')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('applications', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Automatic', 'NNP')\n",
      "('summarization', 'NN')\n",
      "('(', '(')\n",
      "('text', 'JJ')\n",
      "('summarization', 'NN')\n",
      "(')', ')')\n",
      "('Produce', 'VBP')\n",
      "('a', 'DT')\n",
      "('readable', 'JJ')\n",
      "('summary', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('chunk', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Often/NNP)\n",
      "('used', 'VBD')\n",
      "('to', 'TO')\n",
      "('provide', 'VB')\n",
      "('summaries', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('text', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('known', 'JJ')\n",
      "('type', 'NN')\n",
      "(',', ',')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('research', 'NN')\n",
      "('papers', 'NNS')\n",
      "(',', ',')\n",
      "('articles', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('financial', 'JJ')\n",
      "('section', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('newspaper', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Book/NNP)\n",
      "('generation', 'NN')\n",
      "('Not', 'RB')\n",
      "('an', 'DT')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('task', 'NN')\n",
      "('proper', 'NN')\n",
      "('but', 'CC')\n",
      "('an', 'DT')\n",
      "('extension', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('and', 'CC')\n",
      "('other', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('tasks', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('creation', 'NN')\n",
      "('of', 'IN')\n",
      "('full', 'JJ')\n",
      "('-', ':')\n",
      "('fledged', 'VBN')\n",
      "('books', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('generated', 'VBD')\n",
      "('book', 'NN')\n",
      "('was', 'VBD')\n",
      "('created', 'VBN')\n",
      "('by', 'IN')\n",
      "('a', 'DT')\n",
      "('rule', 'NN')\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "('system', 'NN')\n",
      "('in', 'IN')\n",
      "('1984', 'CD')\n",
      "('(', '(')\n",
      "(PERSON Racter/NNP)\n",
      "(',', ',')\n",
      "('The', 'DT')\n",
      "('policeman', 'NN')\n",
      "(\"'\", 'POS')\n",
      "('s', 'JJ')\n",
      "('beard', 'NN')\n",
      "('is', 'VBZ')\n",
      "('half', 'JJ')\n",
      "('-', ':')\n",
      "('constructed', 'VBN')\n",
      "(').', 'JJ')\n",
      "('[', '$')\n",
      "('29', 'CD')\n",
      "(']', 'IN')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('published', 'VBN')\n",
      "('work', 'NN')\n",
      "('by', 'IN')\n",
      "('a', 'DT')\n",
      "('neural', 'JJ')\n",
      "('network', 'NN')\n",
      "('was', 'VBD')\n",
      "('published', 'VBN')\n",
      "('in', 'IN')\n",
      "('2018', 'CD')\n",
      "(',', ',')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Road/NNP)\n",
      "(',', ',')\n",
      "('marketed', 'VBD')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('novel', 'NN')\n",
      "(',', ',')\n",
      "('contains', 'VBZ')\n",
      "('sixty', 'JJ')\n",
      "('million', 'CD')\n",
      "('words', 'NNS')\n",
      "('.', '.')\n",
      "('Both', 'CC')\n",
      "('these', 'DT')\n",
      "('systems', 'NNS')\n",
      "('are', 'VBP')\n",
      "('basically', 'RB')\n",
      "('elaborate', 'JJ')\n",
      "('but', 'CC')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "('sensical', 'JJ')\n",
      "('(', '(')\n",
      "('semantics', 'NNS')\n",
      "('-', ':')\n",
      "('free', 'JJ')\n",
      "(')', ')')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('first', 'JJ')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('generated', 'VBN')\n",
      "('science', 'NN')\n",
      "('book', 'NN')\n",
      "('was', 'VBD')\n",
      "('published', 'VBN')\n",
      "('in', 'IN')\n",
      "('2019', 'CD')\n",
      "('(', '(')\n",
      "(ORGANIZATION Beta/NNP Writer/NNP)\n",
      "(',', ',')\n",
      "(GPE Lithium/NNP)\n",
      "('-', ':')\n",
      "(PERSON Ion/NNP Batteries/NNP)\n",
      "(',', ',')\n",
      "(PERSON Springer/NNP)\n",
      "(',', ',')\n",
      "(PERSON Cham/NNP)\n",
      "(').', 'NNP')\n",
      "('[', 'VBD')\n",
      "('30', 'CD')\n",
      "(']', 'NNS')\n",
      "('Unlike', 'IN')\n",
      "(PERSON Racter/NNP)\n",
      "('and', 'CC')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Road/NNP)\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('is', 'VBZ')\n",
      "('grounded', 'VBN')\n",
      "('on', 'IN')\n",
      "('factual', 'JJ')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('text', 'JJ')\n",
      "('summarization', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Dialogue/NNP)\n",
      "('management', 'NN')\n",
      "(ORGANIZATION Computer/NNP)\n",
      "('systems', 'NNS')\n",
      "('intended', 'VBD')\n",
      "('to', 'TO')\n",
      "('converse', 'VB')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('human', 'JJ')\n",
      "('.', '.')\n",
      "(PERSON Document/NNP AI/NNP)\n",
      "('A', 'NNP')\n",
      "('Document', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('platform', 'NN')\n",
      "('sits', 'NNS')\n",
      "('on', 'IN')\n",
      "('top', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('technology', 'NN')\n",
      "('enabling', 'VBG')\n",
      "('users', 'NNS')\n",
      "('with', 'IN')\n",
      "('no', 'DT')\n",
      "('prior', 'JJ')\n",
      "('experience', 'NN')\n",
      "('of', 'IN')\n",
      "('artificial', 'JJ')\n",
      "('intelligence', 'NN')\n",
      "(',', ',')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "('or', 'CC')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('to', 'TO')\n",
      "('quickly', 'RB')\n",
      "('train', 'VB')\n",
      "('a', 'DT')\n",
      "('computer', 'NN')\n",
      "('to', 'TO')\n",
      "('extract', 'VB')\n",
      "('the', 'DT')\n",
      "('specific', 'JJ')\n",
      "('data', 'NNS')\n",
      "('they', 'PRP')\n",
      "('need', 'VBP')\n",
      "('from', 'IN')\n",
      "('different', 'JJ')\n",
      "('document', 'NN')\n",
      "('types', 'NNS')\n",
      "('.', '.')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('-', ':')\n",
      "('powered', 'VBD')\n",
      "(ORGANIZATION Document/NNP)\n",
      "('AI', 'NNP')\n",
      "('enables', 'VBZ')\n",
      "('non', 'SYM')\n",
      "('-', ':')\n",
      "('technical', 'JJ')\n",
      "('teams', 'NNS')\n",
      "('to', 'TO')\n",
      "('quickly', 'RB')\n",
      "('access', 'NN')\n",
      "('information', 'NN')\n",
      "('hidden', 'NN')\n",
      "('in', 'IN')\n",
      "('documents', 'NNS')\n",
      "(',', ',')\n",
      "('for', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('lawyers', 'NNS')\n",
      "(',', ',')\n",
      "('business', 'NN')\n",
      "('analysts', 'NNS')\n",
      "('and', 'CC')\n",
      "('accountants', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('31', 'CD')\n",
      "(']', 'NNP')\n",
      "('Grammatical', 'NNP')\n",
      "('error', 'NN')\n",
      "('correction', 'NN')\n",
      "('Grammatical', 'NNP')\n",
      "('error', 'NN')\n",
      "('detection', 'NN')\n",
      "('and', 'CC')\n",
      "('correction', 'NN')\n",
      "('involves', 'VBZ')\n",
      "('a', 'DT')\n",
      "('great', 'JJ')\n",
      "('band', 'NN')\n",
      "('-', ':')\n",
      "('width', 'NN')\n",
      "('of', 'IN')\n",
      "('problems', 'NNS')\n",
      "('on', 'IN')\n",
      "('all', 'DT')\n",
      "('levels', 'NNS')\n",
      "('of', 'IN')\n",
      "('linguistic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('(', '(')\n",
      "('phonology', 'NN')\n",
      "('/', 'NNP')\n",
      "('orthography', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('pragmatics', 'NNS')\n",
      "(').', 'VBP')\n",
      "(GPE Grammatical/NNP)\n",
      "('error', 'NN')\n",
      "('correction', 'NN')\n",
      "('is', 'VBZ')\n",
      "('impactful', 'JJ')\n",
      "('since', 'IN')\n",
      "('it', 'PRP')\n",
      "('affects', 'VBZ')\n",
      "('hundreds', 'NNS')\n",
      "('of', 'IN')\n",
      "('millions', 'NNS')\n",
      "('of', 'IN')\n",
      "('people', 'NNS')\n",
      "('that', 'WDT')\n",
      "('use', 'VBP')\n",
      "('or', 'CC')\n",
      "('acquire', 'VB')\n",
      "(GPE English/JJ)\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('second', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('It', 'PRP')\n",
      "('has', 'VBZ')\n",
      "('thus', 'RB')\n",
      "('been', 'VBN')\n",
      "('subject', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('shared', 'VBN')\n",
      "('tasks', 'NNS')\n",
      "('since', 'IN')\n",
      "('2011', 'CD')\n",
      "('.', '.')\n",
      "('[', 'VB')\n",
      "('32', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('33', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('34', 'CD')\n",
      "(']', 'NN')\n",
      "('As', 'RB')\n",
      "('far', 'RB')\n",
      "('as', 'IN')\n",
      "('orthography', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('syntax', 'NN')\n",
      "('and', 'CC')\n",
      "('certain', 'JJ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('are', 'VBP')\n",
      "('concerned', 'VBN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('due', 'JJ')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('development', 'NN')\n",
      "('of', 'IN')\n",
      "('powerful', 'JJ')\n",
      "('neural', 'JJ')\n",
      "('language', 'NN')\n",
      "('models', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "(ORGANIZATION GPT/NNP)\n",
      "('-', ':')\n",
      "('2', 'CD')\n",
      "(',', ',')\n",
      "('this', 'DT')\n",
      "('can', 'MD')\n",
      "('now', 'RB')\n",
      "('(', '(')\n",
      "('2019', 'CD')\n",
      "(')', ')')\n",
      "('be', 'VB')\n",
      "('considered', 'VBN')\n",
      "('a', 'DT')\n",
      "('largely', 'RB')\n",
      "('solved', 'VBN')\n",
      "('problem', 'NN')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('being', 'VBG')\n",
      "('marketed', 'VBN')\n",
      "('in', 'IN')\n",
      "('various', 'JJ')\n",
      "('commercial', 'JJ')\n",
      "('applications', 'NNS')\n",
      "('.', '.')\n",
      "(PERSON Machine/NNP)\n",
      "('translation', 'NN')\n",
      "('Automatically', 'NNP')\n",
      "('translate', 'VBP')\n",
      "('text', 'NN')\n",
      "('from', 'IN')\n",
      "('one', 'CD')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "('to', 'TO')\n",
      "('another', 'DT')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('is', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('most', 'RBS')\n",
      "('difficult', 'JJ')\n",
      "('problems', 'NNS')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('member', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('class', 'NN')\n",
      "('of', 'IN')\n",
      "('problems', 'NNS')\n",
      "('colloquially', 'RB')\n",
      "('termed', 'VBD')\n",
      "('\"', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('-', ':')\n",
      "('complete', 'JJ')\n",
      "('\",', 'NN')\n",
      "('i', 'NN')\n",
      "('.', '.')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('requiring', 'VBG')\n",
      "('all', 'DT')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('different', 'JJ')\n",
      "('types', 'NNS')\n",
      "('of', 'IN')\n",
      "('knowledge', 'NN')\n",
      "('that', 'IN')\n",
      "('humans', 'VBZ')\n",
      "('possess', 'NN')\n",
      "('(', '(')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('facts', 'NNS')\n",
      "('about', 'IN')\n",
      "('the', 'DT')\n",
      "('real', 'JJ')\n",
      "('world', 'NN')\n",
      "(',', ',')\n",
      "('etc', 'FW')\n",
      "('.)', 'FW')\n",
      "('to', 'TO')\n",
      "('solve', 'VB')\n",
      "('properly', 'RB')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NLG/NNP)\n",
      "('):', 'NNP')\n",
      "('Convert', 'NNP')\n",
      "('information', 'NN')\n",
      "('from', 'IN')\n",
      "('computer', 'NN')\n",
      "('databases', 'NNS')\n",
      "('or', 'CC')\n",
      "('semantic', 'JJ')\n",
      "('intents', 'NNS')\n",
      "('into', 'IN')\n",
      "('readable', 'JJ')\n",
      "('human', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NLU/NNP)\n",
      "(')', ')')\n",
      "('Convert', 'NNP')\n",
      "('chunks', 'NNS')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('into', 'IN')\n",
      "('more', 'RBR')\n",
      "('formal', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('first', 'JJ')\n",
      "('-', ':')\n",
      "('order', 'NN')\n",
      "('logic', 'JJ')\n",
      "('structures', 'NNS')\n",
      "('that', 'WDT')\n",
      "('are', 'VBP')\n",
      "('easier', 'JJR')\n",
      "('for', 'IN')\n",
      "('computer', 'NN')\n",
      "('programs', 'NNS')\n",
      "('to', 'TO')\n",
      "('manipulate', 'VB')\n",
      "('.', '.')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'VBG')\n",
      "('involves', 'VBZ')\n",
      "('the', 'DT')\n",
      "('identification', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('intended', 'VBN')\n",
      "('semantic', 'NN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('multiple', 'JJ')\n",
      "('possible', 'JJ')\n",
      "('semantics', 'NNS')\n",
      "('which', 'WDT')\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('derived', 'VBN')\n",
      "('from', 'IN')\n",
      "('a', 'DT')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('expression', 'NN')\n",
      "('which', 'WDT')\n",
      "('usually', 'RB')\n",
      "('takes', 'VBZ')\n",
      "('the', 'DT')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('organized', 'JJ')\n",
      "('notations', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('concepts', 'NNS')\n",
      "('.', '.')\n",
      "('Introduction', 'NN')\n",
      "('and', 'CC')\n",
      "('creation', 'NN')\n",
      "('of', 'IN')\n",
      "('language', 'NN')\n",
      "('metamodel', 'NN')\n",
      "('and', 'CC')\n",
      "('ontology', 'NN')\n",
      "('are', 'VBP')\n",
      "('efficient', 'JJ')\n",
      "('however', 'RB')\n",
      "('empirical', 'JJ')\n",
      "('solutions', 'NNS')\n",
      "('.', '.')\n",
      "('An', 'DT')\n",
      "('explicit', 'JJ')\n",
      "('formalization', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('semantics', 'NNS')\n",
      "('without', 'IN')\n",
      "('confusions', 'NNS')\n",
      "('with', 'IN')\n",
      "('implicit', 'JJ')\n",
      "('assumptions', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('closed', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('assumption', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION CWA/NNP)\n",
      "(')', ')')\n",
      "('vs', 'NN')\n",
      "('.', '.')\n",
      "('open', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('assumption', 'NN')\n",
      "(',', ',')\n",
      "('or', 'CC')\n",
      "('subjective', 'JJ')\n",
      "('Yes', 'NNP')\n",
      "('/', 'NNP')\n",
      "('No', 'NNP')\n",
      "('vs', 'NN')\n",
      "('.', '.')\n",
      "('objective', 'JJ')\n",
      "(PERSON True/NNP)\n",
      "('/', 'NNP')\n",
      "('False', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('expected', 'VBN')\n",
      "('for', 'IN')\n",
      "('the', 'DT')\n",
      "('construction', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('basis', 'NN')\n",
      "('of', 'IN')\n",
      "('semantics', 'NNS')\n",
      "('formalization', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('35', 'CD')\n",
      "(']', 'JJ')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "('Given', 'VBN')\n",
      "('a', 'DT')\n",
      "('human', 'JJ')\n",
      "('-', ':')\n",
      "('language', 'NN')\n",
      "('question', 'NN')\n",
      "(',', ',')\n",
      "('determine', 'VB')\n",
      "('its', 'PRP$')\n",
      "('answer', 'NN')\n",
      "('.', '.')\n",
      "('Typical', 'JJ')\n",
      "('questions', 'NNS')\n",
      "('have', 'VBP')\n",
      "('a', 'DT')\n",
      "('specific', 'JJ')\n",
      "('right', 'NN')\n",
      "('answer', 'NN')\n",
      "('(', '(')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('\"', 'NN')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('capital', 'NN')\n",
      "('of', 'IN')\n",
      "(GPE Canada/NNP)\n",
      "('?\"),', 'NNP')\n",
      "('but', 'CC')\n",
      "('sometimes', 'RB')\n",
      "('open', 'JJ')\n",
      "('-', ':')\n",
      "('ended', 'VBN')\n",
      "('questions', 'NNS')\n",
      "('are', 'VBP')\n",
      "('also', 'RB')\n",
      "('considered', 'VBN')\n",
      "('(', '(')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('\"', 'NN')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('meaning', 'NN')\n",
      "('of', 'IN')\n",
      "('life', 'NN')\n",
      "('?\").', 'NNP')\n",
      "('General', 'NNP')\n",
      "('tendencies', 'NNS')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('possible', 'JJ')\n",
      "(')', ')')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNS')\n",
      "('Based', 'VBD')\n",
      "('on', 'IN')\n",
      "('long', 'JJ')\n",
      "('-', ':')\n",
      "('standing', 'VBG')\n",
      "('trends', 'NNS')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "(',', ',')\n",
      "('it', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('possible', 'JJ')\n",
      "('to', 'TO')\n",
      "('extrapolate', 'VB')\n",
      "('future', 'JJ')\n",
      "('directions', 'NNS')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('of', 'IN')\n",
      "('2020', 'CD')\n",
      "(',', ',')\n",
      "('three', 'CD')\n",
      "('trends', 'NNS')\n",
      "('among', 'IN')\n",
      "('the', 'DT')\n",
      "('topics', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('long', 'JJ')\n",
      "('-', ':')\n",
      "('standing', 'VBG')\n",
      "('series', 'NN')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION CoNLL/NNP Shared/NNP Tasks/NNP)\n",
      "('can', 'MD')\n",
      "('be', 'VB')\n",
      "('observed', 'VBN')\n",
      "(':', ':')\n",
      "('[', 'JJ')\n",
      "('36', 'CD')\n",
      "(']', 'JJ')\n",
      "(ORGANIZATION Interest/NN)\n",
      "('on', 'IN')\n",
      "('increasingly', 'RB')\n",
      "('abstract', 'JJ')\n",
      "(',', ',')\n",
      "('\"', 'JJ')\n",
      "('cognitive', 'JJ')\n",
      "('\"', 'NN')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "('-', ':')\n",
      "('2001', 'CD')\n",
      "(':', ':')\n",
      "('shallow', 'NN')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('2002', 'CD')\n",
      "('-', ':')\n",
      "('03', 'CD')\n",
      "(':', ':')\n",
      "('named', 'VBN')\n",
      "('entity', 'NN')\n",
      "('recognition', 'NN')\n",
      "(',', ',')\n",
      "('2006', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('/', 'NN')\n",
      "('2017', 'CD')\n",
      "('-', ':')\n",
      "('18', 'CD')\n",
      "(':', ':')\n",
      "('dependency', 'NN')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "('2004', 'CD')\n",
      "('-', ':')\n",
      "('05', 'CD')\n",
      "('/', 'NN')\n",
      "('2008', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('semantic', 'JJ')\n",
      "('role', 'NN')\n",
      "('labelling', 'NN')\n",
      "(',', ',')\n",
      "('2011', 'CD')\n",
      "('-', ':')\n",
      "('12', 'CD')\n",
      "('coreference', 'NN')\n",
      "(',', ',')\n",
      "('2015', 'CD')\n",
      "('-', ':')\n",
      "('16', 'CD')\n",
      "(':', ':')\n",
      "('discourse', 'NN')\n",
      "('parsing', 'NN')\n",
      "(',', ',')\n",
      "('2019', 'CD')\n",
      "(':', ':')\n",
      "('semantic', 'JJ')\n",
      "('parsing', 'NN')\n",
      "(').', 'NN')\n",
      "('Increasing', 'VBG')\n",
      "('interest', 'NN')\n",
      "('in', 'IN')\n",
      "('multilinguality', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(',', ',')\n",
      "('potentially', 'RB')\n",
      "(',', ',')\n",
      "('multimodality', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION English/JJ)\n",
      "('since', 'IN')\n",
      "('1999', 'CD')\n",
      "(';', ':')\n",
      "(GPE Spanish/JJ)\n",
      "(',', ',')\n",
      "(GPE Dutch/NNP)\n",
      "('since', 'IN')\n",
      "('2002', 'CD')\n",
      "(';', ':')\n",
      "(GPE German/JJ)\n",
      "('since', 'IN')\n",
      "('2003', 'CD')\n",
      "(';', ':')\n",
      "(GPE Bulgarian/NNP)\n",
      "(',', ',')\n",
      "(GPE Danish/NNP)\n",
      "(',', ',')\n",
      "(GPE Japanese/NNP)\n",
      "(',', ',')\n",
      "(GPE Portuguese/NNP)\n",
      "(',', ',')\n",
      "(GPE Slovenian/NNP)\n",
      "(',', ',')\n",
      "(GPE Swedish/NNP)\n",
      "(',', ',')\n",
      "(GPE Turkish/NNP)\n",
      "('since', 'IN')\n",
      "('2006', 'CD')\n",
      "(';', ':')\n",
      "(GPE Basque/NNP)\n",
      "(',', ',')\n",
      "(PERSON Catalan/NNP)\n",
      "(',', ',')\n",
      "(GPE Chinese/NNP)\n",
      "(',', ',')\n",
      "(GPE Greek/NNP)\n",
      "(',', ',')\n",
      "(GPE Hungarian/NNP)\n",
      "(',', ',')\n",
      "(GPE Italian/NNP)\n",
      "(',', ',')\n",
      "(GPE Turkish/NNP)\n",
      "('since', 'IN')\n",
      "('2007', 'CD')\n",
      "(';', ':')\n",
      "(GPE Czech/NNP)\n",
      "('since', 'IN')\n",
      "('2009', 'CD')\n",
      "(';', ':')\n",
      "(PERSON Arabic/NNP)\n",
      "('since', 'IN')\n",
      "('2012', 'CD')\n",
      "(';', ':')\n",
      "('2017', 'CD')\n",
      "(':', ':')\n",
      "('40', 'CD')\n",
      "('+', 'NN')\n",
      "('languages', 'NNS')\n",
      "(';', ':')\n",
      "('2018', 'CD')\n",
      "(':', ':')\n",
      "('60', 'CD')\n",
      "('+/', '$')\n",
      "('100', 'CD')\n",
      "('+', 'NNP')\n",
      "('languages', 'NNS')\n",
      "(')', ')')\n",
      "('Elimination', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "('representations', 'NNS')\n",
      "('(', '(')\n",
      "('rule', 'NN')\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "('over', 'IN')\n",
      "('supervised', 'JJ')\n",
      "('towards', 'NNS')\n",
      "('weakly', 'RB')\n",
      "('supervised', 'VBD')\n",
      "('methods', 'NNS')\n",
      "(',', ',')\n",
      "('representation', 'NN')\n",
      "('learning', 'NN')\n",
      "('and', 'CC')\n",
      "('end', 'VB')\n",
      "('-', ':')\n",
      "('to', 'TO')\n",
      "('-', ':')\n",
      "('end', 'VB')\n",
      "('systems', 'NNS')\n",
      "(')', ')')\n",
      "('Cognition', 'NNP')\n",
      "('and', 'CC')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'VBZ')\n",
      "('Most', 'JJS')\n",
      "('higher', 'JJR')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('applications', 'NNS')\n",
      "('involve', 'VBP')\n",
      "('aspects', 'NNS')\n",
      "('that', 'WDT')\n",
      "('emulate', 'VBP')\n",
      "('intelligent', 'JJ')\n",
      "('behaviour', 'NN')\n",
      "('and', 'CC')\n",
      "('apparent', 'JJ')\n",
      "('comprehension', 'NN')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('.', '.')\n",
      "('More', 'RBR')\n",
      "('broadly', 'RB')\n",
      "('speaking', 'VBG')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('technical', 'JJ')\n",
      "('operationalization', 'NN')\n",
      "('of', 'IN')\n",
      "('increasingly', 'RB')\n",
      "('advanced', 'JJ')\n",
      "('aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('behaviour', 'NN')\n",
      "('represents', 'VBZ')\n",
      "('one', 'CD')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('developmental', 'JJ')\n",
      "('trajectories', 'NNS')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('see', 'VB')\n",
      "('trends', 'NNS')\n",
      "('among', 'IN')\n",
      "(ORGANIZATION CoNLL/NNP)\n",
      "('shared', 'VBD')\n",
      "('tasks', 'NNS')\n",
      "('above', 'IN')\n",
      "(').', 'NNP')\n",
      "('Cognition', 'NNP')\n",
      "('refers', 'NNS')\n",
      "('to', 'TO')\n",
      "('\"', 'VB')\n",
      "('the', 'DT')\n",
      "('mental', 'JJ')\n",
      "('action', 'NN')\n",
      "('or', 'CC')\n",
      "('process', 'NN')\n",
      "('of', 'IN')\n",
      "('acquiring', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('understanding', 'VBG')\n",
      "('through', 'IN')\n",
      "('thought', 'NN')\n",
      "(',', ',')\n",
      "('experience', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('the', 'DT')\n",
      "('senses', 'NNS')\n",
      "('.\"', 'VBP')\n",
      "('[', '$')\n",
      "('37', 'CD')\n",
      "(']', 'NNP')\n",
      "('Cognitive', 'NNP')\n",
      "('science', 'NN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "(',', ',')\n",
      "('scientific', 'JJ')\n",
      "('study', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('mind', 'NN')\n",
      "('and', 'CC')\n",
      "('its', 'PRP$')\n",
      "('processes', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('38', 'CD')\n",
      "(']', 'NNP')\n",
      "('Cognitive', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "('branch', 'NN')\n",
      "('of', 'IN')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('combining', 'VBG')\n",
      "('knowledge', 'NN')\n",
      "('and', 'CC')\n",
      "('research', 'NN')\n",
      "('from', 'IN')\n",
      "('both', 'DT')\n",
      "('psychology', 'NN')\n",
      "('and', 'CC')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('[', '$')\n",
      "('39', 'CD')\n",
      "(']', 'NNP')\n",
      "('Especially', 'NNP')\n",
      "('during', 'IN')\n",
      "('the', 'DT')\n",
      "('age', 'NN')\n",
      "('of', 'IN')\n",
      "('symbolic', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('area', 'NN')\n",
      "('of', 'IN')\n",
      "('computational', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('maintained', 'VBD')\n",
      "('strong', 'JJ')\n",
      "('ties', 'NNS')\n",
      "('with', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('studies', 'NNS')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('an', 'DT')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "(PERSON George/NNP Lakoff/NNP)\n",
      "('offers', 'VBZ')\n",
      "('a', 'DT')\n",
      "('methodology', 'NN')\n",
      "('to', 'TO')\n",
      "('build', 'VB')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "(')', ')')\n",
      "('algorithms', 'VBP')\n",
      "('through', 'IN')\n",
      "('the', 'DT')\n",
      "('perspective', 'NN')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('along', 'IN')\n",
      "('with', 'IN')\n",
      "('the', 'DT')\n",
      "('findings', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "(',', ',')\n",
      "('[', 'VBP')\n",
      "('40', 'CD')\n",
      "(']', 'NNS')\n",
      "('with', 'IN')\n",
      "('two', 'CD')\n",
      "('defining', 'VBG')\n",
      "('aspects', 'NNS')\n",
      "(':', ':')\n",
      "('Apply', 'VB')\n",
      "('the', 'DT')\n",
      "('theory', 'NN')\n",
      "('of', 'IN')\n",
      "('conceptual', 'JJ')\n",
      "('metaphor', 'NN')\n",
      "(',', ',')\n",
      "('explained', 'VBN')\n",
      "('by', 'IN')\n",
      "(PERSON Lakoff/NNP)\n",
      "('as', 'IN')\n",
      "('“', 'NNP')\n",
      "('the', 'DT')\n",
      "('understanding', 'NN')\n",
      "('of', 'IN')\n",
      "('one', 'CD')\n",
      "('idea', 'NN')\n",
      "(',', ',')\n",
      "('in', 'IN')\n",
      "('terms', 'NNS')\n",
      "('of', 'IN')\n",
      "('another', 'DT')\n",
      "('”', 'NN')\n",
      "('which', 'WDT')\n",
      "('provides', 'VBZ')\n",
      "('an', 'DT')\n",
      "('idea', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('intent', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "('.', '.')\n",
      "('[', 'CC')\n",
      "('41', 'CD')\n",
      "(']', 'NN')\n",
      "('For', 'IN')\n",
      "('example', 'NN')\n",
      "(',', ',')\n",
      "('consider', 'VB')\n",
      "('the', 'DT')\n",
      "(GPE English/NNP)\n",
      "('word', 'NN')\n",
      "('“', 'NNP')\n",
      "('big', 'JJ')\n",
      "('”', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('comparison', 'NN')\n",
      "('(', '(')\n",
      "('“', 'JJ')\n",
      "('That', 'DT')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('tree', 'NN')\n",
      "('”', 'NN')\n",
      "('),', 'VBD')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "(\"'\", 'POS')\n",
      "('s', 'JJ')\n",
      "('intent', 'NN')\n",
      "('is', 'VBZ')\n",
      "('to', 'TO')\n",
      "('imply', 'VB')\n",
      "('that', 'IN')\n",
      "('the', 'DT')\n",
      "('tree', 'NN')\n",
      "('is', 'VBZ')\n",
      "('”', 'VBN')\n",
      "('physically', 'RB')\n",
      "('large', 'JJ')\n",
      "('”', 'NNP')\n",
      "('relative', 'NN')\n",
      "('to', 'TO')\n",
      "('other', 'JJ')\n",
      "('trees', 'NNS')\n",
      "('or', 'CC')\n",
      "('the', 'DT')\n",
      "('authors', 'NNS')\n",
      "('experience', 'NN')\n",
      "('.', '.')\n",
      "('When', 'WRB')\n",
      "('used', 'VBN')\n",
      "('metaphorically', 'RB')\n",
      "('(', '(')\n",
      "('”', 'JJ')\n",
      "(ORGANIZATION Tomorrow/NNP)\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('day', 'NN')\n",
      "('”', 'NNP')\n",
      "('),', 'VBZ')\n",
      "('the', 'DT')\n",
      "('author', 'NN')\n",
      "('’', 'NNP')\n",
      "('s', 'VBZ')\n",
      "('intent', 'NN')\n",
      "('to', 'TO')\n",
      "('imply', 'VB')\n",
      "('”', 'JJ')\n",
      "('importance', 'NN')\n",
      "('”', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('intent', 'NN')\n",
      "('behind', 'IN')\n",
      "('other', 'JJ')\n",
      "('usages', 'NNS')\n",
      "(',', ',')\n",
      "('like', 'IN')\n",
      "('in', 'IN')\n",
      "('”', 'NNP')\n",
      "('She', 'PRP')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('big', 'JJ')\n",
      "('person', 'NN')\n",
      "('”', 'NNP')\n",
      "('will', 'MD')\n",
      "('remain', 'VB')\n",
      "('somewhat', 'RB')\n",
      "('ambiguous', 'JJ')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('person', 'NN')\n",
      "('and', 'CC')\n",
      "('a', 'DT')\n",
      "('cognitive', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('algorithm', 'NN')\n",
      "('alike', 'RB')\n",
      "('without', 'IN')\n",
      "('additional', 'JJ')\n",
      "('information', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Assign/NNP)\n",
      "('relative', 'JJ')\n",
      "('measures', 'NNS')\n",
      "('of', 'IN')\n",
      "('meaning', 'VBG')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('word', 'NN')\n",
      "(',', ',')\n",
      "('phrase', 'NN')\n",
      "(',', ',')\n",
      "('sentence', 'NN')\n",
      "('or', 'CC')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "('information', 'NN')\n",
      "('presented', 'VBN')\n",
      "('before', 'IN')\n",
      "('and', 'CC')\n",
      "('after', 'IN')\n",
      "('the', 'DT')\n",
      "('piece', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "('being', 'VBG')\n",
      "('analyzed', 'VBN')\n",
      "(',', ',')\n",
      "('e', 'FW')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('by', 'IN')\n",
      "('means', 'NNS')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('probabilistic', 'JJ')\n",
      "('context', 'NN')\n",
      "('-', ':')\n",
      "('free', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION PCFG/NNP)\n",
      "(').', 'VBZ')\n",
      "('The', 'DT')\n",
      "('mathematical', 'JJ')\n",
      "('equation', 'NN')\n",
      "('for', 'IN')\n",
      "('such', 'JJ')\n",
      "('algorithms', 'NN')\n",
      "('is', 'VBZ')\n",
      "('presented', 'VBN')\n",
      "('in', 'IN')\n",
      "(GSP US/NNP)\n",
      "('patent', 'NN')\n",
      "('9269353', 'CD')\n",
      "(':', ':')\n",
      "('R', 'NNP')\n",
      "('M', 'NNP')\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'FW')\n",
      "('N', 'NNP')\n",
      "(')', ')')\n",
      "('=', 'VBP')\n",
      "(PERSON P/NNP M/NNP)\n",
      "('M', 'NNP')\n",
      "('(', '(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'FW')\n",
      "('N', 'NNP')\n",
      "(')', ')')\n",
      "('×', 'VBD')\n",
      "('1', 'CD')\n",
      "('2', 'CD')\n",
      "('d', 'NN')\n",
      "('(', '(')\n",
      "('∑', 'JJ')\n",
      "('i', 'NN')\n",
      "('=', 'VBP')\n",
      "('−', 'NNP')\n",
      "('d', 'NN')\n",
      "('d', 'NN')\n",
      "('(', '(')\n",
      "('(', '(')\n",
      "(PERSON P/NNP M/NNP)\n",
      "('M', 'NNP')\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "('−', 'NNP')\n",
      "('1', 'CD')\n",
      "(')', ')')\n",
      "('×', 'NN')\n",
      "(PERSON P/NNP F/NNP)\n",
      "('(', '(')\n",
      "('t', 'JJ')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "(',', ',')\n",
      "('t', 'NN')\n",
      "('o', 'NN')\n",
      "('k', 'NN')\n",
      "('e', 'FW')\n",
      "('n', 'JJ')\n",
      "('N', 'NNP')\n",
      "('−', 'NNP')\n",
      "('1', 'CD')\n",
      "(')', ')')\n",
      "(')', ')')\n",
      "('i', 'NN')\n",
      "(')', ')')\n",
      "('{\\\\', 'NN')\n",
      "('displaystyle', 'JJ')\n",
      "('{', '(')\n",
      "(ORGANIZATION RMM/NNP)\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('})}={', 'NNP')\n",
      "('PMM', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('})}\\\\', 'NNP')\n",
      "('times', 'NNS')\n",
      "('{\\\\', 'NNP')\n",
      "('frac', 'VBD')\n",
      "('{', '(')\n",
      "('1', 'CD')\n",
      "('}{', '$')\n",
      "('2d', 'CD')\n",
      "('}}\\\\', 'NN')\n",
      "('left', 'VBD')\n",
      "('(\\\\', 'NNP')\n",
      "('sum', 'NN')\n",
      "('_', 'NNP')\n",
      "('{', '(')\n",
      "('i', 'JJ')\n",
      "('=-', 'JJ')\n",
      "('d', 'NN')\n",
      "('}^{', 'NNP')\n",
      "('d', 'NN')\n",
      "('}{((', 'NNP')\n",
      "('PMM', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('-', ':')\n",
      "('1', 'CD')\n",
      "('})}\\\\', 'NNP')\n",
      "('times', 'NNS')\n",
      "('{', '(')\n",
      "('PF', 'NNP')\n",
      "('(', '(')\n",
      "('token_', 'JJ')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('},', 'NNP')\n",
      "('token_', 'NN')\n",
      "('{', '(')\n",
      "('N', 'NNP')\n",
      "('-', ':')\n",
      "('1', 'CD')\n",
      "('}))', 'JJ')\n",
      "('_', 'NNP')\n",
      "('{', '(')\n",
      "('i', 'JJ')\n",
      "('}}\\\\', 'VBP')\n",
      "('right', 'JJ')\n",
      "(')}', 'NN')\n",
      "('Where', 'NNP')\n",
      "(',', ',')\n",
      "(ORGANIZATION RMM/NNP)\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('Relative', 'JJ')\n",
      "('Measure', 'NN')\n",
      "('of', 'IN')\n",
      "(GPE Meaning/NNP)\n",
      "('token', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('any', 'DT')\n",
      "('block', 'NN')\n",
      "('of', 'IN')\n",
      "('text', 'NN')\n",
      "(',', ',')\n",
      "('sentence', 'NN')\n",
      "(',', ',')\n",
      "('phrase', 'NN')\n",
      "('or', 'CC')\n",
      "('word', 'NN')\n",
      "('N', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('number', 'NN')\n",
      "('of', 'IN')\n",
      "('tokens', 'NNS')\n",
      "('being', 'VBG')\n",
      "('analyzed', 'VBN')\n",
      "(ORGANIZATION PMM/NNP)\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Probable/JJ Measure/NN)\n",
      "('of', 'IN')\n",
      "('Meaning', 'NNP')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('a', 'DT')\n",
      "('corpora', 'NN')\n",
      "('d', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('location', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('token', 'NN')\n",
      "('along', 'IN')\n",
      "('the', 'DT')\n",
      "('sequence', 'NN')\n",
      "('of', 'IN')\n",
      "(GPE N/NNP)\n",
      "('-', ':')\n",
      "('1', 'CD')\n",
      "('tokens', 'NNS')\n",
      "('PF', 'NNP')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Probability/NNP Function/NNP)\n",
      "('specific', 'NN')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('language', 'NN')\n",
      "('Ties', 'VBZ')\n",
      "('with', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('linguistics', 'NNS')\n",
      "('are', 'VBP')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('historical', 'JJ')\n",
      "('heritage', 'NN')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "(',', ',')\n",
      "('but', 'CC')\n",
      "('they', 'PRP')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('less', 'RBR')\n",
      "('frequently', 'RB')\n",
      "('addressed', 'VBN')\n",
      "('since', 'IN')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('turn', 'NN')\n",
      "('during', 'IN')\n",
      "('the', 'DT')\n",
      "('1990s', 'CD')\n",
      "('.', '.')\n",
      "('Nevertheless', 'RB')\n",
      "(',', ',')\n",
      "('approaches', 'NNS')\n",
      "('to', 'TO')\n",
      "('develop', 'VB')\n",
      "('cognitive', 'JJ')\n",
      "('models', 'NNS')\n",
      "('towards', 'NNS')\n",
      "('technically', 'RB')\n",
      "('operationalizable', 'JJ')\n",
      "('frameworks', 'NNS')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('pursued', 'VBN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('context', 'NN')\n",
      "('of', 'IN')\n",
      "('various', 'JJ')\n",
      "('frameworks', 'NNS')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'JJ')\n",
      "('.,', 'NN')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('42', 'CD')\n",
      "(']', 'JJ')\n",
      "('functional', 'JJ')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('43', 'CD')\n",
      "(']', 'JJ')\n",
      "('construction', 'NN')\n",
      "('grammar', 'NN')\n",
      "(',', ',')\n",
      "('[', 'VBZ')\n",
      "('44', 'CD')\n",
      "(']', 'JJ')\n",
      "('computational', 'JJ')\n",
      "('psycholinguistics', 'NNS')\n",
      "('and', 'CC')\n",
      "('cognitive', 'JJ')\n",
      "('neuroscience', 'NN')\n",
      "('(', '(')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NNP')\n",
      "('ACT', 'NNP')\n",
      "('-', ':')\n",
      "('R', 'NN')\n",
      "('),', 'NN')\n",
      "('however', 'RB')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('limited', 'JJ')\n",
      "('uptake', 'NN')\n",
      "('in', 'IN')\n",
      "('mainstream', 'JJ')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('as', 'IN')\n",
      "('measured', 'VBN')\n",
      "('by', 'IN')\n",
      "('presence', 'NN')\n",
      "('on', 'IN')\n",
      "('major', 'JJ')\n",
      "('conferences', 'NNS')\n",
      "('[', 'VBP')\n",
      "('45', 'CD')\n",
      "(']', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION ACL/NNP)\n",
      "(').', 'NNP')\n",
      "('More', 'RBR')\n",
      "('recently', 'RB')\n",
      "(',', ',')\n",
      "('ideas', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('revived', 'VBN')\n",
      "('as', 'IN')\n",
      "('an', 'DT')\n",
      "('approach', 'NN')\n",
      "('to', 'TO')\n",
      "('achieve', 'VB')\n",
      "('explainability', 'NN')\n",
      "(',', ',')\n",
      "('e', 'NN')\n",
      "('.', '.')\n",
      "('g', 'NN')\n",
      "('.,', 'NN')\n",
      "('under', 'IN')\n",
      "('the', 'DT')\n",
      "('notion', 'NN')\n",
      "('of', 'IN')\n",
      "('\"', 'NNP')\n",
      "('cognitive', 'JJ')\n",
      "('AI', 'NNP')\n",
      "('\".', 'NNP')\n",
      "('[', 'VBD')\n",
      "('46', 'CD')\n",
      "(']', 'NNP')\n",
      "('Likewise', 'NNP')\n",
      "(',', ',')\n",
      "('ideas', 'NNS')\n",
      "('of', 'IN')\n",
      "('cognitive', 'JJ')\n",
      "('NLP', 'NNP')\n",
      "('are', 'VBP')\n",
      "('inherent', 'JJ')\n",
      "('to', 'TO')\n",
      "('neural', 'JJ')\n",
      "('models', 'NNS')\n",
      "('multimodal', 'VBP')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('(', '(')\n",
      "('although', 'IN')\n",
      "('rarely', 'RB')\n",
      "('made', 'VBN')\n",
      "('explicit', 'NN')\n",
      "(').', 'NNP')\n",
      "('[', 'VBZ')\n",
      "('47', 'CD')\n",
      "(']', 'NN')\n",
      "(PERSON See/NNP)\n",
      "('also', 'RB')\n",
      "('[', 'VBP')\n",
      "('edit', 'NN')\n",
      "(']', '$')\n",
      "('1', 'CD')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Road/NNP)\n",
      "('Automated', 'NNP')\n",
      "('essay', 'VBP')\n",
      "('scoring', 'VBG')\n",
      "(ORGANIZATION Biomedical/NNP)\n",
      "('text', 'NN')\n",
      "('mining', 'NN')\n",
      "(ORGANIZATION Compound/NNP)\n",
      "('term', 'NN')\n",
      "('processing', 'VBG')\n",
      "(ORGANIZATION Computational/NNP)\n",
      "('linguistics', 'NNS')\n",
      "(ORGANIZATION Computer/NNP)\n",
      "('-', ':')\n",
      "('assisted', 'VBD')\n",
      "('reviewing', 'VBG')\n",
      "(ORGANIZATION Controlled/NNP)\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('learning', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('linguistic', 'JJ')\n",
      "('processing', 'NN')\n",
      "('Distributional', 'NNP')\n",
      "('semantics', 'NNS')\n",
      "('Foreign', 'NNP')\n",
      "('language', 'NN')\n",
      "('reading', 'VBG')\n",
      "('aid', 'CC')\n",
      "('Foreign', 'NNP')\n",
      "('language', 'NN')\n",
      "('writing', 'VBG')\n",
      "('aid', 'NN')\n",
      "('Information', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Information', 'NNP')\n",
      "('retrieval', 'NN')\n",
      "(PERSON Language/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Communication/NNP Technologies/NNP Language/NNP)\n",
      "('technology', 'NN')\n",
      "('Latent', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('indexing', 'VBG')\n",
      "(ORGANIZATION Native/JJ)\n",
      "('-', ':')\n",
      "('language', 'NN')\n",
      "('identification', 'NN')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('programming', 'VBG')\n",
      "(ORGANIZATION Natural/NNP)\n",
      "('language', 'NN')\n",
      "('search', 'NN')\n",
      "('Outline', 'NNP')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('Query', 'NNP')\n",
      "('expansion', 'NN')\n",
      "('Query', 'NNP')\n",
      "('understanding', 'NN')\n",
      "('Reification', 'NNP')\n",
      "('(', '(')\n",
      "('linguistics', 'NNS')\n",
      "(')', ')')\n",
      "('Speech', 'NNP')\n",
      "('processing', 'VBG')\n",
      "(PERSON Spoken/NNP)\n",
      "('dialogue', 'NN')\n",
      "('systems', 'NNS')\n",
      "(GPE Text/NNP)\n",
      "('-', ':')\n",
      "('proofing', 'VBG')\n",
      "(GPE Text/NNP)\n",
      "('simplification', 'NN')\n",
      "('Transformer', 'NNP')\n",
      "('(', '(')\n",
      "('machine', 'NN')\n",
      "('learning', 'VBG')\n",
      "('model', 'NN')\n",
      "(')', ')')\n",
      "('Truecasing', 'VBG')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "(ORGANIZATION Word2vec/NNP References/NNP)\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('^', 'NNP')\n",
      "(PERSON Kongthon/NNP)\n",
      "(',', ',')\n",
      "(GPE Alisa/NNP)\n",
      "(';', ':')\n",
      "(GPE Sangkeettrakarn/NNP)\n",
      "(',', ',')\n",
      "(GPE Chatchawal/NNP)\n",
      "(';', ':')\n",
      "(PERSON Kongyoung/NNP)\n",
      "(',', ',')\n",
      "(GPE Sarawoot/NNP)\n",
      "(';', ':')\n",
      "(PERSON Haruechaiyasak/NNP)\n",
      "(',', ',')\n",
      "(GPE Choochart/NNP)\n",
      "('(', '(')\n",
      "('October', 'NNP')\n",
      "('27', 'CD')\n",
      "('–', 'VBD')\n",
      "('30', 'CD')\n",
      "(',', ',')\n",
      "('2009', 'CD')\n",
      "(').', 'NN')\n",
      "('Implementing', 'VBG')\n",
      "('an', 'DT')\n",
      "('online', 'NN')\n",
      "('help', 'NN')\n",
      "('desk', 'NN')\n",
      "('system', 'NN')\n",
      "('based', 'VBN')\n",
      "('on', 'IN')\n",
      "('conversational', 'JJ')\n",
      "('agent', 'NN')\n",
      "('.', '.')\n",
      "(ORGANIZATION MEDES/NNP)\n",
      "(\"'\", 'POS')\n",
      "('09', 'CD')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "(ORGANIZATION International/NNP Conference/NNP)\n",
      "('on', 'IN')\n",
      "('Management', 'NNP')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Emergent/NNP Digital/NNP)\n",
      "('EcoSystems', 'NNP')\n",
      "('.', '.')\n",
      "(GPE France/NNP)\n",
      "(':', ':')\n",
      "('ACM', 'NNP')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1145', 'CD')\n",
      "('/', 'JJ')\n",
      "('1643823', 'CD')\n",
      "('.', '.')\n",
      "('1643908', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Hutchins/NNP)\n",
      "(',', ',')\n",
      "('J', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2005', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'VBD')\n",
      "('The', 'DT')\n",
      "('history', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('translation', 'NN')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('nutshell', 'NN')\n",
      "('\"', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('[', 'VB')\n",
      "('self', 'PRP')\n",
      "('-', ':')\n",
      "('published', 'VBN')\n",
      "('source', 'NN')\n",
      "(']', 'NN')\n",
      "('^', 'NNP')\n",
      "('Koskenniemi', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Kimmo/NNP)\n",
      "('(', '(')\n",
      "('1983', 'CD')\n",
      "('),', 'NN')\n",
      "('Two', 'CD')\n",
      "('-', ':')\n",
      "('level', 'NN')\n",
      "('morphology', 'NN')\n",
      "(':', ':')\n",
      "('A', 'DT')\n",
      "('general', 'JJ')\n",
      "('computational', 'JJ')\n",
      "('model', 'NN')\n",
      "('of', 'IN')\n",
      "('word', 'NN')\n",
      "('-', ':')\n",
      "('form', 'NN')\n",
      "('recognition', 'NN')\n",
      "('and', 'CC')\n",
      "('production', 'NN')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "(ORGANIZATION Department/NNP)\n",
      "('of', 'IN')\n",
      "(ORGANIZATION General/NNP Linguistics/NNP)\n",
      "(',', ',')\n",
      "(ORGANIZATION University/NNP)\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Helsinki/NNP)\n",
      "('^', 'NNP')\n",
      "('Joshi', 'NNP')\n",
      "(',', ',')\n",
      "('A', 'NNP')\n",
      "('.', '.')\n",
      "('K', 'NNP')\n",
      "('.,', 'NNP')\n",
      "('&', 'CC')\n",
      "(PERSON Weinstein/NNP)\n",
      "(',', ',')\n",
      "('S', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('1981', 'CD')\n",
      "(',', ',')\n",
      "(PERSON August/NNP)\n",
      "(').', 'NNP')\n",
      "('Control', 'NNP')\n",
      "('of', 'IN')\n",
      "(GPE Inference/NNP)\n",
      "(':', ':')\n",
      "('Role', 'NNP')\n",
      "('of', 'IN')\n",
      "('Some', 'DT')\n",
      "('Aspects', 'NNS')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Discourse/NNP Structure/NNP)\n",
      "('-', ':')\n",
      "('Centering', 'NN')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "(GPE IJCAI/NNP)\n",
      "('(', '(')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('385', 'CD')\n",
      "('-', ':')\n",
      "('387', 'CD')\n",
      "(').', 'JJ')\n",
      "('^', 'NNP')\n",
      "('Guida', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON G/NNP)\n",
      "('.;', 'NNP')\n",
      "('Mauri', 'NNP')\n",
      "(',', ',')\n",
      "('G', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('July', 'NNP')\n",
      "('1986', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Evaluation', 'NNP')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "('systems', 'NNS')\n",
      "(':', ':')\n",
      "(PERSON Issues/NNP)\n",
      "('and', 'CC')\n",
      "('approaches', 'NNS')\n",
      "('\".', 'VBP')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION IEEE/NNP)\n",
      "('.', '.')\n",
      "('74', 'CD')\n",
      "('(', '(')\n",
      "('7', 'CD')\n",
      "('):', 'NN')\n",
      "('1026', 'CD')\n",
      "('–', 'NN')\n",
      "('1035', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1109', 'CD')\n",
      "('/', 'JJ')\n",
      "('PROC', 'NNP')\n",
      "('.', '.')\n",
      "('1986', 'CD')\n",
      "('.', '.')\n",
      "('13580', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NN')\n",
      "('1558', 'CD')\n",
      "('-', ':')\n",
      "('2256', 'CD')\n",
      "('.', '.')\n",
      "('S2CID', 'CC')\n",
      "('30688575', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "(ORGANIZATION Chomskyan/JJ)\n",
      "('linguistics', 'NNS')\n",
      "('encourages', 'VBZ')\n",
      "('the', 'DT')\n",
      "('investigation', 'NN')\n",
      "('of', 'IN')\n",
      "('\"', 'NNP')\n",
      "('corner', 'NN')\n",
      "('cases', 'NNS')\n",
      "('\"', 'VBP')\n",
      "('that', 'IN')\n",
      "('stress', 'NN')\n",
      "('the', 'DT')\n",
      "('limits', 'NNS')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('theoretical', 'JJ')\n",
      "('models', 'NNS')\n",
      "('(', '(')\n",
      "('comparable', 'JJ')\n",
      "('to', 'TO')\n",
      "('pathological', 'JJ')\n",
      "('phenomena', 'NN')\n",
      "('in', 'IN')\n",
      "('mathematics', 'NNS')\n",
      "('),', 'NNP')\n",
      "('typically', 'RB')\n",
      "('created', 'VBD')\n",
      "('using', 'VBG')\n",
      "('thought', 'JJ')\n",
      "('experiments', 'NNS')\n",
      "(',', ',')\n",
      "('rather', 'RB')\n",
      "('than', 'IN')\n",
      "('the', 'DT')\n",
      "('systematic', 'JJ')\n",
      "('investigation', 'NN')\n",
      "('of', 'IN')\n",
      "('typical', 'JJ')\n",
      "('phenomena', 'NNS')\n",
      "('that', 'WDT')\n",
      "('occur', 'VBP')\n",
      "('in', 'IN')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('data', 'NNS')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('is', 'VBZ')\n",
      "('the', 'DT')\n",
      "('case', 'NN')\n",
      "('in', 'IN')\n",
      "('corpus', 'NN')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('creation', 'NN')\n",
      "('and', 'CC')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('corpora', 'NNS')\n",
      "('of', 'IN')\n",
      "('real', 'JJ')\n",
      "('-', ':')\n",
      "('world', 'NN')\n",
      "('data', 'NN')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('fundamental', 'JJ')\n",
      "('part', 'NN')\n",
      "('of', 'IN')\n",
      "('machine', 'NN')\n",
      "('-', ':')\n",
      "('learning', 'NN')\n",
      "('algorithms', 'NN')\n",
      "('for', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('In', 'IN')\n",
      "('addition', 'NN')\n",
      "(',', ',')\n",
      "('theoretical', 'JJ')\n",
      "('underpinnings', 'NNS')\n",
      "('of', 'IN')\n",
      "(GPE Chomskyan/NNP)\n",
      "('linguistics', 'NNS')\n",
      "('such', 'JJ')\n",
      "('as', 'IN')\n",
      "('the', 'DT')\n",
      "('so', 'RB')\n",
      "('-', ':')\n",
      "('called', 'VBN')\n",
      "('\"', 'NNP')\n",
      "('poverty', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('stimulus', 'NN')\n",
      "('\"', 'NNP')\n",
      "('argument', 'NN')\n",
      "('entail', 'NN')\n",
      "('that', 'IN')\n",
      "('general', 'JJ')\n",
      "('learning', 'VBG')\n",
      "('algorithms', 'NN')\n",
      "(',', ',')\n",
      "('as', 'IN')\n",
      "('are', 'VBP')\n",
      "('typically', 'RB')\n",
      "('used', 'VBN')\n",
      "('in', 'IN')\n",
      "('machine', 'NN')\n",
      "('learning', 'NN')\n",
      "(',', ',')\n",
      "('cannot', 'NN')\n",
      "('be', 'VB')\n",
      "('successful', 'JJ')\n",
      "('in', 'IN')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('As', 'IN')\n",
      "('a', 'DT')\n",
      "('result', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Chomskyan/NNP)\n",
      "('paradigm', 'NN')\n",
      "('discouraged', 'VBD')\n",
      "('the', 'DT')\n",
      "('application', 'NN')\n",
      "('of', 'IN')\n",
      "('such', 'JJ')\n",
      "('models', 'NNS')\n",
      "('to', 'TO')\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "(ORGANIZATION Goldberg/NNP)\n",
      "(',', ',')\n",
      "(GPE Yoav/NNP)\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'VBD')\n",
      "('A', 'DT')\n",
      "('Primer', 'NNP')\n",
      "('on', 'IN')\n",
      "(ORGANIZATION Neural/NNP Network/NNP Models/NNP)\n",
      "('for', 'IN')\n",
      "(ORGANIZATION Natural/NNP Language/NNP)\n",
      "('Processing', 'NNP')\n",
      "('\".', 'NNP')\n",
      "('Journal', 'NNP')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Artificial/NNP Intelligence/NNP Research/NNP)\n",
      "('.', '.')\n",
      "('57', 'CD')\n",
      "(':', ':')\n",
      "('345', 'CD')\n",
      "('–', '$')\n",
      "('420', 'CD')\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1807', 'CD')\n",
      "('.', '.')\n",
      "('10854', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1613', 'CD')\n",
      "('/', 'JJ')\n",
      "('jair', 'NN')\n",
      "('.', '.')\n",
      "('4992', 'CD')\n",
      "('.', '.')\n",
      "('S2CID', 'CC')\n",
      "('8273530', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Goodfellow/NNP)\n",
      "(',', ',')\n",
      "(GPE Ian/NNP)\n",
      "(';', ':')\n",
      "(GPE Bengio/NNP)\n",
      "(',', ',')\n",
      "(GPE Yoshua/NNP)\n",
      "(';', ':')\n",
      "(GPE Courville/NNP)\n",
      "(',', ',')\n",
      "(GPE Aaron/NNP)\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(').', 'NNP')\n",
      "('Deep', 'NNP')\n",
      "('Learning', 'NNP')\n",
      "('.', '.')\n",
      "(ORGANIZATION MIT/NNP)\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('^', 'NNP')\n",
      "('Jozefowicz', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Rafal/NNP)\n",
      "(';', ':')\n",
      "('Vinyals', 'NNS')\n",
      "(',', ',')\n",
      "(GPE Oriol/NNP)\n",
      "(';', ':')\n",
      "(PERSON Schuster/NNP)\n",
      "(',', ',')\n",
      "(PERSON Mike/NNP)\n",
      "(';', ':')\n",
      "(PERSON Shazeer/NNP)\n",
      "(',', ',')\n",
      "(GPE Noam/NNP)\n",
      "(';', ':')\n",
      "('Wu', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Yonghui/NNP)\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(').', 'NN')\n",
      "('Exploring', 'VBG')\n",
      "('the', 'DT')\n",
      "('Limits', 'NNS')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Language/NNP Modeling/NNP)\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1602', 'CD')\n",
      "('.', '.')\n",
      "('02410', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Bibcode/NN)\n",
      "(':', ':')\n",
      "('2016arXiv160202410J', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Choe/NNP)\n",
      "(',', ',')\n",
      "(PERSON Do/NNP Kook/NNP)\n",
      "(';', ':')\n",
      "(PERSON Charniak/NNP)\n",
      "(',', ',')\n",
      "(GPE Eugene/NNP)\n",
      "('.', '.')\n",
      "('\"', 'NN')\n",
      "('Parsing', 'VBG')\n",
      "('as', 'IN')\n",
      "(PERSON Language/NNP)\n",
      "('Modeling', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('Emnlp', 'NNP')\n",
      "('2016', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Vinyals', 'NNS')\n",
      "(',', ',')\n",
      "(GPE Oriol/NNP)\n",
      "(';', ':')\n",
      "('et', 'CC')\n",
      "('al', 'NN')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2014', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Grammar', 'NNP')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "(ORGANIZATION Foreign/NNP)\n",
      "('Language', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "(PERSON Nips2015/NNP)\n",
      "('.', '.')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1412', 'CD')\n",
      "('.', '.')\n",
      "('7449', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Bibcode/NN)\n",
      "(':', ':')\n",
      "('2014arXiv1412', 'CD')\n",
      "('.', '.')\n",
      "('7449V', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Turchin/NNP)\n",
      "(',', ',')\n",
      "(PERSON Alexander/NNP)\n",
      "(';', ':')\n",
      "(PERSON Florez/NNP Builes/NNP)\n",
      "(',', ',')\n",
      "(PERSON Luisa/NNP F/NNP)\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('03', 'CD')\n",
      "('-', ':')\n",
      "('19', 'CD')\n",
      "(').', 'NN')\n",
      "('\"', 'NN')\n",
      "('Using', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('to', 'TO')\n",
      "(PERSON Measure/NNP)\n",
      "('and', 'CC')\n",
      "(PERSON Improve/NNP Quality/NNP)\n",
      "('of', 'IN')\n",
      "(PERSON Diabetes/NNP Care/NNP)\n",
      "(':', ':')\n",
      "('A', 'NNP')\n",
      "(ORGANIZATION Systematic/NNP)\n",
      "('Review', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('Journal', 'NNP')\n",
      "('of', 'IN')\n",
      "(PERSON Diabetes/NNP Science/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Technology/NNP)\n",
      "('.', '.')\n",
      "('15', 'CD')\n",
      "('(', '(')\n",
      "('3', 'CD')\n",
      "('):', 'RB')\n",
      "('553', 'CD')\n",
      "('–', 'JJ')\n",
      "('560', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1177', 'CD')\n",
      "('/', 'JJ')\n",
      "('19322968211000831', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NN')\n",
      "('1932', 'CD')\n",
      "('-', ':')\n",
      "('2968', 'CD')\n",
      "('.', '.')\n",
      "('PMC', 'VB')\n",
      "('8120048', 'CD')\n",
      "('.', '.')\n",
      "('PMID', 'VB')\n",
      "('33736486', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Winograd', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Terry/NNP)\n",
      "('(', '(')\n",
      "('1971', 'CD')\n",
      "(').', 'NN')\n",
      "('Procedures', 'NNP')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('Representation', 'NN')\n",
      "('for', 'IN')\n",
      "(PERSON Data/NNP)\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "(ORGANIZATION Computer/NNP Program/NNP)\n",
      "('for', 'IN')\n",
      "('Understanding', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('(', '(')\n",
      "('Thesis', 'NNP')\n",
      "(').', 'NNP')\n",
      "('^', 'NNP')\n",
      "(PERSON Schank/NNP)\n",
      "(',', ',')\n",
      "(PERSON Roger/NNP C/NNP)\n",
      "('.;', 'NNP')\n",
      "(PERSON Abelson/NNP)\n",
      "(',', ',')\n",
      "(PERSON Robert/NNP P/NNP)\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('1977', 'CD')\n",
      "(').', 'NN')\n",
      "(PERSON Scripts/NNP)\n",
      "(',', ',')\n",
      "('Plans', 'VBZ')\n",
      "(',', ',')\n",
      "(GPE Goals/NNP)\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('Understanding', 'NNP')\n",
      "(':', ':')\n",
      "('An', 'DT')\n",
      "(PERSON Inquiry/NNP Into/NNP Human/NNP Knowledge/NNP Structures/NNP)\n",
      "('.', '.')\n",
      "(PERSON Hillsdale/NNP)\n",
      "(':', ':')\n",
      "(PERSON Erlbaum/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('470', 'CD')\n",
      "('-', ':')\n",
      "('99033', 'CD')\n",
      "('-', ':')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "(PERSON Mark/NNP Johnson/NNP)\n",
      "('.', '.')\n",
      "('How', 'WRB')\n",
      "('the', 'DT')\n",
      "('statistical', 'JJ')\n",
      "('revolution', 'NN')\n",
      "('changes', 'NNS')\n",
      "('(', '(')\n",
      "('computational', 'NN')\n",
      "(')', ')')\n",
      "('linguistics', 'NNS')\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION EACL/NNP)\n",
      "('2009', 'CD')\n",
      "('Workshop', 'NNP')\n",
      "('on', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Interaction/NNP)\n",
      "('between', 'IN')\n",
      "(PERSON Linguistics/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Computational/NNP Linguistics/NNP)\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "(PERSON Philip/NNP Resnik/NNP)\n",
      "('.', '.')\n",
      "('Four', 'CD')\n",
      "('revolutions', 'NNS')\n",
      "('.', '.')\n",
      "(PERSON Language/NNP Log/NNP)\n",
      "(',', ',')\n",
      "('February', 'NNP')\n",
      "('5', 'CD')\n",
      "(',', ',')\n",
      "('2011', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "('Investigating', 'NNP')\n",
      "('complex', 'JJ')\n",
      "('-', ':')\n",
      "('valued', 'VBN')\n",
      "('representation', 'NN')\n",
      "('in', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Trabelsi', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Chiheb/NNP)\n",
      "(';', ':')\n",
      "(PERSON Bilaniuk/NNP)\n",
      "(',', ',')\n",
      "(GPE Olexa/NNP)\n",
      "(';', ':')\n",
      "(PERSON Zhang/NNP)\n",
      "(',', ',')\n",
      "(GPE Ying/NNP)\n",
      "(';', ':')\n",
      "(GPE Serdyuk/NNP)\n",
      "(',', ',')\n",
      "(GPE Dmitriy/NNP)\n",
      "(';', ':')\n",
      "(GPE Subramanian/NNP)\n",
      "(',', ',')\n",
      "(GPE Sandeep/NNP)\n",
      "(';', ':')\n",
      "(GPE Santos/NNP)\n",
      "(',', ',')\n",
      "(PERSON João/NNP Felipe/NNP)\n",
      "(';', ':')\n",
      "(GPE Mehri/NNP)\n",
      "(',', ',')\n",
      "(GPE Soroush/NNP)\n",
      "(';', ':')\n",
      "(GPE Rostamzadeh/NNP)\n",
      "(',', ',')\n",
      "(GPE Negar/NNP)\n",
      "(';', ':')\n",
      "(GPE Bengio/NNP)\n",
      "(',', ',')\n",
      "(GPE Yoshua/NNP)\n",
      "(';', ':')\n",
      "(GPE Pal/NNP)\n",
      "(',', ',')\n",
      "(PERSON Christopher/NNP J/NNP)\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2018', 'CD')\n",
      "('-', ':')\n",
      "('02', 'CD')\n",
      "('-', ':')\n",
      "('25', 'CD')\n",
      "(').', 'JJ')\n",
      "('\"', 'JJ')\n",
      "(PERSON Deep/NNP Complex/NNP Networks/NNP)\n",
      "('\".', 'NNP')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('1705', 'CD')\n",
      "('.', '.')\n",
      "('09792', 'CD')\n",
      "('[', 'JJ')\n",
      "('cs', 'NN')\n",
      "('.', '.')\n",
      "('NE', 'NNP')\n",
      "('].', 'NNP')\n",
      "('^', 'NNP')\n",
      "('Socher', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Richard/NNP)\n",
      "('.', '.')\n",
      "('\"', 'VB')\n",
      "(PERSON Deep/NNP Learning/NNP)\n",
      "('For', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('-', ':')\n",
      "(ORGANIZATION ACL/NN 2012/CD)\n",
      "('Tutorial', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('socher', 'NN')\n",
      "('.', '.')\n",
      "('org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2020', 'CD')\n",
      "('-', ':')\n",
      "('08', 'CD')\n",
      "('-', ':')\n",
      "('17', 'CD')\n",
      "('.', '.')\n",
      "('This', 'DT')\n",
      "('was', 'VBD')\n",
      "('an', 'DT')\n",
      "('early', 'JJ')\n",
      "('Deep', 'NNP')\n",
      "('Learning', 'NNP')\n",
      "('tutorial', 'NN')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION ACL/NNP)\n",
      "('2012', 'CD')\n",
      "('and', 'CC')\n",
      "('met', 'VBD')\n",
      "('with', 'IN')\n",
      "('both', 'DT')\n",
      "('interest', 'NN')\n",
      "('and', 'CC')\n",
      "('(', '(')\n",
      "('at', 'IN')\n",
      "('the', 'DT')\n",
      "('time', 'NN')\n",
      "(')', ')')\n",
      "('skepticism', 'NN')\n",
      "('by', 'IN')\n",
      "('most', 'JJS')\n",
      "('participants', 'NNS')\n",
      "('.', '.')\n",
      "('Until', 'IN')\n",
      "('then', 'RB')\n",
      "(',', ',')\n",
      "('neural', 'JJ')\n",
      "('learning', 'NN')\n",
      "('was', 'VBD')\n",
      "('basically', 'RB')\n",
      "('rejected', 'VBN')\n",
      "('because', 'IN')\n",
      "('of', 'IN')\n",
      "('its', 'PRP$')\n",
      "('lack', 'NN')\n",
      "('of', 'IN')\n",
      "('statistical', 'JJ')\n",
      "('interpretability', 'NN')\n",
      "('.', '.')\n",
      "('Until', 'IN')\n",
      "('2015', 'CD')\n",
      "(',', ',')\n",
      "('deep', 'JJ')\n",
      "('learning', 'NN')\n",
      "('had', 'VBD')\n",
      "('evolved', 'VBN')\n",
      "('into', 'IN')\n",
      "('the', 'DT')\n",
      "('major', 'JJ')\n",
      "('framework', 'NN')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Annamoradnejad/NNP)\n",
      "(',', ',')\n",
      "('I', 'PRP')\n",
      "('.', '.')\n",
      "('and', 'CC')\n",
      "(PERSON Zoghi/NNP)\n",
      "(',', ',')\n",
      "('G', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2020', 'CD')\n",
      "(').', 'NN')\n",
      "(PERSON Colbert/NNP)\n",
      "(':', ':')\n",
      "('Using', 'NNP')\n",
      "('bert', 'JJ')\n",
      "('sentence', 'NN')\n",
      "('embedding', 'VBG')\n",
      "('for', 'IN')\n",
      "('humor', 'NN')\n",
      "('detection', 'NN')\n",
      "('.', '.')\n",
      "('arXiv', 'JJ')\n",
      "('preprint', 'NN')\n",
      "('arXiv', 'NN')\n",
      "(':', ':')\n",
      "('2004', 'CD')\n",
      "('.', '.')\n",
      "('12765', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "('Yi', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Chucai/NNP)\n",
      "(';', ':')\n",
      "(GPE Tian/NNP)\n",
      "(',', ',')\n",
      "(GPE Yingli/NNP)\n",
      "('(', '(')\n",
      "('2012', 'CD')\n",
      "('),', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Assistive', 'NNP')\n",
      "('Text', 'NNP')\n",
      "('Reading', 'NNP')\n",
      "('from', 'IN')\n",
      "(ORGANIZATION Complex/NNP Background/NNP)\n",
      "('for', 'IN')\n",
      "(PERSON Blind/NNP Persons/NNP)\n",
      "('\",', 'NNP')\n",
      "(PERSON Camera/NNP)\n",
      "('-', ':')\n",
      "('Based', 'VBD')\n",
      "(ORGANIZATION Document/NNP Analysis/NNP)\n",
      "('and', 'CC')\n",
      "(GPE Recognition/NNP)\n",
      "(',', ',')\n",
      "(PERSON Springer/NNP Berlin/NNP Heidelberg/NNP)\n",
      "(',', ',')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('15', 'CD')\n",
      "('–', 'JJ')\n",
      "('28', 'CD')\n",
      "(',', ',')\n",
      "(ORGANIZATION CiteSeerX/NNP)\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('668', 'CD')\n",
      "('.', '.')\n",
      "('869', 'CD')\n",
      "(',', ',')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1007', 'CD')\n",
      "('/', '$')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('3', 'CD')\n",
      "('-', ':')\n",
      "('642', 'CD')\n",
      "('-', ':')\n",
      "('29364', 'CD')\n",
      "('-', ':')\n",
      "('1_2', 'CD')\n",
      "(',', ',')\n",
      "(ORGANIZATION ISBN/NNP)\n",
      "('9783642293634', 'CD')\n",
      "('^', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('What', 'WP')\n",
      "('is', 'VBZ')\n",
      "(ORGANIZATION Natural/JJ Language/NNP)\n",
      "('Processing', 'NNP')\n",
      "('?', '.')\n",
      "('Intro', 'NNP')\n",
      "('to', 'TO')\n",
      "(ORGANIZATION NLP/NNP)\n",
      "('in', 'IN')\n",
      "(GPE Machine/NNP)\n",
      "('Learning', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "(ORGANIZATION GyanSetu/NNP)\n",
      "('!', '.')\n",
      "('.', '.')\n",
      "('2020', 'CD')\n",
      "('-', ':')\n",
      "('12', 'CD')\n",
      "('-', ':')\n",
      "('06', 'CD')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Kishorjit/NNP)\n",
      "(',', ',')\n",
      "(PERSON N/NNP)\n",
      "('.;', 'NNP')\n",
      "('Vidya', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Raj/NNP RK/NNP)\n",
      "('.;', 'NNP')\n",
      "('Nirmal', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Y/NNP)\n",
      "('.;', 'NNP')\n",
      "('Sivaji', 'NNP')\n",
      "(',', ',')\n",
      "('B', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2012', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Manipuri', 'NNP')\n",
      "('Morpheme', 'NNP')\n",
      "('Identification', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('3rd', 'CD')\n",
      "('Workshop', 'NNP')\n",
      "('on', 'IN')\n",
      "(GPE South/NNP)\n",
      "('and', 'CC')\n",
      "(PERSON Southeast/NNP Asian/NNP Natural/NNP Language/NNP)\n",
      "('Processing', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION SANLP/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('COLING', 'NN')\n",
      "('2012', 'CD')\n",
      "(',', ',')\n",
      "(GPE Mumbai/NNP)\n",
      "(',', ',')\n",
      "('December', 'NNP')\n",
      "('2012', 'CD')\n",
      "(':', ':')\n",
      "('95', 'CD')\n",
      "('–', '$')\n",
      "('108', 'CD')\n",
      "('.', '.')\n",
      "('CS1', 'JJ')\n",
      "('maint', 'NN')\n",
      "(':', ':')\n",
      "('location', 'NN')\n",
      "('(', '(')\n",
      "('link', 'NN')\n",
      "(')', ')')\n",
      "('^', 'NN')\n",
      "(PERSON Klein/NNP)\n",
      "(',', ',')\n",
      "(GPE Dan/NNP)\n",
      "(';', ':')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Christopher/NNP D/NNP)\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2002', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('grammar', 'NN')\n",
      "('induction', 'NN')\n",
      "('using', 'VBG')\n",
      "('a', 'DT')\n",
      "('constituent', 'JJ')\n",
      "('-', ':')\n",
      "('context', 'NN')\n",
      "('model', 'NN')\n",
      "('\"', 'NNP')\n",
      "('(', '(')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Advances', 'NNS')\n",
      "('in', 'IN')\n",
      "(GPE Neural/NNP)\n",
      "('Information', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('Systems', 'NNPS')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "(ORGANIZATION PASCAL/NNP)\n",
      "('Recognizing', 'NNP')\n",
      "(PERSON Textual/NNP Entailment/NNP Challenge/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION RTE/NNP)\n",
      "('-', ':')\n",
      "('7', 'CD')\n",
      "(')', ')')\n",
      "('https', 'NN')\n",
      "('://', 'JJ')\n",
      "('tac', 'NN')\n",
      "('.', '.')\n",
      "('nist', 'NN')\n",
      "('.', '.')\n",
      "('gov', 'NN')\n",
      "('//', 'JJ')\n",
      "('2011', 'CD')\n",
      "('/', 'NNP')\n",
      "('RTE', 'NNP')\n",
      "('/', 'NNP')\n",
      "('^', 'NNP')\n",
      "('Lippi', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Marco/NNP)\n",
      "(';', ':')\n",
      "(GPE Torroni/NNP)\n",
      "(',', ',')\n",
      "(GPE Paolo/NNP)\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "('-', ':')\n",
      "('04', 'CD')\n",
      "('-', ':')\n",
      "('20', 'CD')\n",
      "(').', 'JJ')\n",
      "('\"', 'NNP')\n",
      "('Argumentation', 'NNP')\n",
      "('Mining', 'NNP')\n",
      "(':', ':')\n",
      "('State', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Art/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Emerging/NNP)\n",
      "('Trends', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "(ORGANIZATION ACM/NNP Transactions/NNPS)\n",
      "('on', 'IN')\n",
      "('Internet', 'NNP')\n",
      "('Technology', 'NNP')\n",
      "('.', '.')\n",
      "('16', 'CD')\n",
      "('(', '(')\n",
      "('2', 'CD')\n",
      "('):', 'RB')\n",
      "('1', 'CD')\n",
      "('–', 'JJ')\n",
      "('25', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1145', 'CD')\n",
      "('/', 'JJ')\n",
      "('2850417', 'CD')\n",
      "('.', '.')\n",
      "('ISSN', 'NN')\n",
      "('1533', 'CD')\n",
      "('-', ':')\n",
      "('5399', 'CD')\n",
      "('.', '.')\n",
      "('S2CID', 'CC')\n",
      "('9561587', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(ORGANIZATION Argument/NNP Mining/NNP)\n",
      "('-', ':')\n",
      "(ORGANIZATION IJCAI2016/NNP)\n",
      "('Tutorial', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('i3s', 'NN')\n",
      "('.', '.')\n",
      "('unice', 'NN')\n",
      "('.', '.')\n",
      "('fr', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('03', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(ORGANIZATION NLP/NNP Approaches/NNP)\n",
      "('to', 'TO')\n",
      "(ORGANIZATION Computational/NNP Argumentation/NNP)\n",
      "('–', 'NNP')\n",
      "('ACL', 'NNP')\n",
      "('2016', 'CD')\n",
      "(',', ',')\n",
      "(PERSON Berlin/NNP)\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('03', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "('U', 'NNP')\n",
      "('B', 'NNP')\n",
      "('U', 'NNP')\n",
      "('W', 'NNP')\n",
      "('E', 'NNP')\n",
      "('B', 'NNP')\n",
      "('::', 'NNP')\n",
      "('Racter', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('ubu', 'JJ')\n",
      "('.', '.')\n",
      "('com', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2020', 'CD')\n",
      "('-', ':')\n",
      "('08', 'CD')\n",
      "('-', ':')\n",
      "('17', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Writer', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Beta/NNP)\n",
      "('(', '(')\n",
      "('2019', 'CD')\n",
      "(').', 'NNP')\n",
      "(PERSON Lithium/NNP)\n",
      "('-', ':')\n",
      "(ORGANIZATION Ion/NNP Batteries/NNPS)\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1007', 'CD')\n",
      "('/', '$')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('3', 'CD')\n",
      "('-', ':')\n",
      "('030', 'CD')\n",
      "('-', ':')\n",
      "('16800', 'CD')\n",
      "('-', ':')\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('3', 'CD')\n",
      "('-', ':')\n",
      "('030', 'CD')\n",
      "('-', ':')\n",
      "('16799', 'CD')\n",
      "('-', ':')\n",
      "('8', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "('Document', 'NNP')\n",
      "('Understanding', 'NNP')\n",
      "('AI', 'NNP')\n",
      "('on', 'IN')\n",
      "(PERSON Google/NNP Cloud/NNP)\n",
      "('(', '(')\n",
      "(PERSON Cloud/NNP Next/NNP)\n",
      "(\"'\", 'POS')\n",
      "('19', 'CD')\n",
      "(')', ')')\n",
      "('-', ':')\n",
      "('YouTube', 'NN')\n",
      "('\"', 'NN')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('youtube', 'NN')\n",
      "('.', '.')\n",
      "('com', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "(ORGANIZATION Administration/NNP)\n",
      "('.', '.')\n",
      "('\"', 'NNP')\n",
      "('Centre', 'NNP')\n",
      "('for', 'IN')\n",
      "(PERSON Language/NNP Technology/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION CLT/NNP)\n",
      "(')\"', 'NNP')\n",
      "('.', '.')\n",
      "(PERSON Macquarie/NNP University/NNP)\n",
      "('.', '.')\n",
      "('Retrieved', 'NNP')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(PERSON Shared/NNP)\n",
      "('Task', 'NN')\n",
      "(':', ':')\n",
      "('Grammatical', 'JJ')\n",
      "(PERSON Error/NNP)\n",
      "('Correction', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('comp', 'NN')\n",
      "('.', '.')\n",
      "('nus', 'NN')\n",
      "('.', '.')\n",
      "('edu', 'NN')\n",
      "('.', '.')\n",
      "('sg', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(PERSON Shared/NNP)\n",
      "('Task', 'NN')\n",
      "(':', ':')\n",
      "('Grammatical', 'JJ')\n",
      "(PERSON Error/NNP)\n",
      "('Correction', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('comp', 'NN')\n",
      "('.', '.')\n",
      "('nus', 'NN')\n",
      "('.', '.')\n",
      "('edu', 'NN')\n",
      "('.', '.')\n",
      "('sg', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "('Duan', 'NNP')\n",
      "(',', ',')\n",
      "(GPE Yucong/NNP)\n",
      "(';', ':')\n",
      "(GPE Cruz/NNP)\n",
      "(',', ',')\n",
      "(GPE Christophe/NNP)\n",
      "('(', '(')\n",
      "('2011', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Formalizing', 'NNP')\n",
      "('Semantic', 'NNP')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Natural/NNP Language/NNP)\n",
      "('through', 'IN')\n",
      "('Conceptualization', 'NNP')\n",
      "('from', 'IN')\n",
      "('Existence', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "(ORGANIZATION International/NNP Journal/NNP)\n",
      "('of', 'IN')\n",
      "(GPE Innovation/NNP)\n",
      "(',', ',')\n",
      "(ORGANIZATION Management/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Technology/NNP)\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "('(', '(')\n",
      "('1', 'CD')\n",
      "('):', 'RB')\n",
      "('37', 'CD')\n",
      "('–', 'JJ')\n",
      "('42', 'CD')\n",
      "('.', '.')\n",
      "('Archived', 'VBN')\n",
      "('from', 'IN')\n",
      "('the', 'DT')\n",
      "('original', 'JJ')\n",
      "('on', 'IN')\n",
      "('2011', 'CD')\n",
      "('-', ':')\n",
      "('10', 'CD')\n",
      "('-', ':')\n",
      "('09', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'NNP')\n",
      "('Previous', 'NNP')\n",
      "('shared', 'VBD')\n",
      "('tasks', 'NNS')\n",
      "('|', 'NNP')\n",
      "('CoNLL', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('conll', 'NN')\n",
      "('.', '.')\n",
      "('org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "('Cognition', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "(PERSON Lexico/NNP)\n",
      "('.', '.')\n",
      "(PERSON Oxford/NNP University/NNP)\n",
      "('Press', 'NNP')\n",
      "('and', 'CC')\n",
      "('Dictionary', 'NNP')\n",
      "('.', '.')\n",
      "('com', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBD')\n",
      "('6', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "('Ask', 'NNP')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Cognitive/NNP)\n",
      "('Scientist', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "(ORGANIZATION American/JJ Federation/NNP)\n",
      "('of', 'IN')\n",
      "(GPE Teachers/NNP)\n",
      "('.', '.')\n",
      "('8', 'CD')\n",
      "('August', 'NNP')\n",
      "('2014', 'CD')\n",
      "('.', '.')\n",
      "('Cognitive', 'JJ')\n",
      "('science', 'NN')\n",
      "('is', 'VBZ')\n",
      "('an', 'DT')\n",
      "('interdisciplinary', 'JJ')\n",
      "('field', 'NN')\n",
      "('of', 'IN')\n",
      "('researchers', 'NNS')\n",
      "('from', 'IN')\n",
      "(GPE Linguistics/NNP)\n",
      "(',', ',')\n",
      "('psychology', 'NN')\n",
      "(',', ',')\n",
      "('neuroscience', 'NN')\n",
      "(',', ',')\n",
      "('philosophy', 'NN')\n",
      "(',', ',')\n",
      "('computer', 'NN')\n",
      "('science', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('anthropology', 'NN')\n",
      "('that', 'WDT')\n",
      "('seek', 'VBP')\n",
      "('to', 'TO')\n",
      "('understand', 'VB')\n",
      "('the', 'DT')\n",
      "('mind', 'NN')\n",
      "('.', '.')\n",
      "('^', 'JJ')\n",
      "(PERSON Robinson/NNP)\n",
      "(',', ',')\n",
      "(PERSON Peter/NNP)\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(').', 'NNP')\n",
      "('Handbook', 'NNP')\n",
      "('of', 'IN')\n",
      "(PERSON Cognitive/NNP Linguistics/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Second/NNP Language/NNP Acquisition/NNP)\n",
      "('.', '.')\n",
      "('Routledge', 'NNP')\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('3', 'CD')\n",
      "('–', 'JJ')\n",
      "('8', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('805', 'CD')\n",
      "('-', ':')\n",
      "('85352', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "(PERSON Lakoff/NNP)\n",
      "(',', ',')\n",
      "(GPE George/NNP)\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(').', 'NNP')\n",
      "('Philosophy', 'NNP')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('Flesh', 'NNP')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "(ORGANIZATION Embodied/NNP Mind/NNP)\n",
      "('and', 'CC')\n",
      "('Its', 'PRP$')\n",
      "('Challenge', 'NNP')\n",
      "('to', 'TO')\n",
      "(LOCATION Western/NNP Philosophy/NNP)\n",
      "(';', ':')\n",
      "('Appendix', 'NNP')\n",
      "(':', ':')\n",
      "('The', 'DT')\n",
      "(ORGANIZATION Neural/NNP)\n",
      "('Theory', 'NNP')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Language/NNP Paradigm/NNP)\n",
      "('.', '.')\n",
      "(GPE New/NNP York/NNP)\n",
      "(PERSON Basic/NNP Books/NNP)\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('569', 'CD')\n",
      "('–', 'JJ')\n",
      "('583', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('465', 'CD')\n",
      "('-', ':')\n",
      "('05674', 'CD')\n",
      "('-', ':')\n",
      "('3', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Strauss/NNP)\n",
      "(',', ',')\n",
      "(GPE Claudia/NNP)\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(').', 'VBZ')\n",
      "('A', 'DT')\n",
      "('Cognitive', 'NNP')\n",
      "('Theory', 'NNP')\n",
      "('of', 'IN')\n",
      "('Cultural', 'NNP')\n",
      "('Meaning', 'NNP')\n",
      "('.', '.')\n",
      "(PERSON Cambridge/NNP University/NNP)\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('pp', 'NN')\n",
      "('.', '.')\n",
      "('156', 'CD')\n",
      "('–', 'JJ')\n",
      "('164', 'CD')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('521', 'CD')\n",
      "('-', ':')\n",
      "('59541', 'CD')\n",
      "('-', ':')\n",
      "('4', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(PERSON Universal/NNP Conceptual/NNP Cognitive/NNP Annotation/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION UCCA/NNP)\n",
      "(')\"', 'NNP')\n",
      "('.', '.')\n",
      "(PERSON Universal/NNP Conceptual/NNP Cognitive/NNP Annotation/NNP)\n",
      "('(', '(')\n",
      "(ORGANIZATION UCCA/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'NN')\n",
      "(PERSON Rodríguez/NNP)\n",
      "(',', ',')\n",
      "('F', 'NNP')\n",
      "('.', '.')\n",
      "('C', 'NNP')\n",
      "('.,', 'NNP')\n",
      "('&', 'CC')\n",
      "(ORGANIZATION Mairal/NNP)\n",
      "('-', ':')\n",
      "(GPE Usón/NN)\n",
      "(',', ',')\n",
      "('R', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(').', 'NNP')\n",
      "('Building', 'NNP')\n",
      "('an', 'DT')\n",
      "(ORGANIZATION RRG/NNP)\n",
      "('computational', 'JJ')\n",
      "('grammar', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Onomazein/NNP)\n",
      "(',', ',')\n",
      "('(', '(')\n",
      "('34', 'CD')\n",
      "('),', 'RB')\n",
      "('86', 'CD')\n",
      "('-', ':')\n",
      "('117', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(PERSON Fluid/NNP Construction/NNP Grammar/NNP)\n",
      "('–', 'VBD')\n",
      "('A', 'NNP')\n",
      "('fully', 'RB')\n",
      "('operational', 'JJ')\n",
      "('processing', 'NN')\n",
      "('system', 'NN')\n",
      "('for', 'IN')\n",
      "('construction', 'NN')\n",
      "('grammars', 'NNS')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(ORGANIZATION ACL/NNP)\n",
      "('Member', 'NNP')\n",
      "(PERSON Portal/NNP)\n",
      "('|', 'NNP')\n",
      "('The', 'DT')\n",
      "(ORGANIZATION Association/NNP)\n",
      "('for', 'IN')\n",
      "(ORGANIZATION Computational/NNP Linguistics/NNP)\n",
      "('Member', 'NNP')\n",
      "('Portal', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('aclweb', 'NN')\n",
      "('.', '.')\n",
      "('org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "('\"', 'JJ')\n",
      "(PERSON Chunks/NNP)\n",
      "('and', 'CC')\n",
      "(PERSON Rules/NNP)\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('www', 'NN')\n",
      "('.', '.')\n",
      "('w3', 'NN')\n",
      "('.', '.')\n",
      "('org', 'NN')\n",
      "('.', '.')\n",
      "('Retrieved', 'VBN')\n",
      "('2021', 'CD')\n",
      "('-', ':')\n",
      "('01', 'CD')\n",
      "('-', ':')\n",
      "('11', 'CD')\n",
      "('.', '.')\n",
      "('^', 'VB')\n",
      "(PERSON Socher/NNP)\n",
      "(',', ',')\n",
      "(PERSON Richard/NNP)\n",
      "(';', ':')\n",
      "(PERSON Karpathy/NNP)\n",
      "(',', ',')\n",
      "(GPE Andrej/NNP)\n",
      "(';', ':')\n",
      "(PERSON Le/NNP)\n",
      "(',', ',')\n",
      "(PERSON Quoc/NNP V/NNP)\n",
      "('.;', 'NNP')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Christopher/NNP D/NNP)\n",
      "('.;', 'NNP')\n",
      "('Ng', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Andrew/NNP Y/NNP)\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('2014', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Grounded', 'NNP')\n",
      "('Compositional', 'NNP')\n",
      "('Semantics', 'NNP')\n",
      "('for', 'IN')\n",
      "('Finding', 'NNP')\n",
      "('and', 'CC')\n",
      "('Describing', 'NNP')\n",
      "('Images', 'NNP')\n",
      "('with', 'IN')\n",
      "('Sentences', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('.', '.')\n",
      "('Transactions', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Association/NNP)\n",
      "('for', 'IN')\n",
      "(ORGANIZATION Computational/NNP Linguistics/NNP)\n",
      "('.', '.')\n",
      "('2', 'CD')\n",
      "(':', ':')\n",
      "('207', 'CD')\n",
      "('–', '$')\n",
      "('218', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1162', 'CD')\n",
      "('/', 'JJ')\n",
      "('tacl_a_00177', 'NN')\n",
      "('.', '.')\n",
      "('S2CID', 'NNP')\n",
      "('2317858', 'CD')\n",
      "('.', '.')\n",
      "('Further', 'JJ')\n",
      "('reading', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Bates', 'NNP')\n",
      "(',', ',')\n",
      "(GPE M/NNP)\n",
      "('(', '(')\n",
      "('1995', 'CD')\n",
      "(').', 'NNP')\n",
      "('\"', 'NNP')\n",
      "('Models', 'NNP')\n",
      "('of', 'IN')\n",
      "('natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('understanding', 'JJ')\n",
      "('\"', 'NN')\n",
      "('.', '.')\n",
      "('Proceedings', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION National/NNP Academy/NNP)\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Sciences/NNPS)\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(GPE United/NNP States/NNPS)\n",
      "('of', 'IN')\n",
      "(GPE America/NNP)\n",
      "('.', '.')\n",
      "('92', 'CD')\n",
      "('(', '(')\n",
      "('22', 'CD')\n",
      "('):', 'NN')\n",
      "('9977', 'CD')\n",
      "('–', 'NN')\n",
      "('9982', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Bibcode/NN)\n",
      "(':', ':')\n",
      "('1995PNAS', 'CD')\n",
      "('...', ':')\n",
      "('92', 'CD')\n",
      "('.', '.')\n",
      "('9977B', 'CD')\n",
      "('.', '.')\n",
      "('doi', 'NN')\n",
      "(':', ':')\n",
      "('10', 'CD')\n",
      "('.', '.')\n",
      "('1073', 'CD')\n",
      "('/', 'JJ')\n",
      "('pnas', 'NNS')\n",
      "('.', '.')\n",
      "('92', 'CD')\n",
      "('.', '.')\n",
      "('22', 'CD')\n",
      "('.', '.')\n",
      "('9977', 'CD')\n",
      "('.', '.')\n",
      "('PMC', 'VB')\n",
      "('40721', 'CD')\n",
      "('.', '.')\n",
      "('PMID', 'VB')\n",
      "('7479812', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Steven/NNP Bird/NNP)\n",
      "(',', ',')\n",
      "(PERSON Ewan/NNP Klein/NNP)\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(PERSON Edward/NNP Loper/NNP)\n",
      "('(', '(')\n",
      "('2009', 'CD')\n",
      "(').', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'VBG')\n",
      "('with', 'IN')\n",
      "(PERSON Python/NNP)\n",
      "('.', '.')\n",
      "('O', 'NNP')\n",
      "(\"'\", 'POS')\n",
      "(PERSON Reilly/NNP Media/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('596', 'CD')\n",
      "('-', ':')\n",
      "('51649', 'CD')\n",
      "('-', ':')\n",
      "('9', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Daniel/NNP Jurafsky/NNP)\n",
      "('and', 'CC')\n",
      "(PERSON James/NNP H/NNP)\n",
      "('.', '.')\n",
      "(PERSON Martin/NNP)\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(').', 'NNP')\n",
      "('Speech', 'NNP')\n",
      "('and', 'CC')\n",
      "(PERSON Language/NNP Processing/NNP)\n",
      "(',', ',')\n",
      "('2nd', 'CD')\n",
      "('edition', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Pearson/NNP Prentice/NNP Hall/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('13', 'CD')\n",
      "('-', ':')\n",
      "('187321', 'CD')\n",
      "('-', ':')\n",
      "('6', 'CD')\n",
      "('.', '.')\n",
      "('Mohamed', 'VBN')\n",
      "(PERSON Zakaria/NNP Kurdi/NNP)\n",
      "('(', '(')\n",
      "('2016', 'CD')\n",
      "(').', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Computational/NNP)\n",
      "('Linguistics', 'NNS')\n",
      "(':', ':')\n",
      "('speech', 'NN')\n",
      "(',', ',')\n",
      "('morphology', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('syntax', 'NN')\n",
      "(',', ',')\n",
      "(ORGANIZATION Volume/NN)\n",
      "('1', 'CD')\n",
      "('.', '.')\n",
      "(ORGANIZATION ISTE/NNP)\n",
      "('-', ':')\n",
      "(PERSON Wiley/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('1848218482', 'CD')\n",
      "('.', '.')\n",
      "('Mohamed', 'VBN')\n",
      "(PERSON Zakaria/NNP Kurdi/NNP)\n",
      "('(', '(')\n",
      "('2017', 'CD')\n",
      "(').', 'NNP')\n",
      "('Natural', 'NNP')\n",
      "('Language', 'NNP')\n",
      "('Processing', 'NNP')\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Computational/NNP)\n",
      "('Linguistics', 'NNS')\n",
      "(':', ':')\n",
      "('semantics', 'NNS')\n",
      "(',', ',')\n",
      "('discourse', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('applications', 'NNS')\n",
      "(',', ',')\n",
      "(ORGANIZATION Volume/NN)\n",
      "('2', 'CD')\n",
      "('.', '.')\n",
      "(ORGANIZATION ISTE/NNP)\n",
      "('-', ':')\n",
      "(PERSON Wiley/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('1848219212', 'CD')\n",
      "('.', '.')\n",
      "(PERSON Christopher/NNP D/NNP)\n",
      "('.', '.')\n",
      "('Manning', 'NNP')\n",
      "(',', ',')\n",
      "(PERSON Prabhakar/NNP Raghavan/NNP)\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "(PERSON Hinrich/NNP Schütze/NNP)\n",
      "('(', '(')\n",
      "('2008', 'CD')\n",
      "(').', 'NNP')\n",
      "('Introduction', 'NNP')\n",
      "('to', 'TO')\n",
      "(ORGANIZATION Information/NNP Retrieval/NNP)\n",
      "('.', '.')\n",
      "(PERSON Cambridge/NNP University/NNP)\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('521', 'CD')\n",
      "('-', ':')\n",
      "('86571', 'CD')\n",
      "('-', ':')\n",
      "('5', 'CD')\n",
      "('.', '.')\n",
      "('Official', 'JJ')\n",
      "('html', 'NN')\n",
      "('and', 'CC')\n",
      "('pdf', 'JJ')\n",
      "('versions', 'NNS')\n",
      "('available', 'JJ')\n",
      "('without', 'IN')\n",
      "('charge', 'NN')\n",
      "('.', '.')\n",
      "(PERSON Christopher/NNP D/NNP)\n",
      "('.', '.')\n",
      "('Manning', 'NNP')\n",
      "('and', 'CC')\n",
      "(PERSON Hinrich/NNP Schütze/NNP)\n",
      "('(', '(')\n",
      "('1999', 'CD')\n",
      "(').', 'NNP')\n",
      "('Foundations', 'NNP')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Statistical/NNP Natural/NNP Language/NNP)\n",
      "('Processing', 'NNP')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "(ORGANIZATION MIT/NNP)\n",
      "('Press', 'NNP')\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('262', 'CD')\n",
      "('-', ':')\n",
      "('13360', 'CD')\n",
      "('-', ':')\n",
      "('9', 'CD')\n",
      "('.', '.')\n",
      "(PERSON David/NNP M/NNP)\n",
      "('.', '.')\n",
      "('W', 'NNP')\n",
      "('.', '.')\n",
      "('Powers', 'NNS')\n",
      "('and', 'CC')\n",
      "(PERSON Christopher/NNP C/NNP)\n",
      "('.', '.')\n",
      "('R', 'NNP')\n",
      "('.', '.')\n",
      "(GPE Turk/NNP)\n",
      "('(', '(')\n",
      "('1989', 'CD')\n",
      "(').', 'NNP')\n",
      "(PERSON Machine/NNP Learning/NNP)\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Natural/NNP Language/NNP)\n",
      "('.', '.')\n",
      "(PERSON Springer/NNP)\n",
      "('-', ':')\n",
      "(GPE Verlag/NNP)\n",
      "('.', '.')\n",
      "('ISBN', 'NNP')\n",
      "('978', 'CD')\n",
      "('-', ':')\n",
      "('0', 'CD')\n",
      "('-', ':')\n",
      "('387', 'CD')\n",
      "('-', ':')\n",
      "('19557', 'CD')\n",
      "('-', ':')\n",
      "('5', 'CD')\n",
      "('.', '.')\n",
      "('External', 'JJ')\n",
      "('link', 'NN')\n",
      "('[', 'NNP')\n",
      "('edit', 'NN')\n",
      "(']', 'NNP')\n",
      "('Media', 'NNP')\n",
      "('related', 'VBD')\n",
      "('to', 'TO')\n",
      "(GPE Natural/NNP)\n",
      "('language', 'NN')\n",
      "('processing', 'NN')\n",
      "('at', 'IN')\n",
      "(ORGANIZATION Wikimedia/NNP Commons/NNP)\n",
      "('v', 'NN')\n",
      "('t', 'NN')\n",
      "('e', 'VBZ')\n",
      "(ORGANIZATION Natural/NNP)\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "(ORGANIZATION General/NNP)\n",
      "('terms', 'NNS')\n",
      "(ORGANIZATION AI/NNP)\n",
      "('-', ':')\n",
      "('complete', 'JJ')\n",
      "(ORGANIZATION Bag/NNP)\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('words', 'NNS')\n",
      "('n', 'SYM')\n",
      "('-', ':')\n",
      "('gram', 'NN')\n",
      "(PERSON Bigram/NNP Trigram/NNP)\n",
      "('Computational', 'NNP')\n",
      "('linguistics', 'NNS')\n",
      "(ORGANIZATION Natural/NNP)\n",
      "('-', ':')\n",
      "('language', 'NN')\n",
      "('understanding', 'JJ')\n",
      "('Stopwords', 'NNP')\n",
      "('Text', 'NNP')\n",
      "('processing', 'VBG')\n",
      "(GPE Text/NNP)\n",
      "('analysis', 'NN')\n",
      "('Collocation', 'NNP')\n",
      "('extraction', 'NN')\n",
      "('Concept', 'NNP')\n",
      "('mining', 'NN')\n",
      "('Coreference', 'NNP')\n",
      "('resolution', 'NN')\n",
      "('Deep', 'NNP')\n",
      "('linguistic', 'JJ')\n",
      "('processing', 'NN')\n",
      "(ORGANIZATION Distant/NNP)\n",
      "('reading', 'NN')\n",
      "('Information', 'NNP')\n",
      "('extraction', 'NN')\n",
      "(PERSON Named/NNP)\n",
      "('-', ':')\n",
      "('entity', 'NN')\n",
      "('recognition', 'NN')\n",
      "('Ontology', 'NNP')\n",
      "('learning', 'VBG')\n",
      "('Parsing', 'VBG')\n",
      "(ORGANIZATION Part/NNP)\n",
      "('-', ':')\n",
      "('of', 'IN')\n",
      "('-', ':')\n",
      "('speech', 'NN')\n",
      "('tagging', 'VBG')\n",
      "(ORGANIZATION Semantic/JJ)\n",
      "('role', 'NN')\n",
      "('labeling', 'VBG')\n",
      "(ORGANIZATION Semantic/NNP)\n",
      "('similarity', 'NN')\n",
      "('Sentiment', 'NNP')\n",
      "('analysis', 'NN')\n",
      "('Terminology', 'NNP')\n",
      "('extraction', 'NN')\n",
      "(PERSON Text/NNP)\n",
      "('mining', 'NN')\n",
      "(PERSON Textual/NNP)\n",
      "('entailment', 'NN')\n",
      "('Truecasing', 'NNP')\n",
      "('Word', 'NNP')\n",
      "('-', ':')\n",
      "('sense', 'NN')\n",
      "('disambiguation', 'NN')\n",
      "(ORGANIZATION Word/NNP)\n",
      "('-', ':')\n",
      "('sense', 'NN')\n",
      "('induction', 'NN')\n",
      "(PERSON Text/NNP)\n",
      "('segmentation', 'NN')\n",
      "(ORGANIZATION Compound/NNP)\n",
      "('-', ':')\n",
      "('term', 'NN')\n",
      "('processing', 'NN')\n",
      "('Lemmatisation', 'NNP')\n",
      "('Lexical', 'NNP')\n",
      "('analysis', 'NN')\n",
      "('Text', 'NNP')\n",
      "('chunking', 'VBG')\n",
      "('Stemming', 'VBG')\n",
      "(GPE Sentence/NNP)\n",
      "('segmentation', 'NN')\n",
      "('Word', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "(PERSON Automatic/NNP)\n",
      "('summarization', 'NN')\n",
      "(PERSON Multi/NNP)\n",
      "('-', ':')\n",
      "('document', 'NN')\n",
      "('summarization', 'NN')\n",
      "('Sentence', 'NNP')\n",
      "('extraction', 'NN')\n",
      "(PERSON Text/NNP)\n",
      "('simplification', 'NN')\n",
      "(PERSON Machine/NNP)\n",
      "('translation', 'NN')\n",
      "(ORGANIZATION Computer/NNP)\n",
      "('-', ':')\n",
      "('assisted', 'VBD')\n",
      "(PERSON Example/NNP)\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "(PERSON Rule/NNP)\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "(PERSON Statistical/NNP Transfer/NNP)\n",
      "('-', ':')\n",
      "('based', 'VBN')\n",
      "(ORGANIZATION Neural/NNP Distributional/NNP)\n",
      "('semantics', 'NNS')\n",
      "('models', 'NNS')\n",
      "(ORGANIZATION BERT/NNP Document/NNP)\n",
      "('-', ':')\n",
      "('term', 'NN')\n",
      "('matrix', 'NN')\n",
      "('Explicit', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "(ORGANIZATION fastText/JJ)\n",
      "(ORGANIZATION GloVe/NNP)\n",
      "('Latent', 'NNP')\n",
      "('semantic', 'JJ')\n",
      "('analysis', 'NN')\n",
      "('Word', 'NNP')\n",
      "('embedding', 'VBG')\n",
      "(ORGANIZATION Word2vec/NNP Language/NNP)\n",
      "('resources', 'NNS')\n",
      "(',', ',')\n",
      "('datasets', 'NNS')\n",
      "('and', 'CC')\n",
      "('corpora', 'NNS')\n",
      "(PERSON Types/NNP)\n",
      "('and', 'CC')\n",
      "('standards', 'NNS')\n",
      "(GPE Corpus/NNP)\n",
      "('linguistics', 'NNS')\n",
      "(PERSON Lexical/NNP)\n",
      "('resource', 'NN')\n",
      "(PERSON Linguistic/NNP Linked/NNP Open/NNP Data/NNP Machine/NNP)\n",
      "('-', ':')\n",
      "('readable', 'JJ')\n",
      "('dictionary', 'JJ')\n",
      "(ORGANIZATION Parallel/NNP)\n",
      "('text', 'NN')\n",
      "(ORGANIZATION PropBank/NNP Semantic/NNP)\n",
      "('network', 'NN')\n",
      "(PERSON\n",
      "  Simple/NNP\n",
      "  Knowledge/NNP\n",
      "  Organization/NNP\n",
      "  System/NNP\n",
      "  Speech/NNP)\n",
      "('corpus', 'NN')\n",
      "(PERSON Text/NNP)\n",
      "('corpus', 'NN')\n",
      "('Thesaurus', 'NNP')\n",
      "('(', '(')\n",
      "('information', 'NN')\n",
      "('retrieval', 'NN')\n",
      "(')', ')')\n",
      "(PERSON Treebank/NNP Universal/NNP Dependencies/NNP Data/NNP)\n",
      "(ORGANIZATION BabelNet/NNP Bank/NNP)\n",
      "('of', 'IN')\n",
      "(GPE English/NNP)\n",
      "(ORGANIZATION DBpedia/NNP)\n",
      "('FrameNet', 'NNP')\n",
      "('Google', 'NNP')\n",
      "('Ngram', 'NNP')\n",
      "('Viewer', 'NNP')\n",
      "('ThoughtTreasure', 'NNP')\n",
      "('UBY', 'NNP')\n",
      "('WordNet', 'NNP')\n",
      "('Automatic', 'NNP')\n",
      "('identification', 'NN')\n",
      "('and', 'CC')\n",
      "('data', 'NNS')\n",
      "('capture', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('recognition', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('segmentation', 'NN')\n",
      "('Speech', 'NNP')\n",
      "('synthesis', 'NN')\n",
      "('Natural', 'NNP')\n",
      "('language', 'NN')\n",
      "('generation', 'NN')\n",
      "('Optical', 'NNP')\n",
      "('character', 'NN')\n",
      "('recognition', 'NN')\n",
      "('Topic', 'NNP')\n",
      "('model', 'NN')\n",
      "('Document', 'NNP')\n",
      "('classification', 'NN')\n",
      "(PERSON Latent/NNP Dirichlet/NNP)\n",
      "('allocation', 'NN')\n",
      "(PERSON Pachinko/NNP)\n",
      "('allocation', 'NN')\n",
      "(ORGANIZATION Computer/NNP)\n",
      "('-', ':')\n",
      "('assisted', 'VBD')\n",
      "('reviewing', 'VBG')\n",
      "(GPE Automated/NNP)\n",
      "('essay', 'NN')\n",
      "('scoring', 'VBG')\n",
      "(ORGANIZATION Concordancer/NNP Grammar/NNP)\n",
      "('checker', 'NN')\n",
      "('Predictive', 'NNP')\n",
      "('text', 'NN')\n",
      "('Spell', 'NNP')\n",
      "('checker', 'NN')\n",
      "(PERSON Syntax/NNP)\n",
      "('guessing', 'VBG')\n",
      "(ORGANIZATION Natural/NNP)\n",
      "('language', 'NN')\n",
      "('user', 'NN')\n",
      "('interface', 'NN')\n",
      "(PERSON Chatbot/NNP Interactive/NNP)\n",
      "('fiction', 'NN')\n",
      "('Question', 'NNP')\n",
      "('answering', 'VBG')\n",
      "(PERSON Virtual/NNP)\n",
      "('assistant', 'NN')\n",
      "('Voice', 'NNP')\n",
      "('user', 'RB')\n",
      "('interface', 'VBZ')\n",
      "('Other', 'JJ')\n",
      "('software', 'NN')\n",
      "(ORGANIZATION Natural/NNP Language/NNP Toolkit/NNP)\n",
      "('spaCy', 'JJ')\n",
      "('Authority', 'NNP')\n",
      "('control', 'NN')\n",
      "(':', ':')\n",
      "('National', 'NNP')\n",
      "('libraries', 'NNS')\n",
      "(GPE United/NNP States/NNPS)\n",
      "(PERSON Japan/NNP Language/NNP)\n",
      "('portal', 'JJ')\n",
      "('Retrieved', 'NNP')\n",
      "('from', 'IN')\n",
      "('\"', 'NNP')\n",
      "('https', 'NN')\n",
      "('://', 'NNP')\n",
      "('en', 'NN')\n",
      "('.', '.')\n",
      "('wikipedia', 'NN')\n",
      "('.', '.')\n",
      "('org', 'JJ')\n",
      "('/', 'JJ')\n",
      "('w', 'NN')\n",
      "('/', 'NNP')\n",
      "('index', 'NN')\n",
      "('.', '.')\n",
      "('php', 'VB')\n",
      "('?', '.')\n",
      "('title', 'NN')\n",
      "('=', 'NNP')\n",
      "('Natural_language_processing', 'NNP')\n",
      "('&', 'CC')\n",
      "('oldid', 'JJ')\n",
      "('=', 'NN')\n",
      "('1048621730', 'CD')\n",
      "('\"', 'JJ')\n",
      "('Categories', 'NNS')\n",
      "(':', ':')\n",
      "('Natural', 'JJ')\n",
      "('language', 'NN')\n",
      "('processing', 'VBG')\n",
      "(ORGANIZATION Computational/NNP)\n",
      "('linguistics', 'NNS')\n",
      "(GPE Speech/NNP)\n",
      "('recognition', 'NN')\n",
      "('Computational', 'NNP')\n",
      "('fields', 'NNS')\n",
      "('of', 'IN')\n",
      "('study', 'NN')\n",
      "('Artificial', 'NNP')\n",
      "('intelligence', 'NN')\n",
      "(PERSON Hidden/NNP)\n",
      "('categories', 'NNS')\n",
      "(':', ':')\n",
      "('CS1', 'NNP')\n",
      "('maint', 'NN')\n",
      "(':', ':')\n",
      "('location', 'NN')\n",
      "('Articles', 'NNS')\n",
      "('with', 'IN')\n",
      "('short', 'JJ')\n",
      "('description', 'NN')\n",
      "('Short', 'NNP')\n",
      "('description', 'NN')\n",
      "('matches', 'NNS')\n",
      "(PERSON Wikidata/NNP Commons/NNP)\n",
      "('category', 'NN')\n",
      "('link', 'NN')\n",
      "('from', 'IN')\n",
      "(PERSON Wikidata/NNP Articles/NNP)\n",
      "('with', 'IN')\n",
      "(ORGANIZATION LCCN/NNP)\n",
      "('identifiers', 'NNS')\n",
      "(PERSON Articles/NNP)\n",
      "('with', 'IN')\n",
      "(ORGANIZATION NDL/NNP)\n",
      "('identifiers', 'NNS')\n",
      "(PERSON Navigation/NNP)\n",
      "('menu', 'VBD')\n",
      "('Personal', 'NNP')\n",
      "('tools', 'NNS')\n",
      "('Not', 'RB')\n",
      "('logged', 'VBN')\n",
      "('in', 'IN')\n",
      "(GPE Talk/NNP)\n",
      "('Contributions', 'NNP')\n",
      "('Create', 'NNP')\n",
      "('account', 'NN')\n",
      "('Log', 'NNP')\n",
      "('in', 'IN')\n",
      "(GPE Namespaces/NNP)\n",
      "('Article', 'NNP')\n",
      "('Talk', 'NNP')\n",
      "('Variants', 'NNP')\n",
      "('expanded', 'VBD')\n",
      "('collapsed', 'JJ')\n",
      "(PERSON Views/NNP Read/NNP Edit/NNP View/NNP)\n",
      "('history', 'NN')\n",
      "(PERSON More/NNP)\n",
      "('expanded', 'VBD')\n",
      "('collapsed', 'VBN')\n",
      "(PERSON Search/NNP Navigation/NNP Main/NNP)\n",
      "('page', 'NN')\n",
      "(ORGANIZATION Contents/NNP)\n",
      "('Current', 'NNP')\n",
      "('events', 'NNS')\n",
      "(PERSON Random/NNP)\n",
      "('article', 'NN')\n",
      "('About', 'IN')\n",
      "(PERSON Wikipedia/NNP Contact/NNP)\n",
      "('us', 'PRP')\n",
      "(ORGANIZATION Donate/NNP Contribute/NNP Help/NNP Learn/NNP)\n",
      "('to', 'TO')\n",
      "('edit', 'VB')\n",
      "(ORGANIZATION Community/NNP)\n",
      "('portal', 'JJ')\n",
      "('Recent', 'NNP')\n",
      "('changes', 'NNS')\n",
      "(PERSON Upload/NNP)\n",
      "('file', 'NN')\n",
      "('Tools', 'NNP')\n",
      "('What', 'WP')\n",
      "('links', 'VBZ')\n",
      "('here', 'RB')\n",
      "('Related', 'VBN')\n",
      "('changes', 'NNS')\n",
      "(PERSON Upload/NNP)\n",
      "('file', 'NN')\n",
      "('Special', 'NNP')\n",
      "('pages', 'NNS')\n",
      "('Permanent', 'NNP')\n",
      "('link', 'NN')\n",
      "('Page', 'NNP')\n",
      "('information', 'NN')\n",
      "('Cite', 'NNP')\n",
      "('this', 'DT')\n",
      "('page', 'NN')\n",
      "(PERSON Wikidata/NNP)\n",
      "('item', 'NN')\n",
      "(PERSON Print/NNP)\n",
      "('/', 'NNP')\n",
      "('export', 'NN')\n",
      "('Download', 'NNP')\n",
      "('as', 'IN')\n",
      "(ORGANIZATION PDF/NNP)\n",
      "('Printable', 'NNP')\n",
      "('version', 'NN')\n",
      "('In', 'IN')\n",
      "('other', 'JJ')\n",
      "('projects', 'NNS')\n",
      "(PERSON Wikimedia/NNP Commons/NNP Languages/NNP Afrikaans/NNP)\n",
      "(ORGANIZATION العربية/NNP Azərbaycanca/NNP)\n",
      "('ব', 'NNP')\n",
      "('াং', 'NNP')\n",
      "('ল', 'NNP')\n",
      "('া', 'NNP')\n",
      "('Bân', 'NNP')\n",
      "('-', ':')\n",
      "('lâm', 'NN')\n",
      "('-', ':')\n",
      "('gú', 'NN')\n",
      "(PERSON Беларуская/NN Беларуская/NNP)\n",
      "('(', '(')\n",
      "('тарашкевіца', 'NNP')\n",
      "(')', ')')\n",
      "('Български', 'VBP')\n",
      "(PERSON\n",
      "  Català/NNP\n",
      "  Čeština/NNP\n",
      "  Dansk/NNP\n",
      "  Deutsch/NNP\n",
      "  Eesti/NNP\n",
      "  Ελληνικά/NNP\n",
      "  Español/NNP\n",
      "  Euskara/NNP)\n",
      "('فارسی', 'NNP')\n",
      "('Français', 'NNP')\n",
      "(PERSON Galego/NNP 한국어/NNP Հայերեն/NNP)\n",
      "('ह', 'NNP')\n",
      "('ि', 'NNP')\n",
      "('न', 'NNP')\n",
      "('्', 'NNP')\n",
      "('द', 'NNP')\n",
      "('ी', 'NNP')\n",
      "(PERSON\n",
      "  Hrvatski/NNP\n",
      "  Bahasa/NNP\n",
      "  Indonesia/NNP\n",
      "  Íslenska/NNP\n",
      "  Italiano/NNP)\n",
      "('עברית', 'NNP')\n",
      "('ಕನ', 'NNP')\n",
      "('್', 'NNP')\n",
      "('ನಡ', 'NNP')\n",
      "('ქართული', 'NNP')\n",
      "('Lietuvių', 'NNP')\n",
      "('Македонски', 'NNP')\n",
      "('मर', 'NNP')\n",
      "('ा', 'NNP')\n",
      "('ठ', 'NNP')\n",
      "('ी', 'NNP')\n",
      "('مصرى', 'NNP')\n",
      "(PERSON Монгол/NNP)\n",
      "('မ', 'NNP')\n",
      "('ြ', 'NNP')\n",
      "('န', 'NNP')\n",
      "('်', 'NNP')\n",
      "('မ', 'NNP')\n",
      "('ာ', 'NNP')\n",
      "('ဘ', 'NNP')\n",
      "('ာ', 'NNP')\n",
      "('သ', 'NNP')\n",
      "('ာ', 'NNP')\n",
      "('日本語', 'NNP')\n",
      "('ଓଡ', 'NNP')\n",
      "('଼ି', 'NNP')\n",
      "('ଆ', 'NNP')\n",
      "('Piemontèis', 'NNP')\n",
      "('Polski', 'NNP')\n",
      "(PERSON Português/NNP Română/NNP Русский/NNP Simple/NNP English/NNP)\n",
      "('کوردی', 'NNP')\n",
      "(PERSON Српски/NNP)\n",
      "('/', 'NNP')\n",
      "('srpski', 'VBD')\n",
      "(PERSON Srpskohrvatski/NNP)\n",
      "('/', 'NNP')\n",
      "('српскохрватски', 'NNP')\n",
      "('Suomi', 'NNP')\n",
      "('தம', 'NNP')\n",
      "('ி', 'NNP')\n",
      "('ழ', 'NNP')\n",
      "('்', 'NNP')\n",
      "('ไทย', 'NNP')\n",
      "(PERSON\n",
      "  Türkçe/NNP\n",
      "  Українська/NNP\n",
      "  Tiếng/NNP\n",
      "  Việt/NNP\n",
      "  粵語/NNP\n",
      "  中文/NNP\n",
      "  Edit/NNP)\n",
      "('links', 'VBZ')\n",
      "('This', 'DT')\n",
      "('page', 'NN')\n",
      "('was', 'VBD')\n",
      "('last', 'JJ')\n",
      "('edited', 'VBN')\n",
      "('on', 'IN')\n",
      "('7', 'CD')\n",
      "('October', 'NNP')\n",
      "('2021', 'CD')\n",
      "(',', ',')\n",
      "('at', 'IN')\n",
      "('01', 'CD')\n",
      "(':', ':')\n",
      "('56', 'CD')\n",
      "('(', '(')\n",
      "(ORGANIZATION UTC/NNP)\n",
      "(')', ')')\n",
      "('.', '.')\n",
      "(PERSON Text/NN)\n",
      "('is', 'VBZ')\n",
      "('available', 'JJ')\n",
      "('under', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Creative/JJ Commons/NNPS Attribution/NNP)\n",
      "('-', ':')\n",
      "(ORGANIZATION ShareAlike/NNP License/NNP)\n",
      "(';', ':')\n",
      "('additional', 'JJ')\n",
      "('terms', 'NNS')\n",
      "('may', 'MD')\n",
      "('apply', 'VB')\n",
      "('.', '.')\n",
      "('By', 'IN')\n",
      "('using', 'VBG')\n",
      "('this', 'DT')\n",
      "('site', 'NN')\n",
      "(',', ',')\n",
      "('you', 'PRP')\n",
      "('agree', 'VBP')\n",
      "('to', 'TO')\n",
      "('the', 'DT')\n",
      "('Terms', 'NNS')\n",
      "('of', 'IN')\n",
      "(ORGANIZATION Use/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Privacy/NNP Policy/NNP)\n",
      "('.', '.')\n",
      "(PERSON Wikipedia/NNP)\n",
      "('®', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('a', 'DT')\n",
      "('registered', 'JJ')\n",
      "('trademark', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "(ORGANIZATION Wikimedia/NNP Foundation/NNP)\n",
      "(',', ',')\n",
      "(PERSON Inc/NNP)\n",
      "('.', '.')\n",
      "(',', ',')\n",
      "('a', 'DT')\n",
      "('non', 'JJ')\n",
      "('-', ':')\n",
      "('profit', 'NN')\n",
      "('organization', 'NN')\n",
      "('.', '.')\n",
      "('Privacy', 'NN')\n",
      "('policy', 'NN')\n",
      "('About', 'IN')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON\n",
      "  Wikipedia/NNP\n",
      "  Disclaimers/NNP\n",
      "  Contact/NNP\n",
      "  Wikipedia/NNP\n",
      "  Mobile/NNP)\n",
      "('view', 'NN')\n",
      "(ORGANIZATION Developers/NNP Statistics/NNPS Cookie/NNP)\n",
      "('statement', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# called the perform_NER to do name entity recognition\n",
    "ner_tree = perform_NER(text)\n",
    "for i in ner_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9d537d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', '-')\n",
      "('processing', '-', 'Wikipedia')\n",
      "('-', 'Wikipedia', 'Natural')\n",
      "('Wikipedia', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', 'From')\n",
      "('processing', 'From', 'Wikipedia,')\n",
      "('From', 'Wikipedia,', 'the')\n",
      "('Wikipedia,', 'the', 'free')\n",
      "('the', 'free', 'encyclopedia')\n",
      "('free', 'encyclopedia', 'Jump')\n",
      "('encyclopedia', 'Jump', 'to')\n",
      "('Jump', 'to', 'navigation')\n",
      "('to', 'navigation', 'Jump')\n",
      "('navigation', 'Jump', 'to')\n",
      "('Jump', 'to', 'search')\n",
      "('to', 'search', 'This')\n",
      "('search', 'This', 'article')\n",
      "('This', 'article', 'is')\n",
      "('article', 'is', 'about')\n",
      "('is', 'about', 'natural')\n",
      "('about', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'done')\n",
      "('processing', 'done', 'by')\n",
      "('done', 'by', 'computers.')\n",
      "('by', 'computers.', 'For')\n",
      "('computers.', 'For', 'the')\n",
      "('For', 'the', 'natural')\n",
      "('the', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'done')\n",
      "('processing', 'done', 'by')\n",
      "('done', 'by', 'the')\n",
      "('by', 'the', 'human')\n",
      "('the', 'human', 'brain,')\n",
      "('human', 'brain,', 'see')\n",
      "('brain,', 'see', 'Language')\n",
      "('see', 'Language', 'processing')\n",
      "('Language', 'processing', 'in')\n",
      "('processing', 'in', 'the')\n",
      "('in', 'the', 'brain')\n",
      "('the', 'brain', '.')\n",
      "('brain', '.', 'Field')\n",
      "('.', 'Field', 'of')\n",
      "('Field', 'of', 'computer')\n",
      "('of', 'computer', 'science')\n",
      "('computer', 'science', 'and')\n",
      "('science', 'and', 'linguistics')\n",
      "('and', 'linguistics', 'An')\n",
      "('linguistics', 'An', 'automated')\n",
      "('An', 'automated', 'online')\n",
      "('automated', 'online', 'assistant')\n",
      "('online', 'assistant', 'providing')\n",
      "('assistant', 'providing', 'customer')\n",
      "('providing', 'customer', 'service')\n",
      "('customer', 'service', 'on')\n",
      "('service', 'on', 'a')\n",
      "('on', 'a', 'web')\n",
      "('a', 'web', 'page,')\n",
      "('web', 'page,', 'an')\n",
      "('page,', 'an', 'example')\n",
      "('an', 'example', 'of')\n",
      "('example', 'of', 'an')\n",
      "('of', 'an', 'application')\n",
      "('an', 'application', 'where')\n",
      "('application', 'where', 'natural')\n",
      "('where', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'is')\n",
      "('processing', 'is', 'a')\n",
      "('is', 'a', 'major')\n",
      "('a', 'major', 'component.')\n",
      "('major', 'component.', '[1]')\n",
      "('component.', '[1]', 'Natural')\n",
      "('[1]', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', '(')\n",
      "('processing', '(', 'NLP')\n",
      "('(', 'NLP', ')')\n",
      "('NLP', ')', 'is')\n",
      "(')', 'is', 'a')\n",
      "('is', 'a', 'subfield')\n",
      "('a', 'subfield', 'of')\n",
      "('subfield', 'of', 'linguistics')\n",
      "('of', 'linguistics', ',')\n",
      "('linguistics', ',', 'computer')\n",
      "(',', 'computer', 'science')\n",
      "('computer', 'science', ',')\n",
      "('science', ',', 'and')\n",
      "(',', 'and', 'artificial')\n",
      "('and', 'artificial', 'intelligence')\n",
      "('artificial', 'intelligence', 'concerned')\n",
      "('intelligence', 'concerned', 'with')\n",
      "('concerned', 'with', 'the')\n",
      "('with', 'the', 'interactions')\n",
      "('the', 'interactions', 'between')\n",
      "('interactions', 'between', 'computers')\n",
      "('between', 'computers', 'and')\n",
      "('computers', 'and', 'human')\n",
      "('and', 'human', 'language,')\n",
      "('human', 'language,', 'in')\n",
      "('language,', 'in', 'particular')\n",
      "('in', 'particular', 'how')\n",
      "('particular', 'how', 'to')\n",
      "('how', 'to', 'program')\n",
      "('to', 'program', 'computers')\n",
      "('program', 'computers', 'to')\n",
      "('computers', 'to', 'process')\n",
      "('to', 'process', 'and')\n",
      "('process', 'and', 'analyze')\n",
      "('and', 'analyze', 'large')\n",
      "('analyze', 'large', 'amounts')\n",
      "('large', 'amounts', 'of')\n",
      "('amounts', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'data.')\n",
      "('language', 'data.', 'The')\n",
      "('data.', 'The', 'goal')\n",
      "('The', 'goal', 'is')\n",
      "('goal', 'is', 'a')\n",
      "('is', 'a', 'computer')\n",
      "('a', 'computer', 'capable')\n",
      "('computer', 'capable', 'of')\n",
      "('capable', 'of', '\"understanding\"')\n",
      "('of', '\"understanding\"', 'the')\n",
      "('\"understanding\"', 'the', 'contents')\n",
      "('the', 'contents', 'of')\n",
      "('contents', 'of', 'documents,')\n",
      "('of', 'documents,', 'including')\n",
      "('documents,', 'including', 'the')\n",
      "('including', 'the', 'contextual')\n",
      "('the', 'contextual', 'nuances')\n",
      "('contextual', 'nuances', 'of')\n",
      "('nuances', 'of', 'the')\n",
      "('of', 'the', 'language')\n",
      "('the', 'language', 'within')\n",
      "('language', 'within', 'them.')\n",
      "('within', 'them.', 'The')\n",
      "('them.', 'The', 'technology')\n",
      "('The', 'technology', 'can')\n",
      "('technology', 'can', 'then')\n",
      "('can', 'then', 'accurately')\n",
      "('then', 'accurately', 'extract')\n",
      "('accurately', 'extract', 'information')\n",
      "('extract', 'information', 'and')\n",
      "('information', 'and', 'insights')\n",
      "('and', 'insights', 'contained')\n",
      "('insights', 'contained', 'in')\n",
      "('contained', 'in', 'the')\n",
      "('in', 'the', 'documents')\n",
      "('the', 'documents', 'as')\n",
      "('documents', 'as', 'well')\n",
      "('as', 'well', 'as')\n",
      "('well', 'as', 'categorize')\n",
      "('as', 'categorize', 'and')\n",
      "('categorize', 'and', 'organize')\n",
      "('and', 'organize', 'the')\n",
      "('organize', 'the', 'documents')\n",
      "('the', 'documents', 'themselves.')\n",
      "('documents', 'themselves.', 'Challenges')\n",
      "('themselves.', 'Challenges', 'in')\n",
      "('Challenges', 'in', 'natural')\n",
      "('in', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'frequently')\n",
      "('processing', 'frequently', 'involve')\n",
      "('frequently', 'involve', 'speech')\n",
      "('involve', 'speech', 'recognition')\n",
      "('speech', 'recognition', ',')\n",
      "('recognition', ',', 'natural')\n",
      "(',', 'natural', 'language')\n",
      "('natural', 'language', 'understanding')\n",
      "('language', 'understanding', ',')\n",
      "('understanding', ',', 'and')\n",
      "(',', 'and', 'natural')\n",
      "('and', 'natural', 'language')\n",
      "('natural', 'language', 'generation')\n",
      "('language', 'generation', '.')\n",
      "('generation', '.', 'Contents')\n",
      "('.', 'Contents', '1')\n",
      "('Contents', '1', 'History')\n",
      "('1', 'History', '1.1')\n",
      "('History', '1.1', 'Symbolic')\n",
      "('1.1', 'Symbolic', 'NLP')\n",
      "('Symbolic', 'NLP', '(1950s')\n",
      "('NLP', '(1950s', '–')\n",
      "('(1950s', '–', 'early')\n",
      "('–', 'early', '1990s)')\n",
      "('early', '1990s)', '1.2')\n",
      "('1990s)', '1.2', 'Statistical')\n",
      "('1.2', 'Statistical', 'NLP')\n",
      "('Statistical', 'NLP', '(1990s–2010s)')\n",
      "('NLP', '(1990s–2010s)', '1.3')\n",
      "('(1990s–2010s)', '1.3', 'Neural')\n",
      "('1.3', 'Neural', 'NLP')\n",
      "('Neural', 'NLP', '(present)')\n",
      "('NLP', '(present)', '2')\n",
      "('(present)', '2', 'Methods:')\n",
      "('2', 'Methods:', 'Rules,')\n",
      "('Methods:', 'Rules,', 'statistics,')\n",
      "('Rules,', 'statistics,', 'neural')\n",
      "('statistics,', 'neural', 'networks')\n",
      "('neural', 'networks', '2.1')\n",
      "('networks', '2.1', 'Statistical')\n",
      "('2.1', 'Statistical', 'methods')\n",
      "('Statistical', 'methods', '2.2')\n",
      "('methods', '2.2', 'Neural')\n",
      "('2.2', 'Neural', 'networks')\n",
      "('Neural', 'networks', '3')\n",
      "('networks', '3', 'Common')\n",
      "('3', 'Common', 'NLP')\n",
      "('Common', 'NLP', 'tasks')\n",
      "('NLP', 'tasks', '3.1')\n",
      "('tasks', '3.1', 'Text')\n",
      "('3.1', 'Text', 'and')\n",
      "('Text', 'and', 'speech')\n",
      "('and', 'speech', 'processing')\n",
      "('speech', 'processing', '3.2')\n",
      "('processing', '3.2', 'Morphological')\n",
      "('3.2', 'Morphological', 'analysis')\n",
      "('Morphological', 'analysis', '3.3')\n",
      "('analysis', '3.3', 'Syntactic')\n",
      "('3.3', 'Syntactic', 'analysis')\n",
      "('Syntactic', 'analysis', '3.4')\n",
      "('analysis', '3.4', 'Lexical')\n",
      "('3.4', 'Lexical', 'semantics')\n",
      "('Lexical', 'semantics', '(of')\n",
      "('semantics', '(of', 'individual')\n",
      "('(of', 'individual', 'words')\n",
      "('individual', 'words', 'in')\n",
      "('words', 'in', 'context)')\n",
      "('in', 'context)', '3.5')\n",
      "('context)', '3.5', 'Relational')\n",
      "('3.5', 'Relational', 'semantics')\n",
      "('Relational', 'semantics', '(semantics')\n",
      "('semantics', '(semantics', 'of')\n",
      "('(semantics', 'of', 'individual')\n",
      "('of', 'individual', 'sentences)')\n",
      "('individual', 'sentences)', '3.6')\n",
      "('sentences)', '3.6', 'Discourse')\n",
      "('3.6', 'Discourse', '(semantics')\n",
      "('Discourse', '(semantics', 'beyond')\n",
      "('(semantics', 'beyond', 'individual')\n",
      "('beyond', 'individual', 'sentences)')\n",
      "('individual', 'sentences)', '3.7')\n",
      "('sentences)', '3.7', 'Higher-level')\n",
      "('3.7', 'Higher-level', 'NLP')\n",
      "('Higher-level', 'NLP', 'applications')\n",
      "('NLP', 'applications', '4')\n",
      "('applications', '4', 'General')\n",
      "('4', 'General', 'tendencies')\n",
      "('General', 'tendencies', 'and')\n",
      "('tendencies', 'and', '(possible)')\n",
      "('and', '(possible)', 'future')\n",
      "('(possible)', 'future', 'directions')\n",
      "('future', 'directions', '4.1')\n",
      "('directions', '4.1', 'Cognition')\n",
      "('4.1', 'Cognition', 'and')\n",
      "('Cognition', 'and', 'NLP')\n",
      "('and', 'NLP', '5')\n",
      "('NLP', '5', 'See')\n",
      "('5', 'See', 'also')\n",
      "('See', 'also', '6')\n",
      "('also', '6', 'References')\n",
      "('6', 'References', '7')\n",
      "('References', '7', 'Further')\n",
      "('7', 'Further', 'reading')\n",
      "('Further', 'reading', '8')\n",
      "('reading', '8', 'External')\n",
      "('8', 'External', 'link')\n",
      "('External', 'link', 'History')\n",
      "('link', 'History', '[')\n",
      "('History', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Further')\n",
      "(']', 'Further', 'information:')\n",
      "('Further', 'information:', 'History')\n",
      "('information:', 'History', 'of')\n",
      "('History', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'Natural')\n",
      "('processing', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', 'has')\n",
      "('processing', 'has', 'its')\n",
      "('has', 'its', 'roots')\n",
      "('its', 'roots', 'in')\n",
      "('roots', 'in', 'the')\n",
      "('in', 'the', '1950s.')\n",
      "('the', '1950s.', 'Already')\n",
      "('1950s.', 'Already', 'in')\n",
      "('Already', 'in', '1950,')\n",
      "('in', '1950,', 'Alan')\n",
      "('1950,', 'Alan', 'Turing')\n",
      "('Alan', 'Turing', 'published')\n",
      "('Turing', 'published', 'an')\n",
      "('published', 'an', 'article')\n",
      "('an', 'article', 'titled')\n",
      "('article', 'titled', '\"')\n",
      "('titled', '\"', 'Computing')\n",
      "('\"', 'Computing', 'Machinery')\n",
      "('Computing', 'Machinery', 'and')\n",
      "('Machinery', 'and', 'Intelligence')\n",
      "('and', 'Intelligence', '\"')\n",
      "('Intelligence', '\"', 'which')\n",
      "('\"', 'which', 'proposed')\n",
      "('which', 'proposed', 'what')\n",
      "('proposed', 'what', 'is')\n",
      "('what', 'is', 'now')\n",
      "('is', 'now', 'called')\n",
      "('now', 'called', 'the')\n",
      "('called', 'the', 'Turing')\n",
      "('the', 'Turing', 'test')\n",
      "('Turing', 'test', 'as')\n",
      "('test', 'as', 'a')\n",
      "('as', 'a', 'criterion')\n",
      "('a', 'criterion', 'of')\n",
      "('criterion', 'of', 'intelligence,')\n",
      "('of', 'intelligence,', 'a')\n",
      "('intelligence,', 'a', 'task')\n",
      "('a', 'task', 'that')\n",
      "('task', 'that', 'involves')\n",
      "('that', 'involves', 'the')\n",
      "('involves', 'the', 'automated')\n",
      "('the', 'automated', 'interpretation')\n",
      "('automated', 'interpretation', 'and')\n",
      "('interpretation', 'and', 'generation')\n",
      "('and', 'generation', 'of')\n",
      "('generation', 'of', 'natural')\n",
      "('of', 'natural', 'language,')\n",
      "('natural', 'language,', 'but')\n",
      "('language,', 'but', 'at')\n",
      "('but', 'at', 'the')\n",
      "('at', 'the', 'time')\n",
      "('the', 'time', 'not')\n",
      "('time', 'not', 'articulated')\n",
      "('not', 'articulated', 'as')\n",
      "('articulated', 'as', 'a')\n",
      "('as', 'a', 'problem')\n",
      "('a', 'problem', 'separate')\n",
      "('problem', 'separate', 'from')\n",
      "('separate', 'from', 'artificial')\n",
      "('from', 'artificial', 'intelligence.')\n",
      "('artificial', 'intelligence.', 'Symbolic')\n",
      "('intelligence.', 'Symbolic', 'NLP')\n",
      "('Symbolic', 'NLP', '(1950s')\n",
      "('NLP', '(1950s', '–')\n",
      "('(1950s', '–', 'early')\n",
      "('–', 'early', '1990s)')\n",
      "('early', '1990s)', '[')\n",
      "('1990s)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'The')\n",
      "(']', 'The', 'premise')\n",
      "('The', 'premise', 'of')\n",
      "('premise', 'of', 'symbolic')\n",
      "('of', 'symbolic', 'NLP')\n",
      "('symbolic', 'NLP', 'is')\n",
      "('NLP', 'is', 'well-summarized')\n",
      "('is', 'well-summarized', 'by')\n",
      "('well-summarized', 'by', 'John')\n",
      "('by', 'John', 'Searle')\n",
      "('John', 'Searle', \"'s\")\n",
      "('Searle', \"'s\", 'Chinese')\n",
      "(\"'s\", 'Chinese', 'room')\n",
      "('Chinese', 'room', 'experiment:')\n",
      "('room', 'experiment:', 'Given')\n",
      "('experiment:', 'Given', 'a')\n",
      "('Given', 'a', 'collection')\n",
      "('a', 'collection', 'of')\n",
      "('collection', 'of', 'rules')\n",
      "('of', 'rules', '(e.g.,')\n",
      "('rules', '(e.g.,', 'a')\n",
      "('(e.g.,', 'a', 'Chinese')\n",
      "('a', 'Chinese', 'phrasebook,')\n",
      "('Chinese', 'phrasebook,', 'with')\n",
      "('phrasebook,', 'with', 'questions')\n",
      "('with', 'questions', 'and')\n",
      "('questions', 'and', 'matching')\n",
      "('and', 'matching', 'answers),')\n",
      "('matching', 'answers),', 'the')\n",
      "('answers),', 'the', 'computer')\n",
      "('the', 'computer', 'emulates')\n",
      "('computer', 'emulates', 'natural')\n",
      "('emulates', 'natural', 'language')\n",
      "('natural', 'language', 'understanding')\n",
      "('language', 'understanding', '(or')\n",
      "('understanding', '(or', 'other')\n",
      "('(or', 'other', 'NLP')\n",
      "('other', 'NLP', 'tasks)')\n",
      "('NLP', 'tasks)', 'by')\n",
      "('tasks)', 'by', 'applying')\n",
      "('by', 'applying', 'those')\n",
      "('applying', 'those', 'rules')\n",
      "('those', 'rules', 'to')\n",
      "('rules', 'to', 'the')\n",
      "('to', 'the', 'data')\n",
      "('the', 'data', 'it')\n",
      "('data', 'it', 'is')\n",
      "('it', 'is', 'confronted')\n",
      "('is', 'confronted', 'with.')\n",
      "('confronted', 'with.', '1950s')\n",
      "('with.', '1950s', ':')\n",
      "('1950s', ':', 'The')\n",
      "(':', 'The', 'Georgetown')\n",
      "('The', 'Georgetown', 'experiment')\n",
      "('Georgetown', 'experiment', 'in')\n",
      "('experiment', 'in', '1954')\n",
      "('in', '1954', 'involved')\n",
      "('1954', 'involved', 'fully')\n",
      "('involved', 'fully', 'automatic')\n",
      "('fully', 'automatic', 'translation')\n",
      "('automatic', 'translation', 'of')\n",
      "('translation', 'of', 'more')\n",
      "('of', 'more', 'than')\n",
      "('more', 'than', 'sixty')\n",
      "('than', 'sixty', 'Russian')\n",
      "('sixty', 'Russian', 'sentences')\n",
      "('Russian', 'sentences', 'into')\n",
      "('sentences', 'into', 'English.')\n",
      "('into', 'English.', 'The')\n",
      "('English.', 'The', 'authors')\n",
      "('The', 'authors', 'claimed')\n",
      "('authors', 'claimed', 'that')\n",
      "('claimed', 'that', 'within')\n",
      "('that', 'within', 'three')\n",
      "('within', 'three', 'or')\n",
      "('three', 'or', 'five')\n",
      "('or', 'five', 'years,')\n",
      "('five', 'years,', 'machine')\n",
      "('years,', 'machine', 'translation')\n",
      "('machine', 'translation', 'would')\n",
      "('translation', 'would', 'be')\n",
      "('would', 'be', 'a')\n",
      "('be', 'a', 'solved')\n",
      "('a', 'solved', 'problem.')\n",
      "('solved', 'problem.', '[2]')\n",
      "('problem.', '[2]', 'However,')\n",
      "('[2]', 'However,', 'real')\n",
      "('However,', 'real', 'progress')\n",
      "('real', 'progress', 'was')\n",
      "('progress', 'was', 'much')\n",
      "('was', 'much', 'slower,')\n",
      "('much', 'slower,', 'and')\n",
      "('slower,', 'and', 'after')\n",
      "('and', 'after', 'the')\n",
      "('after', 'the', 'ALPAC')\n",
      "('the', 'ALPAC', 'report')\n",
      "('ALPAC', 'report', 'in')\n",
      "('report', 'in', '1966,')\n",
      "('in', '1966,', 'which')\n",
      "('1966,', 'which', 'found')\n",
      "('which', 'found', 'that')\n",
      "('found', 'that', 'ten-year-long')\n",
      "('that', 'ten-year-long', 'research')\n",
      "('ten-year-long', 'research', 'had')\n",
      "('research', 'had', 'failed')\n",
      "('had', 'failed', 'to')\n",
      "('failed', 'to', 'fulfill')\n",
      "('to', 'fulfill', 'the')\n",
      "('fulfill', 'the', 'expectations,')\n",
      "('the', 'expectations,', 'funding')\n",
      "('expectations,', 'funding', 'for')\n",
      "('funding', 'for', 'machine')\n",
      "('for', 'machine', 'translation')\n",
      "('machine', 'translation', 'was')\n",
      "('translation', 'was', 'dramatically')\n",
      "('was', 'dramatically', 'reduced.')\n",
      "('dramatically', 'reduced.', 'Little')\n",
      "('reduced.', 'Little', 'further')\n",
      "('Little', 'further', 'research')\n",
      "('further', 'research', 'in')\n",
      "('research', 'in', 'machine')\n",
      "('in', 'machine', 'translation')\n",
      "('machine', 'translation', 'was')\n",
      "('translation', 'was', 'conducted')\n",
      "('was', 'conducted', 'until')\n",
      "('conducted', 'until', 'the')\n",
      "('until', 'the', 'late')\n",
      "('the', 'late', '1980s')\n",
      "('late', '1980s', 'when')\n",
      "('1980s', 'when', 'the')\n",
      "('when', 'the', 'first')\n",
      "('the', 'first', 'statistical')\n",
      "('first', 'statistical', 'machine')\n",
      "('statistical', 'machine', 'translation')\n",
      "('machine', 'translation', 'systems')\n",
      "('translation', 'systems', 'were')\n",
      "('systems', 'were', 'developed.')\n",
      "('were', 'developed.', '1960s')\n",
      "('developed.', '1960s', ':')\n",
      "('1960s', ':', 'Some')\n",
      "(':', 'Some', 'notably')\n",
      "('Some', 'notably', 'successful')\n",
      "('notably', 'successful', 'natural')\n",
      "('successful', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'systems')\n",
      "('processing', 'systems', 'developed')\n",
      "('systems', 'developed', 'in')\n",
      "('developed', 'in', 'the')\n",
      "('in', 'the', '1960s')\n",
      "('the', '1960s', 'were')\n",
      "('1960s', 'were', 'SHRDLU')\n",
      "('were', 'SHRDLU', ',')\n",
      "('SHRDLU', ',', 'a')\n",
      "(',', 'a', 'natural')\n",
      "('a', 'natural', 'language')\n",
      "('natural', 'language', 'system')\n",
      "('language', 'system', 'working')\n",
      "('system', 'working', 'in')\n",
      "('working', 'in', 'restricted')\n",
      "('in', 'restricted', '\"')\n",
      "('restricted', '\"', 'blocks')\n",
      "('\"', 'blocks', 'worlds')\n",
      "('blocks', 'worlds', '\"')\n",
      "('worlds', '\"', 'with')\n",
      "('\"', 'with', 'restricted')\n",
      "('with', 'restricted', 'vocabularies,')\n",
      "('restricted', 'vocabularies,', 'and')\n",
      "('vocabularies,', 'and', 'ELIZA')\n",
      "('and', 'ELIZA', ',')\n",
      "('ELIZA', ',', 'a')\n",
      "(',', 'a', 'simulation')\n",
      "('a', 'simulation', 'of')\n",
      "('simulation', 'of', 'a')\n",
      "('of', 'a', 'Rogerian')\n",
      "('a', 'Rogerian', 'psychotherapist')\n",
      "('Rogerian', 'psychotherapist', ',')\n",
      "('psychotherapist', ',', 'written')\n",
      "(',', 'written', 'by')\n",
      "('written', 'by', 'Joseph')\n",
      "('by', 'Joseph', 'Weizenbaum')\n",
      "('Joseph', 'Weizenbaum', 'between')\n",
      "('Weizenbaum', 'between', '1964')\n",
      "('between', '1964', 'and')\n",
      "('1964', 'and', '1966.')\n",
      "('and', '1966.', 'Using')\n",
      "('1966.', 'Using', 'almost')\n",
      "('Using', 'almost', 'no')\n",
      "('almost', 'no', 'information')\n",
      "('no', 'information', 'about')\n",
      "('information', 'about', 'human')\n",
      "('about', 'human', 'thought')\n",
      "('human', 'thought', 'or')\n",
      "('thought', 'or', 'emotion,')\n",
      "('or', 'emotion,', 'ELIZA')\n",
      "('emotion,', 'ELIZA', 'sometimes')\n",
      "('ELIZA', 'sometimes', 'provided')\n",
      "('sometimes', 'provided', 'a')\n",
      "('provided', 'a', 'startlingly')\n",
      "('a', 'startlingly', 'human-like')\n",
      "('startlingly', 'human-like', 'interaction.')\n",
      "('human-like', 'interaction.', 'When')\n",
      "('interaction.', 'When', 'the')\n",
      "('When', 'the', '\"patient\"')\n",
      "('the', '\"patient\"', 'exceeded')\n",
      "('\"patient\"', 'exceeded', 'the')\n",
      "('exceeded', 'the', 'very')\n",
      "('the', 'very', 'small')\n",
      "('very', 'small', 'knowledge')\n",
      "('small', 'knowledge', 'base,')\n",
      "('knowledge', 'base,', 'ELIZA')\n",
      "('base,', 'ELIZA', 'might')\n",
      "('ELIZA', 'might', 'provide')\n",
      "('might', 'provide', 'a')\n",
      "('provide', 'a', 'generic')\n",
      "('a', 'generic', 'response,')\n",
      "('generic', 'response,', 'for')\n",
      "('response,', 'for', 'example,')\n",
      "('for', 'example,', 'responding')\n",
      "('example,', 'responding', 'to')\n",
      "('responding', 'to', '\"My')\n",
      "('to', '\"My', 'head')\n",
      "('\"My', 'head', 'hurts\"')\n",
      "('head', 'hurts\"', 'with')\n",
      "('hurts\"', 'with', '\"Why')\n",
      "('with', '\"Why', 'do')\n",
      "('\"Why', 'do', 'you')\n",
      "('do', 'you', 'say')\n",
      "('you', 'say', 'your')\n",
      "('say', 'your', 'head')\n",
      "('your', 'head', 'hurts?\".')\n",
      "('head', 'hurts?\".', '1970s')\n",
      "('hurts?\".', '1970s', ':')\n",
      "('1970s', ':', 'During')\n",
      "(':', 'During', 'the')\n",
      "('During', 'the', '1970s,')\n",
      "('the', '1970s,', 'many')\n",
      "('1970s,', 'many', 'programmers')\n",
      "('many', 'programmers', 'began')\n",
      "('programmers', 'began', 'to')\n",
      "('began', 'to', 'write')\n",
      "('to', 'write', '\"conceptual')\n",
      "('write', '\"conceptual', 'ontologies')\n",
      "('\"conceptual', 'ontologies', '\",')\n",
      "('ontologies', '\",', 'which')\n",
      "('\",', 'which', 'structured')\n",
      "('which', 'structured', 'real-world')\n",
      "('structured', 'real-world', 'information')\n",
      "('real-world', 'information', 'into')\n",
      "('information', 'into', 'computer-understandable')\n",
      "('into', 'computer-understandable', 'data.')\n",
      "('computer-understandable', 'data.', 'Examples')\n",
      "('data.', 'Examples', 'are')\n",
      "('Examples', 'are', 'MARGIE')\n",
      "('are', 'MARGIE', '(Schank,')\n",
      "('MARGIE', '(Schank,', '1975),')\n",
      "('(Schank,', '1975),', 'SAM')\n",
      "('1975),', 'SAM', '(Cullingford,')\n",
      "('SAM', '(Cullingford,', '1978),')\n",
      "('(Cullingford,', '1978),', 'PAM')\n",
      "('1978),', 'PAM', '(Wilensky,')\n",
      "('PAM', '(Wilensky,', '1978),')\n",
      "('(Wilensky,', '1978),', 'TaleSpin')\n",
      "('1978),', 'TaleSpin', '(Meehan,')\n",
      "('TaleSpin', '(Meehan,', '1976),')\n",
      "('(Meehan,', '1976),', 'QUALM')\n",
      "('1976),', 'QUALM', '(Lehnert,')\n",
      "('QUALM', '(Lehnert,', '1977),')\n",
      "('(Lehnert,', '1977),', 'Politics')\n",
      "('1977),', 'Politics', '(Carbonell,')\n",
      "('Politics', '(Carbonell,', '1979),')\n",
      "('(Carbonell,', '1979),', 'and')\n",
      "('1979),', 'and', 'Plot')\n",
      "('and', 'Plot', 'Units')\n",
      "('Plot', 'Units', '(Lehnert')\n",
      "('Units', '(Lehnert', '1981).')\n",
      "('(Lehnert', '1981).', 'During')\n",
      "('1981).', 'During', 'this')\n",
      "('During', 'this', 'time,')\n",
      "('this', 'time,', 'the')\n",
      "('time,', 'the', 'first')\n",
      "('the', 'first', 'many')\n",
      "('first', 'many', 'chatterbots')\n",
      "('many', 'chatterbots', 'were')\n",
      "('chatterbots', 'were', 'written')\n",
      "('were', 'written', '(e.g.,')\n",
      "('written', '(e.g.,', 'PARRY')\n",
      "('(e.g.,', 'PARRY', ').')\n",
      "('PARRY', ').', '1980s')\n",
      "(').', '1980s', ':')\n",
      "('1980s', ':', 'The')\n",
      "(':', 'The', '1980s')\n",
      "('The', '1980s', 'and')\n",
      "('1980s', 'and', 'early')\n",
      "('and', 'early', '1990s')\n",
      "('early', '1990s', 'mark')\n",
      "('1990s', 'mark', 'the')\n",
      "('mark', 'the', 'hey-day')\n",
      "('the', 'hey-day', 'of')\n",
      "('hey-day', 'of', 'symbolic')\n",
      "('of', 'symbolic', 'methods')\n",
      "('symbolic', 'methods', 'in')\n",
      "('methods', 'in', 'NLP.')\n",
      "('in', 'NLP.', 'Focus')\n",
      "('NLP.', 'Focus', 'areas')\n",
      "('Focus', 'areas', 'of')\n",
      "('areas', 'of', 'the')\n",
      "('of', 'the', 'time')\n",
      "('the', 'time', 'included')\n",
      "('time', 'included', 'research')\n",
      "('included', 'research', 'on')\n",
      "('research', 'on', 'rule-based')\n",
      "('on', 'rule-based', 'parsing')\n",
      "('rule-based', 'parsing', '(e.g.,')\n",
      "('parsing', '(e.g.,', 'the')\n",
      "('(e.g.,', 'the', 'development')\n",
      "('the', 'development', 'of')\n",
      "('development', 'of', 'HPSG')\n",
      "('of', 'HPSG', 'as')\n",
      "('HPSG', 'as', 'a')\n",
      "('as', 'a', 'computational')\n",
      "('a', 'computational', 'operationalization')\n",
      "('computational', 'operationalization', 'of')\n",
      "('operationalization', 'of', 'generative')\n",
      "('of', 'generative', 'grammar')\n",
      "('generative', 'grammar', '),')\n",
      "('grammar', '),', 'morphology')\n",
      "('),', 'morphology', '(e.g.,')\n",
      "('morphology', '(e.g.,', 'two-level')\n",
      "('(e.g.,', 'two-level', 'morphology')\n",
      "('two-level', 'morphology', '[3]')\n",
      "('morphology', '[3]', '),')\n",
      "('[3]', '),', 'semantics')\n",
      "('),', 'semantics', '(e.g.,')\n",
      "('semantics', '(e.g.,', 'Lesk')\n",
      "('(e.g.,', 'Lesk', 'algorithm')\n",
      "('Lesk', 'algorithm', '),')\n",
      "('algorithm', '),', 'reference')\n",
      "('),', 'reference', '(e.g.,')\n",
      "('reference', '(e.g.,', 'within')\n",
      "('(e.g.,', 'within', 'Centering')\n",
      "('within', 'Centering', 'Theory')\n",
      "('Centering', 'Theory', '[4]')\n",
      "('Theory', '[4]', ')')\n",
      "('[4]', ')', 'and')\n",
      "(')', 'and', 'other')\n",
      "('and', 'other', 'areas')\n",
      "('other', 'areas', 'of')\n",
      "('areas', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'understanding')\n",
      "('language', 'understanding', '(e.g.,')\n",
      "('understanding', '(e.g.,', 'in')\n",
      "('(e.g.,', 'in', 'the')\n",
      "('in', 'the', 'Rhetorical')\n",
      "('the', 'Rhetorical', 'Structure')\n",
      "('Rhetorical', 'Structure', 'Theory')\n",
      "('Structure', 'Theory', ').')\n",
      "('Theory', ').', 'Other')\n",
      "(').', 'Other', 'lines')\n",
      "('Other', 'lines', 'of')\n",
      "('lines', 'of', 'research')\n",
      "('of', 'research', 'were')\n",
      "('research', 'were', 'continued,')\n",
      "('were', 'continued,', 'e.g.,')\n",
      "('continued,', 'e.g.,', 'the')\n",
      "('e.g.,', 'the', 'development')\n",
      "('the', 'development', 'of')\n",
      "('development', 'of', 'chatterbots')\n",
      "('of', 'chatterbots', 'with')\n",
      "('chatterbots', 'with', 'Racter')\n",
      "('with', 'Racter', 'and')\n",
      "('Racter', 'and', 'Jabberwacky')\n",
      "('and', 'Jabberwacky', '.')\n",
      "('Jabberwacky', '.', 'An')\n",
      "('.', 'An', 'important')\n",
      "('An', 'important', 'development')\n",
      "('important', 'development', '(that')\n",
      "('development', '(that', 'eventually')\n",
      "('(that', 'eventually', 'led')\n",
      "('eventually', 'led', 'to')\n",
      "('led', 'to', 'the')\n",
      "('to', 'the', 'statistical')\n",
      "('the', 'statistical', 'turn')\n",
      "('statistical', 'turn', 'in')\n",
      "('turn', 'in', 'the')\n",
      "('in', 'the', '1990s)')\n",
      "('the', '1990s)', 'was')\n",
      "('1990s)', 'was', 'the')\n",
      "('was', 'the', 'rising')\n",
      "('the', 'rising', 'importance')\n",
      "('rising', 'importance', 'of')\n",
      "('importance', 'of', 'quantitative')\n",
      "('of', 'quantitative', 'evaluation')\n",
      "('quantitative', 'evaluation', 'in')\n",
      "('evaluation', 'in', 'this')\n",
      "('in', 'this', 'period.')\n",
      "('this', 'period.', '[5]')\n",
      "('period.', '[5]', 'Statistical')\n",
      "('[5]', 'Statistical', 'NLP')\n",
      "('Statistical', 'NLP', '(1990s–2010s)')\n",
      "('NLP', '(1990s–2010s)', '[')\n",
      "('(1990s–2010s)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Up')\n",
      "(']', 'Up', 'to')\n",
      "('Up', 'to', 'the')\n",
      "('to', 'the', '1980s,')\n",
      "('the', '1980s,', 'most')\n",
      "('1980s,', 'most', 'natural')\n",
      "('most', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'systems')\n",
      "('processing', 'systems', 'were')\n",
      "('systems', 'were', 'based')\n",
      "('were', 'based', 'on')\n",
      "('based', 'on', 'complex')\n",
      "('on', 'complex', 'sets')\n",
      "('complex', 'sets', 'of')\n",
      "('sets', 'of', 'hand-written')\n",
      "('of', 'hand-written', 'rules.')\n",
      "('hand-written', 'rules.', 'Starting')\n",
      "('rules.', 'Starting', 'in')\n",
      "('Starting', 'in', 'the')\n",
      "('in', 'the', 'late')\n",
      "('the', 'late', '1980s,')\n",
      "('late', '1980s,', 'however,')\n",
      "('1980s,', 'however,', 'there')\n",
      "('however,', 'there', 'was')\n",
      "('there', 'was', 'a')\n",
      "('was', 'a', 'revolution')\n",
      "('a', 'revolution', 'in')\n",
      "('revolution', 'in', 'natural')\n",
      "('in', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'with')\n",
      "('processing', 'with', 'the')\n",
      "('with', 'the', 'introduction')\n",
      "('the', 'introduction', 'of')\n",
      "('introduction', 'of', 'machine')\n",
      "('of', 'machine', 'learning')\n",
      "('machine', 'learning', 'algorithms')\n",
      "('learning', 'algorithms', 'for')\n",
      "('algorithms', 'for', 'language')\n",
      "('for', 'language', 'processing.')\n",
      "('language', 'processing.', 'This')\n",
      "('processing.', 'This', 'was')\n",
      "('This', 'was', 'due')\n",
      "('was', 'due', 'to')\n",
      "('due', 'to', 'both')\n",
      "('to', 'both', 'the')\n",
      "('both', 'the', 'steady')\n",
      "('the', 'steady', 'increase')\n",
      "('steady', 'increase', 'in')\n",
      "('increase', 'in', 'computational')\n",
      "('in', 'computational', 'power')\n",
      "('computational', 'power', '(see')\n",
      "('power', '(see', \"Moore's\")\n",
      "('(see', \"Moore's\", 'law')\n",
      "(\"Moore's\", 'law', ')')\n",
      "('law', ')', 'and')\n",
      "(')', 'and', 'the')\n",
      "('and', 'the', 'gradual')\n",
      "('the', 'gradual', 'lessening')\n",
      "('gradual', 'lessening', 'of')\n",
      "('lessening', 'of', 'the')\n",
      "('of', 'the', 'dominance')\n",
      "('the', 'dominance', 'of')\n",
      "('dominance', 'of', 'Chomskyan')\n",
      "('of', 'Chomskyan', 'theories')\n",
      "('Chomskyan', 'theories', 'of')\n",
      "('theories', 'of', 'linguistics')\n",
      "('of', 'linguistics', '(e.g.')\n",
      "('linguistics', '(e.g.', 'transformational')\n",
      "('(e.g.', 'transformational', 'grammar')\n",
      "('transformational', 'grammar', '),')\n",
      "('grammar', '),', 'whose')\n",
      "('),', 'whose', 'theoretical')\n",
      "('whose', 'theoretical', 'underpinnings')\n",
      "('theoretical', 'underpinnings', 'discouraged')\n",
      "('underpinnings', 'discouraged', 'the')\n",
      "('discouraged', 'the', 'sort')\n",
      "('the', 'sort', 'of')\n",
      "('sort', 'of', 'corpus')\n",
      "('of', 'corpus', 'linguistics')\n",
      "('corpus', 'linguistics', 'that')\n",
      "('linguistics', 'that', 'underlies')\n",
      "('that', 'underlies', 'the')\n",
      "('underlies', 'the', 'machine-learning')\n",
      "('the', 'machine-learning', 'approach')\n",
      "('machine-learning', 'approach', 'to')\n",
      "('approach', 'to', 'language')\n",
      "('to', 'language', 'processing.')\n",
      "('language', 'processing.', '[6]')\n",
      "('processing.', '[6]', '1990s')\n",
      "('[6]', '1990s', ':')\n",
      "('1990s', ':', 'Many')\n",
      "(':', 'Many', 'of')\n",
      "('Many', 'of', 'the')\n",
      "('of', 'the', 'notable')\n",
      "('the', 'notable', 'early')\n",
      "('notable', 'early', 'successes')\n",
      "('early', 'successes', 'on')\n",
      "('successes', 'on', 'statistical')\n",
      "('on', 'statistical', 'methods')\n",
      "('statistical', 'methods', 'in')\n",
      "('methods', 'in', 'NLP')\n",
      "('in', 'NLP', 'occurred')\n",
      "('NLP', 'occurred', 'in')\n",
      "('occurred', 'in', 'the')\n",
      "('in', 'the', 'field')\n",
      "('the', 'field', 'of')\n",
      "('field', 'of', 'machine')\n",
      "('of', 'machine', 'translation')\n",
      "('machine', 'translation', ',')\n",
      "('translation', ',', 'due')\n",
      "(',', 'due', 'especially')\n",
      "('due', 'especially', 'to')\n",
      "('especially', 'to', 'work')\n",
      "('to', 'work', 'at')\n",
      "('work', 'at', 'IBM')\n",
      "('at', 'IBM', 'Research.')\n",
      "('IBM', 'Research.', 'These')\n",
      "('Research.', 'These', 'systems')\n",
      "('These', 'systems', 'were')\n",
      "('systems', 'were', 'able')\n",
      "('were', 'able', 'to')\n",
      "('able', 'to', 'take')\n",
      "('to', 'take', 'advantage')\n",
      "('take', 'advantage', 'of')\n",
      "('advantage', 'of', 'existing')\n",
      "('of', 'existing', 'multilingual')\n",
      "('existing', 'multilingual', 'textual')\n",
      "('multilingual', 'textual', 'corpora')\n",
      "('textual', 'corpora', 'that')\n",
      "('corpora', 'that', 'had')\n",
      "('that', 'had', 'been')\n",
      "('had', 'been', 'produced')\n",
      "('been', 'produced', 'by')\n",
      "('produced', 'by', 'the')\n",
      "('by', 'the', 'Parliament')\n",
      "('the', 'Parliament', 'of')\n",
      "('Parliament', 'of', 'Canada')\n",
      "('of', 'Canada', 'and')\n",
      "('Canada', 'and', 'the')\n",
      "('and', 'the', 'European')\n",
      "('the', 'European', 'Union')\n",
      "('European', 'Union', 'as')\n",
      "('Union', 'as', 'a')\n",
      "('as', 'a', 'result')\n",
      "('a', 'result', 'of')\n",
      "('result', 'of', 'laws')\n",
      "('of', 'laws', 'calling')\n",
      "('laws', 'calling', 'for')\n",
      "('calling', 'for', 'the')\n",
      "('for', 'the', 'translation')\n",
      "('the', 'translation', 'of')\n",
      "('translation', 'of', 'all')\n",
      "('of', 'all', 'governmental')\n",
      "('all', 'governmental', 'proceedings')\n",
      "('governmental', 'proceedings', 'into')\n",
      "('proceedings', 'into', 'all')\n",
      "('into', 'all', 'official')\n",
      "('all', 'official', 'languages')\n",
      "('official', 'languages', 'of')\n",
      "('languages', 'of', 'the')\n",
      "('of', 'the', 'corresponding')\n",
      "('the', 'corresponding', 'systems')\n",
      "('corresponding', 'systems', 'of')\n",
      "('systems', 'of', 'government.')\n",
      "('of', 'government.', 'However,')\n",
      "('government.', 'However,', 'most')\n",
      "('However,', 'most', 'other')\n",
      "('most', 'other', 'systems')\n",
      "('other', 'systems', 'depended')\n",
      "('systems', 'depended', 'on')\n",
      "('depended', 'on', 'corpora')\n",
      "('on', 'corpora', 'specifically')\n",
      "('corpora', 'specifically', 'developed')\n",
      "('specifically', 'developed', 'for')\n",
      "('developed', 'for', 'the')\n",
      "('for', 'the', 'tasks')\n",
      "('the', 'tasks', 'implemented')\n",
      "('tasks', 'implemented', 'by')\n",
      "('implemented', 'by', 'these')\n",
      "('by', 'these', 'systems,')\n",
      "('these', 'systems,', 'which')\n",
      "('systems,', 'which', 'was')\n",
      "('which', 'was', '(and')\n",
      "('was', '(and', 'often')\n",
      "('(and', 'often', 'continues')\n",
      "('often', 'continues', 'to')\n",
      "('continues', 'to', 'be)')\n",
      "('to', 'be)', 'a')\n",
      "('be)', 'a', 'major')\n",
      "('a', 'major', 'limitation')\n",
      "('major', 'limitation', 'in')\n",
      "('limitation', 'in', 'the')\n",
      "('in', 'the', 'success')\n",
      "('the', 'success', 'of')\n",
      "('success', 'of', 'these')\n",
      "('of', 'these', 'systems.')\n",
      "('these', 'systems.', 'As')\n",
      "('systems.', 'As', 'a')\n",
      "('As', 'a', 'result,')\n",
      "('a', 'result,', 'a')\n",
      "('result,', 'a', 'great')\n",
      "('a', 'great', 'deal')\n",
      "('great', 'deal', 'of')\n",
      "('deal', 'of', 'research')\n",
      "('of', 'research', 'has')\n",
      "('research', 'has', 'gone')\n",
      "('has', 'gone', 'into')\n",
      "('gone', 'into', 'methods')\n",
      "('into', 'methods', 'of')\n",
      "('methods', 'of', 'more')\n",
      "('of', 'more', 'effectively')\n",
      "('more', 'effectively', 'learning')\n",
      "('effectively', 'learning', 'from')\n",
      "('learning', 'from', 'limited')\n",
      "('from', 'limited', 'amounts')\n",
      "('limited', 'amounts', 'of')\n",
      "('amounts', 'of', 'data.')\n",
      "('of', 'data.', '2000s')\n",
      "('data.', '2000s', ':')\n",
      "('2000s', ':', 'With')\n",
      "(':', 'With', 'the')\n",
      "('With', 'the', 'growth')\n",
      "('the', 'growth', 'of')\n",
      "('growth', 'of', 'the')\n",
      "('of', 'the', 'web,')\n",
      "('the', 'web,', 'increasing')\n",
      "('web,', 'increasing', 'amounts')\n",
      "('increasing', 'amounts', 'of')\n",
      "('amounts', 'of', 'raw')\n",
      "('of', 'raw', '(unannotated)')\n",
      "('raw', '(unannotated)', 'language')\n",
      "('(unannotated)', 'language', 'data')\n",
      "('language', 'data', 'has')\n",
      "('data', 'has', 'become')\n",
      "('has', 'become', 'available')\n",
      "('become', 'available', 'since')\n",
      "('available', 'since', 'the')\n",
      "('since', 'the', 'mid-1990s.')\n",
      "('the', 'mid-1990s.', 'Research')\n",
      "('mid-1990s.', 'Research', 'has')\n",
      "('Research', 'has', 'thus')\n",
      "('has', 'thus', 'increasingly')\n",
      "('thus', 'increasingly', 'focused')\n",
      "('increasingly', 'focused', 'on')\n",
      "('focused', 'on', 'unsupervised')\n",
      "('on', 'unsupervised', 'and')\n",
      "('unsupervised', 'and', 'semi-supervised')\n",
      "('and', 'semi-supervised', 'learning')\n",
      "('semi-supervised', 'learning', 'algorithms.')\n",
      "('learning', 'algorithms.', 'Such')\n",
      "('algorithms.', 'Such', 'algorithms')\n",
      "('Such', 'algorithms', 'can')\n",
      "('algorithms', 'can', 'learn')\n",
      "('can', 'learn', 'from')\n",
      "('learn', 'from', 'data')\n",
      "('from', 'data', 'that')\n",
      "('data', 'that', 'has')\n",
      "('that', 'has', 'not')\n",
      "('has', 'not', 'been')\n",
      "('not', 'been', 'hand-annotated')\n",
      "('been', 'hand-annotated', 'with')\n",
      "('hand-annotated', 'with', 'the')\n",
      "('with', 'the', 'desired')\n",
      "('the', 'desired', 'answers')\n",
      "('desired', 'answers', 'or')\n",
      "('answers', 'or', 'using')\n",
      "('or', 'using', 'a')\n",
      "('using', 'a', 'combination')\n",
      "('a', 'combination', 'of')\n",
      "('combination', 'of', 'annotated')\n",
      "('of', 'annotated', 'and')\n",
      "('annotated', 'and', 'non-annotated')\n",
      "('and', 'non-annotated', 'data.')\n",
      "('non-annotated', 'data.', 'Generally,')\n",
      "('data.', 'Generally,', 'this')\n",
      "('Generally,', 'this', 'task')\n",
      "('this', 'task', 'is')\n",
      "('task', 'is', 'much')\n",
      "('is', 'much', 'more')\n",
      "('much', 'more', 'difficult')\n",
      "('more', 'difficult', 'than')\n",
      "('difficult', 'than', 'supervised')\n",
      "('than', 'supervised', 'learning')\n",
      "('supervised', 'learning', ',')\n",
      "('learning', ',', 'and')\n",
      "(',', 'and', 'typically')\n",
      "('and', 'typically', 'produces')\n",
      "('typically', 'produces', 'less')\n",
      "('produces', 'less', 'accurate')\n",
      "('less', 'accurate', 'results')\n",
      "('accurate', 'results', 'for')\n",
      "('results', 'for', 'a')\n",
      "('for', 'a', 'given')\n",
      "('a', 'given', 'amount')\n",
      "('given', 'amount', 'of')\n",
      "('amount', 'of', 'input')\n",
      "('of', 'input', 'data.')\n",
      "('input', 'data.', 'However,')\n",
      "('data.', 'However,', 'there')\n",
      "('However,', 'there', 'is')\n",
      "('there', 'is', 'an')\n",
      "('is', 'an', 'enormous')\n",
      "('an', 'enormous', 'amount')\n",
      "('enormous', 'amount', 'of')\n",
      "('amount', 'of', 'non-annotated')\n",
      "('of', 'non-annotated', 'data')\n",
      "('non-annotated', 'data', 'available')\n",
      "('data', 'available', '(including,')\n",
      "('available', '(including,', 'among')\n",
      "('(including,', 'among', 'other')\n",
      "('among', 'other', 'things,')\n",
      "('other', 'things,', 'the')\n",
      "('things,', 'the', 'entire')\n",
      "('the', 'entire', 'content')\n",
      "('entire', 'content', 'of')\n",
      "('content', 'of', 'the')\n",
      "('of', 'the', 'World')\n",
      "('the', 'World', 'Wide')\n",
      "('World', 'Wide', 'Web')\n",
      "('Wide', 'Web', '),')\n",
      "('Web', '),', 'which')\n",
      "('),', 'which', 'can')\n",
      "('which', 'can', 'often')\n",
      "('can', 'often', 'make')\n",
      "('often', 'make', 'up')\n",
      "('make', 'up', 'for')\n",
      "('up', 'for', 'the')\n",
      "('for', 'the', 'inferior')\n",
      "('the', 'inferior', 'results')\n",
      "('inferior', 'results', 'if')\n",
      "('results', 'if', 'the')\n",
      "('if', 'the', 'algorithm')\n",
      "('the', 'algorithm', 'used')\n",
      "('algorithm', 'used', 'has')\n",
      "('used', 'has', 'a')\n",
      "('has', 'a', 'low')\n",
      "('a', 'low', 'enough')\n",
      "('low', 'enough', 'time')\n",
      "('enough', 'time', 'complexity')\n",
      "('time', 'complexity', 'to')\n",
      "('complexity', 'to', 'be')\n",
      "('to', 'be', 'practical.')\n",
      "('be', 'practical.', 'Neural')\n",
      "('practical.', 'Neural', 'NLP')\n",
      "('Neural', 'NLP', '(present)')\n",
      "('NLP', '(present)', '[')\n",
      "('(present)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'In')\n",
      "(']', 'In', 'the')\n",
      "('In', 'the', '2010s,')\n",
      "('the', '2010s,', 'representation')\n",
      "('2010s,', 'representation', 'learning')\n",
      "('representation', 'learning', 'and')\n",
      "('learning', 'and', 'deep')\n",
      "('and', 'deep', 'neural')\n",
      "('deep', 'neural', 'network')\n",
      "('neural', 'network', '-style')\n",
      "('network', '-style', 'machine')\n",
      "('-style', 'machine', 'learning')\n",
      "('machine', 'learning', 'methods')\n",
      "('learning', 'methods', 'became')\n",
      "('methods', 'became', 'widespread')\n",
      "('became', 'widespread', 'in')\n",
      "('widespread', 'in', 'natural')\n",
      "('in', 'natural', 'language')\n",
      "('natural', 'language', 'processing,')\n",
      "('language', 'processing,', 'due')\n",
      "('processing,', 'due', 'in')\n",
      "('due', 'in', 'part')\n",
      "('in', 'part', 'to')\n",
      "('part', 'to', 'a')\n",
      "('to', 'a', 'flurry')\n",
      "('a', 'flurry', 'of')\n",
      "('flurry', 'of', 'results')\n",
      "('of', 'results', 'showing')\n",
      "('results', 'showing', 'that')\n",
      "('showing', 'that', 'such')\n",
      "('that', 'such', 'techniques')\n",
      "('such', 'techniques', '[7]')\n",
      "('techniques', '[7]', '[8]')\n",
      "('[7]', '[8]', 'can')\n",
      "('[8]', 'can', 'achieve')\n",
      "('can', 'achieve', 'state-of-the-art')\n",
      "('achieve', 'state-of-the-art', 'results')\n",
      "('state-of-the-art', 'results', 'in')\n",
      "('results', 'in', 'many')\n",
      "('in', 'many', 'natural')\n",
      "('many', 'natural', 'language')\n",
      "('natural', 'language', 'tasks,')\n",
      "('language', 'tasks,', 'for')\n",
      "('tasks,', 'for', 'example')\n",
      "('for', 'example', 'in')\n",
      "('example', 'in', 'language')\n",
      "('in', 'language', 'modeling,')\n",
      "('language', 'modeling,', '[9]')\n",
      "('modeling,', '[9]', 'parsing,')\n",
      "('[9]', 'parsing,', '[10]')\n",
      "('parsing,', '[10]', '[11]')\n",
      "('[10]', '[11]', 'and')\n",
      "('[11]', 'and', 'many')\n",
      "('and', 'many', 'others.')\n",
      "('many', 'others.', 'This')\n",
      "('others.', 'This', 'is')\n",
      "('This', 'is', 'increasingly')\n",
      "('is', 'increasingly', 'important')\n",
      "('increasingly', 'important', 'in')\n",
      "('important', 'in', 'medicine')\n",
      "('in', 'medicine', 'and')\n",
      "('medicine', 'and', 'healthcare,')\n",
      "('and', 'healthcare,', 'where')\n",
      "('healthcare,', 'where', 'NLP')\n",
      "('where', 'NLP', 'is')\n",
      "('NLP', 'is', 'being')\n",
      "('is', 'being', 'used')\n",
      "('being', 'used', 'to')\n",
      "('used', 'to', 'analyze')\n",
      "('to', 'analyze', 'notes')\n",
      "('analyze', 'notes', 'and')\n",
      "('notes', 'and', 'text')\n",
      "('and', 'text', 'in')\n",
      "('text', 'in', 'electronic')\n",
      "('in', 'electronic', 'health')\n",
      "('electronic', 'health', 'records')\n",
      "('health', 'records', 'that')\n",
      "('records', 'that', 'would')\n",
      "('that', 'would', 'otherwise')\n",
      "('would', 'otherwise', 'be')\n",
      "('otherwise', 'be', 'inaccessible')\n",
      "('be', 'inaccessible', 'for')\n",
      "('inaccessible', 'for', 'study')\n",
      "('for', 'study', 'when')\n",
      "('study', 'when', 'seeking')\n",
      "('when', 'seeking', 'to')\n",
      "('seeking', 'to', 'improve')\n",
      "('to', 'improve', 'care.')\n",
      "('improve', 'care.', '[12]')\n",
      "('care.', '[12]', 'Methods:')\n",
      "('[12]', 'Methods:', 'Rules,')\n",
      "('Methods:', 'Rules,', 'statistics,')\n",
      "('Rules,', 'statistics,', 'neural')\n",
      "('statistics,', 'neural', 'networks')\n",
      "('neural', 'networks', '[')\n",
      "('networks', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'In')\n",
      "(']', 'In', 'the')\n",
      "('In', 'the', 'early')\n",
      "('the', 'early', 'days,')\n",
      "('early', 'days,', 'many')\n",
      "('days,', 'many', 'language-processing')\n",
      "('many', 'language-processing', 'systems')\n",
      "('language-processing', 'systems', 'were')\n",
      "('systems', 'were', 'designed')\n",
      "('were', 'designed', 'by')\n",
      "('designed', 'by', 'symbolic')\n",
      "('by', 'symbolic', 'methods,')\n",
      "('symbolic', 'methods,', 'i.e.,')\n",
      "('methods,', 'i.e.,', 'the')\n",
      "('i.e.,', 'the', 'hand-coding')\n",
      "('the', 'hand-coding', 'of')\n",
      "('hand-coding', 'of', 'a')\n",
      "('of', 'a', 'set')\n",
      "('a', 'set', 'of')\n",
      "('set', 'of', 'rules,')\n",
      "('of', 'rules,', 'coupled')\n",
      "('rules,', 'coupled', 'with')\n",
      "('coupled', 'with', 'a')\n",
      "('with', 'a', 'dictionary')\n",
      "('a', 'dictionary', 'lookup:')\n",
      "('dictionary', 'lookup:', '[13]')\n",
      "('lookup:', '[13]', '[14]')\n",
      "('[13]', '[14]', 'such')\n",
      "('[14]', 'such', 'as')\n",
      "('such', 'as', 'by')\n",
      "('as', 'by', 'writing')\n",
      "('by', 'writing', 'grammars')\n",
      "('writing', 'grammars', 'or')\n",
      "('grammars', 'or', 'devising')\n",
      "('or', 'devising', 'heuristic')\n",
      "('devising', 'heuristic', 'rules')\n",
      "('heuristic', 'rules', 'for')\n",
      "('rules', 'for', 'stemming')\n",
      "('for', 'stemming', '.')\n",
      "('stemming', '.', 'More')\n",
      "('.', 'More', 'recent')\n",
      "('More', 'recent', 'systems')\n",
      "('recent', 'systems', 'based')\n",
      "('systems', 'based', 'on')\n",
      "('based', 'on', 'machine-learning')\n",
      "('on', 'machine-learning', 'algorithms')\n",
      "('machine-learning', 'algorithms', 'have')\n",
      "('algorithms', 'have', 'many')\n",
      "('have', 'many', 'advantages')\n",
      "('many', 'advantages', 'over')\n",
      "('advantages', 'over', 'hand-produced')\n",
      "('over', 'hand-produced', 'rules:')\n",
      "('hand-produced', 'rules:', 'The')\n",
      "('rules:', 'The', 'learning')\n",
      "('The', 'learning', 'procedures')\n",
      "('learning', 'procedures', 'used')\n",
      "('procedures', 'used', 'during')\n",
      "('used', 'during', 'machine')\n",
      "('during', 'machine', 'learning')\n",
      "('machine', 'learning', 'automatically')\n",
      "('learning', 'automatically', 'focus')\n",
      "('automatically', 'focus', 'on')\n",
      "('focus', 'on', 'the')\n",
      "('on', 'the', 'most')\n",
      "('the', 'most', 'common')\n",
      "('most', 'common', 'cases,')\n",
      "('common', 'cases,', 'whereas')\n",
      "('cases,', 'whereas', 'when')\n",
      "('whereas', 'when', 'writing')\n",
      "('when', 'writing', 'rules')\n",
      "('writing', 'rules', 'by')\n",
      "('rules', 'by', 'hand')\n",
      "('by', 'hand', 'it')\n",
      "('hand', 'it', 'is')\n",
      "('it', 'is', 'often')\n",
      "('is', 'often', 'not')\n",
      "('often', 'not', 'at')\n",
      "('not', 'at', 'all')\n",
      "('at', 'all', 'obvious')\n",
      "('all', 'obvious', 'where')\n",
      "('obvious', 'where', 'the')\n",
      "('where', 'the', 'effort')\n",
      "('the', 'effort', 'should')\n",
      "('effort', 'should', 'be')\n",
      "('should', 'be', 'directed.')\n",
      "('be', 'directed.', 'Automatic')\n",
      "('directed.', 'Automatic', 'learning')\n",
      "('Automatic', 'learning', 'procedures')\n",
      "('learning', 'procedures', 'can')\n",
      "('procedures', 'can', 'make')\n",
      "('can', 'make', 'use')\n",
      "('make', 'use', 'of')\n",
      "('use', 'of', 'statistical')\n",
      "('of', 'statistical', 'inference')\n",
      "('statistical', 'inference', 'algorithms')\n",
      "('inference', 'algorithms', 'to')\n",
      "('algorithms', 'to', 'produce')\n",
      "('to', 'produce', 'models')\n",
      "('produce', 'models', 'that')\n",
      "('models', 'that', 'are')\n",
      "('that', 'are', 'robust')\n",
      "('are', 'robust', 'to')\n",
      "('robust', 'to', 'unfamiliar')\n",
      "('to', 'unfamiliar', 'input')\n",
      "('unfamiliar', 'input', '(e.g.')\n",
      "('input', '(e.g.', 'containing')\n",
      "('(e.g.', 'containing', 'words')\n",
      "('containing', 'words', 'or')\n",
      "('words', 'or', 'structures')\n",
      "('or', 'structures', 'that')\n",
      "('structures', 'that', 'have')\n",
      "('that', 'have', 'not')\n",
      "('have', 'not', 'been')\n",
      "('not', 'been', 'seen')\n",
      "('been', 'seen', 'before)')\n",
      "('seen', 'before)', 'and')\n",
      "('before)', 'and', 'to')\n",
      "('and', 'to', 'erroneous')\n",
      "('to', 'erroneous', 'input')\n",
      "('erroneous', 'input', '(e.g.')\n",
      "('input', '(e.g.', 'with')\n",
      "('(e.g.', 'with', 'misspelled')\n",
      "('with', 'misspelled', 'words')\n",
      "('misspelled', 'words', 'or')\n",
      "('words', 'or', 'words')\n",
      "('or', 'words', 'accidentally')\n",
      "('words', 'accidentally', 'omitted).')\n",
      "('accidentally', 'omitted).', 'Generally,')\n",
      "('omitted).', 'Generally,', 'handling')\n",
      "('Generally,', 'handling', 'such')\n",
      "('handling', 'such', 'input')\n",
      "('such', 'input', 'gracefully')\n",
      "('input', 'gracefully', 'with')\n",
      "('gracefully', 'with', 'handwritten')\n",
      "('with', 'handwritten', 'rules,')\n",
      "('handwritten', 'rules,', 'or,')\n",
      "('rules,', 'or,', 'more')\n",
      "('or,', 'more', 'generally,')\n",
      "('more', 'generally,', 'creating')\n",
      "('generally,', 'creating', 'systems')\n",
      "('creating', 'systems', 'of')\n",
      "('systems', 'of', 'handwritten')\n",
      "('of', 'handwritten', 'rules')\n",
      "('handwritten', 'rules', 'that')\n",
      "('rules', 'that', 'make')\n",
      "('that', 'make', 'soft')\n",
      "('make', 'soft', 'decisions,')\n",
      "('soft', 'decisions,', 'is')\n",
      "('decisions,', 'is', 'extremely')\n",
      "('is', 'extremely', 'difficult,')\n",
      "('extremely', 'difficult,', 'error-prone')\n",
      "('difficult,', 'error-prone', 'and')\n",
      "('error-prone', 'and', 'time-consuming.')\n",
      "('and', 'time-consuming.', 'Systems')\n",
      "('time-consuming.', 'Systems', 'based')\n",
      "('Systems', 'based', 'on')\n",
      "('based', 'on', 'automatically')\n",
      "('on', 'automatically', 'learning')\n",
      "('automatically', 'learning', 'the')\n",
      "('learning', 'the', 'rules')\n",
      "('the', 'rules', 'can')\n",
      "('rules', 'can', 'be')\n",
      "('can', 'be', 'made')\n",
      "('be', 'made', 'more')\n",
      "('made', 'more', 'accurate')\n",
      "('more', 'accurate', 'simply')\n",
      "('accurate', 'simply', 'by')\n",
      "('simply', 'by', 'supplying')\n",
      "('by', 'supplying', 'more')\n",
      "('supplying', 'more', 'input')\n",
      "('more', 'input', 'data.')\n",
      "('input', 'data.', 'However,')\n",
      "('data.', 'However,', 'systems')\n",
      "('However,', 'systems', 'based')\n",
      "('systems', 'based', 'on')\n",
      "('based', 'on', 'handwritten')\n",
      "('on', 'handwritten', 'rules')\n",
      "('handwritten', 'rules', 'can')\n",
      "('rules', 'can', 'only')\n",
      "('can', 'only', 'be')\n",
      "('only', 'be', 'made')\n",
      "('be', 'made', 'more')\n",
      "('made', 'more', 'accurate')\n",
      "('more', 'accurate', 'by')\n",
      "('accurate', 'by', 'increasing')\n",
      "('by', 'increasing', 'the')\n",
      "('increasing', 'the', 'complexity')\n",
      "('the', 'complexity', 'of')\n",
      "('complexity', 'of', 'the')\n",
      "('of', 'the', 'rules,')\n",
      "('the', 'rules,', 'which')\n",
      "('rules,', 'which', 'is')\n",
      "('which', 'is', 'a')\n",
      "('is', 'a', 'much')\n",
      "('a', 'much', 'more')\n",
      "('much', 'more', 'difficult')\n",
      "('more', 'difficult', 'task.')\n",
      "('difficult', 'task.', 'In')\n",
      "('task.', 'In', 'particular,')\n",
      "('In', 'particular,', 'there')\n",
      "('particular,', 'there', 'is')\n",
      "('there', 'is', 'a')\n",
      "('is', 'a', 'limit')\n",
      "('a', 'limit', 'to')\n",
      "('limit', 'to', 'the')\n",
      "('to', 'the', 'complexity')\n",
      "('the', 'complexity', 'of')\n",
      "('complexity', 'of', 'systems')\n",
      "('of', 'systems', 'based')\n",
      "('systems', 'based', 'on')\n",
      "('based', 'on', 'handwritten')\n",
      "('on', 'handwritten', 'rules,')\n",
      "('handwritten', 'rules,', 'beyond')\n",
      "('rules,', 'beyond', 'which')\n",
      "('beyond', 'which', 'the')\n",
      "('which', 'the', 'systems')\n",
      "('the', 'systems', 'become')\n",
      "('systems', 'become', 'more')\n",
      "('become', 'more', 'and')\n",
      "('more', 'and', 'more')\n",
      "('and', 'more', 'unmanageable.')\n",
      "('more', 'unmanageable.', 'However,')\n",
      "('unmanageable.', 'However,', 'creating')\n",
      "('However,', 'creating', 'more')\n",
      "('creating', 'more', 'data')\n",
      "('more', 'data', 'to')\n",
      "('data', 'to', 'input')\n",
      "('to', 'input', 'to')\n",
      "('input', 'to', 'machine-learning')\n",
      "('to', 'machine-learning', 'systems')\n",
      "('machine-learning', 'systems', 'simply')\n",
      "('systems', 'simply', 'requires')\n",
      "('simply', 'requires', 'a')\n",
      "('requires', 'a', 'corresponding')\n",
      "('a', 'corresponding', 'increase')\n",
      "('corresponding', 'increase', 'in')\n",
      "('increase', 'in', 'the')\n",
      "('in', 'the', 'number')\n",
      "('the', 'number', 'of')\n",
      "('number', 'of', 'man-hours')\n",
      "('of', 'man-hours', 'worked,')\n",
      "('man-hours', 'worked,', 'generally')\n",
      "('worked,', 'generally', 'without')\n",
      "('generally', 'without', 'significant')\n",
      "('without', 'significant', 'increases')\n",
      "('significant', 'increases', 'in')\n",
      "('increases', 'in', 'the')\n",
      "('in', 'the', 'complexity')\n",
      "('the', 'complexity', 'of')\n",
      "('complexity', 'of', 'the')\n",
      "('of', 'the', 'annotation')\n",
      "('the', 'annotation', 'process.')\n",
      "('annotation', 'process.', 'Despite')\n",
      "('process.', 'Despite', 'the')\n",
      "('Despite', 'the', 'popularity')\n",
      "('the', 'popularity', 'of')\n",
      "('popularity', 'of', 'machine')\n",
      "('of', 'machine', 'learning')\n",
      "('machine', 'learning', 'in')\n",
      "('learning', 'in', 'NLP')\n",
      "('in', 'NLP', 'research,')\n",
      "('NLP', 'research,', 'symbolic')\n",
      "('research,', 'symbolic', 'methods')\n",
      "('symbolic', 'methods', 'are')\n",
      "('methods', 'are', 'still')\n",
      "('are', 'still', '(2020)')\n",
      "('still', '(2020)', 'commonly')\n",
      "('(2020)', 'commonly', 'used:')\n",
      "('commonly', 'used:', 'when')\n",
      "('used:', 'when', 'the')\n",
      "('when', 'the', 'amount')\n",
      "('the', 'amount', 'of')\n",
      "('amount', 'of', 'training')\n",
      "('of', 'training', 'data')\n",
      "('training', 'data', 'is')\n",
      "('data', 'is', 'insufficient')\n",
      "('is', 'insufficient', 'to')\n",
      "('insufficient', 'to', 'successfully')\n",
      "('to', 'successfully', 'apply')\n",
      "('successfully', 'apply', 'machine')\n",
      "('apply', 'machine', 'learning')\n",
      "('machine', 'learning', 'methods,')\n",
      "('learning', 'methods,', 'e.g.,')\n",
      "('methods,', 'e.g.,', 'for')\n",
      "('e.g.,', 'for', 'the')\n",
      "('for', 'the', 'machine')\n",
      "('the', 'machine', 'translation')\n",
      "('machine', 'translation', 'of')\n",
      "('translation', 'of', 'low-resource')\n",
      "('of', 'low-resource', 'languages')\n",
      "('low-resource', 'languages', 'such')\n",
      "('languages', 'such', 'as')\n",
      "('such', 'as', 'provided')\n",
      "('as', 'provided', 'by')\n",
      "('provided', 'by', 'the')\n",
      "('by', 'the', 'Apertium')\n",
      "('the', 'Apertium', 'system,')\n",
      "('Apertium', 'system,', 'for')\n",
      "('system,', 'for', 'preprocessing')\n",
      "('for', 'preprocessing', 'in')\n",
      "('preprocessing', 'in', 'NLP')\n",
      "('in', 'NLP', 'pipelines,')\n",
      "('NLP', 'pipelines,', 'e.g.,')\n",
      "('pipelines,', 'e.g.,', 'tokenization')\n",
      "('e.g.,', 'tokenization', ',')\n",
      "('tokenization', ',', 'or')\n",
      "(',', 'or', 'for')\n",
      "('or', 'for', 'postprocessing')\n",
      "('for', 'postprocessing', 'and')\n",
      "('postprocessing', 'and', 'transforming')\n",
      "('and', 'transforming', 'the')\n",
      "('transforming', 'the', 'output')\n",
      "('the', 'output', 'of')\n",
      "('output', 'of', 'NLP')\n",
      "('of', 'NLP', 'pipelines,')\n",
      "('NLP', 'pipelines,', 'e.g.,')\n",
      "('pipelines,', 'e.g.,', 'for')\n",
      "('e.g.,', 'for', 'knowledge')\n",
      "('for', 'knowledge', 'extraction')\n",
      "('knowledge', 'extraction', 'from')\n",
      "('extraction', 'from', 'syntactic')\n",
      "('from', 'syntactic', 'parses.')\n",
      "('syntactic', 'parses.', 'Statistical')\n",
      "('parses.', 'Statistical', 'methods')\n",
      "('Statistical', 'methods', '[')\n",
      "('methods', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Since')\n",
      "(']', 'Since', 'the')\n",
      "('Since', 'the', 'so-called')\n",
      "('the', 'so-called', '\"statistical')\n",
      "('so-called', '\"statistical', 'revolution\"')\n",
      "('\"statistical', 'revolution\"', '[15]')\n",
      "('revolution\"', '[15]', '[16]')\n",
      "('[15]', '[16]', 'in')\n",
      "('[16]', 'in', 'the')\n",
      "('in', 'the', 'late')\n",
      "('the', 'late', '1980s')\n",
      "('late', '1980s', 'and')\n",
      "('1980s', 'and', 'mid-1990s,')\n",
      "('and', 'mid-1990s,', 'much')\n",
      "('mid-1990s,', 'much', 'natural')\n",
      "('much', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'research')\n",
      "('processing', 'research', 'has')\n",
      "('research', 'has', 'relied')\n",
      "('has', 'relied', 'heavily')\n",
      "('relied', 'heavily', 'on')\n",
      "('heavily', 'on', 'machine')\n",
      "('on', 'machine', 'learning.')\n",
      "('machine', 'learning.', 'The')\n",
      "('learning.', 'The', 'machine-learning')\n",
      "('The', 'machine-learning', 'paradigm')\n",
      "('machine-learning', 'paradigm', 'calls')\n",
      "('paradigm', 'calls', 'instead')\n",
      "('calls', 'instead', 'for')\n",
      "('instead', 'for', 'using')\n",
      "('for', 'using', 'statistical')\n",
      "('using', 'statistical', 'inference')\n",
      "('statistical', 'inference', 'to')\n",
      "('inference', 'to', 'automatically')\n",
      "('to', 'automatically', 'learn')\n",
      "('automatically', 'learn', 'such')\n",
      "('learn', 'such', 'rules')\n",
      "('such', 'rules', 'through')\n",
      "('rules', 'through', 'the')\n",
      "('through', 'the', 'analysis')\n",
      "('the', 'analysis', 'of')\n",
      "('analysis', 'of', 'large')\n",
      "('of', 'large', 'corpora')\n",
      "('large', 'corpora', '(the')\n",
      "('corpora', '(the', 'plural')\n",
      "('(the', 'plural', 'form')\n",
      "('plural', 'form', 'of')\n",
      "('form', 'of', 'corpus')\n",
      "('of', 'corpus', ',')\n",
      "('corpus', ',', 'is')\n",
      "(',', 'is', 'a')\n",
      "('is', 'a', 'set')\n",
      "('a', 'set', 'of')\n",
      "('set', 'of', 'documents,')\n",
      "('of', 'documents,', 'possibly')\n",
      "('documents,', 'possibly', 'with')\n",
      "('possibly', 'with', 'human')\n",
      "('with', 'human', 'or')\n",
      "('human', 'or', 'computer')\n",
      "('or', 'computer', 'annotations)')\n",
      "('computer', 'annotations)', 'of')\n",
      "('annotations)', 'of', 'typical')\n",
      "('of', 'typical', 'real-world')\n",
      "('typical', 'real-world', 'examples.')\n",
      "('real-world', 'examples.', 'Many')\n",
      "('examples.', 'Many', 'different')\n",
      "('Many', 'different', 'classes')\n",
      "('different', 'classes', 'of')\n",
      "('classes', 'of', 'machine-learning')\n",
      "('of', 'machine-learning', 'algorithms')\n",
      "('machine-learning', 'algorithms', 'have')\n",
      "('algorithms', 'have', 'been')\n",
      "('have', 'been', 'applied')\n",
      "('been', 'applied', 'to')\n",
      "('applied', 'to', 'natural-language-processing')\n",
      "('to', 'natural-language-processing', 'tasks.')\n",
      "('natural-language-processing', 'tasks.', 'These')\n",
      "('tasks.', 'These', 'algorithms')\n",
      "('These', 'algorithms', 'take')\n",
      "('algorithms', 'take', 'as')\n",
      "('take', 'as', 'input')\n",
      "('as', 'input', 'a')\n",
      "('input', 'a', 'large')\n",
      "('a', 'large', 'set')\n",
      "('large', 'set', 'of')\n",
      "('set', 'of', '\"features\"')\n",
      "('of', '\"features\"', 'that')\n",
      "('\"features\"', 'that', 'are')\n",
      "('that', 'are', 'generated')\n",
      "('are', 'generated', 'from')\n",
      "('generated', 'from', 'the')\n",
      "('from', 'the', 'input')\n",
      "('the', 'input', 'data.')\n",
      "('input', 'data.', 'Increasingly,')\n",
      "('data.', 'Increasingly,', 'however,')\n",
      "('Increasingly,', 'however,', 'research')\n",
      "('however,', 'research', 'has')\n",
      "('research', 'has', 'focused')\n",
      "('has', 'focused', 'on')\n",
      "('focused', 'on', 'statistical')\n",
      "('on', 'statistical', 'models')\n",
      "('statistical', 'models', ',')\n",
      "('models', ',', 'which')\n",
      "(',', 'which', 'make')\n",
      "('which', 'make', 'soft,')\n",
      "('make', 'soft,', 'probabilistic')\n",
      "('soft,', 'probabilistic', 'decisions')\n",
      "('probabilistic', 'decisions', 'based')\n",
      "('decisions', 'based', 'on')\n",
      "('based', 'on', 'attaching')\n",
      "('on', 'attaching', 'real-valued')\n",
      "('attaching', 'real-valued', 'weights')\n",
      "('real-valued', 'weights', 'to')\n",
      "('weights', 'to', 'each')\n",
      "('to', 'each', 'input')\n",
      "('each', 'input', 'feature')\n",
      "('input', 'feature', '(complex-valued')\n",
      "('feature', '(complex-valued', 'embeddings')\n",
      "('(complex-valued', 'embeddings', ',')\n",
      "('embeddings', ',', '[17]')\n",
      "(',', '[17]', 'and')\n",
      "('[17]', 'and', 'neural')\n",
      "('and', 'neural', 'networks')\n",
      "('neural', 'networks', 'in')\n",
      "('networks', 'in', 'general')\n",
      "('in', 'general', 'have')\n",
      "('general', 'have', 'also')\n",
      "('have', 'also', 'been')\n",
      "('also', 'been', 'proposed,')\n",
      "('been', 'proposed,', 'for')\n",
      "('proposed,', 'for', 'e.g.')\n",
      "('for', 'e.g.', 'speech')\n",
      "('e.g.', 'speech', '[18]')\n",
      "('speech', '[18]', ').')\n",
      "('[18]', ').', 'Such')\n",
      "(').', 'Such', 'models')\n",
      "('Such', 'models', 'have')\n",
      "('models', 'have', 'the')\n",
      "('have', 'the', 'advantage')\n",
      "('the', 'advantage', 'that')\n",
      "('advantage', 'that', 'they')\n",
      "('that', 'they', 'can')\n",
      "('they', 'can', 'express')\n",
      "('can', 'express', 'the')\n",
      "('express', 'the', 'relative')\n",
      "('the', 'relative', 'certainty')\n",
      "('relative', 'certainty', 'of')\n",
      "('certainty', 'of', 'many')\n",
      "('of', 'many', 'different')\n",
      "('many', 'different', 'possible')\n",
      "('different', 'possible', 'answers')\n",
      "('possible', 'answers', 'rather')\n",
      "('answers', 'rather', 'than')\n",
      "('rather', 'than', 'only')\n",
      "('than', 'only', 'one,')\n",
      "('only', 'one,', 'producing')\n",
      "('one,', 'producing', 'more')\n",
      "('producing', 'more', 'reliable')\n",
      "('more', 'reliable', 'results')\n",
      "('reliable', 'results', 'when')\n",
      "('results', 'when', 'such')\n",
      "('when', 'such', 'a')\n",
      "('such', 'a', 'model')\n",
      "('a', 'model', 'is')\n",
      "('model', 'is', 'included')\n",
      "('is', 'included', 'as')\n",
      "('included', 'as', 'a')\n",
      "('as', 'a', 'component')\n",
      "('a', 'component', 'of')\n",
      "('component', 'of', 'a')\n",
      "('of', 'a', 'larger')\n",
      "('a', 'larger', 'system.')\n",
      "('larger', 'system.', 'Some')\n",
      "('system.', 'Some', 'of')\n",
      "('Some', 'of', 'the')\n",
      "('of', 'the', 'earliest-used')\n",
      "('the', 'earliest-used', 'machine')\n",
      "('earliest-used', 'machine', 'learning')\n",
      "('machine', 'learning', 'algorithms,')\n",
      "('learning', 'algorithms,', 'such')\n",
      "('algorithms,', 'such', 'as')\n",
      "('such', 'as', 'decision')\n",
      "('as', 'decision', 'trees')\n",
      "('decision', 'trees', ',')\n",
      "('trees', ',', 'produced')\n",
      "(',', 'produced', 'systems')\n",
      "('produced', 'systems', 'of')\n",
      "('systems', 'of', 'hard')\n",
      "('of', 'hard', 'if-then')\n",
      "('hard', 'if-then', 'rules')\n",
      "('if-then', 'rules', 'similar')\n",
      "('rules', 'similar', 'to')\n",
      "('similar', 'to', 'existing')\n",
      "('to', 'existing', 'hand-written')\n",
      "('existing', 'hand-written', 'rules.')\n",
      "('hand-written', 'rules.', 'However,')\n",
      "('rules.', 'However,', 'part-of-speech')\n",
      "('However,', 'part-of-speech', 'tagging')\n",
      "('part-of-speech', 'tagging', 'introduced')\n",
      "('tagging', 'introduced', 'the')\n",
      "('introduced', 'the', 'use')\n",
      "('the', 'use', 'of')\n",
      "('use', 'of', 'hidden')\n",
      "('of', 'hidden', 'Markov')\n",
      "('hidden', 'Markov', 'models')\n",
      "('Markov', 'models', 'to')\n",
      "('models', 'to', 'natural')\n",
      "('to', 'natural', 'language')\n",
      "('natural', 'language', 'processing,')\n",
      "('language', 'processing,', 'and')\n",
      "('processing,', 'and', 'increasingly,')\n",
      "('and', 'increasingly,', 'research')\n",
      "('increasingly,', 'research', 'has')\n",
      "('research', 'has', 'focused')\n",
      "('has', 'focused', 'on')\n",
      "('focused', 'on', 'statistical')\n",
      "('on', 'statistical', 'models')\n",
      "('statistical', 'models', ',')\n",
      "('models', ',', 'which')\n",
      "(',', 'which', 'make')\n",
      "('which', 'make', 'soft,')\n",
      "('make', 'soft,', 'probabilistic')\n",
      "('soft,', 'probabilistic', 'decisions')\n",
      "('probabilistic', 'decisions', 'based')\n",
      "('decisions', 'based', 'on')\n",
      "('based', 'on', 'attaching')\n",
      "('on', 'attaching', 'real-valued')\n",
      "('attaching', 'real-valued', 'weights')\n",
      "('real-valued', 'weights', 'to')\n",
      "('weights', 'to', 'the')\n",
      "('to', 'the', 'features')\n",
      "('the', 'features', 'making')\n",
      "('features', 'making', 'up')\n",
      "('making', 'up', 'the')\n",
      "('up', 'the', 'input')\n",
      "('the', 'input', 'data.')\n",
      "('input', 'data.', 'The')\n",
      "('data.', 'The', 'cache')\n",
      "('The', 'cache', 'language')\n",
      "('cache', 'language', 'models')\n",
      "('language', 'models', 'upon')\n",
      "('models', 'upon', 'which')\n",
      "('upon', 'which', 'many')\n",
      "('which', 'many', 'speech')\n",
      "('many', 'speech', 'recognition')\n",
      "('speech', 'recognition', 'systems')\n",
      "('recognition', 'systems', 'now')\n",
      "('systems', 'now', 'rely')\n",
      "('now', 'rely', 'are')\n",
      "('rely', 'are', 'examples')\n",
      "('are', 'examples', 'of')\n",
      "('examples', 'of', 'such')\n",
      "('of', 'such', 'statistical')\n",
      "('such', 'statistical', 'models.')\n",
      "('statistical', 'models.', 'Such')\n",
      "('models.', 'Such', 'models')\n",
      "('Such', 'models', 'are')\n",
      "('models', 'are', 'generally')\n",
      "('are', 'generally', 'more')\n",
      "('generally', 'more', 'robust')\n",
      "('more', 'robust', 'when')\n",
      "('robust', 'when', 'given')\n",
      "('when', 'given', 'unfamiliar')\n",
      "('given', 'unfamiliar', 'input,')\n",
      "('unfamiliar', 'input,', 'especially')\n",
      "('input,', 'especially', 'input')\n",
      "('especially', 'input', 'that')\n",
      "('input', 'that', 'contains')\n",
      "('that', 'contains', 'errors')\n",
      "('contains', 'errors', '(as')\n",
      "('errors', '(as', 'is')\n",
      "('(as', 'is', 'very')\n",
      "('is', 'very', 'common')\n",
      "('very', 'common', 'for')\n",
      "('common', 'for', 'real-world')\n",
      "('for', 'real-world', 'data),')\n",
      "('real-world', 'data),', 'and')\n",
      "('data),', 'and', 'produce')\n",
      "('and', 'produce', 'more')\n",
      "('produce', 'more', 'reliable')\n",
      "('more', 'reliable', 'results')\n",
      "('reliable', 'results', 'when')\n",
      "('results', 'when', 'integrated')\n",
      "('when', 'integrated', 'into')\n",
      "('integrated', 'into', 'a')\n",
      "('into', 'a', 'larger')\n",
      "('a', 'larger', 'system')\n",
      "('larger', 'system', 'comprising')\n",
      "('system', 'comprising', 'multiple')\n",
      "('comprising', 'multiple', 'subtasks.')\n",
      "('multiple', 'subtasks.', 'Since')\n",
      "('subtasks.', 'Since', 'the')\n",
      "('Since', 'the', 'neural')\n",
      "('the', 'neural', 'turn,')\n",
      "('neural', 'turn,', 'statistical')\n",
      "('turn,', 'statistical', 'methods')\n",
      "('statistical', 'methods', 'in')\n",
      "('methods', 'in', 'NLP')\n",
      "('in', 'NLP', 'research')\n",
      "('NLP', 'research', 'have')\n",
      "('research', 'have', 'been')\n",
      "('have', 'been', 'largely')\n",
      "('been', 'largely', 'replaced')\n",
      "('largely', 'replaced', 'by')\n",
      "('replaced', 'by', 'neural')\n",
      "('by', 'neural', 'networks.')\n",
      "('neural', 'networks.', 'However,')\n",
      "('networks.', 'However,', 'they')\n",
      "('However,', 'they', 'continue')\n",
      "('they', 'continue', 'to')\n",
      "('continue', 'to', 'be')\n",
      "('to', 'be', 'relevant')\n",
      "('be', 'relevant', 'for')\n",
      "('relevant', 'for', 'contexts')\n",
      "('for', 'contexts', 'in')\n",
      "('contexts', 'in', 'which')\n",
      "('in', 'which', 'statistical')\n",
      "('which', 'statistical', 'interpretability')\n",
      "('statistical', 'interpretability', 'and')\n",
      "('interpretability', 'and', 'transparency')\n",
      "('and', 'transparency', 'is')\n",
      "('transparency', 'is', 'required.')\n",
      "('is', 'required.', 'Neural')\n",
      "('required.', 'Neural', 'networks')\n",
      "('Neural', 'networks', '[')\n",
      "('networks', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Further')\n",
      "(']', 'Further', 'information:')\n",
      "('Further', 'information:', 'Artificial')\n",
      "('information:', 'Artificial', 'neural')\n",
      "('Artificial', 'neural', 'network')\n",
      "('neural', 'network', 'A')\n",
      "('network', 'A', 'major')\n",
      "('A', 'major', 'drawback')\n",
      "('major', 'drawback', 'of')\n",
      "('drawback', 'of', 'statistical')\n",
      "('of', 'statistical', 'methods')\n",
      "('statistical', 'methods', 'is')\n",
      "('methods', 'is', 'that')\n",
      "('is', 'that', 'they')\n",
      "('that', 'they', 'require')\n",
      "('they', 'require', 'elaborate')\n",
      "('require', 'elaborate', 'feature')\n",
      "('elaborate', 'feature', 'engineering.')\n",
      "('feature', 'engineering.', 'Since')\n",
      "('engineering.', 'Since', '2015,')\n",
      "('Since', '2015,', '[19]')\n",
      "('2015,', '[19]', 'the')\n",
      "('[19]', 'the', 'field')\n",
      "('the', 'field', 'has')\n",
      "('field', 'has', 'thus')\n",
      "('has', 'thus', 'largely')\n",
      "('thus', 'largely', 'abandoned')\n",
      "('largely', 'abandoned', 'statistical')\n",
      "('abandoned', 'statistical', 'methods')\n",
      "('statistical', 'methods', 'and')\n",
      "('methods', 'and', 'shifted')\n",
      "('and', 'shifted', 'to')\n",
      "('shifted', 'to', 'neural')\n",
      "('to', 'neural', 'networks')\n",
      "('neural', 'networks', 'for')\n",
      "('networks', 'for', 'machine')\n",
      "('for', 'machine', 'learning.')\n",
      "('machine', 'learning.', 'Popular')\n",
      "('learning.', 'Popular', 'techniques')\n",
      "('Popular', 'techniques', 'include')\n",
      "('techniques', 'include', 'the')\n",
      "('include', 'the', 'use')\n",
      "('the', 'use', 'of')\n",
      "('use', 'of', 'word')\n",
      "('of', 'word', 'embeddings')\n",
      "('word', 'embeddings', 'to')\n",
      "('embeddings', 'to', 'capture')\n",
      "('to', 'capture', 'semantic')\n",
      "('capture', 'semantic', 'properties')\n",
      "('semantic', 'properties', 'of')\n",
      "('properties', 'of', 'words,')\n",
      "('of', 'words,', 'and')\n",
      "('words,', 'and', 'an')\n",
      "('and', 'an', 'increase')\n",
      "('an', 'increase', 'in')\n",
      "('increase', 'in', 'end-to-end')\n",
      "('in', 'end-to-end', 'learning')\n",
      "('end-to-end', 'learning', 'of')\n",
      "('learning', 'of', 'a')\n",
      "('of', 'a', 'higher-level')\n",
      "('a', 'higher-level', 'task')\n",
      "('higher-level', 'task', '(e.g.,')\n",
      "('task', '(e.g.,', 'question')\n",
      "('(e.g.,', 'question', 'answering)')\n",
      "('question', 'answering)', 'instead')\n",
      "('answering)', 'instead', 'of')\n",
      "('instead', 'of', 'relying')\n",
      "('of', 'relying', 'on')\n",
      "('relying', 'on', 'a')\n",
      "('on', 'a', 'pipeline')\n",
      "('a', 'pipeline', 'of')\n",
      "('pipeline', 'of', 'separate')\n",
      "('of', 'separate', 'intermediate')\n",
      "('separate', 'intermediate', 'tasks')\n",
      "('intermediate', 'tasks', '(e.g.,')\n",
      "('tasks', '(e.g.,', 'part-of-speech')\n",
      "('(e.g.,', 'part-of-speech', 'tagging')\n",
      "('part-of-speech', 'tagging', 'and')\n",
      "('tagging', 'and', 'dependency')\n",
      "('and', 'dependency', 'parsing).')\n",
      "('dependency', 'parsing).', 'In')\n",
      "('parsing).', 'In', 'some')\n",
      "('In', 'some', 'areas,')\n",
      "('some', 'areas,', 'this')\n",
      "('areas,', 'this', 'shift')\n",
      "('this', 'shift', 'has')\n",
      "('shift', 'has', 'entailed')\n",
      "('has', 'entailed', 'substantial')\n",
      "('entailed', 'substantial', 'changes')\n",
      "('substantial', 'changes', 'in')\n",
      "('changes', 'in', 'how')\n",
      "('in', 'how', 'NLP')\n",
      "('how', 'NLP', 'systems')\n",
      "('NLP', 'systems', 'are')\n",
      "('systems', 'are', 'designed,')\n",
      "('are', 'designed,', 'such')\n",
      "('designed,', 'such', 'that')\n",
      "('such', 'that', 'deep')\n",
      "('that', 'deep', 'neural')\n",
      "('deep', 'neural', 'network-based')\n",
      "('neural', 'network-based', 'approaches')\n",
      "('network-based', 'approaches', 'may')\n",
      "('approaches', 'may', 'be')\n",
      "('may', 'be', 'viewed')\n",
      "('be', 'viewed', 'as')\n",
      "('viewed', 'as', 'a')\n",
      "('as', 'a', 'new')\n",
      "('a', 'new', 'paradigm')\n",
      "('new', 'paradigm', 'distinct')\n",
      "('paradigm', 'distinct', 'from')\n",
      "('distinct', 'from', 'statistical')\n",
      "('from', 'statistical', 'natural')\n",
      "('statistical', 'natural', 'language')\n",
      "('natural', 'language', 'processing.')\n",
      "('language', 'processing.', 'For')\n",
      "('processing.', 'For', 'instance,')\n",
      "('For', 'instance,', 'the')\n",
      "('instance,', 'the', 'term')\n",
      "('the', 'term', 'neural')\n",
      "('term', 'neural', 'machine')\n",
      "('neural', 'machine', 'translation')\n",
      "('machine', 'translation', '(NMT)')\n",
      "('translation', '(NMT)', 'emphasizes')\n",
      "('(NMT)', 'emphasizes', 'the')\n",
      "('emphasizes', 'the', 'fact')\n",
      "('the', 'fact', 'that')\n",
      "('fact', 'that', 'deep')\n",
      "('that', 'deep', 'learning-based')\n",
      "('deep', 'learning-based', 'approaches')\n",
      "('learning-based', 'approaches', 'to')\n",
      "('approaches', 'to', 'machine')\n",
      "('to', 'machine', 'translation')\n",
      "('machine', 'translation', 'directly')\n",
      "('translation', 'directly', 'learn')\n",
      "('directly', 'learn', 'sequence-to-sequence')\n",
      "('learn', 'sequence-to-sequence', 'transformations,')\n",
      "('sequence-to-sequence', 'transformations,', 'obviating')\n",
      "('transformations,', 'obviating', 'the')\n",
      "('obviating', 'the', 'need')\n",
      "('the', 'need', 'for')\n",
      "('need', 'for', 'intermediate')\n",
      "('for', 'intermediate', 'steps')\n",
      "('intermediate', 'steps', 'such')\n",
      "('steps', 'such', 'as')\n",
      "('such', 'as', 'word')\n",
      "('as', 'word', 'alignment')\n",
      "('word', 'alignment', 'and')\n",
      "('alignment', 'and', 'language')\n",
      "('and', 'language', 'modeling')\n",
      "('language', 'modeling', 'that')\n",
      "('modeling', 'that', 'was')\n",
      "('that', 'was', 'used')\n",
      "('was', 'used', 'in')\n",
      "('used', 'in', 'statistical')\n",
      "('in', 'statistical', 'machine')\n",
      "('statistical', 'machine', 'translation')\n",
      "('machine', 'translation', '(SMT).')\n",
      "('translation', '(SMT).', 'Latest')\n",
      "('(SMT).', 'Latest', 'works')\n",
      "('Latest', 'works', 'tend')\n",
      "('works', 'tend', 'to')\n",
      "('tend', 'to', 'use')\n",
      "('to', 'use', 'non-technical')\n",
      "('use', 'non-technical', 'structure')\n",
      "('non-technical', 'structure', 'of')\n",
      "('structure', 'of', 'a')\n",
      "('of', 'a', 'given')\n",
      "('a', 'given', 'task')\n",
      "('given', 'task', 'to')\n",
      "('task', 'to', 'build')\n",
      "('to', 'build', 'proper')\n",
      "('build', 'proper', 'neural')\n",
      "('proper', 'neural', 'network.')\n",
      "('neural', 'network.', '[20]')\n",
      "('network.', '[20]', 'Common')\n",
      "('[20]', 'Common', 'NLP')\n",
      "('Common', 'NLP', 'tasks')\n",
      "('NLP', 'tasks', '[')\n",
      "('tasks', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'The')\n",
      "(']', 'The', 'following')\n",
      "('The', 'following', 'is')\n",
      "('following', 'is', 'a')\n",
      "('is', 'a', 'list')\n",
      "('a', 'list', 'of')\n",
      "('list', 'of', 'some')\n",
      "('of', 'some', 'of')\n",
      "('some', 'of', 'the')\n",
      "('of', 'the', 'most')\n",
      "('the', 'most', 'commonly')\n",
      "('most', 'commonly', 'researched')\n",
      "('commonly', 'researched', 'tasks')\n",
      "('researched', 'tasks', 'in')\n",
      "('tasks', 'in', 'natural')\n",
      "('in', 'natural', 'language')\n",
      "('natural', 'language', 'processing.')\n",
      "('language', 'processing.', 'Some')\n",
      "('processing.', 'Some', 'of')\n",
      "('Some', 'of', 'these')\n",
      "('of', 'these', 'tasks')\n",
      "('these', 'tasks', 'have')\n",
      "('tasks', 'have', 'direct')\n",
      "('have', 'direct', 'real-world')\n",
      "('direct', 'real-world', 'applications,')\n",
      "('real-world', 'applications,', 'while')\n",
      "('applications,', 'while', 'others')\n",
      "('while', 'others', 'more')\n",
      "('others', 'more', 'commonly')\n",
      "('more', 'commonly', 'serve')\n",
      "('commonly', 'serve', 'as')\n",
      "('serve', 'as', 'subtasks')\n",
      "('as', 'subtasks', 'that')\n",
      "('subtasks', 'that', 'are')\n",
      "('that', 'are', 'used')\n",
      "('are', 'used', 'to')\n",
      "('used', 'to', 'aid')\n",
      "('to', 'aid', 'in')\n",
      "('aid', 'in', 'solving')\n",
      "('in', 'solving', 'larger')\n",
      "('solving', 'larger', 'tasks.')\n",
      "('larger', 'tasks.', 'Though')\n",
      "('tasks.', 'Though', 'natural')\n",
      "('Though', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'tasks')\n",
      "('processing', 'tasks', 'are')\n",
      "('tasks', 'are', 'closely')\n",
      "('are', 'closely', 'intertwined,')\n",
      "('closely', 'intertwined,', 'they')\n",
      "('intertwined,', 'they', 'can')\n",
      "('they', 'can', 'be')\n",
      "('can', 'be', 'subdivided')\n",
      "('be', 'subdivided', 'into')\n",
      "('subdivided', 'into', 'categories')\n",
      "('into', 'categories', 'for')\n",
      "('categories', 'for', 'convenience.')\n",
      "('for', 'convenience.', 'A')\n",
      "('convenience.', 'A', 'coarse')\n",
      "('A', 'coarse', 'division')\n",
      "('coarse', 'division', 'is')\n",
      "('division', 'is', 'given')\n",
      "('is', 'given', 'below.')\n",
      "('given', 'below.', 'Text')\n",
      "('below.', 'Text', 'and')\n",
      "('Text', 'and', 'speech')\n",
      "('and', 'speech', 'processing')\n",
      "('speech', 'processing', '[')\n",
      "('processing', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Optical')\n",
      "(']', 'Optical', 'character')\n",
      "('Optical', 'character', 'recognition')\n",
      "('character', 'recognition', '(OCR)')\n",
      "('recognition', '(OCR)', 'Given')\n",
      "('(OCR)', 'Given', 'an')\n",
      "('Given', 'an', 'image')\n",
      "('an', 'image', 'representing')\n",
      "('image', 'representing', 'printed')\n",
      "('representing', 'printed', 'text,')\n",
      "('printed', 'text,', 'determine')\n",
      "('text,', 'determine', 'the')\n",
      "('determine', 'the', 'corresponding')\n",
      "('the', 'corresponding', 'text.')\n",
      "('corresponding', 'text.', 'Speech')\n",
      "('text.', 'Speech', 'recognition')\n",
      "('Speech', 'recognition', 'Given')\n",
      "('recognition', 'Given', 'a')\n",
      "('Given', 'a', 'sound')\n",
      "('a', 'sound', 'clip')\n",
      "('sound', 'clip', 'of')\n",
      "('clip', 'of', 'a')\n",
      "('of', 'a', 'person')\n",
      "('a', 'person', 'or')\n",
      "('person', 'or', 'people')\n",
      "('or', 'people', 'speaking,')\n",
      "('people', 'speaking,', 'determine')\n",
      "('speaking,', 'determine', 'the')\n",
      "('determine', 'the', 'textual')\n",
      "('the', 'textual', 'representation')\n",
      "('textual', 'representation', 'of')\n",
      "('representation', 'of', 'the')\n",
      "('of', 'the', 'speech.')\n",
      "('the', 'speech.', 'This')\n",
      "('speech.', 'This', 'is')\n",
      "('This', 'is', 'the')\n",
      "('is', 'the', 'opposite')\n",
      "('the', 'opposite', 'of')\n",
      "('opposite', 'of', 'text')\n",
      "('of', 'text', 'to')\n",
      "('text', 'to', 'speech')\n",
      "('to', 'speech', 'and')\n",
      "('speech', 'and', 'is')\n",
      "('and', 'is', 'one')\n",
      "('is', 'one', 'of')\n",
      "('one', 'of', 'the')\n",
      "('of', 'the', 'extremely')\n",
      "('the', 'extremely', 'difficult')\n",
      "('extremely', 'difficult', 'problems')\n",
      "('difficult', 'problems', 'colloquially')\n",
      "('problems', 'colloquially', 'termed')\n",
      "('colloquially', 'termed', '\"')\n",
      "('termed', '\"', 'AI-complete')\n",
      "('\"', 'AI-complete', '\"')\n",
      "('AI-complete', '\"', '(see')\n",
      "('\"', '(see', 'above).')\n",
      "('(see', 'above).', 'In')\n",
      "('above).', 'In', 'natural')\n",
      "('In', 'natural', 'speech')\n",
      "('natural', 'speech', 'there')\n",
      "('speech', 'there', 'are')\n",
      "('there', 'are', 'hardly')\n",
      "('are', 'hardly', 'any')\n",
      "('hardly', 'any', 'pauses')\n",
      "('any', 'pauses', 'between')\n",
      "('pauses', 'between', 'successive')\n",
      "('between', 'successive', 'words,')\n",
      "('successive', 'words,', 'and')\n",
      "('words,', 'and', 'thus')\n",
      "('and', 'thus', 'speech')\n",
      "('thus', 'speech', 'segmentation')\n",
      "('speech', 'segmentation', 'is')\n",
      "('segmentation', 'is', 'a')\n",
      "('is', 'a', 'necessary')\n",
      "('a', 'necessary', 'subtask')\n",
      "('necessary', 'subtask', 'of')\n",
      "('subtask', 'of', 'speech')\n",
      "('of', 'speech', 'recognition')\n",
      "('speech', 'recognition', '(see')\n",
      "('recognition', '(see', 'below).')\n",
      "('(see', 'below).', 'In')\n",
      "('below).', 'In', 'most')\n",
      "('In', 'most', 'spoken')\n",
      "('most', 'spoken', 'languages,')\n",
      "('spoken', 'languages,', 'the')\n",
      "('languages,', 'the', 'sounds')\n",
      "('the', 'sounds', 'representing')\n",
      "('sounds', 'representing', 'successive')\n",
      "('representing', 'successive', 'letters')\n",
      "('successive', 'letters', 'blend')\n",
      "('letters', 'blend', 'into')\n",
      "('blend', 'into', 'each')\n",
      "('into', 'each', 'other')\n",
      "('each', 'other', 'in')\n",
      "('other', 'in', 'a')\n",
      "('in', 'a', 'process')\n",
      "('a', 'process', 'termed')\n",
      "('process', 'termed', 'coarticulation')\n",
      "('termed', 'coarticulation', ',')\n",
      "('coarticulation', ',', 'so')\n",
      "(',', 'so', 'the')\n",
      "('so', 'the', 'conversion')\n",
      "('the', 'conversion', 'of')\n",
      "('conversion', 'of', 'the')\n",
      "('of', 'the', 'analog')\n",
      "('the', 'analog', 'signal')\n",
      "('analog', 'signal', 'to')\n",
      "('signal', 'to', 'discrete')\n",
      "('to', 'discrete', 'characters')\n",
      "('discrete', 'characters', 'can')\n",
      "('characters', 'can', 'be')\n",
      "('can', 'be', 'a')\n",
      "('be', 'a', 'very')\n",
      "('a', 'very', 'difficult')\n",
      "('very', 'difficult', 'process.')\n",
      "('difficult', 'process.', 'Also,')\n",
      "('process.', 'Also,', 'given')\n",
      "('Also,', 'given', 'that')\n",
      "('given', 'that', 'words')\n",
      "('that', 'words', 'in')\n",
      "('words', 'in', 'the')\n",
      "('in', 'the', 'same')\n",
      "('the', 'same', 'language')\n",
      "('same', 'language', 'are')\n",
      "('language', 'are', 'spoken')\n",
      "('are', 'spoken', 'by')\n",
      "('spoken', 'by', 'people')\n",
      "('by', 'people', 'with')\n",
      "('people', 'with', 'different')\n",
      "('with', 'different', 'accents,')\n",
      "('different', 'accents,', 'the')\n",
      "('accents,', 'the', 'speech')\n",
      "('the', 'speech', 'recognition')\n",
      "('speech', 'recognition', 'software')\n",
      "('recognition', 'software', 'must')\n",
      "('software', 'must', 'be')\n",
      "('must', 'be', 'able')\n",
      "('be', 'able', 'to')\n",
      "('able', 'to', 'recognize')\n",
      "('to', 'recognize', 'the')\n",
      "('recognize', 'the', 'wide')\n",
      "('the', 'wide', 'variety')\n",
      "('wide', 'variety', 'of')\n",
      "('variety', 'of', 'input')\n",
      "('of', 'input', 'as')\n",
      "('input', 'as', 'being')\n",
      "('as', 'being', 'identical')\n",
      "('being', 'identical', 'to')\n",
      "('identical', 'to', 'each')\n",
      "('to', 'each', 'other')\n",
      "('each', 'other', 'in')\n",
      "('other', 'in', 'terms')\n",
      "('in', 'terms', 'of')\n",
      "('terms', 'of', 'its')\n",
      "('of', 'its', 'textual')\n",
      "('its', 'textual', 'equivalent.')\n",
      "('textual', 'equivalent.', 'Speech')\n",
      "('equivalent.', 'Speech', 'segmentation')\n",
      "('Speech', 'segmentation', 'Given')\n",
      "('segmentation', 'Given', 'a')\n",
      "('Given', 'a', 'sound')\n",
      "('a', 'sound', 'clip')\n",
      "('sound', 'clip', 'of')\n",
      "('clip', 'of', 'a')\n",
      "('of', 'a', 'person')\n",
      "('a', 'person', 'or')\n",
      "('person', 'or', 'people')\n",
      "('or', 'people', 'speaking,')\n",
      "('people', 'speaking,', 'separate')\n",
      "('speaking,', 'separate', 'it')\n",
      "('separate', 'it', 'into')\n",
      "('it', 'into', 'words.')\n",
      "('into', 'words.', 'A')\n",
      "('words.', 'A', 'subtask')\n",
      "('A', 'subtask', 'of')\n",
      "('subtask', 'of', 'speech')\n",
      "('of', 'speech', 'recognition')\n",
      "('speech', 'recognition', 'and')\n",
      "('recognition', 'and', 'typically')\n",
      "('and', 'typically', 'grouped')\n",
      "('typically', 'grouped', 'with')\n",
      "('grouped', 'with', 'it.')\n",
      "('with', 'it.', 'Text-to-speech')\n",
      "('it.', 'Text-to-speech', 'Given')\n",
      "('Text-to-speech', 'Given', 'a')\n",
      "('Given', 'a', 'text,')\n",
      "('a', 'text,', 'transform')\n",
      "('text,', 'transform', 'those')\n",
      "('transform', 'those', 'units')\n",
      "('those', 'units', 'and')\n",
      "('units', 'and', 'produce')\n",
      "('and', 'produce', 'a')\n",
      "('produce', 'a', 'spoken')\n",
      "('a', 'spoken', 'representation.')\n",
      "('spoken', 'representation.', 'Text-to-speech')\n",
      "('representation.', 'Text-to-speech', 'can')\n",
      "('Text-to-speech', 'can', 'be')\n",
      "('can', 'be', 'used')\n",
      "('be', 'used', 'to')\n",
      "('used', 'to', 'aid')\n",
      "('to', 'aid', 'the')\n",
      "('aid', 'the', 'visually')\n",
      "('the', 'visually', 'impaired.')\n",
      "('visually', 'impaired.', '[21]')\n",
      "('impaired.', '[21]', 'Word')\n",
      "('[21]', 'Word', 'segmentation')\n",
      "('Word', 'segmentation', '(')\n",
      "('segmentation', '(', 'Tokenization')\n",
      "('(', 'Tokenization', ')')\n",
      "('Tokenization', ')', 'Separate')\n",
      "(')', 'Separate', 'a')\n",
      "('Separate', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'continuous')\n",
      "('of', 'continuous', 'text')\n",
      "('continuous', 'text', 'into')\n",
      "('text', 'into', 'separate')\n",
      "('into', 'separate', 'words.')\n",
      "('separate', 'words.', 'For')\n",
      "('words.', 'For', 'a')\n",
      "('For', 'a', 'language')\n",
      "('a', 'language', 'like')\n",
      "('language', 'like', 'English')\n",
      "('like', 'English', ',')\n",
      "('English', ',', 'this')\n",
      "(',', 'this', 'is')\n",
      "('this', 'is', 'fairly')\n",
      "('is', 'fairly', 'trivial,')\n",
      "('fairly', 'trivial,', 'since')\n",
      "('trivial,', 'since', 'words')\n",
      "('since', 'words', 'are')\n",
      "('words', 'are', 'usually')\n",
      "('are', 'usually', 'separated')\n",
      "('usually', 'separated', 'by')\n",
      "('separated', 'by', 'spaces.')\n",
      "('by', 'spaces.', 'However,')\n",
      "('spaces.', 'However,', 'some')\n",
      "('However,', 'some', 'written')\n",
      "('some', 'written', 'languages')\n",
      "('written', 'languages', 'like')\n",
      "('languages', 'like', 'Chinese')\n",
      "('like', 'Chinese', ',')\n",
      "('Chinese', ',', 'Japanese')\n",
      "(',', 'Japanese', 'and')\n",
      "('Japanese', 'and', 'Thai')\n",
      "('and', 'Thai', 'do')\n",
      "('Thai', 'do', 'not')\n",
      "('do', 'not', 'mark')\n",
      "('not', 'mark', 'word')\n",
      "('mark', 'word', 'boundaries')\n",
      "('word', 'boundaries', 'in')\n",
      "('boundaries', 'in', 'such')\n",
      "('in', 'such', 'a')\n",
      "('such', 'a', 'fashion,')\n",
      "('a', 'fashion,', 'and')\n",
      "('fashion,', 'and', 'in')\n",
      "('and', 'in', 'those')\n",
      "('in', 'those', 'languages')\n",
      "('those', 'languages', 'text')\n",
      "('languages', 'text', 'segmentation')\n",
      "('text', 'segmentation', 'is')\n",
      "('segmentation', 'is', 'a')\n",
      "('is', 'a', 'significant')\n",
      "('a', 'significant', 'task')\n",
      "('significant', 'task', 'requiring')\n",
      "('task', 'requiring', 'knowledge')\n",
      "('requiring', 'knowledge', 'of')\n",
      "('knowledge', 'of', 'the')\n",
      "('of', 'the', 'vocabulary')\n",
      "('the', 'vocabulary', 'and')\n",
      "('vocabulary', 'and', 'morphology')\n",
      "('and', 'morphology', 'of')\n",
      "('morphology', 'of', 'words')\n",
      "('of', 'words', 'in')\n",
      "('words', 'in', 'the')\n",
      "('in', 'the', 'language.')\n",
      "('the', 'language.', 'Sometimes')\n",
      "('language.', 'Sometimes', 'this')\n",
      "('Sometimes', 'this', 'process')\n",
      "('this', 'process', 'is')\n",
      "('process', 'is', 'also')\n",
      "('is', 'also', 'used')\n",
      "('also', 'used', 'in')\n",
      "('used', 'in', 'cases')\n",
      "('in', 'cases', 'like')\n",
      "('cases', 'like', 'bag')\n",
      "('like', 'bag', 'of')\n",
      "('bag', 'of', 'words')\n",
      "('of', 'words', '(BOW)')\n",
      "('words', '(BOW)', 'creation')\n",
      "('(BOW)', 'creation', 'in')\n",
      "('creation', 'in', 'data')\n",
      "('in', 'data', 'mining.')\n",
      "('data', 'mining.', 'Morphological')\n",
      "('mining.', 'Morphological', 'analysis')\n",
      "('Morphological', 'analysis', '[')\n",
      "('analysis', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Lemmatization')\n",
      "(']', 'Lemmatization', 'The')\n",
      "('Lemmatization', 'The', 'task')\n",
      "('The', 'task', 'of')\n",
      "('task', 'of', 'removing')\n",
      "('of', 'removing', 'inflectional')\n",
      "('removing', 'inflectional', 'endings')\n",
      "('inflectional', 'endings', 'only')\n",
      "('endings', 'only', 'and')\n",
      "('only', 'and', 'to')\n",
      "('and', 'to', 'return')\n",
      "('to', 'return', 'the')\n",
      "('return', 'the', 'base')\n",
      "('the', 'base', 'dictionary')\n",
      "('base', 'dictionary', 'form')\n",
      "('dictionary', 'form', 'of')\n",
      "('form', 'of', 'a')\n",
      "('of', 'a', 'word')\n",
      "('a', 'word', 'which')\n",
      "('word', 'which', 'is')\n",
      "('which', 'is', 'also')\n",
      "('is', 'also', 'known')\n",
      "('also', 'known', 'as')\n",
      "('known', 'as', 'a')\n",
      "('as', 'a', 'lemma.')\n",
      "('a', 'lemma.', 'Lemmatization')\n",
      "('lemma.', 'Lemmatization', 'is')\n",
      "('Lemmatization', 'is', 'another')\n",
      "('is', 'another', 'technique')\n",
      "('another', 'technique', 'for')\n",
      "('technique', 'for', 'reducing')\n",
      "('for', 'reducing', 'words')\n",
      "('reducing', 'words', 'to')\n",
      "('words', 'to', 'their')\n",
      "('to', 'their', 'normalized')\n",
      "('their', 'normalized', 'form.')\n",
      "('normalized', 'form.', 'But')\n",
      "('form.', 'But', 'in')\n",
      "('But', 'in', 'this')\n",
      "('in', 'this', 'case,')\n",
      "('this', 'case,', 'the')\n",
      "('case,', 'the', 'transformation')\n",
      "('the', 'transformation', 'actually')\n",
      "('transformation', 'actually', 'uses')\n",
      "('actually', 'uses', 'a')\n",
      "('uses', 'a', 'dictionary')\n",
      "('a', 'dictionary', 'to')\n",
      "('dictionary', 'to', 'map')\n",
      "('to', 'map', 'words')\n",
      "('map', 'words', 'to')\n",
      "('words', 'to', 'their')\n",
      "('to', 'their', 'actual')\n",
      "('their', 'actual', 'form.')\n",
      "('actual', 'form.', '[22]')\n",
      "('form.', '[22]', 'Morphological')\n",
      "('[22]', 'Morphological', 'segmentation')\n",
      "('Morphological', 'segmentation', 'Separate')\n",
      "('segmentation', 'Separate', 'words')\n",
      "('Separate', 'words', 'into')\n",
      "('words', 'into', 'individual')\n",
      "('into', 'individual', 'morphemes')\n",
      "('individual', 'morphemes', 'and')\n",
      "('morphemes', 'and', 'identify')\n",
      "('and', 'identify', 'the')\n",
      "('identify', 'the', 'class')\n",
      "('the', 'class', 'of')\n",
      "('class', 'of', 'the')\n",
      "('of', 'the', 'morphemes.')\n",
      "('the', 'morphemes.', 'The')\n",
      "('morphemes.', 'The', 'difficulty')\n",
      "('The', 'difficulty', 'of')\n",
      "('difficulty', 'of', 'this')\n",
      "('of', 'this', 'task')\n",
      "('this', 'task', 'depends')\n",
      "('task', 'depends', 'greatly')\n",
      "('depends', 'greatly', 'on')\n",
      "('greatly', 'on', 'the')\n",
      "('on', 'the', 'complexity')\n",
      "('the', 'complexity', 'of')\n",
      "('complexity', 'of', 'the')\n",
      "('of', 'the', 'morphology')\n",
      "('the', 'morphology', '(')\n",
      "('morphology', '(', 'i.e.')\n",
      "('(', 'i.e.', ',')\n",
      "('i.e.', ',', 'the')\n",
      "(',', 'the', 'structure')\n",
      "('the', 'structure', 'of')\n",
      "('structure', 'of', 'words)')\n",
      "('of', 'words)', 'of')\n",
      "('words)', 'of', 'the')\n",
      "('of', 'the', 'language')\n",
      "('the', 'language', 'being')\n",
      "('language', 'being', 'considered.')\n",
      "('being', 'considered.', 'English')\n",
      "('considered.', 'English', 'has')\n",
      "('English', 'has', 'fairly')\n",
      "('has', 'fairly', 'simple')\n",
      "('fairly', 'simple', 'morphology,')\n",
      "('simple', 'morphology,', 'especially')\n",
      "('morphology,', 'especially', 'inflectional')\n",
      "('especially', 'inflectional', 'morphology')\n",
      "('inflectional', 'morphology', ',')\n",
      "('morphology', ',', 'and')\n",
      "(',', 'and', 'thus')\n",
      "('and', 'thus', 'it')\n",
      "('thus', 'it', 'is')\n",
      "('it', 'is', 'often')\n",
      "('is', 'often', 'possible')\n",
      "('often', 'possible', 'to')\n",
      "('possible', 'to', 'ignore')\n",
      "('to', 'ignore', 'this')\n",
      "('ignore', 'this', 'task')\n",
      "('this', 'task', 'entirely')\n",
      "('task', 'entirely', 'and')\n",
      "('entirely', 'and', 'simply')\n",
      "('and', 'simply', 'model')\n",
      "('simply', 'model', 'all')\n",
      "('model', 'all', 'possible')\n",
      "('all', 'possible', 'forms')\n",
      "('possible', 'forms', 'of')\n",
      "('forms', 'of', 'a')\n",
      "('of', 'a', 'word')\n",
      "('a', 'word', '(')\n",
      "('word', '(', 'e.g.')\n",
      "('(', 'e.g.', ',')\n",
      "('e.g.', ',', '\"open,')\n",
      "(',', '\"open,', 'opens,')\n",
      "('\"open,', 'opens,', 'opened,')\n",
      "('opens,', 'opened,', 'opening\")')\n",
      "('opened,', 'opening\")', 'as')\n",
      "('opening\")', 'as', 'separate')\n",
      "('as', 'separate', 'words.')\n",
      "('separate', 'words.', 'In')\n",
      "('words.', 'In', 'languages')\n",
      "('In', 'languages', 'such')\n",
      "('languages', 'such', 'as')\n",
      "('such', 'as', 'Turkish')\n",
      "('as', 'Turkish', 'or')\n",
      "('Turkish', 'or', 'Meitei')\n",
      "('or', 'Meitei', ',')\n",
      "('Meitei', ',', '[23]')\n",
      "(',', '[23]', 'a')\n",
      "('[23]', 'a', 'highly')\n",
      "('a', 'highly', 'agglutinated')\n",
      "('highly', 'agglutinated', 'Indian')\n",
      "('agglutinated', 'Indian', 'language,')\n",
      "('Indian', 'language,', 'however,')\n",
      "('language,', 'however,', 'such')\n",
      "('however,', 'such', 'an')\n",
      "('such', 'an', 'approach')\n",
      "('an', 'approach', 'is')\n",
      "('approach', 'is', 'not')\n",
      "('is', 'not', 'possible,')\n",
      "('not', 'possible,', 'as')\n",
      "('possible,', 'as', 'each')\n",
      "('as', 'each', 'dictionary')\n",
      "('each', 'dictionary', 'entry')\n",
      "('dictionary', 'entry', 'has')\n",
      "('entry', 'has', 'thousands')\n",
      "('has', 'thousands', 'of')\n",
      "('thousands', 'of', 'possible')\n",
      "('of', 'possible', 'word')\n",
      "('possible', 'word', 'forms.')\n",
      "('word', 'forms.', 'Part-of-speech')\n",
      "('forms.', 'Part-of-speech', 'tagging')\n",
      "('Part-of-speech', 'tagging', 'Given')\n",
      "('tagging', 'Given', 'a')\n",
      "('Given', 'a', 'sentence,')\n",
      "('a', 'sentence,', 'determine')\n",
      "('sentence,', 'determine', 'the')\n",
      "('determine', 'the', 'part')\n",
      "('the', 'part', 'of')\n",
      "('part', 'of', 'speech')\n",
      "('of', 'speech', '(POS)')\n",
      "('speech', '(POS)', 'for')\n",
      "('(POS)', 'for', 'each')\n",
      "('for', 'each', 'word.')\n",
      "('each', 'word.', 'Many')\n",
      "('word.', 'Many', 'words,')\n",
      "('Many', 'words,', 'especially')\n",
      "('words,', 'especially', 'common')\n",
      "('especially', 'common', 'ones,')\n",
      "('common', 'ones,', 'can')\n",
      "('ones,', 'can', 'serve')\n",
      "('can', 'serve', 'as')\n",
      "('serve', 'as', 'multiple')\n",
      "('as', 'multiple', 'parts')\n",
      "('multiple', 'parts', 'of')\n",
      "('parts', 'of', 'speech')\n",
      "('of', 'speech', '.')\n",
      "('speech', '.', 'For')\n",
      "('.', 'For', 'example,')\n",
      "('For', 'example,', '\"book\"')\n",
      "('example,', '\"book\"', 'can')\n",
      "('\"book\"', 'can', 'be')\n",
      "('can', 'be', 'a')\n",
      "('be', 'a', 'noun')\n",
      "('a', 'noun', '(\"the')\n",
      "('noun', '(\"the', 'book')\n",
      "('(\"the', 'book', 'on')\n",
      "('book', 'on', 'the')\n",
      "('on', 'the', 'table\")')\n",
      "('the', 'table\")', 'or')\n",
      "('table\")', 'or', 'verb')\n",
      "('or', 'verb', '(\"to')\n",
      "('verb', '(\"to', 'book')\n",
      "('(\"to', 'book', 'a')\n",
      "('book', 'a', 'flight\");')\n",
      "('a', 'flight\");', '\"set\"')\n",
      "('flight\");', '\"set\"', 'can')\n",
      "('\"set\"', 'can', 'be')\n",
      "('can', 'be', 'a')\n",
      "('be', 'a', 'noun')\n",
      "('a', 'noun', ',')\n",
      "('noun', ',', 'verb')\n",
      "(',', 'verb', 'or')\n",
      "('verb', 'or', 'adjective')\n",
      "('or', 'adjective', ';')\n",
      "('adjective', ';', 'and')\n",
      "(';', 'and', '\"out\"')\n",
      "('and', '\"out\"', 'can')\n",
      "('\"out\"', 'can', 'be')\n",
      "('can', 'be', 'any')\n",
      "('be', 'any', 'of')\n",
      "('any', 'of', 'at')\n",
      "('of', 'at', 'least')\n",
      "('at', 'least', 'five')\n",
      "('least', 'five', 'different')\n",
      "('five', 'different', 'parts')\n",
      "('different', 'parts', 'of')\n",
      "('parts', 'of', 'speech.')\n",
      "('of', 'speech.', 'Stemming')\n",
      "('speech.', 'Stemming', 'The')\n",
      "('Stemming', 'The', 'process')\n",
      "('The', 'process', 'of')\n",
      "('process', 'of', 'reducing')\n",
      "('of', 'reducing', 'inflected')\n",
      "('reducing', 'inflected', '(or')\n",
      "('inflected', '(or', 'sometimes')\n",
      "('(or', 'sometimes', 'derived)')\n",
      "('sometimes', 'derived)', 'words')\n",
      "('derived)', 'words', 'to')\n",
      "('words', 'to', 'a')\n",
      "('to', 'a', 'base')\n",
      "('a', 'base', 'form')\n",
      "('base', 'form', '(')\n",
      "('form', '(', 'e.g.')\n",
      "('(', 'e.g.', ',')\n",
      "('e.g.', ',', '\"close\"')\n",
      "(',', '\"close\"', 'will')\n",
      "('\"close\"', 'will', 'be')\n",
      "('will', 'be', 'the')\n",
      "('be', 'the', 'root')\n",
      "('the', 'root', 'for')\n",
      "('root', 'for', '\"closed\",')\n",
      "('for', '\"closed\",', '\"closing\",')\n",
      "('\"closed\",', '\"closing\",', '\"close\",')\n",
      "('\"closing\",', '\"close\",', '\"closer\"')\n",
      "('\"close\",', '\"closer\"', 'etc.).')\n",
      "('\"closer\"', 'etc.).', 'Stemming')\n",
      "('etc.).', 'Stemming', 'yields')\n",
      "('Stemming', 'yields', 'similar')\n",
      "('yields', 'similar', 'results')\n",
      "('similar', 'results', 'as')\n",
      "('results', 'as', 'lemmatization,')\n",
      "('as', 'lemmatization,', 'but')\n",
      "('lemmatization,', 'but', 'does')\n",
      "('but', 'does', 'so')\n",
      "('does', 'so', 'on')\n",
      "('so', 'on', 'grounds')\n",
      "('on', 'grounds', 'of')\n",
      "('grounds', 'of', 'rules,')\n",
      "('of', 'rules,', 'not')\n",
      "('rules,', 'not', 'a')\n",
      "('not', 'a', 'dictionary.')\n",
      "('a', 'dictionary.', 'Syntactic')\n",
      "('dictionary.', 'Syntactic', 'analysis')\n",
      "('Syntactic', 'analysis', '[')\n",
      "('analysis', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Grammar')\n",
      "(']', 'Grammar', 'induction')\n",
      "('Grammar', 'induction', '[24]')\n",
      "('induction', '[24]', 'Generate')\n",
      "('[24]', 'Generate', 'a')\n",
      "('Generate', 'a', 'formal')\n",
      "('a', 'formal', 'grammar')\n",
      "('formal', 'grammar', 'that')\n",
      "('grammar', 'that', 'describes')\n",
      "('that', 'describes', 'a')\n",
      "('describes', 'a', \"language's\")\n",
      "('a', \"language's\", 'syntax.')\n",
      "(\"language's\", 'syntax.', 'Sentence')\n",
      "('syntax.', 'Sentence', 'breaking')\n",
      "('Sentence', 'breaking', '(also')\n",
      "('breaking', '(also', 'known')\n",
      "('(also', 'known', 'as')\n",
      "('known', 'as', '\"')\n",
      "('as', '\"', 'sentence')\n",
      "('\"', 'sentence', 'boundary')\n",
      "('sentence', 'boundary', 'disambiguation')\n",
      "('boundary', 'disambiguation', '\")')\n",
      "('disambiguation', '\")', 'Given')\n",
      "('\")', 'Given', 'a')\n",
      "('Given', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'text,')\n",
      "('of', 'text,', 'find')\n",
      "('text,', 'find', 'the')\n",
      "('find', 'the', 'sentence')\n",
      "('the', 'sentence', 'boundaries.')\n",
      "('sentence', 'boundaries.', 'Sentence')\n",
      "('boundaries.', 'Sentence', 'boundaries')\n",
      "('Sentence', 'boundaries', 'are')\n",
      "('boundaries', 'are', 'often')\n",
      "('are', 'often', 'marked')\n",
      "('often', 'marked', 'by')\n",
      "('marked', 'by', 'periods')\n",
      "('by', 'periods', 'or')\n",
      "('periods', 'or', 'other')\n",
      "('or', 'other', 'punctuation')\n",
      "('other', 'punctuation', 'marks')\n",
      "('punctuation', 'marks', ',')\n",
      "('marks', ',', 'but')\n",
      "(',', 'but', 'these')\n",
      "('but', 'these', 'same')\n",
      "('these', 'same', 'characters')\n",
      "('same', 'characters', 'can')\n",
      "('characters', 'can', 'serve')\n",
      "('can', 'serve', 'other')\n",
      "('serve', 'other', 'purposes')\n",
      "('other', 'purposes', '(')\n",
      "('purposes', '(', 'e.g.')\n",
      "('(', 'e.g.', ',')\n",
      "('e.g.', ',', 'marking')\n",
      "(',', 'marking', 'abbreviations')\n",
      "('marking', 'abbreviations', ').')\n",
      "('abbreviations', ').', 'Parsing')\n",
      "(').', 'Parsing', 'Determine')\n",
      "('Parsing', 'Determine', 'the')\n",
      "('Determine', 'the', 'parse')\n",
      "('the', 'parse', 'tree')\n",
      "('parse', 'tree', '(grammatical')\n",
      "('tree', '(grammatical', 'analysis)')\n",
      "('(grammatical', 'analysis)', 'of')\n",
      "('analysis)', 'of', 'a')\n",
      "('of', 'a', 'given')\n",
      "('a', 'given', 'sentence.')\n",
      "('given', 'sentence.', 'The')\n",
      "('sentence.', 'The', 'grammar')\n",
      "('The', 'grammar', 'for')\n",
      "('grammar', 'for', 'natural')\n",
      "('for', 'natural', 'languages')\n",
      "('natural', 'languages', 'is')\n",
      "('languages', 'is', 'ambiguous')\n",
      "('is', 'ambiguous', 'and')\n",
      "('ambiguous', 'and', 'typical')\n",
      "('and', 'typical', 'sentences')\n",
      "('typical', 'sentences', 'have')\n",
      "('sentences', 'have', 'multiple')\n",
      "('have', 'multiple', 'possible')\n",
      "('multiple', 'possible', 'analyses:')\n",
      "('possible', 'analyses:', 'perhaps')\n",
      "('analyses:', 'perhaps', 'surprisingly,')\n",
      "('perhaps', 'surprisingly,', 'for')\n",
      "('surprisingly,', 'for', 'a')\n",
      "('for', 'a', 'typical')\n",
      "('a', 'typical', 'sentence')\n",
      "('typical', 'sentence', 'there')\n",
      "('sentence', 'there', 'may')\n",
      "('there', 'may', 'be')\n",
      "('may', 'be', 'thousands')\n",
      "('be', 'thousands', 'of')\n",
      "('thousands', 'of', 'potential')\n",
      "('of', 'potential', 'parses')\n",
      "('potential', 'parses', '(most')\n",
      "('parses', '(most', 'of')\n",
      "('(most', 'of', 'which')\n",
      "('of', 'which', 'will')\n",
      "('which', 'will', 'seem')\n",
      "('will', 'seem', 'completely')\n",
      "('seem', 'completely', 'nonsensical')\n",
      "('completely', 'nonsensical', 'to')\n",
      "('nonsensical', 'to', 'a')\n",
      "('to', 'a', 'human).')\n",
      "('a', 'human).', 'There')\n",
      "('human).', 'There', 'are')\n",
      "('There', 'are', 'two')\n",
      "('are', 'two', 'primary')\n",
      "('two', 'primary', 'types')\n",
      "('primary', 'types', 'of')\n",
      "('types', 'of', 'parsing:')\n",
      "('of', 'parsing:', 'dependency')\n",
      "('parsing:', 'dependency', 'parsing')\n",
      "('dependency', 'parsing', 'and')\n",
      "('parsing', 'and', 'constituency')\n",
      "('and', 'constituency', 'parsing')\n",
      "('constituency', 'parsing', '.')\n",
      "('parsing', '.', 'Dependency')\n",
      "('.', 'Dependency', 'parsing')\n",
      "('Dependency', 'parsing', 'focuses')\n",
      "('parsing', 'focuses', 'on')\n",
      "('focuses', 'on', 'the')\n",
      "('on', 'the', 'relationships')\n",
      "('the', 'relationships', 'between')\n",
      "('relationships', 'between', 'words')\n",
      "('between', 'words', 'in')\n",
      "('words', 'in', 'a')\n",
      "('in', 'a', 'sentence')\n",
      "('a', 'sentence', '(marking')\n",
      "('sentence', '(marking', 'things')\n",
      "('(marking', 'things', 'like')\n",
      "('things', 'like', 'primary')\n",
      "('like', 'primary', 'objects')\n",
      "('primary', 'objects', 'and')\n",
      "('objects', 'and', 'predicates),')\n",
      "('and', 'predicates),', 'whereas')\n",
      "('predicates),', 'whereas', 'constituency')\n",
      "('whereas', 'constituency', 'parsing')\n",
      "('constituency', 'parsing', 'focuses')\n",
      "('parsing', 'focuses', 'on')\n",
      "('focuses', 'on', 'building')\n",
      "('on', 'building', 'out')\n",
      "('building', 'out', 'the')\n",
      "('out', 'the', 'parse')\n",
      "('the', 'parse', 'tree')\n",
      "('parse', 'tree', 'using')\n",
      "('tree', 'using', 'a')\n",
      "('using', 'a', 'probabilistic')\n",
      "('a', 'probabilistic', 'context-free')\n",
      "('probabilistic', 'context-free', 'grammar')\n",
      "('context-free', 'grammar', '(PCFG)')\n",
      "('grammar', '(PCFG)', '(see')\n",
      "('(PCFG)', '(see', 'also')\n",
      "('(see', 'also', 'stochastic')\n",
      "('also', 'stochastic', 'grammar')\n",
      "('stochastic', 'grammar', ').')\n",
      "('grammar', ').', 'Lexical')\n",
      "(').', 'Lexical', 'semantics')\n",
      "('Lexical', 'semantics', '(of')\n",
      "('semantics', '(of', 'individual')\n",
      "('(of', 'individual', 'words')\n",
      "('individual', 'words', 'in')\n",
      "('words', 'in', 'context)')\n",
      "('in', 'context)', '[')\n",
      "('context)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Lexical')\n",
      "(']', 'Lexical', 'semantics')\n",
      "('Lexical', 'semantics', 'What')\n",
      "('semantics', 'What', 'is')\n",
      "('What', 'is', 'the')\n",
      "('is', 'the', 'computational')\n",
      "('the', 'computational', 'meaning')\n",
      "('computational', 'meaning', 'of')\n",
      "('meaning', 'of', 'individual')\n",
      "('of', 'individual', 'words')\n",
      "('individual', 'words', 'in')\n",
      "('words', 'in', 'context?')\n",
      "('in', 'context?', 'Distributional')\n",
      "('context?', 'Distributional', 'semantics')\n",
      "('Distributional', 'semantics', 'How')\n",
      "('semantics', 'How', 'can')\n",
      "('How', 'can', 'we')\n",
      "('can', 'we', 'learn')\n",
      "('we', 'learn', 'semantic')\n",
      "('learn', 'semantic', 'representations')\n",
      "('semantic', 'representations', 'from')\n",
      "('representations', 'from', 'data?')\n",
      "('from', 'data?', 'Named')\n",
      "('data?', 'Named', 'entity')\n",
      "('Named', 'entity', 'recognition')\n",
      "('entity', 'recognition', '(NER)')\n",
      "('recognition', '(NER)', 'Given')\n",
      "('(NER)', 'Given', 'a')\n",
      "('Given', 'a', 'stream')\n",
      "('a', 'stream', 'of')\n",
      "('stream', 'of', 'text,')\n",
      "('of', 'text,', 'determine')\n",
      "('text,', 'determine', 'which')\n",
      "('determine', 'which', 'items')\n",
      "('which', 'items', 'in')\n",
      "('items', 'in', 'the')\n",
      "('in', 'the', 'text')\n",
      "('the', 'text', 'map')\n",
      "('text', 'map', 'to')\n",
      "('map', 'to', 'proper')\n",
      "('to', 'proper', 'names,')\n",
      "('proper', 'names,', 'such')\n",
      "('names,', 'such', 'as')\n",
      "('such', 'as', 'people')\n",
      "('as', 'people', 'or')\n",
      "('people', 'or', 'places,')\n",
      "('or', 'places,', 'and')\n",
      "('places,', 'and', 'what')\n",
      "('and', 'what', 'the')\n",
      "('what', 'the', 'type')\n",
      "('the', 'type', 'of')\n",
      "('type', 'of', 'each')\n",
      "('of', 'each', 'such')\n",
      "('each', 'such', 'name')\n",
      "('such', 'name', 'is')\n",
      "('name', 'is', '(e.g.')\n",
      "('is', '(e.g.', 'person,')\n",
      "('(e.g.', 'person,', 'location,')\n",
      "('person,', 'location,', 'organization).')\n",
      "('location,', 'organization).', 'Although')\n",
      "('organization).', 'Although', 'capitalization')\n",
      "('Although', 'capitalization', 'can')\n",
      "('capitalization', 'can', 'aid')\n",
      "('can', 'aid', 'in')\n",
      "('aid', 'in', 'recognizing')\n",
      "('in', 'recognizing', 'named')\n",
      "('recognizing', 'named', 'entities')\n",
      "('named', 'entities', 'in')\n",
      "('entities', 'in', 'languages')\n",
      "('in', 'languages', 'such')\n",
      "('languages', 'such', 'as')\n",
      "('such', 'as', 'English,')\n",
      "('as', 'English,', 'this')\n",
      "('English,', 'this', 'information')\n",
      "('this', 'information', 'cannot')\n",
      "('information', 'cannot', 'aid')\n",
      "('cannot', 'aid', 'in')\n",
      "('aid', 'in', 'determining')\n",
      "('in', 'determining', 'the')\n",
      "('determining', 'the', 'type')\n",
      "('the', 'type', 'of')\n",
      "('type', 'of', 'named')\n",
      "('of', 'named', 'entity')\n",
      "('named', 'entity', ',')\n",
      "('entity', ',', 'and')\n",
      "(',', 'and', 'in')\n",
      "('and', 'in', 'any')\n",
      "('in', 'any', 'case,')\n",
      "('any', 'case,', 'is')\n",
      "('case,', 'is', 'often')\n",
      "('is', 'often', 'inaccurate')\n",
      "('often', 'inaccurate', 'or')\n",
      "('inaccurate', 'or', 'insufficient.')\n",
      "('or', 'insufficient.', 'For')\n",
      "('insufficient.', 'For', 'example,')\n",
      "('For', 'example,', 'the')\n",
      "('example,', 'the', 'first')\n",
      "('the', 'first', 'letter')\n",
      "('first', 'letter', 'of')\n",
      "('letter', 'of', 'a')\n",
      "('of', 'a', 'sentence')\n",
      "('a', 'sentence', 'is')\n",
      "('sentence', 'is', 'also')\n",
      "('is', 'also', 'capitalized,')\n",
      "('also', 'capitalized,', 'and')\n",
      "('capitalized,', 'and', 'named')\n",
      "('and', 'named', 'entities')\n",
      "('named', 'entities', 'often')\n",
      "('entities', 'often', 'span')\n",
      "('often', 'span', 'several')\n",
      "('span', 'several', 'words,')\n",
      "('several', 'words,', 'only')\n",
      "('words,', 'only', 'some')\n",
      "('only', 'some', 'of')\n",
      "('some', 'of', 'which')\n",
      "('of', 'which', 'are')\n",
      "('which', 'are', 'capitalized.')\n",
      "('are', 'capitalized.', 'Furthermore,')\n",
      "('capitalized.', 'Furthermore,', 'many')\n",
      "('Furthermore,', 'many', 'other')\n",
      "('many', 'other', 'languages')\n",
      "('other', 'languages', 'in')\n",
      "('languages', 'in', 'non-Western')\n",
      "('in', 'non-Western', 'scripts')\n",
      "('non-Western', 'scripts', '(e.g.')\n",
      "('scripts', '(e.g.', 'Chinese')\n",
      "('(e.g.', 'Chinese', 'or')\n",
      "('Chinese', 'or', 'Arabic')\n",
      "('or', 'Arabic', ')')\n",
      "('Arabic', ')', 'do')\n",
      "(')', 'do', 'not')\n",
      "('do', 'not', 'have')\n",
      "('not', 'have', 'any')\n",
      "('have', 'any', 'capitalization')\n",
      "('any', 'capitalization', 'at')\n",
      "('capitalization', 'at', 'all,')\n",
      "('at', 'all,', 'and')\n",
      "('all,', 'and', 'even')\n",
      "('and', 'even', 'languages')\n",
      "('even', 'languages', 'with')\n",
      "('languages', 'with', 'capitalization')\n",
      "('with', 'capitalization', 'may')\n",
      "('capitalization', 'may', 'not')\n",
      "('may', 'not', 'consistently')\n",
      "('not', 'consistently', 'use')\n",
      "('consistently', 'use', 'it')\n",
      "('use', 'it', 'to')\n",
      "('it', 'to', 'distinguish')\n",
      "('to', 'distinguish', 'names.')\n",
      "('distinguish', 'names.', 'For')\n",
      "('names.', 'For', 'example,')\n",
      "('For', 'example,', 'German')\n",
      "('example,', 'German', 'capitalizes')\n",
      "('German', 'capitalizes', 'all')\n",
      "('capitalizes', 'all', 'nouns')\n",
      "('all', 'nouns', ',')\n",
      "('nouns', ',', 'regardless')\n",
      "(',', 'regardless', 'of')\n",
      "('regardless', 'of', 'whether')\n",
      "('of', 'whether', 'they')\n",
      "('whether', 'they', 'are')\n",
      "('they', 'are', 'names,')\n",
      "('are', 'names,', 'and')\n",
      "('names,', 'and', 'French')\n",
      "('and', 'French', 'and')\n",
      "('French', 'and', 'Spanish')\n",
      "('and', 'Spanish', 'do')\n",
      "('Spanish', 'do', 'not')\n",
      "('do', 'not', 'capitalize')\n",
      "('not', 'capitalize', 'names')\n",
      "('capitalize', 'names', 'that')\n",
      "('names', 'that', 'serve')\n",
      "('that', 'serve', 'as')\n",
      "('serve', 'as', 'adjectives')\n",
      "('as', 'adjectives', '.')\n",
      "('adjectives', '.', 'Sentiment')\n",
      "('.', 'Sentiment', 'analysis')\n",
      "('Sentiment', 'analysis', '(see')\n",
      "('analysis', '(see', 'also')\n",
      "('(see', 'also', 'Multimodal')\n",
      "('also', 'Multimodal', 'sentiment')\n",
      "('Multimodal', 'sentiment', 'analysis')\n",
      "('sentiment', 'analysis', ')')\n",
      "('analysis', ')', 'Extract')\n",
      "(')', 'Extract', 'subjective')\n",
      "('Extract', 'subjective', 'information')\n",
      "('subjective', 'information', 'usually')\n",
      "('information', 'usually', 'from')\n",
      "('usually', 'from', 'a')\n",
      "('from', 'a', 'set')\n",
      "('a', 'set', 'of')\n",
      "('set', 'of', 'documents,')\n",
      "('of', 'documents,', 'often')\n",
      "('documents,', 'often', 'using')\n",
      "('often', 'using', 'online')\n",
      "('using', 'online', 'reviews')\n",
      "('online', 'reviews', 'to')\n",
      "('reviews', 'to', 'determine')\n",
      "('to', 'determine', '\"polarity\"')\n",
      "('determine', '\"polarity\"', 'about')\n",
      "('\"polarity\"', 'about', 'specific')\n",
      "('about', 'specific', 'objects.')\n",
      "('specific', 'objects.', 'It')\n",
      "('objects.', 'It', 'is')\n",
      "('It', 'is', 'especially')\n",
      "('is', 'especially', 'useful')\n",
      "('especially', 'useful', 'for')\n",
      "('useful', 'for', 'identifying')\n",
      "('for', 'identifying', 'trends')\n",
      "('identifying', 'trends', 'of')\n",
      "('trends', 'of', 'public')\n",
      "('of', 'public', 'opinion')\n",
      "('public', 'opinion', 'in')\n",
      "('opinion', 'in', 'social')\n",
      "('in', 'social', 'media,')\n",
      "('social', 'media,', 'for')\n",
      "('media,', 'for', 'marketing.')\n",
      "('for', 'marketing.', 'Terminology')\n",
      "('marketing.', 'Terminology', 'extraction')\n",
      "('Terminology', 'extraction', 'The')\n",
      "('extraction', 'The', 'goal')\n",
      "('The', 'goal', 'of')\n",
      "('goal', 'of', 'terminology')\n",
      "('of', 'terminology', 'extraction')\n",
      "('terminology', 'extraction', 'is')\n",
      "('extraction', 'is', 'to')\n",
      "('is', 'to', 'automatically')\n",
      "('to', 'automatically', 'extract')\n",
      "('automatically', 'extract', 'relevant')\n",
      "('extract', 'relevant', 'terms')\n",
      "('relevant', 'terms', 'from')\n",
      "('terms', 'from', 'a')\n",
      "('from', 'a', 'given')\n",
      "('a', 'given', 'corpus.')\n",
      "('given', 'corpus.', 'Word')\n",
      "('corpus.', 'Word', 'sense')\n",
      "('Word', 'sense', 'disambiguation')\n",
      "('sense', 'disambiguation', '(WSD)')\n",
      "('disambiguation', '(WSD)', 'Many')\n",
      "('(WSD)', 'Many', 'words')\n",
      "('Many', 'words', 'have')\n",
      "('words', 'have', 'more')\n",
      "('have', 'more', 'than')\n",
      "('more', 'than', 'one')\n",
      "('than', 'one', 'meaning')\n",
      "('one', 'meaning', ';')\n",
      "('meaning', ';', 'we')\n",
      "(';', 'we', 'have')\n",
      "('we', 'have', 'to')\n",
      "('have', 'to', 'select')\n",
      "('to', 'select', 'the')\n",
      "('select', 'the', 'meaning')\n",
      "('the', 'meaning', 'which')\n",
      "('meaning', 'which', 'makes')\n",
      "('which', 'makes', 'the')\n",
      "('makes', 'the', 'most')\n",
      "('the', 'most', 'sense')\n",
      "('most', 'sense', 'in')\n",
      "('sense', 'in', 'context.')\n",
      "('in', 'context.', 'For')\n",
      "('context.', 'For', 'this')\n",
      "('For', 'this', 'problem,')\n",
      "('this', 'problem,', 'we')\n",
      "('problem,', 'we', 'are')\n",
      "('we', 'are', 'typically')\n",
      "('are', 'typically', 'given')\n",
      "('typically', 'given', 'a')\n",
      "('given', 'a', 'list')\n",
      "('a', 'list', 'of')\n",
      "('list', 'of', 'words')\n",
      "('of', 'words', 'and')\n",
      "('words', 'and', 'associated')\n",
      "('and', 'associated', 'word')\n",
      "('associated', 'word', 'senses,')\n",
      "('word', 'senses,', 'e.g.')\n",
      "('senses,', 'e.g.', 'from')\n",
      "('e.g.', 'from', 'a')\n",
      "('from', 'a', 'dictionary')\n",
      "('a', 'dictionary', 'or')\n",
      "('dictionary', 'or', 'an')\n",
      "('or', 'an', 'online')\n",
      "('an', 'online', 'resource')\n",
      "('online', 'resource', 'such')\n",
      "('resource', 'such', 'as')\n",
      "('such', 'as', 'WordNet')\n",
      "('as', 'WordNet', '.')\n",
      "('WordNet', '.', 'Entity')\n",
      "('.', 'Entity', 'linking')\n",
      "('Entity', 'linking', 'Many')\n",
      "('linking', 'Many', 'words')\n",
      "('Many', 'words', '-')\n",
      "('words', '-', 'typically')\n",
      "('-', 'typically', 'proper')\n",
      "('typically', 'proper', 'names')\n",
      "('proper', 'names', '-')\n",
      "('names', '-', 'refer')\n",
      "('-', 'refer', 'to')\n",
      "('refer', 'to', 'named')\n",
      "('to', 'named', 'entities')\n",
      "('named', 'entities', ';')\n",
      "('entities', ';', 'here')\n",
      "(';', 'here', 'we')\n",
      "('here', 'we', 'have')\n",
      "('we', 'have', 'to')\n",
      "('have', 'to', 'select')\n",
      "('to', 'select', 'the')\n",
      "('select', 'the', 'entity')\n",
      "('the', 'entity', '(a')\n",
      "('entity', '(a', 'famous')\n",
      "('(a', 'famous', 'individual,')\n",
      "('famous', 'individual,', 'a')\n",
      "('individual,', 'a', 'location,')\n",
      "('a', 'location,', 'a')\n",
      "('location,', 'a', 'company,')\n",
      "('a', 'company,', 'etc.)')\n",
      "('company,', 'etc.)', 'which')\n",
      "('etc.)', 'which', 'is')\n",
      "('which', 'is', 'referred')\n",
      "('is', 'referred', 'to')\n",
      "('referred', 'to', 'in')\n",
      "('to', 'in', 'context.')\n",
      "('in', 'context.', 'Relational')\n",
      "('context.', 'Relational', 'semantics')\n",
      "('Relational', 'semantics', '(semantics')\n",
      "('semantics', '(semantics', 'of')\n",
      "('(semantics', 'of', 'individual')\n",
      "('of', 'individual', 'sentences)')\n",
      "('individual', 'sentences)', '[')\n",
      "('sentences)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Relationship')\n",
      "(']', 'Relationship', 'extraction')\n",
      "('Relationship', 'extraction', 'Given')\n",
      "('extraction', 'Given', 'a')\n",
      "('Given', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'text,')\n",
      "('of', 'text,', 'identify')\n",
      "('text,', 'identify', 'the')\n",
      "('identify', 'the', 'relationships')\n",
      "('the', 'relationships', 'among')\n",
      "('relationships', 'among', 'named')\n",
      "('among', 'named', 'entities')\n",
      "('named', 'entities', '(e.g.')\n",
      "('entities', '(e.g.', 'who')\n",
      "('(e.g.', 'who', 'is')\n",
      "('who', 'is', 'married')\n",
      "('is', 'married', 'to')\n",
      "('married', 'to', 'whom).')\n",
      "('to', 'whom).', 'Semantic')\n",
      "('whom).', 'Semantic', 'parsing')\n",
      "('Semantic', 'parsing', 'Given')\n",
      "('parsing', 'Given', 'a')\n",
      "('Given', 'a', 'piece')\n",
      "('a', 'piece', 'of')\n",
      "('piece', 'of', 'text')\n",
      "('of', 'text', '(typically')\n",
      "('text', '(typically', 'a')\n",
      "('(typically', 'a', 'sentence),')\n",
      "('a', 'sentence),', 'produce')\n",
      "('sentence),', 'produce', 'a')\n",
      "('produce', 'a', 'formal')\n",
      "('a', 'formal', 'representation')\n",
      "('formal', 'representation', 'of')\n",
      "('representation', 'of', 'its')\n",
      "('of', 'its', 'semantics,')\n",
      "('its', 'semantics,', 'either')\n",
      "('semantics,', 'either', 'as')\n",
      "('either', 'as', 'a')\n",
      "('as', 'a', 'graph')\n",
      "('a', 'graph', '(e.g.,')\n",
      "('graph', '(e.g.,', 'in')\n",
      "('(e.g.,', 'in', 'AMR')\n",
      "('in', 'AMR', 'parsing')\n",
      "('AMR', 'parsing', ')')\n",
      "('parsing', ')', 'or')\n",
      "(')', 'or', 'in')\n",
      "('or', 'in', 'accordance')\n",
      "('in', 'accordance', 'with')\n",
      "('accordance', 'with', 'a')\n",
      "('with', 'a', 'logical')\n",
      "('a', 'logical', 'formalism')\n",
      "('logical', 'formalism', '(e.g.,')\n",
      "('formalism', '(e.g.,', 'in')\n",
      "('(e.g.,', 'in', 'DRT')\n",
      "('in', 'DRT', 'parsing')\n",
      "('DRT', 'parsing', ').')\n",
      "('parsing', ').', 'This')\n",
      "(').', 'This', 'challenge')\n",
      "('This', 'challenge', 'typically')\n",
      "('challenge', 'typically', 'includes')\n",
      "('typically', 'includes', 'aspects')\n",
      "('includes', 'aspects', 'of')\n",
      "('aspects', 'of', 'several')\n",
      "('of', 'several', 'more')\n",
      "('several', 'more', 'elementary')\n",
      "('more', 'elementary', 'NLP')\n",
      "('elementary', 'NLP', 'tasks')\n",
      "('NLP', 'tasks', 'from')\n",
      "('tasks', 'from', 'semantics')\n",
      "('from', 'semantics', '(e.g.,')\n",
      "('semantics', '(e.g.,', 'semantic')\n",
      "('(e.g.,', 'semantic', 'role')\n",
      "('semantic', 'role', 'labelling,')\n",
      "('role', 'labelling,', 'word')\n",
      "('labelling,', 'word', 'sense')\n",
      "('word', 'sense', 'disambiguation)')\n",
      "('sense', 'disambiguation)', 'and')\n",
      "('disambiguation)', 'and', 'can')\n",
      "('and', 'can', 'be')\n",
      "('can', 'be', 'extended')\n",
      "('be', 'extended', 'to')\n",
      "('extended', 'to', 'include')\n",
      "('to', 'include', 'full-fledged')\n",
      "('include', 'full-fledged', 'discourse')\n",
      "('full-fledged', 'discourse', 'analysis')\n",
      "('discourse', 'analysis', '(e.g.,')\n",
      "('analysis', '(e.g.,', 'discourse')\n",
      "('(e.g.,', 'discourse', 'analysis,')\n",
      "('discourse', 'analysis,', 'coreference;')\n",
      "('analysis,', 'coreference;', 'see')\n",
      "('coreference;', 'see', 'Natural')\n",
      "('see', 'Natural', 'language')\n",
      "('Natural', 'language', 'understanding')\n",
      "('language', 'understanding', 'below).')\n",
      "('understanding', 'below).', 'Semantic')\n",
      "('below).', 'Semantic', 'role')\n",
      "('Semantic', 'role', 'labelling')\n",
      "('role', 'labelling', '(see')\n",
      "('labelling', '(see', 'also')\n",
      "('(see', 'also', 'implicit')\n",
      "('also', 'implicit', 'semantic')\n",
      "('implicit', 'semantic', 'role')\n",
      "('semantic', 'role', 'labelling')\n",
      "('role', 'labelling', 'below)')\n",
      "('labelling', 'below)', 'Given')\n",
      "('below)', 'Given', 'a')\n",
      "('Given', 'a', 'single')\n",
      "('a', 'single', 'sentence,')\n",
      "('single', 'sentence,', 'identify')\n",
      "('sentence,', 'identify', 'and')\n",
      "('identify', 'and', 'disambiguate')\n",
      "('and', 'disambiguate', 'semantic')\n",
      "('disambiguate', 'semantic', 'predicates')\n",
      "('semantic', 'predicates', '(e.g.,')\n",
      "('predicates', '(e.g.,', 'verbal')\n",
      "('(e.g.,', 'verbal', 'frames')\n",
      "('verbal', 'frames', '),')\n",
      "('frames', '),', 'then')\n",
      "('),', 'then', 'identify')\n",
      "('then', 'identify', 'and')\n",
      "('identify', 'and', 'classify')\n",
      "('and', 'classify', 'the')\n",
      "('classify', 'the', 'frame')\n",
      "('the', 'frame', 'elements')\n",
      "('frame', 'elements', '(')\n",
      "('elements', '(', 'semantic')\n",
      "('(', 'semantic', 'roles')\n",
      "('semantic', 'roles', ').')\n",
      "('roles', ').', 'Discourse')\n",
      "(').', 'Discourse', '(semantics')\n",
      "('Discourse', '(semantics', 'beyond')\n",
      "('(semantics', 'beyond', 'individual')\n",
      "('beyond', 'individual', 'sentences)')\n",
      "('individual', 'sentences)', '[')\n",
      "('sentences)', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Coreference')\n",
      "(']', 'Coreference', 'resolution')\n",
      "('Coreference', 'resolution', 'Given')\n",
      "('resolution', 'Given', 'a')\n",
      "('Given', 'a', 'sentence')\n",
      "('a', 'sentence', 'or')\n",
      "('sentence', 'or', 'larger')\n",
      "('or', 'larger', 'chunk')\n",
      "('larger', 'chunk', 'of')\n",
      "('chunk', 'of', 'text,')\n",
      "('of', 'text,', 'determine')\n",
      "('text,', 'determine', 'which')\n",
      "('determine', 'which', 'words')\n",
      "('which', 'words', '(\"mentions\")')\n",
      "('words', '(\"mentions\")', 'refer')\n",
      "('(\"mentions\")', 'refer', 'to')\n",
      "('refer', 'to', 'the')\n",
      "('to', 'the', 'same')\n",
      "('the', 'same', 'objects')\n",
      "('same', 'objects', '(\"entities\").')\n",
      "('objects', '(\"entities\").', 'Anaphora')\n",
      "('(\"entities\").', 'Anaphora', 'resolution')\n",
      "('Anaphora', 'resolution', 'is')\n",
      "('resolution', 'is', 'a')\n",
      "('is', 'a', 'specific')\n",
      "('a', 'specific', 'example')\n",
      "('specific', 'example', 'of')\n",
      "('example', 'of', 'this')\n",
      "('of', 'this', 'task,')\n",
      "('this', 'task,', 'and')\n",
      "('task,', 'and', 'is')\n",
      "('and', 'is', 'specifically')\n",
      "('is', 'specifically', 'concerned')\n",
      "('specifically', 'concerned', 'with')\n",
      "('concerned', 'with', 'matching')\n",
      "('with', 'matching', 'up')\n",
      "('matching', 'up', 'pronouns')\n",
      "('up', 'pronouns', 'with')\n",
      "('pronouns', 'with', 'the')\n",
      "('with', 'the', 'nouns')\n",
      "('the', 'nouns', 'or')\n",
      "('nouns', 'or', 'names')\n",
      "('or', 'names', 'to')\n",
      "('names', 'to', 'which')\n",
      "('to', 'which', 'they')\n",
      "('which', 'they', 'refer.')\n",
      "('they', 'refer.', 'The')\n",
      "('refer.', 'The', 'more')\n",
      "('The', 'more', 'general')\n",
      "('more', 'general', 'task')\n",
      "('general', 'task', 'of')\n",
      "('task', 'of', 'coreference')\n",
      "('of', 'coreference', 'resolution')\n",
      "('coreference', 'resolution', 'also')\n",
      "('resolution', 'also', 'includes')\n",
      "('also', 'includes', 'identifying')\n",
      "('includes', 'identifying', 'so-called')\n",
      "('identifying', 'so-called', '\"bridging')\n",
      "('so-called', '\"bridging', 'relationships\"')\n",
      "('\"bridging', 'relationships\"', 'involving')\n",
      "('relationships\"', 'involving', 'referring')\n",
      "('involving', 'referring', 'expressions')\n",
      "('referring', 'expressions', '.')\n",
      "('expressions', '.', 'For')\n",
      "('.', 'For', 'example,')\n",
      "('For', 'example,', 'in')\n",
      "('example,', 'in', 'a')\n",
      "('in', 'a', 'sentence')\n",
      "('a', 'sentence', 'such')\n",
      "('sentence', 'such', 'as')\n",
      "('such', 'as', '\"He')\n",
      "('as', '\"He', 'entered')\n",
      "('\"He', 'entered', \"John's\")\n",
      "('entered', \"John's\", 'house')\n",
      "(\"John's\", 'house', 'through')\n",
      "('house', 'through', 'the')\n",
      "('through', 'the', 'front')\n",
      "('the', 'front', 'door\",')\n",
      "('front', 'door\",', '\"the')\n",
      "('door\",', '\"the', 'front')\n",
      "('\"the', 'front', 'door\"')\n",
      "('front', 'door\"', 'is')\n",
      "('door\"', 'is', 'a')\n",
      "('is', 'a', 'referring')\n",
      "('a', 'referring', 'expression')\n",
      "('referring', 'expression', 'and')\n",
      "('expression', 'and', 'the')\n",
      "('and', 'the', 'bridging')\n",
      "('the', 'bridging', 'relationship')\n",
      "('bridging', 'relationship', 'to')\n",
      "('relationship', 'to', 'be')\n",
      "('to', 'be', 'identified')\n",
      "('be', 'identified', 'is')\n",
      "('identified', 'is', 'the')\n",
      "('is', 'the', 'fact')\n",
      "('the', 'fact', 'that')\n",
      "('fact', 'that', 'the')\n",
      "('that', 'the', 'door')\n",
      "('the', 'door', 'being')\n",
      "('door', 'being', 'referred')\n",
      "('being', 'referred', 'to')\n",
      "('referred', 'to', 'is')\n",
      "('to', 'is', 'the')\n",
      "('is', 'the', 'front')\n",
      "('the', 'front', 'door')\n",
      "('front', 'door', 'of')\n",
      "('door', 'of', \"John's\")\n",
      "('of', \"John's\", 'house')\n",
      "(\"John's\", 'house', '(rather')\n",
      "('house', '(rather', 'than')\n",
      "('(rather', 'than', 'of')\n",
      "('than', 'of', 'some')\n",
      "('of', 'some', 'other')\n",
      "('some', 'other', 'structure')\n",
      "('other', 'structure', 'that')\n",
      "('structure', 'that', 'might')\n",
      "('that', 'might', 'also')\n",
      "('might', 'also', 'be')\n",
      "('also', 'be', 'referred')\n",
      "('be', 'referred', 'to).')\n",
      "('referred', 'to).', 'Discourse')\n",
      "('to).', 'Discourse', 'analysis')\n",
      "('Discourse', 'analysis', 'This')\n",
      "('analysis', 'This', 'rubric')\n",
      "('This', 'rubric', 'includes')\n",
      "('rubric', 'includes', 'several')\n",
      "('includes', 'several', 'related')\n",
      "('several', 'related', 'tasks.')\n",
      "('related', 'tasks.', 'One')\n",
      "('tasks.', 'One', 'task')\n",
      "('One', 'task', 'is')\n",
      "('task', 'is', 'discourse')\n",
      "('is', 'discourse', 'parsing,')\n",
      "('discourse', 'parsing,', 'i.e.,')\n",
      "('parsing,', 'i.e.,', 'identifying')\n",
      "('i.e.,', 'identifying', 'the')\n",
      "('identifying', 'the', 'discourse')\n",
      "('the', 'discourse', 'structure')\n",
      "('discourse', 'structure', 'of')\n",
      "('structure', 'of', 'a')\n",
      "('of', 'a', 'connected')\n",
      "('a', 'connected', 'text,')\n",
      "('connected', 'text,', 'i.e.')\n",
      "('text,', 'i.e.', 'the')\n",
      "('i.e.', 'the', 'nature')\n",
      "('the', 'nature', 'of')\n",
      "('nature', 'of', 'the')\n",
      "('of', 'the', 'discourse')\n",
      "('the', 'discourse', 'relationships')\n",
      "('discourse', 'relationships', 'between')\n",
      "('relationships', 'between', 'sentences')\n",
      "('between', 'sentences', '(e.g.')\n",
      "('sentences', '(e.g.', 'elaboration,')\n",
      "('(e.g.', 'elaboration,', 'explanation,')\n",
      "('elaboration,', 'explanation,', 'contrast).')\n",
      "('explanation,', 'contrast).', 'Another')\n",
      "('contrast).', 'Another', 'possible')\n",
      "('Another', 'possible', 'task')\n",
      "('possible', 'task', 'is')\n",
      "('task', 'is', 'recognizing')\n",
      "('is', 'recognizing', 'and')\n",
      "('recognizing', 'and', 'classifying')\n",
      "('and', 'classifying', 'the')\n",
      "('classifying', 'the', 'speech')\n",
      "('the', 'speech', 'acts')\n",
      "('speech', 'acts', 'in')\n",
      "('acts', 'in', 'a')\n",
      "('in', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'text')\n",
      "('of', 'text', '(e.g.')\n",
      "('text', '(e.g.', 'yes-no')\n",
      "('(e.g.', 'yes-no', 'question,')\n",
      "('yes-no', 'question,', 'content')\n",
      "('question,', 'content', 'question,')\n",
      "('content', 'question,', 'statement,')\n",
      "('question,', 'statement,', 'assertion,')\n",
      "('statement,', 'assertion,', 'etc.).')\n",
      "('assertion,', 'etc.).', 'Implicit')\n",
      "('etc.).', 'Implicit', 'semantic')\n",
      "('Implicit', 'semantic', 'role')\n",
      "('semantic', 'role', 'labelling')\n",
      "('role', 'labelling', 'Given')\n",
      "('labelling', 'Given', 'a')\n",
      "('Given', 'a', 'single')\n",
      "('a', 'single', 'sentence,')\n",
      "('single', 'sentence,', 'identify')\n",
      "('sentence,', 'identify', 'and')\n",
      "('identify', 'and', 'disambiguate')\n",
      "('and', 'disambiguate', 'semantic')\n",
      "('disambiguate', 'semantic', 'predicates')\n",
      "('semantic', 'predicates', '(e.g.,')\n",
      "('predicates', '(e.g.,', 'verbal')\n",
      "('(e.g.,', 'verbal', 'frames')\n",
      "('verbal', 'frames', ')')\n",
      "('frames', ')', 'and')\n",
      "(')', 'and', 'their')\n",
      "('and', 'their', 'explicit')\n",
      "('their', 'explicit', 'semantic')\n",
      "('explicit', 'semantic', 'roles')\n",
      "('semantic', 'roles', 'in')\n",
      "('roles', 'in', 'the')\n",
      "('in', 'the', 'current')\n",
      "('the', 'current', 'sentence')\n",
      "('current', 'sentence', '(see')\n",
      "('sentence', '(see', 'Semantic')\n",
      "('(see', 'Semantic', 'role')\n",
      "('Semantic', 'role', 'labelling')\n",
      "('role', 'labelling', 'above).')\n",
      "('labelling', 'above).', 'Then,')\n",
      "('above).', 'Then,', 'identify')\n",
      "('Then,', 'identify', 'semantic')\n",
      "('identify', 'semantic', 'roles')\n",
      "('semantic', 'roles', 'that')\n",
      "('roles', 'that', 'are')\n",
      "('that', 'are', 'not')\n",
      "('are', 'not', 'explicitly')\n",
      "('not', 'explicitly', 'realized')\n",
      "('explicitly', 'realized', 'in')\n",
      "('realized', 'in', 'the')\n",
      "('in', 'the', 'current')\n",
      "('the', 'current', 'sentence,')\n",
      "('current', 'sentence,', 'classify')\n",
      "('sentence,', 'classify', 'them')\n",
      "('classify', 'them', 'into')\n",
      "('them', 'into', 'arguments')\n",
      "('into', 'arguments', 'that')\n",
      "('arguments', 'that', 'are')\n",
      "('that', 'are', 'explicitly')\n",
      "('are', 'explicitly', 'realized')\n",
      "('explicitly', 'realized', 'elsewhere')\n",
      "('realized', 'elsewhere', 'in')\n",
      "('elsewhere', 'in', 'the')\n",
      "('in', 'the', 'text')\n",
      "('the', 'text', 'and')\n",
      "('text', 'and', 'those')\n",
      "('and', 'those', 'that')\n",
      "('those', 'that', 'are')\n",
      "('that', 'are', 'not')\n",
      "('are', 'not', 'specified,')\n",
      "('not', 'specified,', 'and')\n",
      "('specified,', 'and', 'resolve')\n",
      "('and', 'resolve', 'the')\n",
      "('resolve', 'the', 'former')\n",
      "('the', 'former', 'against')\n",
      "('former', 'against', 'the')\n",
      "('against', 'the', 'local')\n",
      "('the', 'local', 'text.')\n",
      "('local', 'text.', 'A')\n",
      "('text.', 'A', 'closely')\n",
      "('A', 'closely', 'related')\n",
      "('closely', 'related', 'task')\n",
      "('related', 'task', 'is')\n",
      "('task', 'is', 'zero')\n",
      "('is', 'zero', 'anaphora')\n",
      "('zero', 'anaphora', 'resolution,')\n",
      "('anaphora', 'resolution,', 'i.e.,')\n",
      "('resolution,', 'i.e.,', 'the')\n",
      "('i.e.,', 'the', 'extension')\n",
      "('the', 'extension', 'of')\n",
      "('extension', 'of', 'coreference')\n",
      "('of', 'coreference', 'resolution')\n",
      "('coreference', 'resolution', 'to')\n",
      "('resolution', 'to', 'pro-drop')\n",
      "('to', 'pro-drop', 'languages')\n",
      "('pro-drop', 'languages', '.')\n",
      "('languages', '.', 'Recognizing')\n",
      "('.', 'Recognizing', 'textual')\n",
      "('Recognizing', 'textual', 'entailment')\n",
      "('textual', 'entailment', 'Given')\n",
      "('entailment', 'Given', 'two')\n",
      "('Given', 'two', 'text')\n",
      "('two', 'text', 'fragments,')\n",
      "('text', 'fragments,', 'determine')\n",
      "('fragments,', 'determine', 'if')\n",
      "('determine', 'if', 'one')\n",
      "('if', 'one', 'being')\n",
      "('one', 'being', 'true')\n",
      "('being', 'true', 'entails')\n",
      "('true', 'entails', 'the')\n",
      "('entails', 'the', 'other,')\n",
      "('the', 'other,', 'entails')\n",
      "('other,', 'entails', 'the')\n",
      "('entails', 'the', \"other's\")\n",
      "('the', \"other's\", 'negation,')\n",
      "(\"other's\", 'negation,', 'or')\n",
      "('negation,', 'or', 'allows')\n",
      "('or', 'allows', 'the')\n",
      "('allows', 'the', 'other')\n",
      "('the', 'other', 'to')\n",
      "('other', 'to', 'be')\n",
      "('to', 'be', 'either')\n",
      "('be', 'either', 'true')\n",
      "('either', 'true', 'or')\n",
      "('true', 'or', 'false.')\n",
      "('or', 'false.', '[25]')\n",
      "('false.', '[25]', 'Topic')\n",
      "('[25]', 'Topic', 'segmentation')\n",
      "('Topic', 'segmentation', 'and')\n",
      "('segmentation', 'and', 'recognition')\n",
      "('and', 'recognition', 'Given')\n",
      "('recognition', 'Given', 'a')\n",
      "('Given', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'text,')\n",
      "('of', 'text,', 'separate')\n",
      "('text,', 'separate', 'it')\n",
      "('separate', 'it', 'into')\n",
      "('it', 'into', 'segments')\n",
      "('into', 'segments', 'each')\n",
      "('segments', 'each', 'of')\n",
      "('each', 'of', 'which')\n",
      "('of', 'which', 'is')\n",
      "('which', 'is', 'devoted')\n",
      "('is', 'devoted', 'to')\n",
      "('devoted', 'to', 'a')\n",
      "('to', 'a', 'topic,')\n",
      "('a', 'topic,', 'and')\n",
      "('topic,', 'and', 'identify')\n",
      "('and', 'identify', 'the')\n",
      "('identify', 'the', 'topic')\n",
      "('the', 'topic', 'of')\n",
      "('topic', 'of', 'the')\n",
      "('of', 'the', 'segment.')\n",
      "('the', 'segment.', 'Argument')\n",
      "('segment.', 'Argument', 'mining')\n",
      "('Argument', 'mining', 'The')\n",
      "('mining', 'The', 'goal')\n",
      "('The', 'goal', 'of')\n",
      "('goal', 'of', 'argument')\n",
      "('of', 'argument', 'mining')\n",
      "('argument', 'mining', 'is')\n",
      "('mining', 'is', 'the')\n",
      "('is', 'the', 'automatic')\n",
      "('the', 'automatic', 'extraction')\n",
      "('automatic', 'extraction', 'and')\n",
      "('extraction', 'and', 'identification')\n",
      "('and', 'identification', 'of')\n",
      "('identification', 'of', 'argumentative')\n",
      "('of', 'argumentative', 'structures')\n",
      "('argumentative', 'structures', 'from')\n",
      "('structures', 'from', 'natural')\n",
      "('from', 'natural', 'language')\n",
      "('natural', 'language', 'text')\n",
      "('language', 'text', 'with')\n",
      "('text', 'with', 'the')\n",
      "('with', 'the', 'aid')\n",
      "('the', 'aid', 'of')\n",
      "('aid', 'of', 'computer')\n",
      "('of', 'computer', 'programs.')\n",
      "('computer', 'programs.', '[26]')\n",
      "('programs.', '[26]', 'Such')\n",
      "('[26]', 'Such', 'argumentative')\n",
      "('Such', 'argumentative', 'structures')\n",
      "('argumentative', 'structures', 'include')\n",
      "('structures', 'include', 'the')\n",
      "('include', 'the', 'premise,')\n",
      "('the', 'premise,', 'conclusions,')\n",
      "('premise,', 'conclusions,', 'the')\n",
      "('conclusions,', 'the', 'argument')\n",
      "('the', 'argument', 'scheme')\n",
      "('argument', 'scheme', 'and')\n",
      "('scheme', 'and', 'the')\n",
      "('and', 'the', 'relationship')\n",
      "('the', 'relationship', 'between')\n",
      "('relationship', 'between', 'the')\n",
      "('between', 'the', 'main')\n",
      "('the', 'main', 'and')\n",
      "('main', 'and', 'subsidiary')\n",
      "('and', 'subsidiary', 'argument,')\n",
      "('subsidiary', 'argument,', 'or')\n",
      "('argument,', 'or', 'the')\n",
      "('or', 'the', 'main')\n",
      "('the', 'main', 'and')\n",
      "('main', 'and', 'counter-argument')\n",
      "('and', 'counter-argument', 'within')\n",
      "('counter-argument', 'within', 'discourse.')\n",
      "('within', 'discourse.', '[27]')\n",
      "('discourse.', '[27]', '[28]')\n",
      "('[27]', '[28]', 'Higher-level')\n",
      "('[28]', 'Higher-level', 'NLP')\n",
      "('Higher-level', 'NLP', 'applications')\n",
      "('NLP', 'applications', '[')\n",
      "('applications', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Automatic')\n",
      "(']', 'Automatic', 'summarization')\n",
      "('Automatic', 'summarization', '(text')\n",
      "('summarization', '(text', 'summarization)')\n",
      "('(text', 'summarization)', 'Produce')\n",
      "('summarization)', 'Produce', 'a')\n",
      "('Produce', 'a', 'readable')\n",
      "('a', 'readable', 'summary')\n",
      "('readable', 'summary', 'of')\n",
      "('summary', 'of', 'a')\n",
      "('of', 'a', 'chunk')\n",
      "('a', 'chunk', 'of')\n",
      "('chunk', 'of', 'text.')\n",
      "('of', 'text.', 'Often')\n",
      "('text.', 'Often', 'used')\n",
      "('Often', 'used', 'to')\n",
      "('used', 'to', 'provide')\n",
      "('to', 'provide', 'summaries')\n",
      "('provide', 'summaries', 'of')\n",
      "('summaries', 'of', 'the')\n",
      "('of', 'the', 'text')\n",
      "('the', 'text', 'of')\n",
      "('text', 'of', 'a')\n",
      "('of', 'a', 'known')\n",
      "('a', 'known', 'type,')\n",
      "('known', 'type,', 'such')\n",
      "('type,', 'such', 'as')\n",
      "('such', 'as', 'research')\n",
      "('as', 'research', 'papers,')\n",
      "('research', 'papers,', 'articles')\n",
      "('papers,', 'articles', 'in')\n",
      "('articles', 'in', 'the')\n",
      "('in', 'the', 'financial')\n",
      "('the', 'financial', 'section')\n",
      "('financial', 'section', 'of')\n",
      "('section', 'of', 'a')\n",
      "('of', 'a', 'newspaper.')\n",
      "('a', 'newspaper.', 'Book')\n",
      "('newspaper.', 'Book', 'generation')\n",
      "('Book', 'generation', 'Not')\n",
      "('generation', 'Not', 'an')\n",
      "('Not', 'an', 'NLP')\n",
      "('an', 'NLP', 'task')\n",
      "('NLP', 'task', 'proper')\n",
      "('task', 'proper', 'but')\n",
      "('proper', 'but', 'an')\n",
      "('but', 'an', 'extension')\n",
      "('an', 'extension', 'of')\n",
      "('extension', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'generation')\n",
      "('language', 'generation', 'and')\n",
      "('generation', 'and', 'other')\n",
      "('and', 'other', 'NLP')\n",
      "('other', 'NLP', 'tasks')\n",
      "('NLP', 'tasks', 'is')\n",
      "('tasks', 'is', 'the')\n",
      "('is', 'the', 'creation')\n",
      "('the', 'creation', 'of')\n",
      "('creation', 'of', 'full-fledged')\n",
      "('of', 'full-fledged', 'books.')\n",
      "('full-fledged', 'books.', 'The')\n",
      "('books.', 'The', 'first')\n",
      "('The', 'first', 'machine-generated')\n",
      "('first', 'machine-generated', 'book')\n",
      "('machine-generated', 'book', 'was')\n",
      "('book', 'was', 'created')\n",
      "('was', 'created', 'by')\n",
      "('created', 'by', 'a')\n",
      "('by', 'a', 'rule-based')\n",
      "('a', 'rule-based', 'system')\n",
      "('rule-based', 'system', 'in')\n",
      "('system', 'in', '1984')\n",
      "('in', '1984', '(Racter,')\n",
      "('1984', '(Racter,', 'The')\n",
      "('(Racter,', 'The', \"policeman's\")\n",
      "('The', \"policeman's\", 'beard')\n",
      "(\"policeman's\", 'beard', 'is')\n",
      "('beard', 'is', 'half-constructed')\n",
      "('is', 'half-constructed', ').')\n",
      "('half-constructed', ').', '[29]')\n",
      "(').', '[29]', 'The')\n",
      "('[29]', 'The', 'first')\n",
      "('The', 'first', 'published')\n",
      "('first', 'published', 'work')\n",
      "('published', 'work', 'by')\n",
      "('work', 'by', 'a')\n",
      "('by', 'a', 'neural')\n",
      "('a', 'neural', 'network')\n",
      "('neural', 'network', 'was')\n",
      "('network', 'was', 'published')\n",
      "('was', 'published', 'in')\n",
      "('published', 'in', '2018,')\n",
      "('in', '2018,', '1')\n",
      "('2018,', '1', 'the')\n",
      "('1', 'the', 'Road')\n",
      "('the', 'Road', ',')\n",
      "('Road', ',', 'marketed')\n",
      "(',', 'marketed', 'as')\n",
      "('marketed', 'as', 'a')\n",
      "('as', 'a', 'novel,')\n",
      "('a', 'novel,', 'contains')\n",
      "('novel,', 'contains', 'sixty')\n",
      "('contains', 'sixty', 'million')\n",
      "('sixty', 'million', 'words.')\n",
      "('million', 'words.', 'Both')\n",
      "('words.', 'Both', 'these')\n",
      "('Both', 'these', 'systems')\n",
      "('these', 'systems', 'are')\n",
      "('systems', 'are', 'basically')\n",
      "('are', 'basically', 'elaborate')\n",
      "('basically', 'elaborate', 'but')\n",
      "('elaborate', 'but', 'non-sensical')\n",
      "('but', 'non-sensical', '(semantics-free)')\n",
      "('non-sensical', '(semantics-free)', 'language')\n",
      "('(semantics-free)', 'language', 'models')\n",
      "('language', 'models', '.')\n",
      "('models', '.', 'The')\n",
      "('.', 'The', 'first')\n",
      "('The', 'first', 'machine-generated')\n",
      "('first', 'machine-generated', 'science')\n",
      "('machine-generated', 'science', 'book')\n",
      "('science', 'book', 'was')\n",
      "('book', 'was', 'published')\n",
      "('was', 'published', 'in')\n",
      "('published', 'in', '2019')\n",
      "('in', '2019', '(Beta')\n",
      "('2019', '(Beta', 'Writer,')\n",
      "('(Beta', 'Writer,', 'Lithium-Ion')\n",
      "('Writer,', 'Lithium-Ion', 'Batteries')\n",
      "('Lithium-Ion', 'Batteries', ',')\n",
      "('Batteries', ',', 'Springer,')\n",
      "(',', 'Springer,', 'Cham).')\n",
      "('Springer,', 'Cham).', '[30]')\n",
      "('Cham).', '[30]', 'Unlike')\n",
      "('[30]', 'Unlike', 'Racter')\n",
      "('Unlike', 'Racter', 'and')\n",
      "('Racter', 'and', '1')\n",
      "('and', '1', 'the')\n",
      "('1', 'the', 'Road')\n",
      "('the', 'Road', ',')\n",
      "('Road', ',', 'this')\n",
      "(',', 'this', 'is')\n",
      "('this', 'is', 'grounded')\n",
      "('is', 'grounded', 'on')\n",
      "('grounded', 'on', 'factual')\n",
      "('on', 'factual', 'knowledge')\n",
      "('factual', 'knowledge', 'and')\n",
      "('knowledge', 'and', 'based')\n",
      "('and', 'based', 'on')\n",
      "('based', 'on', 'text')\n",
      "('on', 'text', 'summarization.')\n",
      "('text', 'summarization.', 'Dialogue')\n",
      "('summarization.', 'Dialogue', 'management')\n",
      "('Dialogue', 'management', 'Computer')\n",
      "('management', 'Computer', 'systems')\n",
      "('Computer', 'systems', 'intended')\n",
      "('systems', 'intended', 'to')\n",
      "('intended', 'to', 'converse')\n",
      "('to', 'converse', 'with')\n",
      "('converse', 'with', 'a')\n",
      "('with', 'a', 'human.')\n",
      "('a', 'human.', 'Document')\n",
      "('human.', 'Document', 'AI')\n",
      "('Document', 'AI', 'A')\n",
      "('AI', 'A', 'Document')\n",
      "('A', 'Document', 'AI')\n",
      "('Document', 'AI', 'platform')\n",
      "('AI', 'platform', 'sits')\n",
      "('platform', 'sits', 'on')\n",
      "('sits', 'on', 'top')\n",
      "('on', 'top', 'of')\n",
      "('top', 'of', 'the')\n",
      "('of', 'the', 'NLP')\n",
      "('the', 'NLP', 'technology')\n",
      "('NLP', 'technology', 'enabling')\n",
      "('technology', 'enabling', 'users')\n",
      "('enabling', 'users', 'with')\n",
      "('users', 'with', 'no')\n",
      "('with', 'no', 'prior')\n",
      "('no', 'prior', 'experience')\n",
      "('prior', 'experience', 'of')\n",
      "('experience', 'of', 'artificial')\n",
      "('of', 'artificial', 'intelligence,')\n",
      "('artificial', 'intelligence,', 'machine')\n",
      "('intelligence,', 'machine', 'learning')\n",
      "('machine', 'learning', 'or')\n",
      "('learning', 'or', 'NLP')\n",
      "('or', 'NLP', 'to')\n",
      "('NLP', 'to', 'quickly')\n",
      "('to', 'quickly', 'train')\n",
      "('quickly', 'train', 'a')\n",
      "('train', 'a', 'computer')\n",
      "('a', 'computer', 'to')\n",
      "('computer', 'to', 'extract')\n",
      "('to', 'extract', 'the')\n",
      "('extract', 'the', 'specific')\n",
      "('the', 'specific', 'data')\n",
      "('specific', 'data', 'they')\n",
      "('data', 'they', 'need')\n",
      "('they', 'need', 'from')\n",
      "('need', 'from', 'different')\n",
      "('from', 'different', 'document')\n",
      "('different', 'document', 'types.')\n",
      "('document', 'types.', 'NLP-powered')\n",
      "('types.', 'NLP-powered', 'Document')\n",
      "('NLP-powered', 'Document', 'AI')\n",
      "('Document', 'AI', 'enables')\n",
      "('AI', 'enables', 'non-technical')\n",
      "('enables', 'non-technical', 'teams')\n",
      "('non-technical', 'teams', 'to')\n",
      "('teams', 'to', 'quickly')\n",
      "('to', 'quickly', 'access')\n",
      "('quickly', 'access', 'information')\n",
      "('access', 'information', 'hidden')\n",
      "('information', 'hidden', 'in')\n",
      "('hidden', 'in', 'documents,')\n",
      "('in', 'documents,', 'for')\n",
      "('documents,', 'for', 'example,')\n",
      "('for', 'example,', 'lawyers,')\n",
      "('example,', 'lawyers,', 'business')\n",
      "('lawyers,', 'business', 'analysts')\n",
      "('business', 'analysts', 'and')\n",
      "('analysts', 'and', 'accountants.')\n",
      "('and', 'accountants.', '[31]')\n",
      "('accountants.', '[31]', 'Grammatical')\n",
      "('[31]', 'Grammatical', 'error')\n",
      "('Grammatical', 'error', 'correction')\n",
      "('error', 'correction', 'Grammatical')\n",
      "('correction', 'Grammatical', 'error')\n",
      "('Grammatical', 'error', 'detection')\n",
      "('error', 'detection', 'and')\n",
      "('detection', 'and', 'correction')\n",
      "('and', 'correction', 'involves')\n",
      "('correction', 'involves', 'a')\n",
      "('involves', 'a', 'great')\n",
      "('a', 'great', 'band-width')\n",
      "('great', 'band-width', 'of')\n",
      "('band-width', 'of', 'problems')\n",
      "('of', 'problems', 'on')\n",
      "('problems', 'on', 'all')\n",
      "('on', 'all', 'levels')\n",
      "('all', 'levels', 'of')\n",
      "('levels', 'of', 'linguistic')\n",
      "('of', 'linguistic', 'analysis')\n",
      "('linguistic', 'analysis', '(phonology/orthography,')\n",
      "('analysis', '(phonology/orthography,', 'morphology,')\n",
      "('(phonology/orthography,', 'morphology,', 'syntax,')\n",
      "('morphology,', 'syntax,', 'semantics,')\n",
      "('syntax,', 'semantics,', 'pragmatics).')\n",
      "('semantics,', 'pragmatics).', 'Grammatical')\n",
      "('pragmatics).', 'Grammatical', 'error')\n",
      "('Grammatical', 'error', 'correction')\n",
      "('error', 'correction', 'is')\n",
      "('correction', 'is', 'impactful')\n",
      "('is', 'impactful', 'since')\n",
      "('impactful', 'since', 'it')\n",
      "('since', 'it', 'affects')\n",
      "('it', 'affects', 'hundreds')\n",
      "('affects', 'hundreds', 'of')\n",
      "('hundreds', 'of', 'millions')\n",
      "('of', 'millions', 'of')\n",
      "('millions', 'of', 'people')\n",
      "('of', 'people', 'that')\n",
      "('people', 'that', 'use')\n",
      "('that', 'use', 'or')\n",
      "('use', 'or', 'acquire')\n",
      "('or', 'acquire', 'English')\n",
      "('acquire', 'English', 'as')\n",
      "('English', 'as', 'a')\n",
      "('as', 'a', 'second')\n",
      "('a', 'second', 'language.')\n",
      "('second', 'language.', 'It')\n",
      "('language.', 'It', 'has')\n",
      "('It', 'has', 'thus')\n",
      "('has', 'thus', 'been')\n",
      "('thus', 'been', 'subject')\n",
      "('been', 'subject', 'to')\n",
      "('subject', 'to', 'a')\n",
      "('to', 'a', 'number')\n",
      "('a', 'number', 'of')\n",
      "('number', 'of', 'shared')\n",
      "('of', 'shared', 'tasks')\n",
      "('shared', 'tasks', 'since')\n",
      "('tasks', 'since', '2011.')\n",
      "('since', '2011.', '[32]')\n",
      "('2011.', '[32]', '[33]')\n",
      "('[32]', '[33]', '[34]')\n",
      "('[33]', '[34]', 'As')\n",
      "('[34]', 'As', 'far')\n",
      "('As', 'far', 'as')\n",
      "('far', 'as', 'orthography,')\n",
      "('as', 'orthography,', 'morphology,')\n",
      "('orthography,', 'morphology,', 'syntax')\n",
      "('morphology,', 'syntax', 'and')\n",
      "('syntax', 'and', 'certain')\n",
      "('and', 'certain', 'aspects')\n",
      "('certain', 'aspects', 'of')\n",
      "('aspects', 'of', 'semantics')\n",
      "('of', 'semantics', 'are')\n",
      "('semantics', 'are', 'concerned,')\n",
      "('are', 'concerned,', 'and')\n",
      "('concerned,', 'and', 'due')\n",
      "('and', 'due', 'to')\n",
      "('due', 'to', 'the')\n",
      "('to', 'the', 'development')\n",
      "('the', 'development', 'of')\n",
      "('development', 'of', 'powerful')\n",
      "('of', 'powerful', 'neural')\n",
      "('powerful', 'neural', 'language')\n",
      "('neural', 'language', 'models')\n",
      "('language', 'models', 'such')\n",
      "('models', 'such', 'as')\n",
      "('such', 'as', 'GPT-2')\n",
      "('as', 'GPT-2', ',')\n",
      "('GPT-2', ',', 'this')\n",
      "(',', 'this', 'can')\n",
      "('this', 'can', 'now')\n",
      "('can', 'now', '(2019)')\n",
      "('now', '(2019)', 'be')\n",
      "('(2019)', 'be', 'considered')\n",
      "('be', 'considered', 'a')\n",
      "('considered', 'a', 'largely')\n",
      "('a', 'largely', 'solved')\n",
      "('largely', 'solved', 'problem')\n",
      "('solved', 'problem', 'and')\n",
      "('problem', 'and', 'is')\n",
      "('and', 'is', 'being')\n",
      "('is', 'being', 'marketed')\n",
      "('being', 'marketed', 'in')\n",
      "('marketed', 'in', 'various')\n",
      "('in', 'various', 'commercial')\n",
      "('various', 'commercial', 'applications.')\n",
      "('commercial', 'applications.', 'Machine')\n",
      "('applications.', 'Machine', 'translation')\n",
      "('Machine', 'translation', 'Automatically')\n",
      "('translation', 'Automatically', 'translate')\n",
      "('Automatically', 'translate', 'text')\n",
      "('translate', 'text', 'from')\n",
      "('text', 'from', 'one')\n",
      "('from', 'one', 'human')\n",
      "('one', 'human', 'language')\n",
      "('human', 'language', 'to')\n",
      "('language', 'to', 'another.')\n",
      "('to', 'another.', 'This')\n",
      "('another.', 'This', 'is')\n",
      "('This', 'is', 'one')\n",
      "('is', 'one', 'of')\n",
      "('one', 'of', 'the')\n",
      "('of', 'the', 'most')\n",
      "('the', 'most', 'difficult')\n",
      "('most', 'difficult', 'problems,')\n",
      "('difficult', 'problems,', 'and')\n",
      "('problems,', 'and', 'is')\n",
      "('and', 'is', 'a')\n",
      "('is', 'a', 'member')\n",
      "('a', 'member', 'of')\n",
      "('member', 'of', 'a')\n",
      "('of', 'a', 'class')\n",
      "('a', 'class', 'of')\n",
      "('class', 'of', 'problems')\n",
      "('of', 'problems', 'colloquially')\n",
      "('problems', 'colloquially', 'termed')\n",
      "('colloquially', 'termed', '\"')\n",
      "('termed', '\"', 'AI-complete')\n",
      "('\"', 'AI-complete', '\",')\n",
      "('AI-complete', '\",', 'i.e.')\n",
      "('\",', 'i.e.', 'requiring')\n",
      "('i.e.', 'requiring', 'all')\n",
      "('requiring', 'all', 'of')\n",
      "('all', 'of', 'the')\n",
      "('of', 'the', 'different')\n",
      "('the', 'different', 'types')\n",
      "('different', 'types', 'of')\n",
      "('types', 'of', 'knowledge')\n",
      "('of', 'knowledge', 'that')\n",
      "('knowledge', 'that', 'humans')\n",
      "('that', 'humans', 'possess')\n",
      "('humans', 'possess', '(grammar,')\n",
      "('possess', '(grammar,', 'semantics,')\n",
      "('(grammar,', 'semantics,', 'facts')\n",
      "('semantics,', 'facts', 'about')\n",
      "('facts', 'about', 'the')\n",
      "('about', 'the', 'real')\n",
      "('the', 'real', 'world,')\n",
      "('real', 'world,', 'etc.)')\n",
      "('world,', 'etc.)', 'to')\n",
      "('etc.)', 'to', 'solve')\n",
      "('to', 'solve', 'properly.')\n",
      "('solve', 'properly.', 'Natural')\n",
      "('properly.', 'Natural', 'language')\n",
      "('Natural', 'language', 'generation')\n",
      "('language', 'generation', '(NLG):')\n",
      "('generation', '(NLG):', 'Convert')\n",
      "('(NLG):', 'Convert', 'information')\n",
      "('Convert', 'information', 'from')\n",
      "('information', 'from', 'computer')\n",
      "('from', 'computer', 'databases')\n",
      "('computer', 'databases', 'or')\n",
      "('databases', 'or', 'semantic')\n",
      "('or', 'semantic', 'intents')\n",
      "('semantic', 'intents', 'into')\n",
      "('intents', 'into', 'readable')\n",
      "('into', 'readable', 'human')\n",
      "('readable', 'human', 'language.')\n",
      "('human', 'language.', 'Natural')\n",
      "('language.', 'Natural', 'language')\n",
      "('Natural', 'language', 'understanding')\n",
      "('language', 'understanding', '(NLU)')\n",
      "('understanding', '(NLU)', 'Convert')\n",
      "('(NLU)', 'Convert', 'chunks')\n",
      "('Convert', 'chunks', 'of')\n",
      "('chunks', 'of', 'text')\n",
      "('of', 'text', 'into')\n",
      "('text', 'into', 'more')\n",
      "('into', 'more', 'formal')\n",
      "('more', 'formal', 'representations')\n",
      "('formal', 'representations', 'such')\n",
      "('representations', 'such', 'as')\n",
      "('such', 'as', 'first-order')\n",
      "('as', 'first-order', 'logic')\n",
      "('first-order', 'logic', 'structures')\n",
      "('logic', 'structures', 'that')\n",
      "('structures', 'that', 'are')\n",
      "('that', 'are', 'easier')\n",
      "('are', 'easier', 'for')\n",
      "('easier', 'for', 'computer')\n",
      "('for', 'computer', 'programs')\n",
      "('computer', 'programs', 'to')\n",
      "('programs', 'to', 'manipulate.')\n",
      "('to', 'manipulate.', 'Natural')\n",
      "('manipulate.', 'Natural', 'language')\n",
      "('Natural', 'language', 'understanding')\n",
      "('language', 'understanding', 'involves')\n",
      "('understanding', 'involves', 'the')\n",
      "('involves', 'the', 'identification')\n",
      "('the', 'identification', 'of')\n",
      "('identification', 'of', 'the')\n",
      "('of', 'the', 'intended')\n",
      "('the', 'intended', 'semantic')\n",
      "('intended', 'semantic', 'from')\n",
      "('semantic', 'from', 'the')\n",
      "('from', 'the', 'multiple')\n",
      "('the', 'multiple', 'possible')\n",
      "('multiple', 'possible', 'semantics')\n",
      "('possible', 'semantics', 'which')\n",
      "('semantics', 'which', 'can')\n",
      "('which', 'can', 'be')\n",
      "('can', 'be', 'derived')\n",
      "('be', 'derived', 'from')\n",
      "('derived', 'from', 'a')\n",
      "('from', 'a', 'natural')\n",
      "('a', 'natural', 'language')\n",
      "('natural', 'language', 'expression')\n",
      "('language', 'expression', 'which')\n",
      "('expression', 'which', 'usually')\n",
      "('which', 'usually', 'takes')\n",
      "('usually', 'takes', 'the')\n",
      "('takes', 'the', 'form')\n",
      "('the', 'form', 'of')\n",
      "('form', 'of', 'organized')\n",
      "('of', 'organized', 'notations')\n",
      "('organized', 'notations', 'of')\n",
      "('notations', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'concepts.')\n",
      "('language', 'concepts.', 'Introduction')\n",
      "('concepts.', 'Introduction', 'and')\n",
      "('Introduction', 'and', 'creation')\n",
      "('and', 'creation', 'of')\n",
      "('creation', 'of', 'language')\n",
      "('of', 'language', 'metamodel')\n",
      "('language', 'metamodel', 'and')\n",
      "('metamodel', 'and', 'ontology')\n",
      "('and', 'ontology', 'are')\n",
      "('ontology', 'are', 'efficient')\n",
      "('are', 'efficient', 'however')\n",
      "('efficient', 'however', 'empirical')\n",
      "('however', 'empirical', 'solutions.')\n",
      "('empirical', 'solutions.', 'An')\n",
      "('solutions.', 'An', 'explicit')\n",
      "('An', 'explicit', 'formalization')\n",
      "('explicit', 'formalization', 'of')\n",
      "('formalization', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'semantics')\n",
      "('language', 'semantics', 'without')\n",
      "('semantics', 'without', 'confusions')\n",
      "('without', 'confusions', 'with')\n",
      "('confusions', 'with', 'implicit')\n",
      "('with', 'implicit', 'assumptions')\n",
      "('implicit', 'assumptions', 'such')\n",
      "('assumptions', 'such', 'as')\n",
      "('such', 'as', 'closed-world')\n",
      "('as', 'closed-world', 'assumption')\n",
      "('closed-world', 'assumption', '(CWA)')\n",
      "('assumption', '(CWA)', 'vs.')\n",
      "('(CWA)', 'vs.', 'open-world')\n",
      "('vs.', 'open-world', 'assumption')\n",
      "('open-world', 'assumption', ',')\n",
      "('assumption', ',', 'or')\n",
      "(',', 'or', 'subjective')\n",
      "('or', 'subjective', 'Yes/No')\n",
      "('subjective', 'Yes/No', 'vs.')\n",
      "('Yes/No', 'vs.', 'objective')\n",
      "('vs.', 'objective', 'True/False')\n",
      "('objective', 'True/False', 'is')\n",
      "('True/False', 'is', 'expected')\n",
      "('is', 'expected', 'for')\n",
      "('expected', 'for', 'the')\n",
      "('for', 'the', 'construction')\n",
      "('the', 'construction', 'of')\n",
      "('construction', 'of', 'a')\n",
      "('of', 'a', 'basis')\n",
      "('a', 'basis', 'of')\n",
      "('basis', 'of', 'semantics')\n",
      "('of', 'semantics', 'formalization.')\n",
      "('semantics', 'formalization.', '[35]')\n",
      "('formalization.', '[35]', 'Question')\n",
      "('[35]', 'Question', 'answering')\n",
      "('Question', 'answering', 'Given')\n",
      "('answering', 'Given', 'a')\n",
      "('Given', 'a', 'human-language')\n",
      "('a', 'human-language', 'question,')\n",
      "('human-language', 'question,', 'determine')\n",
      "('question,', 'determine', 'its')\n",
      "('determine', 'its', 'answer.')\n",
      "('its', 'answer.', 'Typical')\n",
      "('answer.', 'Typical', 'questions')\n",
      "('Typical', 'questions', 'have')\n",
      "('questions', 'have', 'a')\n",
      "('have', 'a', 'specific')\n",
      "('a', 'specific', 'right')\n",
      "('specific', 'right', 'answer')\n",
      "('right', 'answer', '(such')\n",
      "('answer', '(such', 'as')\n",
      "('(such', 'as', '\"What')\n",
      "('as', '\"What', 'is')\n",
      "('\"What', 'is', 'the')\n",
      "('is', 'the', 'capital')\n",
      "('the', 'capital', 'of')\n",
      "('capital', 'of', 'Canada?\"),')\n",
      "('of', 'Canada?\"),', 'but')\n",
      "('Canada?\"),', 'but', 'sometimes')\n",
      "('but', 'sometimes', 'open-ended')\n",
      "('sometimes', 'open-ended', 'questions')\n",
      "('open-ended', 'questions', 'are')\n",
      "('questions', 'are', 'also')\n",
      "('are', 'also', 'considered')\n",
      "('also', 'considered', '(such')\n",
      "('considered', '(such', 'as')\n",
      "('(such', 'as', '\"What')\n",
      "('as', '\"What', 'is')\n",
      "('\"What', 'is', 'the')\n",
      "('is', 'the', 'meaning')\n",
      "('the', 'meaning', 'of')\n",
      "('meaning', 'of', 'life?\").')\n",
      "('of', 'life?\").', 'General')\n",
      "('life?\").', 'General', 'tendencies')\n",
      "('General', 'tendencies', 'and')\n",
      "('tendencies', 'and', '(possible)')\n",
      "('and', '(possible)', 'future')\n",
      "('(possible)', 'future', 'directions')\n",
      "('future', 'directions', '[')\n",
      "('directions', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Based')\n",
      "(']', 'Based', 'on')\n",
      "('Based', 'on', 'long-standing')\n",
      "('on', 'long-standing', 'trends')\n",
      "('long-standing', 'trends', 'in')\n",
      "('trends', 'in', 'the')\n",
      "('in', 'the', 'field,')\n",
      "('the', 'field,', 'it')\n",
      "('field,', 'it', 'is')\n",
      "('it', 'is', 'possible')\n",
      "('is', 'possible', 'to')\n",
      "('possible', 'to', 'extrapolate')\n",
      "('to', 'extrapolate', 'future')\n",
      "('extrapolate', 'future', 'directions')\n",
      "('future', 'directions', 'of')\n",
      "('directions', 'of', 'NLP.')\n",
      "('of', 'NLP.', 'As')\n",
      "('NLP.', 'As', 'of')\n",
      "('As', 'of', '2020,')\n",
      "('of', '2020,', 'three')\n",
      "('2020,', 'three', 'trends')\n",
      "('three', 'trends', 'among')\n",
      "('trends', 'among', 'the')\n",
      "('among', 'the', 'topics')\n",
      "('the', 'topics', 'of')\n",
      "('topics', 'of', 'the')\n",
      "('of', 'the', 'long-standing')\n",
      "('the', 'long-standing', 'series')\n",
      "('long-standing', 'series', 'of')\n",
      "('series', 'of', 'CoNLL')\n",
      "('of', 'CoNLL', 'Shared')\n",
      "('CoNLL', 'Shared', 'Tasks')\n",
      "('Shared', 'Tasks', 'can')\n",
      "('Tasks', 'can', 'be')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('can', 'be', 'observed:')\n",
      "('be', 'observed:', '[36]')\n",
      "('observed:', '[36]', 'Interest')\n",
      "('[36]', 'Interest', 'on')\n",
      "('Interest', 'on', 'increasingly')\n",
      "('on', 'increasingly', 'abstract,')\n",
      "('increasingly', 'abstract,', '\"cognitive\"')\n",
      "('abstract,', '\"cognitive\"', 'aspects')\n",
      "('\"cognitive\"', 'aspects', 'of')\n",
      "('aspects', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', '(1999-2001:')\n",
      "('language', '(1999-2001:', 'shallow')\n",
      "('(1999-2001:', 'shallow', 'parsing,')\n",
      "('shallow', 'parsing,', '2002-03:')\n",
      "('parsing,', '2002-03:', 'named')\n",
      "('2002-03:', 'named', 'entity')\n",
      "('named', 'entity', 'recognition,')\n",
      "('entity', 'recognition,', '2006-09/2017-18:')\n",
      "('recognition,', '2006-09/2017-18:', 'dependency')\n",
      "('2006-09/2017-18:', 'dependency', 'syntax,')\n",
      "('dependency', 'syntax,', '2004-05/2008-09')\n",
      "('syntax,', '2004-05/2008-09', 'semantic')\n",
      "('2004-05/2008-09', 'semantic', 'role')\n",
      "('semantic', 'role', 'labelling,')\n",
      "('role', 'labelling,', '2011-12')\n",
      "('labelling,', '2011-12', 'coreference,')\n",
      "('2011-12', 'coreference,', '2015-16:')\n",
      "('coreference,', '2015-16:', 'discourse')\n",
      "('2015-16:', 'discourse', 'parsing,')\n",
      "('discourse', 'parsing,', '2019:')\n",
      "('parsing,', '2019:', 'semantic')\n",
      "('2019:', 'semantic', 'parsing).')\n",
      "('semantic', 'parsing).', 'Increasing')\n",
      "('parsing).', 'Increasing', 'interest')\n",
      "('Increasing', 'interest', 'in')\n",
      "('interest', 'in', 'multilinguality,')\n",
      "('in', 'multilinguality,', 'and,')\n",
      "('multilinguality,', 'and,', 'potentially,')\n",
      "('and,', 'potentially,', 'multimodality')\n",
      "('potentially,', 'multimodality', '(English')\n",
      "('multimodality', '(English', 'since')\n",
      "('(English', 'since', '1999;')\n",
      "('since', '1999;', 'Spanish,')\n",
      "('1999;', 'Spanish,', 'Dutch')\n",
      "('Spanish,', 'Dutch', 'since')\n",
      "('Dutch', 'since', '2002;')\n",
      "('since', '2002;', 'German')\n",
      "('2002;', 'German', 'since')\n",
      "('German', 'since', '2003;')\n",
      "('since', '2003;', 'Bulgarian,')\n",
      "('2003;', 'Bulgarian,', 'Danish,')\n",
      "('Bulgarian,', 'Danish,', 'Japanese,')\n",
      "('Danish,', 'Japanese,', 'Portuguese,')\n",
      "('Japanese,', 'Portuguese,', 'Slovenian,')\n",
      "('Portuguese,', 'Slovenian,', 'Swedish,')\n",
      "('Slovenian,', 'Swedish,', 'Turkish')\n",
      "('Swedish,', 'Turkish', 'since')\n",
      "('Turkish', 'since', '2006;')\n",
      "('since', '2006;', 'Basque,')\n",
      "('2006;', 'Basque,', 'Catalan,')\n",
      "('Basque,', 'Catalan,', 'Chinese,')\n",
      "('Catalan,', 'Chinese,', 'Greek,')\n",
      "('Chinese,', 'Greek,', 'Hungarian,')\n",
      "('Greek,', 'Hungarian,', 'Italian,')\n",
      "('Hungarian,', 'Italian,', 'Turkish')\n",
      "('Italian,', 'Turkish', 'since')\n",
      "('Turkish', 'since', '2007;')\n",
      "('since', '2007;', 'Czech')\n",
      "('2007;', 'Czech', 'since')\n",
      "('Czech', 'since', '2009;')\n",
      "('since', '2009;', 'Arabic')\n",
      "('2009;', 'Arabic', 'since')\n",
      "('Arabic', 'since', '2012;')\n",
      "('since', '2012;', '2017:')\n",
      "('2012;', '2017:', '40+')\n",
      "('2017:', '40+', 'languages;')\n",
      "('40+', 'languages;', '2018:')\n",
      "('languages;', '2018:', '60+/100+')\n",
      "('2018:', '60+/100+', 'languages)')\n",
      "('60+/100+', 'languages)', 'Elimination')\n",
      "('languages)', 'Elimination', 'of')\n",
      "('Elimination', 'of', 'symbolic')\n",
      "('of', 'symbolic', 'representations')\n",
      "('symbolic', 'representations', '(rule-based')\n",
      "('representations', '(rule-based', 'over')\n",
      "('(rule-based', 'over', 'supervised')\n",
      "('over', 'supervised', 'towards')\n",
      "('supervised', 'towards', 'weakly')\n",
      "('towards', 'weakly', 'supervised')\n",
      "('weakly', 'supervised', 'methods,')\n",
      "('supervised', 'methods,', 'representation')\n",
      "('methods,', 'representation', 'learning')\n",
      "('representation', 'learning', 'and')\n",
      "('learning', 'and', 'end-to-end')\n",
      "('and', 'end-to-end', 'systems)')\n",
      "('end-to-end', 'systems)', 'Cognition')\n",
      "('systems)', 'Cognition', 'and')\n",
      "('Cognition', 'and', 'NLP')\n",
      "('and', 'NLP', '[')\n",
      "('NLP', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Most')\n",
      "(']', 'Most', 'higher-level')\n",
      "('Most', 'higher-level', 'NLP')\n",
      "('higher-level', 'NLP', 'applications')\n",
      "('NLP', 'applications', 'involve')\n",
      "('applications', 'involve', 'aspects')\n",
      "('involve', 'aspects', 'that')\n",
      "('aspects', 'that', 'emulate')\n",
      "('that', 'emulate', 'intelligent')\n",
      "('emulate', 'intelligent', 'behaviour')\n",
      "('intelligent', 'behaviour', 'and')\n",
      "('behaviour', 'and', 'apparent')\n",
      "('and', 'apparent', 'comprehension')\n",
      "('apparent', 'comprehension', 'of')\n",
      "('comprehension', 'of', 'natural')\n",
      "('of', 'natural', 'language.')\n",
      "('natural', 'language.', 'More')\n",
      "('language.', 'More', 'broadly')\n",
      "('More', 'broadly', 'speaking,')\n",
      "('broadly', 'speaking,', 'the')\n",
      "('speaking,', 'the', 'technical')\n",
      "('the', 'technical', 'operationalization')\n",
      "('technical', 'operationalization', 'of')\n",
      "('operationalization', 'of', 'increasingly')\n",
      "('of', 'increasingly', 'advanced')\n",
      "('increasingly', 'advanced', 'aspects')\n",
      "('advanced', 'aspects', 'of')\n",
      "('aspects', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'behaviour')\n",
      "('cognitive', 'behaviour', 'represents')\n",
      "('behaviour', 'represents', 'one')\n",
      "('represents', 'one', 'of')\n",
      "('one', 'of', 'the')\n",
      "('of', 'the', 'developmental')\n",
      "('the', 'developmental', 'trajectories')\n",
      "('developmental', 'trajectories', 'of')\n",
      "('trajectories', 'of', 'NLP')\n",
      "('of', 'NLP', '(see')\n",
      "('NLP', '(see', 'trends')\n",
      "('(see', 'trends', 'among')\n",
      "('trends', 'among', 'CoNLL')\n",
      "('among', 'CoNLL', 'shared')\n",
      "('CoNLL', 'shared', 'tasks')\n",
      "('shared', 'tasks', 'above).')\n",
      "('tasks', 'above).', 'Cognition')\n",
      "('above).', 'Cognition', 'refers')\n",
      "('Cognition', 'refers', 'to')\n",
      "('refers', 'to', '\"the')\n",
      "('to', '\"the', 'mental')\n",
      "('\"the', 'mental', 'action')\n",
      "('mental', 'action', 'or')\n",
      "('action', 'or', 'process')\n",
      "('or', 'process', 'of')\n",
      "('process', 'of', 'acquiring')\n",
      "('of', 'acquiring', 'knowledge')\n",
      "('acquiring', 'knowledge', 'and')\n",
      "('knowledge', 'and', 'understanding')\n",
      "('and', 'understanding', 'through')\n",
      "('understanding', 'through', 'thought,')\n",
      "('through', 'thought,', 'experience,')\n",
      "('thought,', 'experience,', 'and')\n",
      "('experience,', 'and', 'the')\n",
      "('and', 'the', 'senses.\"')\n",
      "('the', 'senses.\"', '[37]')\n",
      "('senses.\"', '[37]', 'Cognitive')\n",
      "('[37]', 'Cognitive', 'science')\n",
      "('Cognitive', 'science', 'is')\n",
      "('science', 'is', 'the')\n",
      "('is', 'the', 'interdisciplinary,')\n",
      "('the', 'interdisciplinary,', 'scientific')\n",
      "('interdisciplinary,', 'scientific', 'study')\n",
      "('scientific', 'study', 'of')\n",
      "('study', 'of', 'the')\n",
      "('of', 'the', 'mind')\n",
      "('the', 'mind', 'and')\n",
      "('mind', 'and', 'its')\n",
      "('and', 'its', 'processes.')\n",
      "('its', 'processes.', '[38]')\n",
      "('processes.', '[38]', 'Cognitive')\n",
      "('[38]', 'Cognitive', 'linguistics')\n",
      "('Cognitive', 'linguistics', 'is')\n",
      "('linguistics', 'is', 'an')\n",
      "('is', 'an', 'interdisciplinary')\n",
      "('an', 'interdisciplinary', 'branch')\n",
      "('interdisciplinary', 'branch', 'of')\n",
      "('branch', 'of', 'linguistics,')\n",
      "('of', 'linguistics,', 'combining')\n",
      "('linguistics,', 'combining', 'knowledge')\n",
      "('combining', 'knowledge', 'and')\n",
      "('knowledge', 'and', 'research')\n",
      "('and', 'research', 'from')\n",
      "('research', 'from', 'both')\n",
      "('from', 'both', 'psychology')\n",
      "('both', 'psychology', 'and')\n",
      "('psychology', 'and', 'linguistics.')\n",
      "('and', 'linguistics.', '[39]')\n",
      "('linguistics.', '[39]', 'Especially')\n",
      "('[39]', 'Especially', 'during')\n",
      "('Especially', 'during', 'the')\n",
      "('during', 'the', 'age')\n",
      "('the', 'age', 'of')\n",
      "('age', 'of', 'symbolic')\n",
      "('of', 'symbolic', 'NLP')\n",
      "('symbolic', 'NLP', ',')\n",
      "('NLP', ',', 'the')\n",
      "(',', 'the', 'area')\n",
      "('the', 'area', 'of')\n",
      "('area', 'of', 'computational')\n",
      "('of', 'computational', 'linguistics')\n",
      "('computational', 'linguistics', 'maintained')\n",
      "('linguistics', 'maintained', 'strong')\n",
      "('maintained', 'strong', 'ties')\n",
      "('strong', 'ties', 'with')\n",
      "('ties', 'with', 'cognitive')\n",
      "('with', 'cognitive', 'studies.')\n",
      "('cognitive', 'studies.', 'As')\n",
      "('studies.', 'As', 'an')\n",
      "('As', 'an', 'example,')\n",
      "('an', 'example,', 'George')\n",
      "('example,', 'George', 'Lakoff')\n",
      "('George', 'Lakoff', 'offers')\n",
      "('Lakoff', 'offers', 'a')\n",
      "('offers', 'a', 'methodology')\n",
      "('a', 'methodology', 'to')\n",
      "('methodology', 'to', 'build')\n",
      "('to', 'build', 'natural')\n",
      "('build', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', '(NLP)')\n",
      "('processing', '(NLP)', 'algorithms')\n",
      "('(NLP)', 'algorithms', 'through')\n",
      "('algorithms', 'through', 'the')\n",
      "('through', 'the', 'perspective')\n",
      "('the', 'perspective', 'of')\n",
      "('perspective', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'science')\n",
      "('cognitive', 'science', ',')\n",
      "('science', ',', 'along')\n",
      "(',', 'along', 'with')\n",
      "('along', 'with', 'the')\n",
      "('with', 'the', 'findings')\n",
      "('the', 'findings', 'of')\n",
      "('findings', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'linguistics')\n",
      "('cognitive', 'linguistics', ',')\n",
      "('linguistics', ',', '[40]')\n",
      "(',', '[40]', 'with')\n",
      "('[40]', 'with', 'two')\n",
      "('with', 'two', 'defining')\n",
      "('two', 'defining', 'aspects:')\n",
      "('defining', 'aspects:', 'Apply')\n",
      "('aspects:', 'Apply', 'the')\n",
      "('Apply', 'the', 'theory')\n",
      "('the', 'theory', 'of')\n",
      "('theory', 'of', 'conceptual')\n",
      "('of', 'conceptual', 'metaphor')\n",
      "('conceptual', 'metaphor', ',')\n",
      "('metaphor', ',', 'explained')\n",
      "(',', 'explained', 'by')\n",
      "('explained', 'by', 'Lakoff')\n",
      "('by', 'Lakoff', 'as')\n",
      "('Lakoff', 'as', '“the')\n",
      "('as', '“the', 'understanding')\n",
      "('“the', 'understanding', 'of')\n",
      "('understanding', 'of', 'one')\n",
      "('of', 'one', 'idea,')\n",
      "('one', 'idea,', 'in')\n",
      "('idea,', 'in', 'terms')\n",
      "('in', 'terms', 'of')\n",
      "('terms', 'of', 'another”')\n",
      "('of', 'another”', 'which')\n",
      "('another”', 'which', 'provides')\n",
      "('which', 'provides', 'an')\n",
      "('provides', 'an', 'idea')\n",
      "('an', 'idea', 'of')\n",
      "('idea', 'of', 'the')\n",
      "('of', 'the', 'intent')\n",
      "('the', 'intent', 'of')\n",
      "('intent', 'of', 'the')\n",
      "('of', 'the', 'author.')\n",
      "('the', 'author.', '[41]')\n",
      "('author.', '[41]', 'For')\n",
      "('[41]', 'For', 'example,')\n",
      "('For', 'example,', 'consider')\n",
      "('example,', 'consider', 'the')\n",
      "('consider', 'the', 'English')\n",
      "('the', 'English', 'word')\n",
      "('English', 'word', '“big”')\n",
      "('word', '“big”', '.')\n",
      "('“big”', '.', 'When')\n",
      "('.', 'When', 'used')\n",
      "('When', 'used', 'in')\n",
      "('used', 'in', 'a')\n",
      "('in', 'a', 'comparison')\n",
      "('a', 'comparison', '(')\n",
      "('comparison', '(', '“That')\n",
      "('(', '“That', 'is')\n",
      "('“That', 'is', 'a')\n",
      "('is', 'a', 'big')\n",
      "('a', 'big', 'tree”')\n",
      "('big', 'tree”', '),')\n",
      "('tree”', '),', 'the')\n",
      "('),', 'the', \"author's\")\n",
      "('the', \"author's\", 'intent')\n",
      "(\"author's\", 'intent', 'is')\n",
      "('intent', 'is', 'to')\n",
      "('is', 'to', 'imply')\n",
      "('to', 'imply', 'that')\n",
      "('imply', 'that', 'the')\n",
      "('that', 'the', 'tree')\n",
      "('the', 'tree', 'is')\n",
      "('tree', 'is', '”physically')\n",
      "('is', '”physically', 'large”')\n",
      "('”physically', 'large”', 'relative')\n",
      "('large”', 'relative', 'to')\n",
      "('relative', 'to', 'other')\n",
      "('to', 'other', 'trees')\n",
      "('other', 'trees', 'or')\n",
      "('trees', 'or', 'the')\n",
      "('or', 'the', 'authors')\n",
      "('the', 'authors', 'experience.')\n",
      "('authors', 'experience.', 'When')\n",
      "('experience.', 'When', 'used')\n",
      "('When', 'used', 'metaphorically')\n",
      "('used', 'metaphorically', '(')\n",
      "('metaphorically', '(', '”Tomorrow')\n",
      "('(', '”Tomorrow', 'is')\n",
      "('”Tomorrow', 'is', 'a')\n",
      "('is', 'a', 'big')\n",
      "('a', 'big', 'day”')\n",
      "('big', 'day”', '),')\n",
      "('day”', '),', 'the')\n",
      "('),', 'the', 'author’s')\n",
      "('the', 'author’s', 'intent')\n",
      "('author’s', 'intent', 'to')\n",
      "('intent', 'to', 'imply')\n",
      "('to', 'imply', '”importance”')\n",
      "('imply', '”importance”', '.')\n",
      "('”importance”', '.', 'The')\n",
      "('.', 'The', 'intent')\n",
      "('The', 'intent', 'behind')\n",
      "('intent', 'behind', 'other')\n",
      "('behind', 'other', 'usages,')\n",
      "('other', 'usages,', 'like')\n",
      "('usages,', 'like', 'in')\n",
      "('like', 'in', '”She')\n",
      "('in', '”She', 'is')\n",
      "('”She', 'is', 'a')\n",
      "('is', 'a', 'big')\n",
      "('a', 'big', 'person”')\n",
      "('big', 'person”', 'will')\n",
      "('person”', 'will', 'remain')\n",
      "('will', 'remain', 'somewhat')\n",
      "('remain', 'somewhat', 'ambiguous')\n",
      "('somewhat', 'ambiguous', 'to')\n",
      "('ambiguous', 'to', 'a')\n",
      "('to', 'a', 'person')\n",
      "('a', 'person', 'and')\n",
      "('person', 'and', 'a')\n",
      "('and', 'a', 'cognitive')\n",
      "('a', 'cognitive', 'NLP')\n",
      "('cognitive', 'NLP', 'algorithm')\n",
      "('NLP', 'algorithm', 'alike')\n",
      "('algorithm', 'alike', 'without')\n",
      "('alike', 'without', 'additional')\n",
      "('without', 'additional', 'information.')\n",
      "('additional', 'information.', 'Assign')\n",
      "('information.', 'Assign', 'relative')\n",
      "('Assign', 'relative', 'measures')\n",
      "('relative', 'measures', 'of')\n",
      "('measures', 'of', 'meaning')\n",
      "('of', 'meaning', 'to')\n",
      "('meaning', 'to', 'a')\n",
      "('to', 'a', 'word,')\n",
      "('a', 'word,', 'phrase,')\n",
      "('word,', 'phrase,', 'sentence')\n",
      "('phrase,', 'sentence', 'or')\n",
      "('sentence', 'or', 'piece')\n",
      "('or', 'piece', 'of')\n",
      "('piece', 'of', 'text')\n",
      "('of', 'text', 'based')\n",
      "('text', 'based', 'on')\n",
      "('based', 'on', 'the')\n",
      "('on', 'the', 'information')\n",
      "('the', 'information', 'presented')\n",
      "('information', 'presented', 'before')\n",
      "('presented', 'before', 'and')\n",
      "('before', 'and', 'after')\n",
      "('and', 'after', 'the')\n",
      "('after', 'the', 'piece')\n",
      "('the', 'piece', 'of')\n",
      "('piece', 'of', 'text')\n",
      "('of', 'text', 'being')\n",
      "('text', 'being', 'analyzed,')\n",
      "('being', 'analyzed,', 'e.g.,')\n",
      "('analyzed,', 'e.g.,', 'by')\n",
      "('e.g.,', 'by', 'means')\n",
      "('by', 'means', 'of')\n",
      "('means', 'of', 'a')\n",
      "('of', 'a', 'probabilistic')\n",
      "('a', 'probabilistic', 'context-free')\n",
      "('probabilistic', 'context-free', 'grammar')\n",
      "('context-free', 'grammar', '(PCFG).')\n",
      "('grammar', '(PCFG).', 'The')\n",
      "('(PCFG).', 'The', 'mathematical')\n",
      "('The', 'mathematical', 'equation')\n",
      "('mathematical', 'equation', 'for')\n",
      "('equation', 'for', 'such')\n",
      "('for', 'such', 'algorithms')\n",
      "('such', 'algorithms', 'is')\n",
      "('algorithms', 'is', 'presented')\n",
      "('is', 'presented', 'in')\n",
      "('presented', 'in', 'US')\n",
      "('in', 'US', 'patent')\n",
      "('US', 'patent', '9269353')\n",
      "('patent', '9269353', ':')\n",
      "('9269353', ':', 'R')\n",
      "(':', 'R', 'M')\n",
      "('R', 'M', 'M')\n",
      "('M', 'M', '(')\n",
      "('M', '(', 't')\n",
      "('(', 't', 'o')\n",
      "('t', 'o', 'k')\n",
      "('o', 'k', 'e')\n",
      "('k', 'e', 'n')\n",
      "('e', 'n', 'N')\n",
      "('n', 'N', ')')\n",
      "('N', ')', '=')\n",
      "(')', '=', 'P')\n",
      "('=', 'P', 'M')\n",
      "('P', 'M', 'M')\n",
      "('M', 'M', '(')\n",
      "('M', '(', 't')\n",
      "('(', 't', 'o')\n",
      "('t', 'o', 'k')\n",
      "('o', 'k', 'e')\n",
      "('k', 'e', 'n')\n",
      "('e', 'n', 'N')\n",
      "('n', 'N', ')')\n",
      "('N', ')', '×')\n",
      "(')', '×', '1')\n",
      "('×', '1', '2')\n",
      "('1', '2', 'd')\n",
      "('2', 'd', '(')\n",
      "('d', '(', '∑')\n",
      "('(', '∑', 'i')\n",
      "('∑', 'i', '=')\n",
      "('i', '=', '−')\n",
      "('=', '−', 'd')\n",
      "('−', 'd', 'd')\n",
      "('d', 'd', '(')\n",
      "('d', '(', '(')\n",
      "('(', '(', 'P')\n",
      "('(', 'P', 'M')\n",
      "('P', 'M', 'M')\n",
      "('M', 'M', '(')\n",
      "('M', '(', 't')\n",
      "('(', 't', 'o')\n",
      "('t', 'o', 'k')\n",
      "('o', 'k', 'e')\n",
      "('k', 'e', 'n')\n",
      "('e', 'n', 'N')\n",
      "('n', 'N', '−')\n",
      "('N', '−', '1')\n",
      "('−', '1', ')')\n",
      "('1', ')', '×')\n",
      "(')', '×', 'P')\n",
      "('×', 'P', 'F')\n",
      "('P', 'F', '(')\n",
      "('F', '(', 't')\n",
      "('(', 't', 'o')\n",
      "('t', 'o', 'k')\n",
      "('o', 'k', 'e')\n",
      "('k', 'e', 'n')\n",
      "('e', 'n', 'N')\n",
      "('n', 'N', ',')\n",
      "('N', ',', 't')\n",
      "(',', 't', 'o')\n",
      "('t', 'o', 'k')\n",
      "('o', 'k', 'e')\n",
      "('k', 'e', 'n')\n",
      "('e', 'n', 'N')\n",
      "('n', 'N', '−')\n",
      "('N', '−', '1')\n",
      "('−', '1', ')')\n",
      "('1', ')', ')')\n",
      "(')', ')', 'i')\n",
      "(')', 'i', ')')\n",
      "('i', ')', '{\\\\displaystyle')\n",
      "(')', '{\\\\displaystyle', '{RMM(token_{N})}={PMM(token_{N})}\\\\times')\n",
      "('{\\\\displaystyle', '{RMM(token_{N})}={PMM(token_{N})}\\\\times', '{\\\\frac')\n",
      "('{RMM(token_{N})}={PMM(token_{N})}\\\\times', '{\\\\frac', '{1}{2d}}\\\\left(\\\\sum')\n",
      "('{\\\\frac', '{1}{2d}}\\\\left(\\\\sum', '_{i=-d}^{d}{((PMM(token_{N-1})}\\\\times')\n",
      "('{1}{2d}}\\\\left(\\\\sum', '_{i=-d}^{d}{((PMM(token_{N-1})}\\\\times', '{PF(token_{N},token_{N-1}))_{i}}\\\\right)}')\n",
      "('_{i=-d}^{d}{((PMM(token_{N-1})}\\\\times', '{PF(token_{N},token_{N-1}))_{i}}\\\\right)}', 'Where,')\n",
      "('{PF(token_{N},token_{N-1}))_{i}}\\\\right)}', 'Where,', 'RMM')\n",
      "('Where,', 'RMM', ',')\n",
      "('RMM', ',', 'is')\n",
      "(',', 'is', 'the')\n",
      "('is', 'the', 'Relative')\n",
      "('the', 'Relative', 'Measure')\n",
      "('Relative', 'Measure', 'of')\n",
      "('Measure', 'of', 'Meaning')\n",
      "('of', 'Meaning', 'token')\n",
      "('Meaning', 'token', ',')\n",
      "('token', ',', 'is')\n",
      "(',', 'is', 'any')\n",
      "('is', 'any', 'block')\n",
      "('any', 'block', 'of')\n",
      "('block', 'of', 'text,')\n",
      "('of', 'text,', 'sentence,')\n",
      "('text,', 'sentence,', 'phrase')\n",
      "('sentence,', 'phrase', 'or')\n",
      "('phrase', 'or', 'word')\n",
      "('or', 'word', 'N')\n",
      "('word', 'N', ',')\n",
      "('N', ',', 'is')\n",
      "(',', 'is', 'the')\n",
      "('is', 'the', 'number')\n",
      "('the', 'number', 'of')\n",
      "('number', 'of', 'tokens')\n",
      "('of', 'tokens', 'being')\n",
      "('tokens', 'being', 'analyzed')\n",
      "('being', 'analyzed', 'PMM')\n",
      "('analyzed', 'PMM', ',')\n",
      "('PMM', ',', 'is')\n",
      "(',', 'is', 'the')\n",
      "('is', 'the', 'Probable')\n",
      "('the', 'Probable', 'Measure')\n",
      "('Probable', 'Measure', 'of')\n",
      "('Measure', 'of', 'Meaning')\n",
      "('of', 'Meaning', 'based')\n",
      "('Meaning', 'based', 'on')\n",
      "('based', 'on', 'a')\n",
      "('on', 'a', 'corpora')\n",
      "('a', 'corpora', 'd')\n",
      "('corpora', 'd', ',')\n",
      "('d', ',', 'is')\n",
      "(',', 'is', 'the')\n",
      "('is', 'the', 'location')\n",
      "('the', 'location', 'of')\n",
      "('location', 'of', 'the')\n",
      "('of', 'the', 'token')\n",
      "('the', 'token', 'along')\n",
      "('token', 'along', 'the')\n",
      "('along', 'the', 'sequence')\n",
      "('the', 'sequence', 'of')\n",
      "('sequence', 'of', 'N-1')\n",
      "('of', 'N-1', 'tokens')\n",
      "('N-1', 'tokens', 'PF')\n",
      "('tokens', 'PF', ',')\n",
      "('PF', ',', 'is')\n",
      "(',', 'is', 'the')\n",
      "('is', 'the', 'Probability')\n",
      "('the', 'Probability', 'Function')\n",
      "('Probability', 'Function', 'specific')\n",
      "('Function', 'specific', 'to')\n",
      "('specific', 'to', 'a')\n",
      "('to', 'a', 'language')\n",
      "('a', 'language', 'Ties')\n",
      "('language', 'Ties', 'with')\n",
      "('Ties', 'with', 'cognitive')\n",
      "('with', 'cognitive', 'linguistics')\n",
      "('cognitive', 'linguistics', 'are')\n",
      "('linguistics', 'are', 'part')\n",
      "('are', 'part', 'of')\n",
      "('part', 'of', 'the')\n",
      "('of', 'the', 'historical')\n",
      "('the', 'historical', 'heritage')\n",
      "('historical', 'heritage', 'of')\n",
      "('heritage', 'of', 'NLP,')\n",
      "('of', 'NLP,', 'but')\n",
      "('NLP,', 'but', 'they')\n",
      "('but', 'they', 'have')\n",
      "('they', 'have', 'been')\n",
      "('have', 'been', 'less')\n",
      "('been', 'less', 'frequently')\n",
      "('less', 'frequently', 'addressed')\n",
      "('frequently', 'addressed', 'since')\n",
      "('addressed', 'since', 'the')\n",
      "('since', 'the', 'statistical')\n",
      "('the', 'statistical', 'turn')\n",
      "('statistical', 'turn', 'during')\n",
      "('turn', 'during', 'the')\n",
      "('during', 'the', '1990s.')\n",
      "('the', '1990s.', 'Nevertheless,')\n",
      "('1990s.', 'Nevertheless,', 'approaches')\n",
      "('Nevertheless,', 'approaches', 'to')\n",
      "('approaches', 'to', 'develop')\n",
      "('to', 'develop', 'cognitive')\n",
      "('develop', 'cognitive', 'models')\n",
      "('cognitive', 'models', 'towards')\n",
      "('models', 'towards', 'technically')\n",
      "('towards', 'technically', 'operationalizable')\n",
      "('technically', 'operationalizable', 'frameworks')\n",
      "('operationalizable', 'frameworks', 'have')\n",
      "('frameworks', 'have', 'been')\n",
      "('have', 'been', 'pursued')\n",
      "('been', 'pursued', 'in')\n",
      "('pursued', 'in', 'the')\n",
      "('in', 'the', 'context')\n",
      "('the', 'context', 'of')\n",
      "('context', 'of', 'various')\n",
      "('of', 'various', 'frameworks,')\n",
      "('various', 'frameworks,', 'e.g.,')\n",
      "('frameworks,', 'e.g.,', 'of')\n",
      "('e.g.,', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'grammar,')\n",
      "('cognitive', 'grammar,', '[42]')\n",
      "('grammar,', '[42]', 'functional')\n",
      "('[42]', 'functional', 'grammar,')\n",
      "('functional', 'grammar,', '[43]')\n",
      "('grammar,', '[43]', 'construction')\n",
      "('[43]', 'construction', 'grammar,')\n",
      "('construction', 'grammar,', '[44]')\n",
      "('grammar,', '[44]', 'computational')\n",
      "('[44]', 'computational', 'psycholinguistics')\n",
      "('computational', 'psycholinguistics', 'and')\n",
      "('psycholinguistics', 'and', 'cognitive')\n",
      "('and', 'cognitive', 'neuroscience')\n",
      "('cognitive', 'neuroscience', '(e.g.,')\n",
      "('neuroscience', '(e.g.,', 'ACT-R')\n",
      "('(e.g.,', 'ACT-R', '),')\n",
      "('ACT-R', '),', 'however,')\n",
      "('),', 'however,', 'with')\n",
      "('however,', 'with', 'limited')\n",
      "('with', 'limited', 'uptake')\n",
      "('limited', 'uptake', 'in')\n",
      "('uptake', 'in', 'mainstream')\n",
      "('in', 'mainstream', 'NLP')\n",
      "('mainstream', 'NLP', '(as')\n",
      "('NLP', '(as', 'measured')\n",
      "('(as', 'measured', 'by')\n",
      "('measured', 'by', 'presence')\n",
      "('by', 'presence', 'on')\n",
      "('presence', 'on', 'major')\n",
      "('on', 'major', 'conferences')\n",
      "('major', 'conferences', '[45]')\n",
      "('conferences', '[45]', 'of')\n",
      "('[45]', 'of', 'the')\n",
      "('of', 'the', 'ACL')\n",
      "('the', 'ACL', ').')\n",
      "('ACL', ').', 'More')\n",
      "(').', 'More', 'recently,')\n",
      "('More', 'recently,', 'ideas')\n",
      "('recently,', 'ideas', 'of')\n",
      "('ideas', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'NLP')\n",
      "('cognitive', 'NLP', 'have')\n",
      "('NLP', 'have', 'been')\n",
      "('have', 'been', 'revived')\n",
      "('been', 'revived', 'as')\n",
      "('revived', 'as', 'an')\n",
      "('as', 'an', 'approach')\n",
      "('an', 'approach', 'to')\n",
      "('approach', 'to', 'achieve')\n",
      "('to', 'achieve', 'explainability')\n",
      "('achieve', 'explainability', ',')\n",
      "('explainability', ',', 'e.g.,')\n",
      "(',', 'e.g.,', 'under')\n",
      "('e.g.,', 'under', 'the')\n",
      "('under', 'the', 'notion')\n",
      "('the', 'notion', 'of')\n",
      "('notion', 'of', '\"cognitive')\n",
      "('of', '\"cognitive', 'AI\".')\n",
      "('\"cognitive', 'AI\".', '[46]')\n",
      "('AI\".', '[46]', 'Likewise,')\n",
      "('[46]', 'Likewise,', 'ideas')\n",
      "('Likewise,', 'ideas', 'of')\n",
      "('ideas', 'of', 'cognitive')\n",
      "('of', 'cognitive', 'NLP')\n",
      "('cognitive', 'NLP', 'are')\n",
      "('NLP', 'are', 'inherent')\n",
      "('are', 'inherent', 'to')\n",
      "('inherent', 'to', 'neural')\n",
      "('to', 'neural', 'models')\n",
      "('neural', 'models', 'multimodal')\n",
      "('models', 'multimodal', 'NLP')\n",
      "('multimodal', 'NLP', '(although')\n",
      "('NLP', '(although', 'rarely')\n",
      "('(although', 'rarely', 'made')\n",
      "('rarely', 'made', 'explicit).')\n",
      "('made', 'explicit).', '[47]')\n",
      "('explicit).', '[47]', 'See')\n",
      "('[47]', 'See', 'also')\n",
      "('See', 'also', '[')\n",
      "('also', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', '1')\n",
      "(']', '1', 'the')\n",
      "('1', 'the', 'Road')\n",
      "('the', 'Road', 'Automated')\n",
      "('Road', 'Automated', 'essay')\n",
      "('Automated', 'essay', 'scoring')\n",
      "('essay', 'scoring', 'Biomedical')\n",
      "('scoring', 'Biomedical', 'text')\n",
      "('Biomedical', 'text', 'mining')\n",
      "('text', 'mining', 'Compound')\n",
      "('mining', 'Compound', 'term')\n",
      "('Compound', 'term', 'processing')\n",
      "('term', 'processing', 'Computational')\n",
      "('processing', 'Computational', 'linguistics')\n",
      "('Computational', 'linguistics', 'Computer-assisted')\n",
      "('linguistics', 'Computer-assisted', 'reviewing')\n",
      "('Computer-assisted', 'reviewing', 'Controlled')\n",
      "('reviewing', 'Controlled', 'natural')\n",
      "('Controlled', 'natural', 'language')\n",
      "('natural', 'language', 'Deep')\n",
      "('language', 'Deep', 'learning')\n",
      "('Deep', 'learning', 'Deep')\n",
      "('learning', 'Deep', 'linguistic')\n",
      "('Deep', 'linguistic', 'processing')\n",
      "('linguistic', 'processing', 'Distributional')\n",
      "('processing', 'Distributional', 'semantics')\n",
      "('Distributional', 'semantics', 'Foreign')\n",
      "('semantics', 'Foreign', 'language')\n",
      "('Foreign', 'language', 'reading')\n",
      "('language', 'reading', 'aid')\n",
      "('reading', 'aid', 'Foreign')\n",
      "('aid', 'Foreign', 'language')\n",
      "('Foreign', 'language', 'writing')\n",
      "('language', 'writing', 'aid')\n",
      "('writing', 'aid', 'Information')\n",
      "('aid', 'Information', 'extraction')\n",
      "('Information', 'extraction', 'Information')\n",
      "('extraction', 'Information', 'retrieval')\n",
      "('Information', 'retrieval', 'Language')\n",
      "('retrieval', 'Language', 'and')\n",
      "('Language', 'and', 'Communication')\n",
      "('and', 'Communication', 'Technologies')\n",
      "('Communication', 'Technologies', 'Language')\n",
      "('Technologies', 'Language', 'technology')\n",
      "('Language', 'technology', 'Latent')\n",
      "('technology', 'Latent', 'semantic')\n",
      "('Latent', 'semantic', 'indexing')\n",
      "('semantic', 'indexing', 'Native-language')\n",
      "('indexing', 'Native-language', 'identification')\n",
      "('Native-language', 'identification', 'Natural')\n",
      "('identification', 'Natural', 'language')\n",
      "('Natural', 'language', 'programming')\n",
      "('language', 'programming', 'Natural')\n",
      "('programming', 'Natural', 'language')\n",
      "('Natural', 'language', 'search')\n",
      "('language', 'search', 'Outline')\n",
      "('search', 'Outline', 'of')\n",
      "('Outline', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'Query')\n",
      "('processing', 'Query', 'expansion')\n",
      "('Query', 'expansion', 'Query')\n",
      "('expansion', 'Query', 'understanding')\n",
      "('Query', 'understanding', 'Reification')\n",
      "('understanding', 'Reification', '(linguistics)')\n",
      "('Reification', '(linguistics)', 'Speech')\n",
      "('(linguistics)', 'Speech', 'processing')\n",
      "('Speech', 'processing', 'Spoken')\n",
      "('processing', 'Spoken', 'dialogue')\n",
      "('Spoken', 'dialogue', 'systems')\n",
      "('dialogue', 'systems', 'Text-proofing')\n",
      "('systems', 'Text-proofing', 'Text')\n",
      "('Text-proofing', 'Text', 'simplification')\n",
      "('Text', 'simplification', 'Transformer')\n",
      "('simplification', 'Transformer', '(machine')\n",
      "('Transformer', '(machine', 'learning')\n",
      "('(machine', 'learning', 'model)')\n",
      "('learning', 'model)', 'Truecasing')\n",
      "('model)', 'Truecasing', 'Question')\n",
      "('Truecasing', 'Question', 'answering')\n",
      "('Question', 'answering', 'Word2vec')\n",
      "('answering', 'Word2vec', 'References')\n",
      "('Word2vec', 'References', '[')\n",
      "('References', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', '^')\n",
      "(']', '^', 'Kongthon,')\n",
      "('^', 'Kongthon,', 'Alisa;')\n",
      "('Kongthon,', 'Alisa;', 'Sangkeettrakarn,')\n",
      "('Alisa;', 'Sangkeettrakarn,', 'Chatchawal;')\n",
      "('Sangkeettrakarn,', 'Chatchawal;', 'Kongyoung,')\n",
      "('Chatchawal;', 'Kongyoung,', 'Sarawoot;')\n",
      "('Kongyoung,', 'Sarawoot;', 'Haruechaiyasak,')\n",
      "('Sarawoot;', 'Haruechaiyasak,', 'Choochart')\n",
      "('Haruechaiyasak,', 'Choochart', '(October')\n",
      "('Choochart', '(October', '27–30,')\n",
      "('(October', '27–30,', '2009).')\n",
      "('27–30,', '2009).', 'Implementing')\n",
      "('2009).', 'Implementing', 'an')\n",
      "('Implementing', 'an', 'online')\n",
      "('an', 'online', 'help')\n",
      "('online', 'help', 'desk')\n",
      "('help', 'desk', 'system')\n",
      "('desk', 'system', 'based')\n",
      "('system', 'based', 'on')\n",
      "('based', 'on', 'conversational')\n",
      "('on', 'conversational', 'agent')\n",
      "('conversational', 'agent', '.')\n",
      "('agent', '.', 'MEDES')\n",
      "('.', 'MEDES', \"'09:\")\n",
      "('MEDES', \"'09:\", 'The')\n",
      "(\"'09:\", 'The', 'International')\n",
      "('The', 'International', 'Conference')\n",
      "('International', 'Conference', 'on')\n",
      "('Conference', 'on', 'Management')\n",
      "('on', 'Management', 'of')\n",
      "('Management', 'of', 'Emergent')\n",
      "('of', 'Emergent', 'Digital')\n",
      "('Emergent', 'Digital', 'EcoSystems.')\n",
      "('Digital', 'EcoSystems.', 'France:')\n",
      "('EcoSystems.', 'France:', 'ACM.')\n",
      "('France:', 'ACM.', 'doi')\n",
      "('ACM.', 'doi', ':')\n",
      "('doi', ':', '10.1145/1643823.1643908')\n",
      "(':', '10.1145/1643823.1643908', '.')\n",
      "('10.1145/1643823.1643908', '.', '^')\n",
      "('.', '^', 'Hutchins,')\n",
      "('^', 'Hutchins,', 'J.')\n",
      "('Hutchins,', 'J.', '(2005).')\n",
      "('J.', '(2005).', '\"The')\n",
      "('(2005).', '\"The', 'history')\n",
      "('\"The', 'history', 'of')\n",
      "('history', 'of', 'machine')\n",
      "('of', 'machine', 'translation')\n",
      "('machine', 'translation', 'in')\n",
      "('translation', 'in', 'a')\n",
      "('in', 'a', 'nutshell\"')\n",
      "('a', 'nutshell\"', '(PDF)')\n",
      "('nutshell\"', '(PDF)', '.')\n",
      "('(PDF)', '.', '[')\n",
      "('.', '[', 'self-published')\n",
      "('[', 'self-published', 'source')\n",
      "('self-published', 'source', ']')\n",
      "('source', ']', '^')\n",
      "(']', '^', 'Koskenniemi,')\n",
      "('^', 'Koskenniemi,', 'Kimmo')\n",
      "('Koskenniemi,', 'Kimmo', '(1983),')\n",
      "('Kimmo', '(1983),', 'Two-level')\n",
      "('(1983),', 'Two-level', 'morphology:')\n",
      "('Two-level', 'morphology:', 'A')\n",
      "('morphology:', 'A', 'general')\n",
      "('A', 'general', 'computational')\n",
      "('general', 'computational', 'model')\n",
      "('computational', 'model', 'of')\n",
      "('model', 'of', 'word-form')\n",
      "('of', 'word-form', 'recognition')\n",
      "('word-form', 'recognition', 'and')\n",
      "('recognition', 'and', 'production')\n",
      "('and', 'production', '(PDF)')\n",
      "('production', '(PDF)', ',')\n",
      "('(PDF)', ',', 'Department')\n",
      "(',', 'Department', 'of')\n",
      "('Department', 'of', 'General')\n",
      "('of', 'General', 'Linguistics,')\n",
      "('General', 'Linguistics,', 'University')\n",
      "('Linguistics,', 'University', 'of')\n",
      "('University', 'of', 'Helsinki')\n",
      "('of', 'Helsinki', '^')\n",
      "('Helsinki', '^', 'Joshi,')\n",
      "('^', 'Joshi,', 'A.')\n",
      "('Joshi,', 'A.', 'K.,')\n",
      "('A.', 'K.,', '&')\n",
      "('K.,', '&', 'Weinstein,')\n",
      "('&', 'Weinstein,', 'S.')\n",
      "('Weinstein,', 'S.', '(1981,')\n",
      "('S.', '(1981,', 'August).')\n",
      "('(1981,', 'August).', 'Control')\n",
      "('August).', 'Control', 'of')\n",
      "('Control', 'of', 'Inference:')\n",
      "('of', 'Inference:', 'Role')\n",
      "('Inference:', 'Role', 'of')\n",
      "('Role', 'of', 'Some')\n",
      "('of', 'Some', 'Aspects')\n",
      "('Some', 'Aspects', 'of')\n",
      "('Aspects', 'of', 'Discourse')\n",
      "('of', 'Discourse', 'Structure-Centering')\n",
      "('Discourse', 'Structure-Centering', '.')\n",
      "('Structure-Centering', '.', 'In')\n",
      "('.', 'In', 'IJCAI')\n",
      "('In', 'IJCAI', '(pp.')\n",
      "('IJCAI', '(pp.', '385-387).')\n",
      "('(pp.', '385-387).', '^')\n",
      "('385-387).', '^', 'Guida,')\n",
      "('^', 'Guida,', 'G.;')\n",
      "('Guida,', 'G.;', 'Mauri,')\n",
      "('G.;', 'Mauri,', 'G.')\n",
      "('Mauri,', 'G.', '(July')\n",
      "('G.', '(July', '1986).')\n",
      "('(July', '1986).', '\"Evaluation')\n",
      "('1986).', '\"Evaluation', 'of')\n",
      "('\"Evaluation', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'processing')\n",
      "('language', 'processing', 'systems:')\n",
      "('processing', 'systems:', 'Issues')\n",
      "('systems:', 'Issues', 'and')\n",
      "('Issues', 'and', 'approaches\".')\n",
      "('and', 'approaches\".', 'Proceedings')\n",
      "('approaches\".', 'Proceedings', 'of')\n",
      "('Proceedings', 'of', 'the')\n",
      "('of', 'the', 'IEEE')\n",
      "('the', 'IEEE', '.')\n",
      "('IEEE', '.', '74')\n",
      "('.', '74', '(7):')\n",
      "('74', '(7):', '1026–1035.')\n",
      "('(7):', '1026–1035.', 'doi')\n",
      "('1026–1035.', 'doi', ':')\n",
      "('doi', ':', '10.1109/PROC.1986.13580')\n",
      "(':', '10.1109/PROC.1986.13580', '.')\n",
      "('10.1109/PROC.1986.13580', '.', 'ISSN')\n",
      "('.', 'ISSN', '1558-2256')\n",
      "('ISSN', '1558-2256', '.')\n",
      "('1558-2256', '.', 'S2CID')\n",
      "('.', 'S2CID', '30688575')\n",
      "('S2CID', '30688575', '.')\n",
      "('30688575', '.', '^')\n",
      "('.', '^', 'Chomskyan')\n",
      "('^', 'Chomskyan', 'linguistics')\n",
      "('Chomskyan', 'linguistics', 'encourages')\n",
      "('linguistics', 'encourages', 'the')\n",
      "('encourages', 'the', 'investigation')\n",
      "('the', 'investigation', 'of')\n",
      "('investigation', 'of', '\"')\n",
      "('of', '\"', 'corner')\n",
      "('\"', 'corner', 'cases')\n",
      "('corner', 'cases', '\"')\n",
      "('cases', '\"', 'that')\n",
      "('\"', 'that', 'stress')\n",
      "('that', 'stress', 'the')\n",
      "('stress', 'the', 'limits')\n",
      "('the', 'limits', 'of')\n",
      "('limits', 'of', 'its')\n",
      "('of', 'its', 'theoretical')\n",
      "('its', 'theoretical', 'models')\n",
      "('theoretical', 'models', '(comparable')\n",
      "('models', '(comparable', 'to')\n",
      "('(comparable', 'to', 'pathological')\n",
      "('to', 'pathological', 'phenomena')\n",
      "('pathological', 'phenomena', 'in')\n",
      "('phenomena', 'in', 'mathematics),')\n",
      "('in', 'mathematics),', 'typically')\n",
      "('mathematics),', 'typically', 'created')\n",
      "('typically', 'created', 'using')\n",
      "('created', 'using', 'thought')\n",
      "('using', 'thought', 'experiments')\n",
      "('thought', 'experiments', ',')\n",
      "('experiments', ',', 'rather')\n",
      "(',', 'rather', 'than')\n",
      "('rather', 'than', 'the')\n",
      "('than', 'the', 'systematic')\n",
      "('the', 'systematic', 'investigation')\n",
      "('systematic', 'investigation', 'of')\n",
      "('investigation', 'of', 'typical')\n",
      "('of', 'typical', 'phenomena')\n",
      "('typical', 'phenomena', 'that')\n",
      "('phenomena', 'that', 'occur')\n",
      "('that', 'occur', 'in')\n",
      "('occur', 'in', 'real-world')\n",
      "('in', 'real-world', 'data,')\n",
      "('real-world', 'data,', 'as')\n",
      "('data,', 'as', 'is')\n",
      "('as', 'is', 'the')\n",
      "('is', 'the', 'case')\n",
      "('the', 'case', 'in')\n",
      "('case', 'in', 'corpus')\n",
      "('in', 'corpus', 'linguistics')\n",
      "('corpus', 'linguistics', '.')\n",
      "('linguistics', '.', 'The')\n",
      "('.', 'The', 'creation')\n",
      "('The', 'creation', 'and')\n",
      "('creation', 'and', 'use')\n",
      "('and', 'use', 'of')\n",
      "('use', 'of', 'such')\n",
      "('of', 'such', 'corpora')\n",
      "('such', 'corpora', 'of')\n",
      "('corpora', 'of', 'real-world')\n",
      "('of', 'real-world', 'data')\n",
      "('real-world', 'data', 'is')\n",
      "('data', 'is', 'a')\n",
      "('is', 'a', 'fundamental')\n",
      "('a', 'fundamental', 'part')\n",
      "('fundamental', 'part', 'of')\n",
      "('part', 'of', 'machine-learning')\n",
      "('of', 'machine-learning', 'algorithms')\n",
      "('machine-learning', 'algorithms', 'for')\n",
      "('algorithms', 'for', 'natural')\n",
      "('for', 'natural', 'language')\n",
      "('natural', 'language', 'processing.')\n",
      "('language', 'processing.', 'In')\n",
      "('processing.', 'In', 'addition,')\n",
      "('In', 'addition,', 'theoretical')\n",
      "('addition,', 'theoretical', 'underpinnings')\n",
      "('theoretical', 'underpinnings', 'of')\n",
      "('underpinnings', 'of', 'Chomskyan')\n",
      "('of', 'Chomskyan', 'linguistics')\n",
      "('Chomskyan', 'linguistics', 'such')\n",
      "('linguistics', 'such', 'as')\n",
      "('such', 'as', 'the')\n",
      "('as', 'the', 'so-called')\n",
      "('the', 'so-called', '\"')\n",
      "('so-called', '\"', 'poverty')\n",
      "('\"', 'poverty', 'of')\n",
      "('poverty', 'of', 'the')\n",
      "('of', 'the', 'stimulus')\n",
      "('the', 'stimulus', '\"')\n",
      "('stimulus', '\"', 'argument')\n",
      "('\"', 'argument', 'entail')\n",
      "('argument', 'entail', 'that')\n",
      "('entail', 'that', 'general')\n",
      "('that', 'general', 'learning')\n",
      "('general', 'learning', 'algorithms,')\n",
      "('learning', 'algorithms,', 'as')\n",
      "('algorithms,', 'as', 'are')\n",
      "('as', 'are', 'typically')\n",
      "('are', 'typically', 'used')\n",
      "('typically', 'used', 'in')\n",
      "('used', 'in', 'machine')\n",
      "('in', 'machine', 'learning,')\n",
      "('machine', 'learning,', 'cannot')\n",
      "('learning,', 'cannot', 'be')\n",
      "('cannot', 'be', 'successful')\n",
      "('be', 'successful', 'in')\n",
      "('successful', 'in', 'language')\n",
      "('in', 'language', 'processing.')\n",
      "('language', 'processing.', 'As')\n",
      "('processing.', 'As', 'a')\n",
      "('As', 'a', 'result,')\n",
      "('a', 'result,', 'the')\n",
      "('result,', 'the', 'Chomskyan')\n",
      "('the', 'Chomskyan', 'paradigm')\n",
      "('Chomskyan', 'paradigm', 'discouraged')\n",
      "('paradigm', 'discouraged', 'the')\n",
      "('discouraged', 'the', 'application')\n",
      "('the', 'application', 'of')\n",
      "('application', 'of', 'such')\n",
      "('of', 'such', 'models')\n",
      "('such', 'models', 'to')\n",
      "('models', 'to', 'language')\n",
      "('to', 'language', 'processing.')\n",
      "('language', 'processing.', '^')\n",
      "('processing.', '^', 'Goldberg,')\n",
      "('^', 'Goldberg,', 'Yoav')\n",
      "('Goldberg,', 'Yoav', '(2016).')\n",
      "('Yoav', '(2016).', '\"A')\n",
      "('(2016).', '\"A', 'Primer')\n",
      "('\"A', 'Primer', 'on')\n",
      "('Primer', 'on', 'Neural')\n",
      "('on', 'Neural', 'Network')\n",
      "('Neural', 'Network', 'Models')\n",
      "('Network', 'Models', 'for')\n",
      "('Models', 'for', 'Natural')\n",
      "('for', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing\".')\n",
      "('Language', 'Processing\".', 'Journal')\n",
      "('Processing\".', 'Journal', 'of')\n",
      "('Journal', 'of', 'Artificial')\n",
      "('of', 'Artificial', 'Intelligence')\n",
      "('Artificial', 'Intelligence', 'Research')\n",
      "('Intelligence', 'Research', '.')\n",
      "('Research', '.', '57')\n",
      "('.', '57', ':')\n",
      "('57', ':', '345–420.')\n",
      "(':', '345–420.', 'arXiv')\n",
      "('345–420.', 'arXiv', ':')\n",
      "('arXiv', ':', '1807.10854')\n",
      "(':', '1807.10854', '.')\n",
      "('1807.10854', '.', 'doi')\n",
      "('.', 'doi', ':')\n",
      "('doi', ':', '10.1613/jair.4992')\n",
      "(':', '10.1613/jair.4992', '.')\n",
      "('10.1613/jair.4992', '.', 'S2CID')\n",
      "('.', 'S2CID', '8273530')\n",
      "('S2CID', '8273530', '.')\n",
      "('8273530', '.', '^')\n",
      "('.', '^', 'Goodfellow,')\n",
      "('^', 'Goodfellow,', 'Ian;')\n",
      "('Goodfellow,', 'Ian;', 'Bengio,')\n",
      "('Ian;', 'Bengio,', 'Yoshua;')\n",
      "('Bengio,', 'Yoshua;', 'Courville,')\n",
      "('Yoshua;', 'Courville,', 'Aaron')\n",
      "('Courville,', 'Aaron', '(2016).')\n",
      "('Aaron', '(2016).', 'Deep')\n",
      "('(2016).', 'Deep', 'Learning')\n",
      "('Deep', 'Learning', '.')\n",
      "('Learning', '.', 'MIT')\n",
      "('.', 'MIT', 'Press.')\n",
      "('MIT', 'Press.', '^')\n",
      "('Press.', '^', 'Jozefowicz,')\n",
      "('^', 'Jozefowicz,', 'Rafal;')\n",
      "('Jozefowicz,', 'Rafal;', 'Vinyals,')\n",
      "('Rafal;', 'Vinyals,', 'Oriol;')\n",
      "('Vinyals,', 'Oriol;', 'Schuster,')\n",
      "('Oriol;', 'Schuster,', 'Mike;')\n",
      "('Schuster,', 'Mike;', 'Shazeer,')\n",
      "('Mike;', 'Shazeer,', 'Noam;')\n",
      "('Shazeer,', 'Noam;', 'Wu,')\n",
      "('Noam;', 'Wu,', 'Yonghui')\n",
      "('Wu,', 'Yonghui', '(2016).')\n",
      "('Yonghui', '(2016).', 'Exploring')\n",
      "('(2016).', 'Exploring', 'the')\n",
      "('Exploring', 'the', 'Limits')\n",
      "('the', 'Limits', 'of')\n",
      "('Limits', 'of', 'Language')\n",
      "('of', 'Language', 'Modeling')\n",
      "('Language', 'Modeling', '.')\n",
      "('Modeling', '.', 'arXiv')\n",
      "('.', 'arXiv', ':')\n",
      "('arXiv', ':', '1602.02410')\n",
      "(':', '1602.02410', '.')\n",
      "('1602.02410', '.', 'Bibcode')\n",
      "('.', 'Bibcode', ':')\n",
      "('Bibcode', ':', '2016arXiv160202410J')\n",
      "(':', '2016arXiv160202410J', '.')\n",
      "('2016arXiv160202410J', '.', '^')\n",
      "('.', '^', 'Choe,')\n",
      "('^', 'Choe,', 'Do')\n",
      "('Choe,', 'Do', 'Kook;')\n",
      "('Do', 'Kook;', 'Charniak,')\n",
      "('Kook;', 'Charniak,', 'Eugene.')\n",
      "('Charniak,', 'Eugene.', '\"Parsing')\n",
      "('Eugene.', '\"Parsing', 'as')\n",
      "('\"Parsing', 'as', 'Language')\n",
      "('as', 'Language', 'Modeling\"')\n",
      "('Language', 'Modeling\"', '.')\n",
      "('Modeling\"', '.', 'Emnlp')\n",
      "('.', 'Emnlp', '2016')\n",
      "('Emnlp', '2016', '.')\n",
      "('2016', '.', '^')\n",
      "('.', '^', 'Vinyals,')\n",
      "('^', 'Vinyals,', 'Oriol;')\n",
      "('Vinyals,', 'Oriol;', 'et')\n",
      "('Oriol;', 'et', 'al.')\n",
      "('et', 'al.', '(2014).')\n",
      "('al.', '(2014).', '\"Grammar')\n",
      "('(2014).', '\"Grammar', 'as')\n",
      "('\"Grammar', 'as', 'a')\n",
      "('as', 'a', 'Foreign')\n",
      "('a', 'Foreign', 'Language\"')\n",
      "('Foreign', 'Language\"', '(PDF)')\n",
      "('Language\"', '(PDF)', '.')\n",
      "('(PDF)', '.', 'Nips2015')\n",
      "('.', 'Nips2015', '.')\n",
      "('Nips2015', '.', 'arXiv')\n",
      "('.', 'arXiv', ':')\n",
      "('arXiv', ':', '1412.7449')\n",
      "(':', '1412.7449', '.')\n",
      "('1412.7449', '.', 'Bibcode')\n",
      "('.', 'Bibcode', ':')\n",
      "('Bibcode', ':', '2014arXiv1412.7449V')\n",
      "(':', '2014arXiv1412.7449V', '.')\n",
      "('2014arXiv1412.7449V', '.', '^')\n",
      "('.', '^', 'Turchin,')\n",
      "('^', 'Turchin,', 'Alexander;')\n",
      "('Turchin,', 'Alexander;', 'Florez')\n",
      "('Alexander;', 'Florez', 'Builes,')\n",
      "('Florez', 'Builes,', 'Luisa')\n",
      "('Builes,', 'Luisa', 'F.')\n",
      "('Luisa', 'F.', '(2021-03-19).')\n",
      "('F.', '(2021-03-19).', '\"Using')\n",
      "('(2021-03-19).', '\"Using', 'Natural')\n",
      "('\"Using', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', 'to')\n",
      "('Processing', 'to', 'Measure')\n",
      "('to', 'Measure', 'and')\n",
      "('Measure', 'and', 'Improve')\n",
      "('and', 'Improve', 'Quality')\n",
      "('Improve', 'Quality', 'of')\n",
      "('Quality', 'of', 'Diabetes')\n",
      "('of', 'Diabetes', 'Care:')\n",
      "('Diabetes', 'Care:', 'A')\n",
      "('Care:', 'A', 'Systematic')\n",
      "('A', 'Systematic', 'Review\"')\n",
      "('Systematic', 'Review\"', '.')\n",
      "('Review\"', '.', 'Journal')\n",
      "('.', 'Journal', 'of')\n",
      "('Journal', 'of', 'Diabetes')\n",
      "('of', 'Diabetes', 'Science')\n",
      "('Diabetes', 'Science', 'and')\n",
      "('Science', 'and', 'Technology')\n",
      "('and', 'Technology', '.')\n",
      "('Technology', '.', '15')\n",
      "('.', '15', '(3):')\n",
      "('15', '(3):', '553–560.')\n",
      "('(3):', '553–560.', 'doi')\n",
      "('553–560.', 'doi', ':')\n",
      "('doi', ':', '10.1177/19322968211000831')\n",
      "(':', '10.1177/19322968211000831', '.')\n",
      "('10.1177/19322968211000831', '.', 'ISSN')\n",
      "('.', 'ISSN', '1932-2968')\n",
      "('ISSN', '1932-2968', '.')\n",
      "('1932-2968', '.', 'PMC')\n",
      "('.', 'PMC', '8120048.')\n",
      "('PMC', '8120048.', 'PMID')\n",
      "('8120048.', 'PMID', '33736486')\n",
      "('PMID', '33736486', '.')\n",
      "('33736486', '.', '^')\n",
      "('.', '^', 'Winograd,')\n",
      "('^', 'Winograd,', 'Terry')\n",
      "('Winograd,', 'Terry', '(1971).')\n",
      "('Terry', '(1971).', 'Procedures')\n",
      "('(1971).', 'Procedures', 'as')\n",
      "('Procedures', 'as', 'a')\n",
      "('as', 'a', 'Representation')\n",
      "('a', 'Representation', 'for')\n",
      "('Representation', 'for', 'Data')\n",
      "('for', 'Data', 'in')\n",
      "('Data', 'in', 'a')\n",
      "('in', 'a', 'Computer')\n",
      "('a', 'Computer', 'Program')\n",
      "('Computer', 'Program', 'for')\n",
      "('Program', 'for', 'Understanding')\n",
      "('for', 'Understanding', 'Natural')\n",
      "('Understanding', 'Natural', 'Language')\n",
      "('Natural', 'Language', '(Thesis).')\n",
      "('Language', '(Thesis).', '^')\n",
      "('(Thesis).', '^', 'Schank,')\n",
      "('^', 'Schank,', 'Roger')\n",
      "('Schank,', 'Roger', 'C.;')\n",
      "('Roger', 'C.;', 'Abelson,')\n",
      "('C.;', 'Abelson,', 'Robert')\n",
      "('Abelson,', 'Robert', 'P.')\n",
      "('Robert', 'P.', '(1977).')\n",
      "('P.', '(1977).', 'Scripts,')\n",
      "('(1977).', 'Scripts,', 'Plans,')\n",
      "('Scripts,', 'Plans,', 'Goals,')\n",
      "('Plans,', 'Goals,', 'and')\n",
      "('Goals,', 'and', 'Understanding:')\n",
      "('and', 'Understanding:', 'An')\n",
      "('Understanding:', 'An', 'Inquiry')\n",
      "('An', 'Inquiry', 'Into')\n",
      "('Inquiry', 'Into', 'Human')\n",
      "('Into', 'Human', 'Knowledge')\n",
      "('Human', 'Knowledge', 'Structures')\n",
      "('Knowledge', 'Structures', '.')\n",
      "('Structures', '.', 'Hillsdale:')\n",
      "('.', 'Hillsdale:', 'Erlbaum.')\n",
      "('Hillsdale:', 'Erlbaum.', 'ISBN')\n",
      "('Erlbaum.', 'ISBN', '0-470-99033-3')\n",
      "('ISBN', '0-470-99033-3', '.')\n",
      "('0-470-99033-3', '.', '^')\n",
      "('.', '^', 'Mark')\n",
      "('^', 'Mark', 'Johnson.')\n",
      "('Mark', 'Johnson.', 'How')\n",
      "('Johnson.', 'How', 'the')\n",
      "('How', 'the', 'statistical')\n",
      "('the', 'statistical', 'revolution')\n",
      "('statistical', 'revolution', 'changes')\n",
      "('revolution', 'changes', '(computational)')\n",
      "('changes', '(computational)', 'linguistics.')\n",
      "('(computational)', 'linguistics.', 'Proceedings')\n",
      "('linguistics.', 'Proceedings', 'of')\n",
      "('Proceedings', 'of', 'the')\n",
      "('of', 'the', 'EACL')\n",
      "('the', 'EACL', '2009')\n",
      "('EACL', '2009', 'Workshop')\n",
      "('2009', 'Workshop', 'on')\n",
      "('Workshop', 'on', 'the')\n",
      "('on', 'the', 'Interaction')\n",
      "('the', 'Interaction', 'between')\n",
      "('Interaction', 'between', 'Linguistics')\n",
      "('between', 'Linguistics', 'and')\n",
      "('Linguistics', 'and', 'Computational')\n",
      "('and', 'Computational', 'Linguistics.')\n",
      "('Computational', 'Linguistics.', '^')\n",
      "('Linguistics.', '^', 'Philip')\n",
      "('^', 'Philip', 'Resnik.')\n",
      "('Philip', 'Resnik.', 'Four')\n",
      "('Resnik.', 'Four', 'revolutions.')\n",
      "('Four', 'revolutions.', 'Language')\n",
      "('revolutions.', 'Language', 'Log,')\n",
      "('Language', 'Log,', 'February')\n",
      "('Log,', 'February', '5,')\n",
      "('February', '5,', '2011.')\n",
      "('5,', '2011.', '^')\n",
      "('2011.', '^', '\"Investigating')\n",
      "('^', '\"Investigating', 'complex-valued')\n",
      "('\"Investigating', 'complex-valued', 'representation')\n",
      "('complex-valued', 'representation', 'in')\n",
      "('representation', 'in', 'NLP\"')\n",
      "('in', 'NLP\"', '(PDF)')\n",
      "('NLP\"', '(PDF)', '.')\n",
      "('(PDF)', '.', '^')\n",
      "('.', '^', 'Trabelsi,')\n",
      "('^', 'Trabelsi,', 'Chiheb;')\n",
      "('Trabelsi,', 'Chiheb;', 'Bilaniuk,')\n",
      "('Chiheb;', 'Bilaniuk,', 'Olexa;')\n",
      "('Bilaniuk,', 'Olexa;', 'Zhang,')\n",
      "('Olexa;', 'Zhang,', 'Ying;')\n",
      "('Zhang,', 'Ying;', 'Serdyuk,')\n",
      "('Ying;', 'Serdyuk,', 'Dmitriy;')\n",
      "('Serdyuk,', 'Dmitriy;', 'Subramanian,')\n",
      "('Dmitriy;', 'Subramanian,', 'Sandeep;')\n",
      "('Subramanian,', 'Sandeep;', 'Santos,')\n",
      "('Sandeep;', 'Santos,', 'João')\n",
      "('Santos,', 'João', 'Felipe;')\n",
      "('João', 'Felipe;', 'Mehri,')\n",
      "('Felipe;', 'Mehri,', 'Soroush;')\n",
      "('Mehri,', 'Soroush;', 'Rostamzadeh,')\n",
      "('Soroush;', 'Rostamzadeh,', 'Negar;')\n",
      "('Rostamzadeh,', 'Negar;', 'Bengio,')\n",
      "('Negar;', 'Bengio,', 'Yoshua;')\n",
      "('Bengio,', 'Yoshua;', 'Pal,')\n",
      "('Yoshua;', 'Pal,', 'Christopher')\n",
      "('Pal,', 'Christopher', 'J.')\n",
      "('Christopher', 'J.', '(2018-02-25).')\n",
      "('J.', '(2018-02-25).', '\"Deep')\n",
      "('(2018-02-25).', '\"Deep', 'Complex')\n",
      "('\"Deep', 'Complex', 'Networks\".')\n",
      "('Complex', 'Networks\".', 'arXiv')\n",
      "('Networks\".', 'arXiv', ':')\n",
      "('arXiv', ':', '1705.09792')\n",
      "(':', '1705.09792', '[')\n",
      "('1705.09792', '[', 'cs.NE')\n",
      "('[', 'cs.NE', '].')\n",
      "('cs.NE', '].', '^')\n",
      "('].', '^', 'Socher,')\n",
      "('^', 'Socher,', 'Richard.')\n",
      "('Socher,', 'Richard.', '\"Deep')\n",
      "('Richard.', '\"Deep', 'Learning')\n",
      "('\"Deep', 'Learning', 'For')\n",
      "('Learning', 'For', 'NLP-ACL')\n",
      "('For', 'NLP-ACL', '2012')\n",
      "('NLP-ACL', '2012', 'Tutorial\"')\n",
      "('2012', 'Tutorial\"', '.')\n",
      "('Tutorial\"', '.', 'www.socher.org')\n",
      "('.', 'www.socher.org', '.')\n",
      "('www.socher.org', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2020-08-17')\n",
      "('Retrieved', '2020-08-17', '.')\n",
      "('2020-08-17', '.', 'This')\n",
      "('.', 'This', 'was')\n",
      "('This', 'was', 'an')\n",
      "('was', 'an', 'early')\n",
      "('an', 'early', 'Deep')\n",
      "('early', 'Deep', 'Learning')\n",
      "('Deep', 'Learning', 'tutorial')\n",
      "('Learning', 'tutorial', 'at')\n",
      "('tutorial', 'at', 'the')\n",
      "('at', 'the', 'ACL')\n",
      "('the', 'ACL', '2012')\n",
      "('ACL', '2012', 'and')\n",
      "('2012', 'and', 'met')\n",
      "('and', 'met', 'with')\n",
      "('met', 'with', 'both')\n",
      "('with', 'both', 'interest')\n",
      "('both', 'interest', 'and')\n",
      "('interest', 'and', '(at')\n",
      "('and', '(at', 'the')\n",
      "('(at', 'the', 'time)')\n",
      "('the', 'time)', 'skepticism')\n",
      "('time)', 'skepticism', 'by')\n",
      "('skepticism', 'by', 'most')\n",
      "('by', 'most', 'participants.')\n",
      "('most', 'participants.', 'Until')\n",
      "('participants.', 'Until', 'then,')\n",
      "('Until', 'then,', 'neural')\n",
      "('then,', 'neural', 'learning')\n",
      "('neural', 'learning', 'was')\n",
      "('learning', 'was', 'basically')\n",
      "('was', 'basically', 'rejected')\n",
      "('basically', 'rejected', 'because')\n",
      "('rejected', 'because', 'of')\n",
      "('because', 'of', 'its')\n",
      "('of', 'its', 'lack')\n",
      "('its', 'lack', 'of')\n",
      "('lack', 'of', 'statistical')\n",
      "('of', 'statistical', 'interpretability.')\n",
      "('statistical', 'interpretability.', 'Until')\n",
      "('interpretability.', 'Until', '2015,')\n",
      "('Until', '2015,', 'deep')\n",
      "('2015,', 'deep', 'learning')\n",
      "('deep', 'learning', 'had')\n",
      "('learning', 'had', 'evolved')\n",
      "('had', 'evolved', 'into')\n",
      "('evolved', 'into', 'the')\n",
      "('into', 'the', 'major')\n",
      "('the', 'major', 'framework')\n",
      "('major', 'framework', 'of')\n",
      "('framework', 'of', 'NLP.')\n",
      "('of', 'NLP.', '^')\n",
      "('NLP.', '^', 'Annamoradnejad,')\n",
      "('^', 'Annamoradnejad,', 'I.')\n",
      "('Annamoradnejad,', 'I.', 'and')\n",
      "('I.', 'and', 'Zoghi,')\n",
      "('and', 'Zoghi,', 'G.')\n",
      "('Zoghi,', 'G.', '(2020).')\n",
      "('G.', '(2020).', 'Colbert:')\n",
      "('(2020).', 'Colbert:', 'Using')\n",
      "('Colbert:', 'Using', 'bert')\n",
      "('Using', 'bert', 'sentence')\n",
      "('bert', 'sentence', 'embedding')\n",
      "('sentence', 'embedding', 'for')\n",
      "('embedding', 'for', 'humor')\n",
      "('for', 'humor', 'detection')\n",
      "('humor', 'detection', '.')\n",
      "('detection', '.', 'arXiv')\n",
      "('.', 'arXiv', 'preprint')\n",
      "('arXiv', 'preprint', 'arXiv:2004.12765.')\n",
      "('preprint', 'arXiv:2004.12765.', '^')\n",
      "('arXiv:2004.12765.', '^', 'Yi,')\n",
      "('^', 'Yi,', 'Chucai;')\n",
      "('Yi,', 'Chucai;', 'Tian,')\n",
      "('Chucai;', 'Tian,', 'Yingli')\n",
      "('Tian,', 'Yingli', '(2012),')\n",
      "('Yingli', '(2012),', '\"Assistive')\n",
      "('(2012),', '\"Assistive', 'Text')\n",
      "('\"Assistive', 'Text', 'Reading')\n",
      "('Text', 'Reading', 'from')\n",
      "('Reading', 'from', 'Complex')\n",
      "('from', 'Complex', 'Background')\n",
      "('Complex', 'Background', 'for')\n",
      "('Background', 'for', 'Blind')\n",
      "('for', 'Blind', 'Persons\",')\n",
      "('Blind', 'Persons\",', 'Camera-Based')\n",
      "('Persons\",', 'Camera-Based', 'Document')\n",
      "('Camera-Based', 'Document', 'Analysis')\n",
      "('Document', 'Analysis', 'and')\n",
      "('Analysis', 'and', 'Recognition')\n",
      "('and', 'Recognition', ',')\n",
      "('Recognition', ',', 'Springer')\n",
      "(',', 'Springer', 'Berlin')\n",
      "('Springer', 'Berlin', 'Heidelberg,')\n",
      "('Berlin', 'Heidelberg,', 'pp.')\n",
      "('Heidelberg,', 'pp.', '15–28,')\n",
      "('pp.', '15–28,', 'CiteSeerX')\n",
      "('15–28,', 'CiteSeerX', '10.1.1.668.869')\n",
      "('CiteSeerX', '10.1.1.668.869', ',')\n",
      "('10.1.1.668.869', ',', 'doi')\n",
      "(',', 'doi', ':')\n",
      "('doi', ':', '10.1007/978-3-642-29364-1_2')\n",
      "(':', '10.1007/978-3-642-29364-1_2', ',')\n",
      "('10.1007/978-3-642-29364-1_2', ',', 'ISBN')\n",
      "(',', 'ISBN', '9783642293634')\n",
      "('ISBN', '9783642293634', '^')\n",
      "('9783642293634', '^', '\"What')\n",
      "('^', '\"What', 'is')\n",
      "('\"What', 'is', 'Natural')\n",
      "('is', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing?')\n",
      "('Language', 'Processing?', 'Intro')\n",
      "('Processing?', 'Intro', 'to')\n",
      "('Intro', 'to', 'NLP')\n",
      "('to', 'NLP', 'in')\n",
      "('NLP', 'in', 'Machine')\n",
      "('in', 'Machine', 'Learning\"')\n",
      "('Machine', 'Learning\"', '.')\n",
      "('Learning\"', '.', 'GyanSetu!')\n",
      "('.', 'GyanSetu!', '.')\n",
      "('GyanSetu!', '.', '2020-12-06')\n",
      "('.', '2020-12-06', '.')\n",
      "('2020-12-06', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-09')\n",
      "('Retrieved', '2021-01-09', '.')\n",
      "('2021-01-09', '.', '^')\n",
      "('.', '^', 'Kishorjit,')\n",
      "('^', 'Kishorjit,', 'N.;')\n",
      "('Kishorjit,', 'N.;', 'Vidya,')\n",
      "('N.;', 'Vidya,', 'Raj')\n",
      "('Vidya,', 'Raj', 'RK.;')\n",
      "('Raj', 'RK.;', 'Nirmal,')\n",
      "('RK.;', 'Nirmal,', 'Y.;')\n",
      "('Nirmal,', 'Y.;', 'Sivaji,')\n",
      "('Y.;', 'Sivaji,', 'B.')\n",
      "('Sivaji,', 'B.', '(2012).')\n",
      "('B.', '(2012).', '\"Manipuri')\n",
      "('(2012).', '\"Manipuri', 'Morpheme')\n",
      "('\"Manipuri', 'Morpheme', 'Identification\"')\n",
      "('Morpheme', 'Identification\"', '(PDF)')\n",
      "('Identification\"', '(PDF)', '.')\n",
      "('(PDF)', '.', 'Proceedings')\n",
      "('.', 'Proceedings', 'of')\n",
      "('Proceedings', 'of', 'the')\n",
      "('of', 'the', '3rd')\n",
      "('the', '3rd', 'Workshop')\n",
      "('3rd', 'Workshop', 'on')\n",
      "('Workshop', 'on', 'South')\n",
      "('on', 'South', 'and')\n",
      "('South', 'and', 'Southeast')\n",
      "('and', 'Southeast', 'Asian')\n",
      "('Southeast', 'Asian', 'Natural')\n",
      "('Asian', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', '(SANLP)')\n",
      "('Processing', '(SANLP)', '.')\n",
      "('(SANLP)', '.', 'COLING')\n",
      "('.', 'COLING', '2012,')\n",
      "('COLING', '2012,', 'Mumbai,')\n",
      "('2012,', 'Mumbai,', 'December')\n",
      "('Mumbai,', 'December', '2012:')\n",
      "('December', '2012:', '95–108.')\n",
      "('2012:', '95–108.', 'CS1')\n",
      "('95–108.', 'CS1', 'maint:')\n",
      "('CS1', 'maint:', 'location')\n",
      "('maint:', 'location', '(')\n",
      "('location', '(', 'link')\n",
      "('(', 'link', ')')\n",
      "('link', ')', '^')\n",
      "(')', '^', 'Klein,')\n",
      "('^', 'Klein,', 'Dan;')\n",
      "('Klein,', 'Dan;', 'Manning,')\n",
      "('Dan;', 'Manning,', 'Christopher')\n",
      "('Manning,', 'Christopher', 'D.')\n",
      "('Christopher', 'D.', '(2002).')\n",
      "('D.', '(2002).', '\"Natural')\n",
      "('(2002).', '\"Natural', 'language')\n",
      "('\"Natural', 'language', 'grammar')\n",
      "('language', 'grammar', 'induction')\n",
      "('grammar', 'induction', 'using')\n",
      "('induction', 'using', 'a')\n",
      "('using', 'a', 'constituent-context')\n",
      "('a', 'constituent-context', 'model\"')\n",
      "('constituent-context', 'model\"', '(PDF)')\n",
      "('model\"', '(PDF)', '.')\n",
      "('(PDF)', '.', 'Advances')\n",
      "('.', 'Advances', 'in')\n",
      "('Advances', 'in', 'Neural')\n",
      "('in', 'Neural', 'Information')\n",
      "('Neural', 'Information', 'Processing')\n",
      "('Information', 'Processing', 'Systems')\n",
      "('Processing', 'Systems', '.')\n",
      "('Systems', '.', '^')\n",
      "('.', '^', 'PASCAL')\n",
      "('^', 'PASCAL', 'Recognizing')\n",
      "('PASCAL', 'Recognizing', 'Textual')\n",
      "('Recognizing', 'Textual', 'Entailment')\n",
      "('Textual', 'Entailment', 'Challenge')\n",
      "('Entailment', 'Challenge', '(RTE-7)')\n",
      "('Challenge', '(RTE-7)', 'https://tac.nist.gov//2011/RTE/')\n",
      "('(RTE-7)', 'https://tac.nist.gov//2011/RTE/', '^')\n",
      "('https://tac.nist.gov//2011/RTE/', '^', 'Lippi,')\n",
      "('^', 'Lippi,', 'Marco;')\n",
      "('Lippi,', 'Marco;', 'Torroni,')\n",
      "('Marco;', 'Torroni,', 'Paolo')\n",
      "('Torroni,', 'Paolo', '(2016-04-20).')\n",
      "('Paolo', '(2016-04-20).', '\"Argumentation')\n",
      "('(2016-04-20).', '\"Argumentation', 'Mining:')\n",
      "('\"Argumentation', 'Mining:', 'State')\n",
      "('Mining:', 'State', 'of')\n",
      "('State', 'of', 'the')\n",
      "('of', 'the', 'Art')\n",
      "('the', 'Art', 'and')\n",
      "('Art', 'and', 'Emerging')\n",
      "('and', 'Emerging', 'Trends\"')\n",
      "('Emerging', 'Trends\"', '.')\n",
      "('Trends\"', '.', 'ACM')\n",
      "('.', 'ACM', 'Transactions')\n",
      "('ACM', 'Transactions', 'on')\n",
      "('Transactions', 'on', 'Internet')\n",
      "('on', 'Internet', 'Technology')\n",
      "('Internet', 'Technology', '.')\n",
      "('Technology', '.', '16')\n",
      "('.', '16', '(2):')\n",
      "('16', '(2):', '1–25.')\n",
      "('(2):', '1–25.', 'doi')\n",
      "('1–25.', 'doi', ':')\n",
      "('doi', ':', '10.1145/2850417')\n",
      "(':', '10.1145/2850417', '.')\n",
      "('10.1145/2850417', '.', 'ISSN')\n",
      "('.', 'ISSN', '1533-5399')\n",
      "('ISSN', '1533-5399', '.')\n",
      "('1533-5399', '.', 'S2CID')\n",
      "('.', 'S2CID', '9561587')\n",
      "('S2CID', '9561587', '.')\n",
      "('9561587', '.', '^')\n",
      "('.', '^', '\"Argument')\n",
      "('^', '\"Argument', 'Mining')\n",
      "('\"Argument', 'Mining', '-')\n",
      "('Mining', '-', 'IJCAI2016')\n",
      "('-', 'IJCAI2016', 'Tutorial\"')\n",
      "('IJCAI2016', 'Tutorial\"', '.')\n",
      "('Tutorial\"', '.', 'www.i3s.unice.fr')\n",
      "('.', 'www.i3s.unice.fr', '.')\n",
      "('www.i3s.unice.fr', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-03-09')\n",
      "('Retrieved', '2021-03-09', '.')\n",
      "('2021-03-09', '.', '^')\n",
      "('.', '^', '\"NLP')\n",
      "('^', '\"NLP', 'Approaches')\n",
      "('\"NLP', 'Approaches', 'to')\n",
      "('Approaches', 'to', 'Computational')\n",
      "('to', 'Computational', 'Argumentation')\n",
      "('Computational', 'Argumentation', '–')\n",
      "('Argumentation', '–', 'ACL')\n",
      "('–', 'ACL', '2016,')\n",
      "('ACL', '2016,', 'Berlin\"')\n",
      "('2016,', 'Berlin\"', '.')\n",
      "('Berlin\"', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-03-09')\n",
      "('Retrieved', '2021-03-09', '.')\n",
      "('2021-03-09', '.', '^')\n",
      "('.', '^', '\"U')\n",
      "('^', '\"U', 'B')\n",
      "('\"U', 'B', 'U')\n",
      "('B', 'U', 'W')\n",
      "('U', 'W', 'E')\n",
      "('W', 'E', 'B')\n",
      "('E', 'B', '::')\n",
      "('B', '::', 'Racter\"')\n",
      "('::', 'Racter\"', '.')\n",
      "('Racter\"', '.', 'www.ubu.com')\n",
      "('.', 'www.ubu.com', '.')\n",
      "('www.ubu.com', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2020-08-17')\n",
      "('Retrieved', '2020-08-17', '.')\n",
      "('2020-08-17', '.', '^')\n",
      "('.', '^', 'Writer,')\n",
      "('^', 'Writer,', 'Beta')\n",
      "('Writer,', 'Beta', '(2019).')\n",
      "('Beta', '(2019).', 'Lithium-Ion')\n",
      "('(2019).', 'Lithium-Ion', 'Batteries')\n",
      "('Lithium-Ion', 'Batteries', '.')\n",
      "('Batteries', '.', 'doi')\n",
      "('.', 'doi', ':')\n",
      "('doi', ':', '10.1007/978-3-030-16800-1')\n",
      "(':', '10.1007/978-3-030-16800-1', '.')\n",
      "('10.1007/978-3-030-16800-1', '.', 'ISBN')\n",
      "('.', 'ISBN', '978-3-030-16799-8')\n",
      "('ISBN', '978-3-030-16799-8', '.')\n",
      "('978-3-030-16799-8', '.', '^')\n",
      "('.', '^', '\"Document')\n",
      "('^', '\"Document', 'Understanding')\n",
      "('\"Document', 'Understanding', 'AI')\n",
      "('Understanding', 'AI', 'on')\n",
      "('AI', 'on', 'Google')\n",
      "('on', 'Google', 'Cloud')\n",
      "('Google', 'Cloud', '(Cloud')\n",
      "('Cloud', '(Cloud', 'Next')\n",
      "('(Cloud', 'Next', \"'19)\")\n",
      "('Next', \"'19)\", '-')\n",
      "(\"'19)\", '-', 'YouTube\"')\n",
      "('-', 'YouTube\"', '.')\n",
      "('YouTube\"', '.', 'www.youtube.com')\n",
      "('.', 'www.youtube.com', '.')\n",
      "('www.youtube.com', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', 'Administration.')\n",
      "('^', 'Administration.', '\"Centre')\n",
      "('Administration.', '\"Centre', 'for')\n",
      "('\"Centre', 'for', 'Language')\n",
      "('for', 'Language', 'Technology')\n",
      "('Language', 'Technology', '(CLT)\"')\n",
      "('Technology', '(CLT)\"', '.')\n",
      "('(CLT)\"', '.', 'Macquarie')\n",
      "('.', 'Macquarie', 'University')\n",
      "('Macquarie', 'University', '.')\n",
      "('University', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', '\"Shared')\n",
      "('^', '\"Shared', 'Task:')\n",
      "('\"Shared', 'Task:', 'Grammatical')\n",
      "('Task:', 'Grammatical', 'Error')\n",
      "('Grammatical', 'Error', 'Correction\"')\n",
      "('Error', 'Correction\"', '.')\n",
      "('Correction\"', '.', 'www.comp.nus.edu.sg')\n",
      "('.', 'www.comp.nus.edu.sg', '.')\n",
      "('www.comp.nus.edu.sg', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', '\"Shared')\n",
      "('^', '\"Shared', 'Task:')\n",
      "('\"Shared', 'Task:', 'Grammatical')\n",
      "('Task:', 'Grammatical', 'Error')\n",
      "('Grammatical', 'Error', 'Correction\"')\n",
      "('Error', 'Correction\"', '.')\n",
      "('Correction\"', '.', 'www.comp.nus.edu.sg')\n",
      "('.', 'www.comp.nus.edu.sg', '.')\n",
      "('www.comp.nus.edu.sg', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', 'Duan,')\n",
      "('^', 'Duan,', 'Yucong;')\n",
      "('Duan,', 'Yucong;', 'Cruz,')\n",
      "('Yucong;', 'Cruz,', 'Christophe')\n",
      "('Cruz,', 'Christophe', '(2011).')\n",
      "('Christophe', '(2011).', '\"Formalizing')\n",
      "('(2011).', '\"Formalizing', 'Semantic')\n",
      "('\"Formalizing', 'Semantic', 'of')\n",
      "('Semantic', 'of', 'Natural')\n",
      "('of', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'through')\n",
      "('Language', 'through', 'Conceptualization')\n",
      "('through', 'Conceptualization', 'from')\n",
      "('Conceptualization', 'from', 'Existence\"')\n",
      "('from', 'Existence\"', '.')\n",
      "('Existence\"', '.', 'International')\n",
      "('.', 'International', 'Journal')\n",
      "('International', 'Journal', 'of')\n",
      "('Journal', 'of', 'Innovation,')\n",
      "('of', 'Innovation,', 'Management')\n",
      "('Innovation,', 'Management', 'and')\n",
      "('Management', 'and', 'Technology')\n",
      "('and', 'Technology', '.')\n",
      "('Technology', '.', '2')\n",
      "('.', '2', '(1):')\n",
      "('2', '(1):', '37–42.')\n",
      "('(1):', '37–42.', 'Archived')\n",
      "('37–42.', 'Archived', 'from')\n",
      "('Archived', 'from', 'the')\n",
      "('from', 'the', 'original')\n",
      "('the', 'original', 'on')\n",
      "('original', 'on', '2011-10-09.')\n",
      "('on', '2011-10-09.', '^')\n",
      "('2011-10-09.', '^', '\"Previous')\n",
      "('^', '\"Previous', 'shared')\n",
      "('\"Previous', 'shared', 'tasks')\n",
      "('shared', 'tasks', '|')\n",
      "('tasks', '|', 'CoNLL\"')\n",
      "('|', 'CoNLL\"', '.')\n",
      "('CoNLL\"', '.', 'www.conll.org')\n",
      "('.', 'www.conll.org', '.')\n",
      "('www.conll.org', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', '\"Cognition\"')\n",
      "('^', '\"Cognition\"', '.')\n",
      "('\"Cognition\"', '.', 'Lexico')\n",
      "('.', 'Lexico', '.')\n",
      "('Lexico', '.', 'Oxford')\n",
      "('.', 'Oxford', 'University')\n",
      "('Oxford', 'University', 'Press')\n",
      "('University', 'Press', 'and')\n",
      "('Press', 'and', 'Dictionary.com')\n",
      "('and', 'Dictionary.com', '.')\n",
      "('Dictionary.com', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '6')\n",
      "('Retrieved', '6', 'May')\n",
      "('6', 'May', '2020')\n",
      "('May', '2020', '.')\n",
      "('2020', '.', '^')\n",
      "('.', '^', '\"Ask')\n",
      "('^', '\"Ask', 'the')\n",
      "('\"Ask', 'the', 'Cognitive')\n",
      "('the', 'Cognitive', 'Scientist\"')\n",
      "('Cognitive', 'Scientist\"', '.')\n",
      "('Scientist\"', '.', 'American')\n",
      "('.', 'American', 'Federation')\n",
      "('American', 'Federation', 'of')\n",
      "('Federation', 'of', 'Teachers')\n",
      "('of', 'Teachers', '.')\n",
      "('Teachers', '.', '8')\n",
      "('.', '8', 'August')\n",
      "('8', 'August', '2014.')\n",
      "('August', '2014.', 'Cognitive')\n",
      "('2014.', 'Cognitive', 'science')\n",
      "('Cognitive', 'science', 'is')\n",
      "('science', 'is', 'an')\n",
      "('is', 'an', 'interdisciplinary')\n",
      "('an', 'interdisciplinary', 'field')\n",
      "('interdisciplinary', 'field', 'of')\n",
      "('field', 'of', 'researchers')\n",
      "('of', 'researchers', 'from')\n",
      "('researchers', 'from', 'Linguistics,')\n",
      "('from', 'Linguistics,', 'psychology,')\n",
      "('Linguistics,', 'psychology,', 'neuroscience,')\n",
      "('psychology,', 'neuroscience,', 'philosophy,')\n",
      "('neuroscience,', 'philosophy,', 'computer')\n",
      "('philosophy,', 'computer', 'science,')\n",
      "('computer', 'science,', 'and')\n",
      "('science,', 'and', 'anthropology')\n",
      "('and', 'anthropology', 'that')\n",
      "('anthropology', 'that', 'seek')\n",
      "('that', 'seek', 'to')\n",
      "('seek', 'to', 'understand')\n",
      "('to', 'understand', 'the')\n",
      "('understand', 'the', 'mind.')\n",
      "('the', 'mind.', '^')\n",
      "('mind.', '^', 'Robinson,')\n",
      "('^', 'Robinson,', 'Peter')\n",
      "('Robinson,', 'Peter', '(2008).')\n",
      "('Peter', '(2008).', 'Handbook')\n",
      "('(2008).', 'Handbook', 'of')\n",
      "('Handbook', 'of', 'Cognitive')\n",
      "('of', 'Cognitive', 'Linguistics')\n",
      "('Cognitive', 'Linguistics', 'and')\n",
      "('Linguistics', 'and', 'Second')\n",
      "('and', 'Second', 'Language')\n",
      "('Second', 'Language', 'Acquisition')\n",
      "('Language', 'Acquisition', '.')\n",
      "('Acquisition', '.', 'Routledge.')\n",
      "('.', 'Routledge.', 'pp.')\n",
      "('Routledge.', 'pp.', '3–8.')\n",
      "('pp.', '3–8.', 'ISBN')\n",
      "('3–8.', 'ISBN', '978-0-805-85352-0')\n",
      "('ISBN', '978-0-805-85352-0', '.')\n",
      "('978-0-805-85352-0', '.', '^')\n",
      "('.', '^', 'Lakoff,')\n",
      "('^', 'Lakoff,', 'George')\n",
      "('Lakoff,', 'George', '(1999).')\n",
      "('George', '(1999).', 'Philosophy')\n",
      "('(1999).', 'Philosophy', 'in')\n",
      "('Philosophy', 'in', 'the')\n",
      "('in', 'the', 'Flesh:')\n",
      "('the', 'Flesh:', 'The')\n",
      "('Flesh:', 'The', 'Embodied')\n",
      "('The', 'Embodied', 'Mind')\n",
      "('Embodied', 'Mind', 'and')\n",
      "('Mind', 'and', 'Its')\n",
      "('and', 'Its', 'Challenge')\n",
      "('Its', 'Challenge', 'to')\n",
      "('Challenge', 'to', 'Western')\n",
      "('to', 'Western', 'Philosophy;')\n",
      "('Western', 'Philosophy;', 'Appendix:')\n",
      "('Philosophy;', 'Appendix:', 'The')\n",
      "('Appendix:', 'The', 'Neural')\n",
      "('The', 'Neural', 'Theory')\n",
      "('Neural', 'Theory', 'of')\n",
      "('Theory', 'of', 'Language')\n",
      "('of', 'Language', 'Paradigm')\n",
      "('Language', 'Paradigm', '.')\n",
      "('Paradigm', '.', 'New')\n",
      "('.', 'New', 'York')\n",
      "('New', 'York', 'Basic')\n",
      "('York', 'Basic', 'Books.')\n",
      "('Basic', 'Books.', 'pp.')\n",
      "('Books.', 'pp.', '569–583.')\n",
      "('pp.', '569–583.', 'ISBN')\n",
      "('569–583.', 'ISBN', '978-0-465-05674-3')\n",
      "('ISBN', '978-0-465-05674-3', '.')\n",
      "('978-0-465-05674-3', '.', '^')\n",
      "('.', '^', 'Strauss,')\n",
      "('^', 'Strauss,', 'Claudia')\n",
      "('Strauss,', 'Claudia', '(1999).')\n",
      "('Claudia', '(1999).', 'A')\n",
      "('(1999).', 'A', 'Cognitive')\n",
      "('A', 'Cognitive', 'Theory')\n",
      "('Cognitive', 'Theory', 'of')\n",
      "('Theory', 'of', 'Cultural')\n",
      "('of', 'Cultural', 'Meaning')\n",
      "('Cultural', 'Meaning', '.')\n",
      "('Meaning', '.', 'Cambridge')\n",
      "('.', 'Cambridge', 'University')\n",
      "('Cambridge', 'University', 'Press.')\n",
      "('University', 'Press.', 'pp.')\n",
      "('Press.', 'pp.', '156–164.')\n",
      "('pp.', '156–164.', 'ISBN')\n",
      "('156–164.', 'ISBN', '978-0-521-59541-4')\n",
      "('ISBN', '978-0-521-59541-4', '.')\n",
      "('978-0-521-59541-4', '.', '^')\n",
      "('.', '^', '\"Universal')\n",
      "('^', '\"Universal', 'Conceptual')\n",
      "('\"Universal', 'Conceptual', 'Cognitive')\n",
      "('Conceptual', 'Cognitive', 'Annotation')\n",
      "('Cognitive', 'Annotation', '(UCCA)\"')\n",
      "('Annotation', '(UCCA)\"', '.')\n",
      "('(UCCA)\"', '.', 'Universal')\n",
      "('.', 'Universal', 'Conceptual')\n",
      "('Universal', 'Conceptual', 'Cognitive')\n",
      "('Conceptual', 'Cognitive', 'Annotation')\n",
      "('Cognitive', 'Annotation', '(UCCA)')\n",
      "('Annotation', '(UCCA)', '.')\n",
      "('(UCCA)', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', 'Rodríguez,')\n",
      "('^', 'Rodríguez,', 'F.')\n",
      "('Rodríguez,', 'F.', 'C.,')\n",
      "('F.', 'C.,', '&')\n",
      "('C.,', '&', 'Mairal-Usón,')\n",
      "('&', 'Mairal-Usón,', 'R.')\n",
      "('Mairal-Usón,', 'R.', '(2016).')\n",
      "('R.', '(2016).', 'Building')\n",
      "('(2016).', 'Building', 'an')\n",
      "('Building', 'an', 'RRG')\n",
      "('an', 'RRG', 'computational')\n",
      "('RRG', 'computational', 'grammar')\n",
      "('computational', 'grammar', '.')\n",
      "('grammar', '.', 'Onomazein')\n",
      "('.', 'Onomazein', ',')\n",
      "('Onomazein', ',', '(34),')\n",
      "(',', '(34),', '86-117.')\n",
      "('(34),', '86-117.', '^')\n",
      "('86-117.', '^', '\"Fluid')\n",
      "('^', '\"Fluid', 'Construction')\n",
      "('\"Fluid', 'Construction', 'Grammar')\n",
      "('Construction', 'Grammar', '–')\n",
      "('Grammar', '–', 'A')\n",
      "('–', 'A', 'fully')\n",
      "('A', 'fully', 'operational')\n",
      "('fully', 'operational', 'processing')\n",
      "('operational', 'processing', 'system')\n",
      "('processing', 'system', 'for')\n",
      "('system', 'for', 'construction')\n",
      "('for', 'construction', 'grammars\"')\n",
      "('construction', 'grammars\"', '.')\n",
      "('grammars\"', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', '\"ACL')\n",
      "('^', '\"ACL', 'Member')\n",
      "('\"ACL', 'Member', 'Portal')\n",
      "('Member', 'Portal', '|')\n",
      "('Portal', '|', 'The')\n",
      "('|', 'The', 'Association')\n",
      "('The', 'Association', 'for')\n",
      "('Association', 'for', 'Computational')\n",
      "('for', 'Computational', 'Linguistics')\n",
      "('Computational', 'Linguistics', 'Member')\n",
      "('Linguistics', 'Member', 'Portal\"')\n",
      "('Member', 'Portal\"', '.')\n",
      "('Portal\"', '.', 'www.aclweb.org')\n",
      "('.', 'www.aclweb.org', '.')\n",
      "('www.aclweb.org', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', '\"Chunks')\n",
      "('^', '\"Chunks', 'and')\n",
      "('\"Chunks', 'and', 'Rules\"')\n",
      "('and', 'Rules\"', '.')\n",
      "('Rules\"', '.', 'www.w3.org')\n",
      "('.', 'www.w3.org', '.')\n",
      "('www.w3.org', '.', 'Retrieved')\n",
      "('.', 'Retrieved', '2021-01-11')\n",
      "('Retrieved', '2021-01-11', '.')\n",
      "('2021-01-11', '.', '^')\n",
      "('.', '^', 'Socher,')\n",
      "('^', 'Socher,', 'Richard;')\n",
      "('Socher,', 'Richard;', 'Karpathy,')\n",
      "('Richard;', 'Karpathy,', 'Andrej;')\n",
      "('Karpathy,', 'Andrej;', 'Le,')\n",
      "('Andrej;', 'Le,', 'Quoc')\n",
      "('Le,', 'Quoc', 'V.;')\n",
      "('Quoc', 'V.;', 'Manning,')\n",
      "('V.;', 'Manning,', 'Christopher')\n",
      "('Manning,', 'Christopher', 'D.;')\n",
      "('Christopher', 'D.;', 'Ng,')\n",
      "('D.;', 'Ng,', 'Andrew')\n",
      "('Ng,', 'Andrew', 'Y.')\n",
      "('Andrew', 'Y.', '(2014).')\n",
      "('Y.', '(2014).', '\"Grounded')\n",
      "('(2014).', '\"Grounded', 'Compositional')\n",
      "('\"Grounded', 'Compositional', 'Semantics')\n",
      "('Compositional', 'Semantics', 'for')\n",
      "('Semantics', 'for', 'Finding')\n",
      "('for', 'Finding', 'and')\n",
      "('Finding', 'and', 'Describing')\n",
      "('and', 'Describing', 'Images')\n",
      "('Describing', 'Images', 'with')\n",
      "('Images', 'with', 'Sentences\"')\n",
      "('with', 'Sentences\"', '.')\n",
      "('Sentences\"', '.', 'Transactions')\n",
      "('.', 'Transactions', 'of')\n",
      "('Transactions', 'of', 'the')\n",
      "('of', 'the', 'Association')\n",
      "('the', 'Association', 'for')\n",
      "('Association', 'for', 'Computational')\n",
      "('for', 'Computational', 'Linguistics')\n",
      "('Computational', 'Linguistics', '.')\n",
      "('Linguistics', '.', '2')\n",
      "('.', '2', ':')\n",
      "('2', ':', '207–218.')\n",
      "(':', '207–218.', 'doi')\n",
      "('207–218.', 'doi', ':')\n",
      "('doi', ':', '10.1162/tacl_a_00177')\n",
      "(':', '10.1162/tacl_a_00177', '.')\n",
      "('10.1162/tacl_a_00177', '.', 'S2CID')\n",
      "('.', 'S2CID', '2317858')\n",
      "('S2CID', '2317858', '.')\n",
      "('2317858', '.', 'Further')\n",
      "('.', 'Further', 'reading')\n",
      "('Further', 'reading', '[')\n",
      "('reading', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Bates,')\n",
      "(']', 'Bates,', 'M')\n",
      "('Bates,', 'M', '(1995).')\n",
      "('M', '(1995).', '\"Models')\n",
      "('(1995).', '\"Models', 'of')\n",
      "('\"Models', 'of', 'natural')\n",
      "('of', 'natural', 'language')\n",
      "('natural', 'language', 'understanding\"')\n",
      "('language', 'understanding\"', '.')\n",
      "('understanding\"', '.', 'Proceedings')\n",
      "('.', 'Proceedings', 'of')\n",
      "('Proceedings', 'of', 'the')\n",
      "('of', 'the', 'National')\n",
      "('the', 'National', 'Academy')\n",
      "('National', 'Academy', 'of')\n",
      "('Academy', 'of', 'Sciences')\n",
      "('of', 'Sciences', 'of')\n",
      "('Sciences', 'of', 'the')\n",
      "('of', 'the', 'United')\n",
      "('the', 'United', 'States')\n",
      "('United', 'States', 'of')\n",
      "('States', 'of', 'America')\n",
      "('of', 'America', '.')\n",
      "('America', '.', '92')\n",
      "('.', '92', '(22):')\n",
      "('92', '(22):', '9977–9982.')\n",
      "('(22):', '9977–9982.', 'Bibcode')\n",
      "('9977–9982.', 'Bibcode', ':')\n",
      "('Bibcode', ':', '1995PNAS...92.9977B')\n",
      "(':', '1995PNAS...92.9977B', '.')\n",
      "('1995PNAS...92.9977B', '.', 'doi')\n",
      "('.', 'doi', ':')\n",
      "('doi', ':', '10.1073/pnas.92.22.9977')\n",
      "(':', '10.1073/pnas.92.22.9977', '.')\n",
      "('10.1073/pnas.92.22.9977', '.', 'PMC')\n",
      "('.', 'PMC', '40721')\n",
      "('PMC', '40721', '.')\n",
      "('40721', '.', 'PMID')\n",
      "('.', 'PMID', '7479812')\n",
      "('PMID', '7479812', '.')\n",
      "('7479812', '.', 'Steven')\n",
      "('.', 'Steven', 'Bird,')\n",
      "('Steven', 'Bird,', 'Ewan')\n",
      "('Bird,', 'Ewan', 'Klein,')\n",
      "('Ewan', 'Klein,', 'and')\n",
      "('Klein,', 'and', 'Edward')\n",
      "('and', 'Edward', 'Loper')\n",
      "('Edward', 'Loper', '(2009).')\n",
      "('Loper', '(2009).', 'Natural')\n",
      "('(2009).', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', 'with')\n",
      "('Processing', 'with', 'Python')\n",
      "('with', 'Python', '.')\n",
      "('Python', '.', \"O'Reilly\")\n",
      "('.', \"O'Reilly\", 'Media.')\n",
      "(\"O'Reilly\", 'Media.', 'ISBN')\n",
      "('Media.', 'ISBN', '978-0-596-51649-9')\n",
      "('ISBN', '978-0-596-51649-9', '.')\n",
      "('978-0-596-51649-9', '.', 'Daniel')\n",
      "('.', 'Daniel', 'Jurafsky')\n",
      "('Daniel', 'Jurafsky', 'and')\n",
      "('Jurafsky', 'and', 'James')\n",
      "('and', 'James', 'H.')\n",
      "('James', 'H.', 'Martin')\n",
      "('H.', 'Martin', '(2008).')\n",
      "('Martin', '(2008).', 'Speech')\n",
      "('(2008).', 'Speech', 'and')\n",
      "('Speech', 'and', 'Language')\n",
      "('and', 'Language', 'Processing')\n",
      "('Language', 'Processing', ',')\n",
      "('Processing', ',', '2nd')\n",
      "(',', '2nd', 'edition.')\n",
      "('2nd', 'edition.', 'Pearson')\n",
      "('edition.', 'Pearson', 'Prentice')\n",
      "('Pearson', 'Prentice', 'Hall.')\n",
      "('Prentice', 'Hall.', 'ISBN')\n",
      "('Hall.', 'ISBN', '978-0-13-187321-6')\n",
      "('ISBN', '978-0-13-187321-6', '.')\n",
      "('978-0-13-187321-6', '.', 'Mohamed')\n",
      "('.', 'Mohamed', 'Zakaria')\n",
      "('Mohamed', 'Zakaria', 'Kurdi')\n",
      "('Zakaria', 'Kurdi', '(2016).')\n",
      "('Kurdi', '(2016).', 'Natural')\n",
      "('(2016).', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', 'and')\n",
      "('Processing', 'and', 'Computational')\n",
      "('and', 'Computational', 'Linguistics:')\n",
      "('Computational', 'Linguistics:', 'speech,')\n",
      "('Linguistics:', 'speech,', 'morphology,')\n",
      "('speech,', 'morphology,', 'and')\n",
      "('morphology,', 'and', 'syntax')\n",
      "('and', 'syntax', ',')\n",
      "('syntax', ',', 'Volume')\n",
      "(',', 'Volume', '1.')\n",
      "('Volume', '1.', 'ISTE-Wiley.')\n",
      "('1.', 'ISTE-Wiley.', 'ISBN')\n",
      "('ISTE-Wiley.', 'ISBN', '978-1848218482')\n",
      "('ISBN', '978-1848218482', '.')\n",
      "('978-1848218482', '.', 'Mohamed')\n",
      "('.', 'Mohamed', 'Zakaria')\n",
      "('Mohamed', 'Zakaria', 'Kurdi')\n",
      "('Zakaria', 'Kurdi', '(2017).')\n",
      "('Kurdi', '(2017).', 'Natural')\n",
      "('(2017).', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', 'and')\n",
      "('Processing', 'and', 'Computational')\n",
      "('and', 'Computational', 'Linguistics:')\n",
      "('Computational', 'Linguistics:', 'semantics,')\n",
      "('Linguistics:', 'semantics,', 'discourse,')\n",
      "('semantics,', 'discourse,', 'and')\n",
      "('discourse,', 'and', 'applications')\n",
      "('and', 'applications', ',')\n",
      "('applications', ',', 'Volume')\n",
      "(',', 'Volume', '2.')\n",
      "('Volume', '2.', 'ISTE-Wiley.')\n",
      "('2.', 'ISTE-Wiley.', 'ISBN')\n",
      "('ISTE-Wiley.', 'ISBN', '978-1848219212')\n",
      "('ISBN', '978-1848219212', '.')\n",
      "('978-1848219212', '.', 'Christopher')\n",
      "('.', 'Christopher', 'D.')\n",
      "('Christopher', 'D.', 'Manning,')\n",
      "('D.', 'Manning,', 'Prabhakar')\n",
      "('Manning,', 'Prabhakar', 'Raghavan,')\n",
      "('Prabhakar', 'Raghavan,', 'and')\n",
      "('Raghavan,', 'and', 'Hinrich')\n",
      "('and', 'Hinrich', 'Schütze')\n",
      "('Hinrich', 'Schütze', '(2008).')\n",
      "('Schütze', '(2008).', 'Introduction')\n",
      "('(2008).', 'Introduction', 'to')\n",
      "('Introduction', 'to', 'Information')\n",
      "('to', 'Information', 'Retrieval')\n",
      "('Information', 'Retrieval', '.')\n",
      "('Retrieval', '.', 'Cambridge')\n",
      "('.', 'Cambridge', 'University')\n",
      "('Cambridge', 'University', 'Press.')\n",
      "('University', 'Press.', 'ISBN')\n",
      "('Press.', 'ISBN', '978-0-521-86571-5')\n",
      "('ISBN', '978-0-521-86571-5', '.')\n",
      "('978-0-521-86571-5', '.', 'Official')\n",
      "('.', 'Official', 'html')\n",
      "('Official', 'html', 'and')\n",
      "('html', 'and', 'pdf')\n",
      "('and', 'pdf', 'versions')\n",
      "('pdf', 'versions', 'available')\n",
      "('versions', 'available', 'without')\n",
      "('available', 'without', 'charge.')\n",
      "('without', 'charge.', 'Christopher')\n",
      "('charge.', 'Christopher', 'D.')\n",
      "('Christopher', 'D.', 'Manning')\n",
      "('D.', 'Manning', 'and')\n",
      "('Manning', 'and', 'Hinrich')\n",
      "('and', 'Hinrich', 'Schütze')\n",
      "('Hinrich', 'Schütze', '(1999).')\n",
      "('Schütze', '(1999).', 'Foundations')\n",
      "('(1999).', 'Foundations', 'of')\n",
      "('Foundations', 'of', 'Statistical')\n",
      "('of', 'Statistical', 'Natural')\n",
      "('Statistical', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Processing')\n",
      "('Language', 'Processing', '.')\n",
      "('Processing', '.', 'The')\n",
      "('.', 'The', 'MIT')\n",
      "('The', 'MIT', 'Press.')\n",
      "('MIT', 'Press.', 'ISBN')\n",
      "('Press.', 'ISBN', '978-0-262-13360-9')\n",
      "('ISBN', '978-0-262-13360-9', '.')\n",
      "('978-0-262-13360-9', '.', 'David')\n",
      "('.', 'David', 'M.')\n",
      "('David', 'M.', 'W.')\n",
      "('M.', 'W.', 'Powers')\n",
      "('W.', 'Powers', 'and')\n",
      "('Powers', 'and', 'Christopher')\n",
      "('and', 'Christopher', 'C.')\n",
      "('Christopher', 'C.', 'R.')\n",
      "('C.', 'R.', 'Turk')\n",
      "('R.', 'Turk', '(1989).')\n",
      "('Turk', '(1989).', 'Machine')\n",
      "('(1989).', 'Machine', 'Learning')\n",
      "('Machine', 'Learning', 'of')\n",
      "('Learning', 'of', 'Natural')\n",
      "('of', 'Natural', 'Language')\n",
      "('Natural', 'Language', '.')\n",
      "('Language', '.', 'Springer-Verlag.')\n",
      "('.', 'Springer-Verlag.', 'ISBN')\n",
      "('Springer-Verlag.', 'ISBN', '978-0-387-19557-5')\n",
      "('ISBN', '978-0-387-19557-5', '.')\n",
      "('978-0-387-19557-5', '.', 'External')\n",
      "('.', 'External', 'link')\n",
      "('External', 'link', '[')\n",
      "('link', '[', 'edit')\n",
      "('[', 'edit', ']')\n",
      "('edit', ']', 'Media')\n",
      "(']', 'Media', 'related')\n",
      "('Media', 'related', 'to')\n",
      "('related', 'to', 'Natural')\n",
      "('to', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', 'at')\n",
      "('processing', 'at', 'Wikimedia')\n",
      "('at', 'Wikimedia', 'Commons')\n",
      "('Wikimedia', 'Commons', 'v')\n",
      "('Commons', 'v', 't')\n",
      "('v', 't', 'e')\n",
      "('t', 'e', 'Natural')\n",
      "('e', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', 'General')\n",
      "('processing', 'General', 'terms')\n",
      "('General', 'terms', 'AI-complete')\n",
      "('terms', 'AI-complete', 'Bag-of-words')\n",
      "('AI-complete', 'Bag-of-words', 'n-gram')\n",
      "('Bag-of-words', 'n-gram', 'Bigram')\n",
      "('n-gram', 'Bigram', 'Trigram')\n",
      "('Bigram', 'Trigram', 'Computational')\n",
      "('Trigram', 'Computational', 'linguistics')\n",
      "('Computational', 'linguistics', 'Natural-language')\n",
      "('linguistics', 'Natural-language', 'understanding')\n",
      "('Natural-language', 'understanding', 'Stopwords')\n",
      "('understanding', 'Stopwords', 'Text')\n",
      "('Stopwords', 'Text', 'processing')\n",
      "('Text', 'processing', 'Text')\n",
      "('processing', 'Text', 'analysis')\n",
      "('Text', 'analysis', 'Collocation')\n",
      "('analysis', 'Collocation', 'extraction')\n",
      "('Collocation', 'extraction', 'Concept')\n",
      "('extraction', 'Concept', 'mining')\n",
      "('Concept', 'mining', 'Coreference')\n",
      "('mining', 'Coreference', 'resolution')\n",
      "('Coreference', 'resolution', 'Deep')\n",
      "('resolution', 'Deep', 'linguistic')\n",
      "('Deep', 'linguistic', 'processing')\n",
      "('linguistic', 'processing', 'Distant')\n",
      "('processing', 'Distant', 'reading')\n",
      "('Distant', 'reading', 'Information')\n",
      "('reading', 'Information', 'extraction')\n",
      "('Information', 'extraction', 'Named-entity')\n",
      "('extraction', 'Named-entity', 'recognition')\n",
      "('Named-entity', 'recognition', 'Ontology')\n",
      "('recognition', 'Ontology', 'learning')\n",
      "('Ontology', 'learning', 'Parsing')\n",
      "('learning', 'Parsing', 'Part-of-speech')\n",
      "('Parsing', 'Part-of-speech', 'tagging')\n",
      "('Part-of-speech', 'tagging', 'Semantic')\n",
      "('tagging', 'Semantic', 'role')\n",
      "('Semantic', 'role', 'labeling')\n",
      "('role', 'labeling', 'Semantic')\n",
      "('labeling', 'Semantic', 'similarity')\n",
      "('Semantic', 'similarity', 'Sentiment')\n",
      "('similarity', 'Sentiment', 'analysis')\n",
      "('Sentiment', 'analysis', 'Terminology')\n",
      "('analysis', 'Terminology', 'extraction')\n",
      "('Terminology', 'extraction', 'Text')\n",
      "('extraction', 'Text', 'mining')\n",
      "('Text', 'mining', 'Textual')\n",
      "('mining', 'Textual', 'entailment')\n",
      "('Textual', 'entailment', 'Truecasing')\n",
      "('entailment', 'Truecasing', 'Word-sense')\n",
      "('Truecasing', 'Word-sense', 'disambiguation')\n",
      "('Word-sense', 'disambiguation', 'Word-sense')\n",
      "('disambiguation', 'Word-sense', 'induction')\n",
      "('Word-sense', 'induction', 'Text')\n",
      "('induction', 'Text', 'segmentation')\n",
      "('Text', 'segmentation', 'Compound-term')\n",
      "('segmentation', 'Compound-term', 'processing')\n",
      "('Compound-term', 'processing', 'Lemmatisation')\n",
      "('processing', 'Lemmatisation', 'Lexical')\n",
      "('Lemmatisation', 'Lexical', 'analysis')\n",
      "('Lexical', 'analysis', 'Text')\n",
      "('analysis', 'Text', 'chunking')\n",
      "('Text', 'chunking', 'Stemming')\n",
      "('chunking', 'Stemming', 'Sentence')\n",
      "('Stemming', 'Sentence', 'segmentation')\n",
      "('Sentence', 'segmentation', 'Word')\n",
      "('segmentation', 'Word', 'segmentation')\n",
      "('Word', 'segmentation', 'Automatic')\n",
      "('segmentation', 'Automatic', 'summarization')\n",
      "('Automatic', 'summarization', 'Multi-document')\n",
      "('summarization', 'Multi-document', 'summarization')\n",
      "('Multi-document', 'summarization', 'Sentence')\n",
      "('summarization', 'Sentence', 'extraction')\n",
      "('Sentence', 'extraction', 'Text')\n",
      "('extraction', 'Text', 'simplification')\n",
      "('Text', 'simplification', 'Machine')\n",
      "('simplification', 'Machine', 'translation')\n",
      "('Machine', 'translation', 'Computer-assisted')\n",
      "('translation', 'Computer-assisted', 'Example-based')\n",
      "('Computer-assisted', 'Example-based', 'Rule-based')\n",
      "('Example-based', 'Rule-based', 'Statistical')\n",
      "('Rule-based', 'Statistical', 'Transfer-based')\n",
      "('Statistical', 'Transfer-based', 'Neural')\n",
      "('Transfer-based', 'Neural', 'Distributional')\n",
      "('Neural', 'Distributional', 'semantics')\n",
      "('Distributional', 'semantics', 'models')\n",
      "('semantics', 'models', 'BERT')\n",
      "('models', 'BERT', 'Document-term')\n",
      "('BERT', 'Document-term', 'matrix')\n",
      "('Document-term', 'matrix', 'Explicit')\n",
      "('matrix', 'Explicit', 'semantic')\n",
      "('Explicit', 'semantic', 'analysis')\n",
      "('semantic', 'analysis', 'fastText')\n",
      "('analysis', 'fastText', 'GloVe')\n",
      "('fastText', 'GloVe', 'Latent')\n",
      "('GloVe', 'Latent', 'semantic')\n",
      "('Latent', 'semantic', 'analysis')\n",
      "('semantic', 'analysis', 'Word')\n",
      "('analysis', 'Word', 'embedding')\n",
      "('Word', 'embedding', 'Word2vec')\n",
      "('embedding', 'Word2vec', 'Language')\n",
      "('Word2vec', 'Language', 'resources')\n",
      "('Language', 'resources', ',')\n",
      "('resources', ',', 'datasets')\n",
      "(',', 'datasets', 'and')\n",
      "('datasets', 'and', 'corpora')\n",
      "('and', 'corpora', 'Types')\n",
      "('corpora', 'Types', 'and')\n",
      "('Types', 'and', 'standards')\n",
      "('and', 'standards', 'Corpus')\n",
      "('standards', 'Corpus', 'linguistics')\n",
      "('Corpus', 'linguistics', 'Lexical')\n",
      "('linguistics', 'Lexical', 'resource')\n",
      "('Lexical', 'resource', 'Linguistic')\n",
      "('resource', 'Linguistic', 'Linked')\n",
      "('Linguistic', 'Linked', 'Open')\n",
      "('Linked', 'Open', 'Data')\n",
      "('Open', 'Data', 'Machine-readable')\n",
      "('Data', 'Machine-readable', 'dictionary')\n",
      "('Machine-readable', 'dictionary', 'Parallel')\n",
      "('dictionary', 'Parallel', 'text')\n",
      "('Parallel', 'text', 'PropBank')\n",
      "('text', 'PropBank', 'Semantic')\n",
      "('PropBank', 'Semantic', 'network')\n",
      "('Semantic', 'network', 'Simple')\n",
      "('network', 'Simple', 'Knowledge')\n",
      "('Simple', 'Knowledge', 'Organization')\n",
      "('Knowledge', 'Organization', 'System')\n",
      "('Organization', 'System', 'Speech')\n",
      "('System', 'Speech', 'corpus')\n",
      "('Speech', 'corpus', 'Text')\n",
      "('corpus', 'Text', 'corpus')\n",
      "('Text', 'corpus', 'Thesaurus')\n",
      "('corpus', 'Thesaurus', '(information')\n",
      "('Thesaurus', '(information', 'retrieval)')\n",
      "('(information', 'retrieval)', 'Treebank')\n",
      "('retrieval)', 'Treebank', 'Universal')\n",
      "('Treebank', 'Universal', 'Dependencies')\n",
      "('Universal', 'Dependencies', 'Data')\n",
      "('Dependencies', 'Data', 'BabelNet')\n",
      "('Data', 'BabelNet', 'Bank')\n",
      "('BabelNet', 'Bank', 'of')\n",
      "('Bank', 'of', 'English')\n",
      "('of', 'English', 'DBpedia')\n",
      "('English', 'DBpedia', 'FrameNet')\n",
      "('DBpedia', 'FrameNet', 'Google')\n",
      "('FrameNet', 'Google', 'Ngram')\n",
      "('Google', 'Ngram', 'Viewer')\n",
      "('Ngram', 'Viewer', 'ThoughtTreasure')\n",
      "('Viewer', 'ThoughtTreasure', 'UBY')\n",
      "('ThoughtTreasure', 'UBY', 'WordNet')\n",
      "('UBY', 'WordNet', 'Automatic')\n",
      "('WordNet', 'Automatic', 'identification')\n",
      "('Automatic', 'identification', 'and')\n",
      "('identification', 'and', 'data')\n",
      "('and', 'data', 'capture')\n",
      "('data', 'capture', 'Speech')\n",
      "('capture', 'Speech', 'recognition')\n",
      "('Speech', 'recognition', 'Speech')\n",
      "('recognition', 'Speech', 'segmentation')\n",
      "('Speech', 'segmentation', 'Speech')\n",
      "('segmentation', 'Speech', 'synthesis')\n",
      "('Speech', 'synthesis', 'Natural')\n",
      "('synthesis', 'Natural', 'language')\n",
      "('Natural', 'language', 'generation')\n",
      "('language', 'generation', 'Optical')\n",
      "('generation', 'Optical', 'character')\n",
      "('Optical', 'character', 'recognition')\n",
      "('character', 'recognition', 'Topic')\n",
      "('recognition', 'Topic', 'model')\n",
      "('Topic', 'model', 'Document')\n",
      "('model', 'Document', 'classification')\n",
      "('Document', 'classification', 'Latent')\n",
      "('classification', 'Latent', 'Dirichlet')\n",
      "('Latent', 'Dirichlet', 'allocation')\n",
      "('Dirichlet', 'allocation', 'Pachinko')\n",
      "('allocation', 'Pachinko', 'allocation')\n",
      "('Pachinko', 'allocation', 'Computer-assisted')\n",
      "('allocation', 'Computer-assisted', 'reviewing')\n",
      "('Computer-assisted', 'reviewing', 'Automated')\n",
      "('reviewing', 'Automated', 'essay')\n",
      "('Automated', 'essay', 'scoring')\n",
      "('essay', 'scoring', 'Concordancer')\n",
      "('scoring', 'Concordancer', 'Grammar')\n",
      "('Concordancer', 'Grammar', 'checker')\n",
      "('Grammar', 'checker', 'Predictive')\n",
      "('checker', 'Predictive', 'text')\n",
      "('Predictive', 'text', 'Spell')\n",
      "('text', 'Spell', 'checker')\n",
      "('Spell', 'checker', 'Syntax')\n",
      "('checker', 'Syntax', 'guessing')\n",
      "('Syntax', 'guessing', 'Natural')\n",
      "('guessing', 'Natural', 'language')\n",
      "('Natural', 'language', 'user')\n",
      "('language', 'user', 'interface')\n",
      "('user', 'interface', 'Chatbot')\n",
      "('interface', 'Chatbot', 'Interactive')\n",
      "('Chatbot', 'Interactive', 'fiction')\n",
      "('Interactive', 'fiction', 'Question')\n",
      "('fiction', 'Question', 'answering')\n",
      "('Question', 'answering', 'Virtual')\n",
      "('answering', 'Virtual', 'assistant')\n",
      "('Virtual', 'assistant', 'Voice')\n",
      "('assistant', 'Voice', 'user')\n",
      "('Voice', 'user', 'interface')\n",
      "('user', 'interface', 'Other')\n",
      "('interface', 'Other', 'software')\n",
      "('Other', 'software', 'Natural')\n",
      "('software', 'Natural', 'Language')\n",
      "('Natural', 'Language', 'Toolkit')\n",
      "('Language', 'Toolkit', 'spaCy')\n",
      "('Toolkit', 'spaCy', 'Authority')\n",
      "('spaCy', 'Authority', 'control:')\n",
      "('Authority', 'control:', 'National')\n",
      "('control:', 'National', 'libraries')\n",
      "('National', 'libraries', 'United')\n",
      "('libraries', 'United', 'States')\n",
      "('United', 'States', 'Japan')\n",
      "('States', 'Japan', 'Language')\n",
      "('Japan', 'Language', 'portal')\n",
      "('Language', 'portal', 'Retrieved')\n",
      "('portal', 'Retrieved', 'from')\n",
      "('Retrieved', 'from', '\"')\n",
      "('from', '\"', 'https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1048621730')\n",
      "('\"', 'https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1048621730', '\"')\n",
      "('https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1048621730', '\"', 'Categories')\n",
      "('\"', 'Categories', ':')\n",
      "('Categories', ':', 'Natural')\n",
      "(':', 'Natural', 'language')\n",
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', 'Computational')\n",
      "('processing', 'Computational', 'linguistics')\n",
      "('Computational', 'linguistics', 'Speech')\n",
      "('linguistics', 'Speech', 'recognition')\n",
      "('Speech', 'recognition', 'Computational')\n",
      "('recognition', 'Computational', 'fields')\n",
      "('Computational', 'fields', 'of')\n",
      "('fields', 'of', 'study')\n",
      "('of', 'study', 'Artificial')\n",
      "('study', 'Artificial', 'intelligence')\n",
      "('Artificial', 'intelligence', 'Hidden')\n",
      "('intelligence', 'Hidden', 'categories:')\n",
      "('Hidden', 'categories:', 'CS1')\n",
      "('categories:', 'CS1', 'maint:')\n",
      "('CS1', 'maint:', 'location')\n",
      "('maint:', 'location', 'Articles')\n",
      "('location', 'Articles', 'with')\n",
      "('Articles', 'with', 'short')\n",
      "('with', 'short', 'description')\n",
      "('short', 'description', 'Short')\n",
      "('description', 'Short', 'description')\n",
      "('Short', 'description', 'matches')\n",
      "('description', 'matches', 'Wikidata')\n",
      "('matches', 'Wikidata', 'Commons')\n",
      "('Wikidata', 'Commons', 'category')\n",
      "('Commons', 'category', 'link')\n",
      "('category', 'link', 'from')\n",
      "('link', 'from', 'Wikidata')\n",
      "('from', 'Wikidata', 'Articles')\n",
      "('Wikidata', 'Articles', 'with')\n",
      "('Articles', 'with', 'LCCN')\n",
      "('with', 'LCCN', 'identifiers')\n",
      "('LCCN', 'identifiers', 'Articles')\n",
      "('identifiers', 'Articles', 'with')\n",
      "('Articles', 'with', 'NDL')\n",
      "('with', 'NDL', 'identifiers')\n",
      "('NDL', 'identifiers', 'Navigation')\n",
      "('identifiers', 'Navigation', 'menu')\n",
      "('Navigation', 'menu', 'Personal')\n",
      "('menu', 'Personal', 'tools')\n",
      "('Personal', 'tools', 'Not')\n",
      "('tools', 'Not', 'logged')\n",
      "('Not', 'logged', 'in')\n",
      "('logged', 'in', 'Talk')\n",
      "('in', 'Talk', 'Contributions')\n",
      "('Talk', 'Contributions', 'Create')\n",
      "('Contributions', 'Create', 'account')\n",
      "('Create', 'account', 'Log')\n",
      "('account', 'Log', 'in')\n",
      "('Log', 'in', 'Namespaces')\n",
      "('in', 'Namespaces', 'Article')\n",
      "('Namespaces', 'Article', 'Talk')\n",
      "('Article', 'Talk', 'Variants')\n",
      "('Talk', 'Variants', 'expanded')\n",
      "('Variants', 'expanded', 'collapsed')\n",
      "('expanded', 'collapsed', 'Views')\n",
      "('collapsed', 'Views', 'Read')\n",
      "('Views', 'Read', 'Edit')\n",
      "('Read', 'Edit', 'View')\n",
      "('Edit', 'View', 'history')\n",
      "('View', 'history', 'More')\n",
      "('history', 'More', 'expanded')\n",
      "('More', 'expanded', 'collapsed')\n",
      "('expanded', 'collapsed', 'Search')\n",
      "('collapsed', 'Search', 'Navigation')\n",
      "('Search', 'Navigation', 'Main')\n",
      "('Navigation', 'Main', 'page')\n",
      "('Main', 'page', 'Contents')\n",
      "('page', 'Contents', 'Current')\n",
      "('Contents', 'Current', 'events')\n",
      "('Current', 'events', 'Random')\n",
      "('events', 'Random', 'article')\n",
      "('Random', 'article', 'About')\n",
      "('article', 'About', 'Wikipedia')\n",
      "('About', 'Wikipedia', 'Contact')\n",
      "('Wikipedia', 'Contact', 'us')\n",
      "('Contact', 'us', 'Donate')\n",
      "('us', 'Donate', 'Contribute')\n",
      "('Donate', 'Contribute', 'Help')\n",
      "('Contribute', 'Help', 'Learn')\n",
      "('Help', 'Learn', 'to')\n",
      "('Learn', 'to', 'edit')\n",
      "('to', 'edit', 'Community')\n",
      "('edit', 'Community', 'portal')\n",
      "('Community', 'portal', 'Recent')\n",
      "('portal', 'Recent', 'changes')\n",
      "('Recent', 'changes', 'Upload')\n",
      "('changes', 'Upload', 'file')\n",
      "('Upload', 'file', 'Tools')\n",
      "('file', 'Tools', 'What')\n",
      "('Tools', 'What', 'links')\n",
      "('What', 'links', 'here')\n",
      "('links', 'here', 'Related')\n",
      "('here', 'Related', 'changes')\n",
      "('Related', 'changes', 'Upload')\n",
      "('changes', 'Upload', 'file')\n",
      "('Upload', 'file', 'Special')\n",
      "('file', 'Special', 'pages')\n",
      "('Special', 'pages', 'Permanent')\n",
      "('pages', 'Permanent', 'link')\n",
      "('Permanent', 'link', 'Page')\n",
      "('link', 'Page', 'information')\n",
      "('Page', 'information', 'Cite')\n",
      "('information', 'Cite', 'this')\n",
      "('Cite', 'this', 'page')\n",
      "('this', 'page', 'Wikidata')\n",
      "('page', 'Wikidata', 'item')\n",
      "('Wikidata', 'item', 'Print/export')\n",
      "('item', 'Print/export', 'Download')\n",
      "('Print/export', 'Download', 'as')\n",
      "('Download', 'as', 'PDF')\n",
      "('as', 'PDF', 'Printable')\n",
      "('PDF', 'Printable', 'version')\n",
      "('Printable', 'version', 'In')\n",
      "('version', 'In', 'other')\n",
      "('In', 'other', 'projects')\n",
      "('other', 'projects', 'Wikimedia')\n",
      "('projects', 'Wikimedia', 'Commons')\n",
      "('Wikimedia', 'Commons', 'Languages')\n",
      "('Commons', 'Languages', 'Afrikaans')\n",
      "('Languages', 'Afrikaans', 'العربية')\n",
      "('Afrikaans', 'العربية', 'Azərbaycanca')\n",
      "('العربية', 'Azərbaycanca', 'বাংলা')\n",
      "('Azərbaycanca', 'বাংলা', 'Bân-lâm-gú')\n",
      "('বাংলা', 'Bân-lâm-gú', 'Беларуская')\n",
      "('Bân-lâm-gú', 'Беларуская', 'Беларуская')\n",
      "('Беларуская', 'Беларуская', '(тарашкевіца)')\n",
      "('Беларуская', '(тарашкевіца)', 'Български')\n",
      "('(тарашкевіца)', 'Български', 'Català')\n",
      "('Български', 'Català', 'Čeština')\n",
      "('Català', 'Čeština', 'Dansk')\n",
      "('Čeština', 'Dansk', 'Deutsch')\n",
      "('Dansk', 'Deutsch', 'Eesti')\n",
      "('Deutsch', 'Eesti', 'Ελληνικά')\n",
      "('Eesti', 'Ελληνικά', 'Español')\n",
      "('Ελληνικά', 'Español', 'Euskara')\n",
      "('Español', 'Euskara', 'فارسی')\n",
      "('Euskara', 'فارسی', 'Français')\n",
      "('فارسی', 'Français', 'Galego')\n",
      "('Français', 'Galego', '한국어')\n",
      "('Galego', '한국어', 'Հայերեն')\n",
      "('한국어', 'Հայերեն', 'हिन्दी')\n",
      "('Հայերեն', 'हिन्दी', 'Hrvatski')\n",
      "('हिन्दी', 'Hrvatski', 'Bahasa')\n",
      "('Hrvatski', 'Bahasa', 'Indonesia')\n",
      "('Bahasa', 'Indonesia', 'Íslenska')\n",
      "('Indonesia', 'Íslenska', 'Italiano')\n",
      "('Íslenska', 'Italiano', 'עברית')\n",
      "('Italiano', 'עברית', 'ಕನ್ನಡ')\n",
      "('עברית', 'ಕನ್ನಡ', 'ქართული')\n",
      "('ಕನ್ನಡ', 'ქართული', 'Lietuvių')\n",
      "('ქართული', 'Lietuvių', 'Македонски')\n",
      "('Lietuvių', 'Македонски', 'मराठी')\n",
      "('Македонски', 'मराठी', 'مصرى')\n",
      "('मराठी', 'مصرى', 'Монгол')\n",
      "('مصرى', 'Монгол', 'မြန်မာဘာသာ')\n",
      "('Монгол', 'မြန်မာဘာသာ', '日本語')\n",
      "('မြန်မာဘာသာ', '日本語', 'ଓଡ଼ିଆ')\n",
      "('日本語', 'ଓଡ଼ିଆ', 'Piemontèis')\n",
      "('ଓଡ଼ିଆ', 'Piemontèis', 'Polski')\n",
      "('Piemontèis', 'Polski', 'Português')\n",
      "('Polski', 'Português', 'Română')\n",
      "('Português', 'Română', 'Русский')\n",
      "('Română', 'Русский', 'Simple')\n",
      "('Русский', 'Simple', 'English')\n",
      "('Simple', 'English', 'کوردی')\n",
      "('English', 'کوردی', 'Српски')\n",
      "('کوردی', 'Српски', '/')\n",
      "('Српски', '/', 'srpski')\n",
      "('/', 'srpski', 'Srpskohrvatski')\n",
      "('srpski', 'Srpskohrvatski', '/')\n",
      "('Srpskohrvatski', '/', 'српскохрватски')\n",
      "('/', 'српскохрватски', 'Suomi')\n",
      "('српскохрватски', 'Suomi', 'தமிழ்')\n",
      "('Suomi', 'தமிழ்', 'ไทย')\n",
      "('தமிழ்', 'ไทย', 'Türkçe')\n",
      "('ไทย', 'Türkçe', 'Українська')\n",
      "('Türkçe', 'Українська', 'Tiếng')\n",
      "('Українська', 'Tiếng', 'Việt')\n",
      "('Tiếng', 'Việt', '粵語')\n",
      "('Việt', '粵語', '中文')\n",
      "('粵語', '中文', 'Edit')\n",
      "('中文', 'Edit', 'links')\n",
      "('Edit', 'links', 'This')\n",
      "('links', 'This', 'page')\n",
      "('This', 'page', 'was')\n",
      "('page', 'was', 'last')\n",
      "('was', 'last', 'edited')\n",
      "('last', 'edited', 'on')\n",
      "('edited', 'on', '7')\n",
      "('on', '7', 'October')\n",
      "('7', 'October', '2021,')\n",
      "('October', '2021,', 'at')\n",
      "('2021,', 'at', '01:56')\n",
      "('at', '01:56', '(UTC)')\n",
      "('01:56', '(UTC)', '.')\n",
      "('(UTC)', '.', 'Text')\n",
      "('.', 'Text', 'is')\n",
      "('Text', 'is', 'available')\n",
      "('is', 'available', 'under')\n",
      "('available', 'under', 'the')\n",
      "('under', 'the', 'Creative')\n",
      "('the', 'Creative', 'Commons')\n",
      "('Creative', 'Commons', 'Attribution-ShareAlike')\n",
      "('Commons', 'Attribution-ShareAlike', 'License')\n",
      "('Attribution-ShareAlike', 'License', ';')\n",
      "('License', ';', 'additional')\n",
      "(';', 'additional', 'terms')\n",
      "('additional', 'terms', 'may')\n",
      "('terms', 'may', 'apply.')\n",
      "('may', 'apply.', 'By')\n",
      "('apply.', 'By', 'using')\n",
      "('By', 'using', 'this')\n",
      "('using', 'this', 'site,')\n",
      "('this', 'site,', 'you')\n",
      "('site,', 'you', 'agree')\n",
      "('you', 'agree', 'to')\n",
      "('agree', 'to', 'the')\n",
      "('to', 'the', 'Terms')\n",
      "('the', 'Terms', 'of')\n",
      "('Terms', 'of', 'Use')\n",
      "('of', 'Use', 'and')\n",
      "('Use', 'and', 'Privacy')\n",
      "('and', 'Privacy', 'Policy')\n",
      "('Privacy', 'Policy', '.')\n",
      "('Policy', '.', 'Wikipedia®')\n",
      "('.', 'Wikipedia®', 'is')\n",
      "('Wikipedia®', 'is', 'a')\n",
      "('is', 'a', 'registered')\n",
      "('a', 'registered', 'trademark')\n",
      "('registered', 'trademark', 'of')\n",
      "('trademark', 'of', 'the')\n",
      "('of', 'the', 'Wikimedia')\n",
      "('the', 'Wikimedia', 'Foundation,')\n",
      "('Wikimedia', 'Foundation,', 'Inc.')\n",
      "('Foundation,', 'Inc.', ',')\n",
      "('Inc.', ',', 'a')\n",
      "(',', 'a', 'non-profit')\n",
      "('a', 'non-profit', 'organization.')\n",
      "('non-profit', 'organization.', 'Privacy')\n",
      "('organization.', 'Privacy', 'policy')\n",
      "('Privacy', 'policy', 'About')\n",
      "('policy', 'About', 'Wikipedia')\n",
      "('About', 'Wikipedia', 'Disclaimers')\n",
      "('Wikipedia', 'Disclaimers', 'Contact')\n",
      "('Disclaimers', 'Contact', 'Wikipedia')\n",
      "('Contact', 'Wikipedia', 'Mobile')\n",
      "('Wikipedia', 'Mobile', 'view')\n",
      "('Mobile', 'view', 'Developers')\n",
      "('view', 'Developers', 'Statistics')\n",
      "('Developers', 'Statistics', 'Cookie')\n",
      "('Statistics', 'Cookie', 'statement')\n"
     ]
    }
   ],
   "source": [
    "# called the get_trigram() function to create trigrams of the text.\n",
    "trigrams = get_trigram(text)\n",
    "for i in trigrams:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a74a8",
   "metadata": {},
   "source": [
    "# Plot the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5708847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "from nltk.probability import FreqDist\n",
    "# sent the words collection of the scrapped data and found the frequency distribution for each word.\n",
    "data = nltk.FreqDist(words)\n",
    "# converted the data into the dictionary\n",
    "filter_words = dict([(m, n) for m, n in data.items() if len(m)>3])\n",
    "\n",
    "data = nltk.FreqDist(filter_words)\n",
    "# plotted the word versus frequency graph\n",
    "data.plot(25, cumulative=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
