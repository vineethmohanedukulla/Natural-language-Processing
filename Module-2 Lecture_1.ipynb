{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_7 Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-nb_uzddVQJ"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d_OgVzfdjZa",
        "outputId": "f764f765-e581-45ea-946c-378a2b0b1b61"
      },
      "source": [
        "nltk.download('brown') \n",
        "nltk.download('punkt') \n",
        "nltk.download('tagset')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import brown"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Error loading tagset: Package 'tagset' not found in index\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SB0ZhBvJ9uj"
      },
      "source": [
        "sent = \"Hello my name is Ahmed\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQbAL11LgEP",
        "outputId": "89735479-f369-4a83-d2af-e62e92cbe62b"
      },
      "source": [
        "tagged_text = nltk.pos_tag(sent)\n",
        "print(tagged_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('H', 'NNP'), ('e', 'NN'), ('l', 'NN'), ('l', 'NN'), ('o', 'NN'), (' ', 'NNP'), ('m', 'NN'), ('y', 'NN'), (' ', 'NNP'), ('n', 'VBZ'), ('a', 'DT'), ('m', 'NN'), ('e', 'NN'), (' ', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'PDT'), ('A', 'DT'), ('h', 'NN'), ('m', 'NN'), ('e', 'NN'), ('d', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHrrPajgvJkQ"
      },
      "source": [
        "brown_learned_text = brown.words(categories='learned')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLMW91j8vJtN",
        "outputId": "ebe5b931-8d2c-4343-9830-584002218a78"
      },
      "source": [
        "# often = set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often')\n",
        "often = [b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often']\n",
        "print(type(often))\n",
        "print(often, '\\n')\n",
        "often_sorted = sorted(often)\n",
        "print(type(often_sorted))\n",
        "print(often_sorted)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['more', 'extremely', 'contain', 'differed', 'colorful', ',', 'appear', 'stated', 'found', 'involved', ',', 'composed', 'than', 'shortened', 'equate', 'supported', 'assuming', 'in', 'quite', 'out', 'revamped', 'chose', 'carefully', 'set', 'became', 'seclude', 'sounded', 'than', ',', 'than', 'sung', 'work', 'analytically', 'become', 'more', 'difficult', 'of', 'nightly', 'called', 'apt', 'happens', 'called', 'classified', 'represent', 'ignored', 'enough', 'been', 'needed', 'still', 'began', 'on', 'in', 'when', 'sing', '.', 'to', 'call', 'associated', 'stated', 'accomplished', 'responsible', 'observed', 'encountered', 'have'] \n",
            "\n",
            "<class 'list'>\n",
            "[',', ',', ',', '.', 'accomplished', 'analytically', 'appear', 'apt', 'associated', 'assuming', 'became', 'become', 'been', 'began', 'call', 'called', 'called', 'carefully', 'chose', 'classified', 'colorful', 'composed', 'contain', 'differed', 'difficult', 'encountered', 'enough', 'equate', 'extremely', 'found', 'happens', 'have', 'ignored', 'in', 'in', 'involved', 'more', 'more', 'needed', 'nightly', 'observed', 'of', 'on', 'out', 'quite', 'represent', 'responsible', 'revamped', 'seclude', 'set', 'shortened', 'sing', 'sounded', 'stated', 'stated', 'still', 'sung', 'supported', 'than', 'than', 'than', 'to', 'when', 'work']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKzPIXyv6J1",
        "outputId": "e7cf138e-e986-44e3-ca6d-e6d7e7730d74"
      },
      "source": [
        "nltk.download('universal_tagset')\n",
        "brown_learned_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
        "print(type(brown_learned_tagged))\n",
        "print(brown_learned_tagged)\n",
        "print(len(brown_learned_tagged))\n",
        "\n",
        "for i in range(5):\n",
        "  print(brown_learned_tagged[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n",
            "[('1', 'NUM'), ('.', '.'), ('Introduction', 'NOUN'), ...]\n",
            "181888\n",
            "('1', 'NUM')\n",
            "('.', '.')\n",
            "('Introduction', 'NOUN')\n",
            "('It', 'PRON')\n",
            "('has', 'VERB')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAM-kbZvvJx6",
        "outputId": "c5c2c717-2992-4ba5-ff12-9817ca398531"
      },
      "source": [
        "tags = [b[1] for (a, b) in nltk.bigrams(brown_learned_tagged) if a[0] == 'often']\n",
        "\n",
        "print(type(tags))\n",
        "print(tags)\n",
        "print(len(tags))\n",
        "print()\n",
        "\n",
        "fd = nltk.FreqDist(tags)\n",
        "fd.tabulate()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['ADJ', 'ADV', 'VERB', 'VERB', 'ADJ', '.', 'VERB', 'VERB', 'VERB', 'VERB', '.', 'VERB', 'ADP', 'VERB', 'VERB', 'VERB', 'VERB', 'ADP', 'ADV', 'PRT', 'VERB', 'VERB', 'ADV', 'VERB', 'VERB', 'VERB', 'VERB', 'ADP', '.', 'ADP', 'VERB', 'VERB', 'ADV', 'VERB', 'ADV', 'ADJ', 'ADP', 'ADV', 'VERB', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'ADV', 'VERB', 'VERB', 'ADJ', 'VERB', 'ADP', 'ADP', 'ADV', 'VERB', '.', 'PRT', 'VERB', 'VERB', 'VERB', 'VERB', 'ADJ', 'VERB', 'VERB', 'VERB']\n",
            "64\n",
            "\n",
            "VERB  ADV  ADP  ADJ    .  PRT \n",
            "  37    8    7    6    4    2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4AS0-FDpfdt"
      },
      "source": [
        "sent = \"Hello Students!. Good Moorning! Today we will learn natural language processing it is a our new topic\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vOthvXsAP6"
      },
      "source": [
        "# Sentence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXPltJt8pVM0",
        "outputId": "09651dd8-f898-438c-d4ce-6a5cf98e9a4a"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "s_tokens = sent_tokenize(sent)\n",
        "print(s_tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello Students!.', 'Good Moorning!', 'Today we will learn natural language processing it is a our new topic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcuBqpbesG2i"
      },
      "source": [
        "# Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrnvN6czqvTW",
        "outputId": "a0c445a7-c104-4845-b2a8-fe7109bd971f"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "w_tokens = word_tokenize(sent)\n",
        "print(w_tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Students', '!', '.', 'Good', 'Moorning', '!', 'Today', 'we', 'will', 'learn', 'natural', 'language', 'processing', 'it', 'is', 'a', 'our', 'new', 'topic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6AkBFKwdzVb",
        "outputId": "8ee62e90-fc7b-4832-d928-f51d1e2be124"
      },
      "source": [
        "for i in s_tokens:\n",
        "  print(i)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Students!.\n",
            "Good Moorning!\n",
            "Today we will learn natural language processing it is a our new topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMh7tvfNd_xi",
        "outputId": "def8b234-48ce-4ee6-cbc3-fbc4e004a6bb"
      },
      "source": [
        "for i in w_tokens:\n",
        "  print(i)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "Students\n",
            "!\n",
            ".\n",
            "Good\n",
            "Moorning\n",
            "!\n",
            "Today\n",
            "we\n",
            "will\n",
            "learn\n",
            "natural\n",
            "language\n",
            "processing\n",
            "it\n",
            "is\n",
            "a\n",
            "our\n",
            "new\n",
            "topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-dbkenttX24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40520e10-b748-484a-ee19-6fbc8e1a30ea"
      },
      "source": [
        "nltk.download('tagsets')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpeZCR9it3Xs",
        "outputId": "02dececd-7b36-4edc-d18c-708f304d25e7"
      },
      "source": [
        "nltk.help.upenn_tagset('CC')\n",
        "nltk.help.upenn_tagset('JJ')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpOho7U_kwJs",
        "outputId": "a9835cf2-cc5d-41a1-c33c-9957c119edda"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFJZShcdvNc"
      },
      "source": [
        "synsets = wn.synsets(\"phone\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfW-Pc9Zf9aJ",
        "outputId": "bd7150ae-79ff-4a86-ddf8-9a8344dbc1dc"
      },
      "source": [
        "print(type(synsets))\n",
        "print(type(synsets[0]))\n",
        "for i in synsets:\n",
        "  print(i)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'nltk.corpus.reader.wordnet.Synset'>\n",
            "Synset('telephone.n.01')\n",
            "Synset('phone.n.02')\n",
            "Synset('earphone.n.01')\n",
            "Synset('call.v.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9DGrYBGgjF0",
        "outputId": "5e056d76-30cf-45fe-e321-9a733b29decd"
      },
      "source": [
        "# print(type(synsets[0]))\n",
        "for syns in synsets:\n",
        "  print(syns.definition(),'\\n')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "electronic equipment that converts sound into electrical signals that can be transmitted over distances and then converts received signals back into sounds \n",
            "\n",
            "(phonetics) an individual sound unit of speech without concern as to whether or not it is a phoneme of some language \n",
            "\n",
            "electro-acoustic transducer for converting electric signals into sounds; it is held over or inserted into the ear \n",
            "\n",
            "get or try to get into communication (with someone) by telephone \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vAQ9tfUez6Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}